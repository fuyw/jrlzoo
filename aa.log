# Step 10000: eval_reward = 16.96
	alpha_loss: 0.35, alpha: 0.25, logp: 3.25
	actor_loss: -134.28, sampled_q: 135.08
	critic_loss: 6.87, q1: 134.72, q2: 134.73, target_q: 134.71
	cql1_loss: 13.12, cql2_loss: 13.33
	cql_q1: 135.47, cql_next_q1: 135.00, random_q1: 129.14
	cql_q2: 135.56, cql_next_q2: 135.07, random_q2: 129.14
	logp_next_action: 3.36, cql_logp: 3.12, cql_logp_next_action: 3.19

# Step 20000: eval_reward = 27.20
	alpha_loss: 0.09, alpha: 0.27, logp: 3.07
	actor_loss: -219.61, sampled_q: 220.45
	critic_loss: 12.06, q1: 219.95, q2: 220.25, target_q: 219.92
	cql1_loss: 13.72, cql2_loss: 15.45
	cql_q1: 220.83, cql_next_q1: 220.24, random_q1: 213.67
	cql_q2: 221.44, cql_next_q2: 220.91, random_q2: 213.67
	logp_next_action: 3.21, cql_logp: 3.07, cql_logp_next_action: 3.17

# Step 30000: eval_reward = 40.30
	alpha_loss: 0.13, alpha: 0.29, logp: 3.11
	actor_loss: -266.08, sampled_q: 266.97
	critic_loss: 17.36, q1: 266.13, q2: 266.26, target_q: 265.56
	cql1_loss: 17.09, cql2_loss: 17.14
	cql_q1: 267.79, cql_next_q1: 267.29, random_q1: 259.53
	cql_q2: 267.93, cql_next_q2: 267.49, random_q2: 259.53
	logp_next_action: 3.33, cql_logp: 3.06, cql_logp_next_action: 3.08

# Step 40000: eval_reward = 44.33
	alpha_loss: -0.06, alpha: 0.30, logp: 2.95
	actor_loss: -296.81, sampled_q: 297.70
	critic_loss: 12.62, q1: 297.26, q2: 297.29, target_q: 297.05
	cql1_loss: 15.61, cql2_loss: 14.67
	cql_q1: 298.61, cql_next_q1: 297.99, random_q1: 290.09
	cql_q2: 298.53, cql_next_q2: 297.82, random_q2: 290.09
	logp_next_action: 2.76, cql_logp: 2.94, cql_logp_next_action: 2.87

# Step 50000: eval_reward = 111.21
	alpha_loss: 0.11, alpha: 0.30, logp: 3.09
	actor_loss: -309.94, sampled_q: 310.87
	critic_loss: 11.29, q1: 310.18, q2: 310.32, target_q: 310.46
	cql1_loss: 14.86, cql2_loss: 15.46
	cql_q1: 311.55, cql_next_q1: 310.82, random_q1: 302.93
	cql_q2: 311.88, cql_next_q2: 311.10, random_q2: 302.93
	logp_next_action: 3.07, cql_logp: 3.14, cql_logp_next_action: 3.01

# Step 60000: eval_reward = 109.91
	alpha_loss: -0.24, alpha: 0.31, logp: 2.80
	actor_loss: -334.23, sampled_q: 335.10
	critic_loss: 14.55, q1: 335.31, q2: 334.43, target_q: 334.89
	cql1_loss: 15.30, cql2_loss: 15.83
	cql_q1: 336.33, cql_next_q1: 335.72, random_q1: 328.47
	cql_q2: 335.58, cql_next_q2: 334.97, random_q2: 328.47
	logp_next_action: 2.41, cql_logp: 2.67, cql_logp_next_action: 2.53

# Step 70000: eval_reward = 37.68
	alpha_loss: 0.12, alpha: 0.32, logp: 3.11
	actor_loss: -338.06, sampled_q: 339.04
	critic_loss: 17.41, q1: 339.26, q2: 338.59, target_q: 338.76
	cql1_loss: 12.41, cql2_loss: 12.27
	cql_q1: 340.23, cql_next_q1: 339.54, random_q1: 330.86
	cql_q2: 339.62, cql_next_q2: 338.96, random_q2: 330.86
	logp_next_action: 3.24, cql_logp: 3.18, cql_logp_next_action: 3.12

# Step 80000: eval_reward = 53.59
	alpha_loss: 0.16, alpha: 0.32, logp: 3.14
	actor_loss: -325.90, sampled_q: 326.89
	critic_loss: 17.06, q1: 326.79, q2: 326.00, target_q: 326.13
	cql1_loss: 16.61, cql2_loss: 17.15
	cql_q1: 328.41, cql_next_q1: 327.19, random_q1: 319.13
	cql_q2: 327.66, cql_next_q2: 326.45, random_q2: 319.13
	logp_next_action: 2.83, cql_logp: 3.06, cql_logp_next_action: 2.88

# Step 90000: eval_reward = 101.84
	alpha_loss: -0.04, alpha: 0.33, logp: 2.97
	actor_loss: -346.61, sampled_q: 347.60
	critic_loss: 14.13, q1: 346.71, q2: 348.33, target_q: 347.15
	cql1_loss: 14.12, cql2_loss: 14.35
	cql_q1: 347.96, cql_next_q1: 347.36, random_q1: 338.81
	cql_q2: 349.64, cql_next_q2: 349.00, random_q2: 338.81
	logp_next_action: 2.84, cql_logp: 2.92, cql_logp_next_action: 2.82

# Step 100000: eval_reward = 70.18
	alpha_loss: 0.09, alpha: 0.34, logp: 3.08
	actor_loss: -326.01, sampled_q: 327.04
	critic_loss: 24.44, q1: 326.37, q2: 326.87, target_q: 325.21
	cql1_loss: 15.40, cql2_loss: 15.45
	cql_q1: 327.81, cql_next_q1: 327.11, random_q1: 318.90
	cql_q2: 328.33, cql_next_q2: 327.67, random_q2: 318.90
	logp_next_action: 2.74, cql_logp: 2.91, cql_logp_next_action: 2.89

# Step 110000: eval_reward = 54.05
	alpha_loss: -0.18, alpha: 0.33, logp: 2.84
	actor_loss: -336.82, sampled_q: 337.76
	critic_loss: 14.91, q1: 337.69, q2: 337.53, target_q: 337.54
	cql1_loss: 15.71, cql2_loss: 14.49
	cql_q1: 338.96, cql_next_q1: 338.28, random_q1: 330.58
	cql_q2: 338.67, cql_next_q2: 337.97, random_q2: 330.58
	logp_next_action: 2.95, cql_logp: 2.90, cql_logp_next_action: 2.91

# Step 120000: eval_reward = 57.05
	alpha_loss: 0.11, alpha: 0.34, logp: 3.10
	actor_loss: -331.37, sampled_q: 332.42
	critic_loss: 16.60, q1: 332.51, q2: 331.39, target_q: 333.13
	cql1_loss: 16.24, cql2_loss: 16.18
	cql_q1: 333.91, cql_next_q1: 333.30, random_q1: 325.67
	cql_q2: 332.90, cql_next_q2: 332.23, random_q2: 325.67
	logp_next_action: 3.11, cql_logp: 3.05, cql_logp_next_action: 2.99

# Step 130000: eval_reward = 81.02
	alpha_loss: -0.06, alpha: 0.35, logp: 2.94
	actor_loss: -340.14, sampled_q: 341.16
	critic_loss: 16.71, q1: 340.32, q2: 340.93, target_q: 340.36
	cql1_loss: 15.95, cql2_loss: 16.35
	cql_q1: 341.76, cql_next_q1: 341.11, random_q1: 332.57
	cql_q2: 342.51, cql_next_q2: 341.79, random_q2: 332.57
	logp_next_action: 2.80, cql_logp: 2.97, cql_logp_next_action: 3.04

# Step 140000: eval_reward = 101.68
	alpha_loss: -0.12, alpha: 0.35, logp: 2.89
	actor_loss: -325.48, sampled_q: 326.49
	critic_loss: 31.96, q1: 326.25, q2: 325.91, target_q: 326.71
	cql1_loss: 13.56, cql2_loss: 14.85
	cql_q1: 327.41, cql_next_q1: 326.56, random_q1: 318.01
	cql_q2: 327.30, cql_next_q2: 326.40, random_q2: 318.01
	logp_next_action: 2.88, cql_logp: 2.97, cql_logp_next_action: 2.97

# Step 150000: eval_reward = 99.96
	alpha_loss: -0.40, alpha: 0.36, logp: 2.61
	actor_loss: -337.97, sampled_q: 338.90
	critic_loss: 72.56, q1: 338.64, q2: 337.62, target_q: 338.99
	cql1_loss: 17.84, cql2_loss: 18.74
	cql_q1: 340.44, cql_next_q1: 339.70, random_q1: 331.16
	cql_q2: 339.59, cql_next_q2: 338.86, random_q2: 331.16
	logp_next_action: 2.93, cql_logp: 2.67, cql_logp_next_action: 2.88

# Step 160000: eval_reward = 99.79
	alpha_loss: -0.24, alpha: 0.37, logp: 2.76
	actor_loss: -337.09, sampled_q: 338.10
	critic_loss: 30.90, q1: 337.17, q2: 337.12, target_q: 337.22
	cql1_loss: 19.41, cql2_loss: 19.46
	cql_q1: 339.39, cql_next_q1: 338.65, random_q1: 329.22
	cql_q2: 339.41, cql_next_q2: 338.68, random_q2: 329.22
	logp_next_action: 2.87, cql_logp: 3.02, cql_logp_next_action: 3.04

# Step 170000: eval_reward = 49.05
	alpha_loss: 0.15, alpha: 0.37, logp: 3.15
	actor_loss: -341.54, sampled_q: 342.70
	critic_loss: 24.63, q1: 342.56, q2: 342.92, target_q: 340.71
	cql1_loss: 13.16, cql2_loss: 12.80
	cql_q1: 343.52, cql_next_q1: 342.94, random_q1: 335.38
	cql_q2: 343.76, cql_next_q2: 343.17, random_q2: 335.38
	logp_next_action: 3.02, cql_logp: 3.01, cql_logp_next_action: 3.05

# Step 180000: eval_reward = 81.06
	alpha_loss: 0.44, alpha: 0.37, logp: 3.44
	actor_loss: -348.26, sampled_q: 349.53
	critic_loss: 14.22, q1: 349.00, q2: 347.88, target_q: 348.33
	cql1_loss: 16.21, cql2_loss: 17.31
	cql_q1: 351.14, cql_next_q1: 350.49, random_q1: 340.10
	cql_q2: 350.09, cql_next_q2: 349.35, random_q2: 340.10
	logp_next_action: 3.29, cql_logp: 3.35, cql_logp_next_action: 3.32

# Step 190000: eval_reward = 87.23
	alpha_loss: 0.21, alpha: 0.37, logp: 3.21
	actor_loss: -335.63, sampled_q: 336.83
	critic_loss: 15.55, q1: 335.71, q2: 335.44, target_q: 335.14
	cql1_loss: 17.44, cql2_loss: 17.58
	cql_q1: 337.87, cql_next_q1: 337.02, random_q1: 327.57
	cql_q2: 337.58, cql_next_q2: 336.60, random_q2: 327.57
	logp_next_action: 3.04, cql_logp: 3.15, cql_logp_next_action: 3.17

# Step 200000: eval_reward = 99.63
	alpha_loss: 0.03, alpha: 0.37, logp: 3.03
	actor_loss: -334.57, sampled_q: 335.70
	critic_loss: 19.94, q1: 335.45, q2: 335.22, target_q: 336.23
	cql1_loss: 14.80, cql2_loss: 16.21
	cql_q1: 336.80, cql_next_q1: 336.17, random_q1: 327.31
	cql_q2: 336.85, cql_next_q2: 336.27, random_q2: 327.31
	logp_next_action: 3.20, cql_logp: 3.22, cql_logp_next_action: 3.09

# Step 210000: eval_reward = 107.90
	alpha_loss: 0.10, alpha: 0.39, logp: 3.10
	actor_loss: -342.17, sampled_q: 343.38
	critic_loss: 16.63, q1: 341.95, q2: 342.52, target_q: 341.40
	cql1_loss: 15.99, cql2_loss: 16.57
	cql_q1: 343.94, cql_next_q1: 343.04, random_q1: 333.00
	cql_q2: 344.55, cql_next_q2: 343.63, random_q2: 333.00
	logp_next_action: 3.09, cql_logp: 3.22, cql_logp_next_action: 3.13

# Step 220000: eval_reward = 75.81
	alpha_loss: 0.11, alpha: 0.39, logp: 3.11
	actor_loss: -341.96, sampled_q: 343.17
	critic_loss: 14.51, q1: 342.88, q2: 342.36, target_q: 341.88
	cql1_loss: 16.48, cql2_loss: 16.60
	cql_q1: 344.41, cql_next_q1: 343.62, random_q1: 334.94
	cql_q2: 343.74, cql_next_q2: 342.93, random_q2: 334.94
	logp_next_action: 3.03, cql_logp: 2.85, cql_logp_next_action: 2.77

# Step 230000: eval_reward = 93.62
	alpha_loss: -0.14, alpha: 0.40, logp: 2.85
	actor_loss: -338.18, sampled_q: 339.31
	critic_loss: 18.19, q1: 339.35, q2: 339.28, target_q: 339.23
	cql1_loss: 13.13, cql2_loss: 13.95
	cql_q1: 340.42, cql_next_q1: 339.65, random_q1: 330.64
	cql_q2: 340.39, cql_next_q2: 339.71, random_q2: 330.64
	logp_next_action: 2.62, cql_logp: 2.86, cql_logp_next_action: 2.80

# Step 240000: eval_reward = 107.04
	alpha_loss: -0.03, alpha: 0.39, logp: 2.96
	actor_loss: -331.78, sampled_q: 332.93
	critic_loss: 22.63, q1: 332.79, q2: 332.44, target_q: 333.13
	cql1_loss: 16.11, cql2_loss: 15.31
	cql_q1: 334.31, cql_next_q1: 333.53, random_q1: 324.53
	cql_q2: 333.74, cql_next_q2: 333.07, random_q2: 324.53
	logp_next_action: 3.17, cql_logp: 3.03, cql_logp_next_action: 2.96

# Step 250000: eval_reward = 43.43
	alpha_loss: 0.09, alpha: 0.40, logp: 3.10
	actor_loss: -338.40, sampled_q: 339.65
	critic_loss: 31.08, q1: 339.71, q2: 338.92, target_q: 339.72
	cql1_loss: 14.98, cql2_loss: 15.75
	cql_q1: 341.04, cql_next_q1: 340.40, random_q1: 332.45
	cql_q2: 340.39, cql_next_q2: 339.75, random_q2: 332.45
	logp_next_action: 2.98, cql_logp: 3.16, cql_logp_next_action: 2.96

# Step 260000: eval_reward = 57.88
	alpha_loss: -0.14, alpha: 0.41, logp: 2.84
	actor_loss: -344.10, sampled_q: 345.25
	critic_loss: 25.59, q1: 344.03, q2: 344.69, target_q: 344.45
	cql1_loss: 17.42, cql2_loss: 17.62
	cql_q1: 345.89, cql_next_q1: 344.76, random_q1: 335.66
	cql_q2: 346.57, cql_next_q2: 345.51, random_q2: 335.66
	logp_next_action: 2.98, cql_logp: 2.80, cql_logp_next_action: 2.92

# Step 270000: eval_reward = 108.37
	alpha_loss: 0.05, alpha: 0.41, logp: 3.06
	actor_loss: -341.61, sampled_q: 342.87
	critic_loss: 18.40, q1: 342.72, q2: 342.23, target_q: 342.28
	cql1_loss: 13.38, cql2_loss: 14.08
	cql_q1: 343.93, cql_next_q1: 343.30, random_q1: 334.01
	cql_q2: 343.47, cql_next_q2: 342.79, random_q2: 334.01
	logp_next_action: 2.71, cql_logp: 3.00, cql_logp_next_action: 2.88

# Step 280000: eval_reward = 82.75
	alpha_loss: 0.06, alpha: 0.41, logp: 3.07
	actor_loss: -337.63, sampled_q: 338.89
	critic_loss: 33.50, q1: 338.75, q2: 338.36, target_q: 338.25
	cql1_loss: 16.10, cql2_loss: 15.68
	cql_q1: 340.08, cql_next_q1: 338.97, random_q1: 329.56
	cql_q2: 339.65, cql_next_q2: 338.58, random_q2: 329.56
	logp_next_action: 2.83, cql_logp: 2.88, cql_logp_next_action: 2.84

# Step 290000: eval_reward = 104.96
	alpha_loss: -0.13, alpha: 0.42, logp: 2.85
	actor_loss: -339.75, sampled_q: 340.96
	critic_loss: 17.03, q1: 340.42, q2: 341.16, target_q: 341.92
	cql1_loss: 13.77, cql2_loss: 13.81
	cql_q1: 341.68, cql_next_q1: 340.78, random_q1: 330.77
	cql_q2: 342.59, cql_next_q2: 341.60, random_q2: 330.77
	logp_next_action: 3.43, cql_logp: 3.26, cql_logp_next_action: 3.15

# Step 300000: eval_reward = 70.58
	alpha_loss: 0.27, alpha: 0.43, logp: 3.32
	actor_loss: -340.81, sampled_q: 342.22
	critic_loss: 20.43, q1: 341.63, q2: 341.62, target_q: 341.71
	cql1_loss: 14.67, cql2_loss: 14.75
	cql_q1: 343.15, cql_next_q1: 342.30, random_q1: 331.44
	cql_q2: 343.18, cql_next_q2: 342.46, random_q2: 331.44
	logp_next_action: 3.15, cql_logp: 3.43, cql_logp_next_action: 3.47

# Step 310000: eval_reward = 101.23
	alpha_loss: 0.03, alpha: 0.43, logp: 3.04
	actor_loss: -333.12, sampled_q: 334.42
	critic_loss: 19.07, q1: 333.86, q2: 334.55, target_q: 334.21
	cql1_loss: 14.09, cql2_loss: 13.54
	cql_q1: 335.08, cql_next_q1: 333.90, random_q1: 324.90
	cql_q2: 335.89, cql_next_q2: 334.82, random_q2: 324.90
	logp_next_action: 3.15, cql_logp: 3.12, cql_logp_next_action: 3.04

# Step 320000: eval_reward = 102.47
	alpha_loss: 0.12, alpha: 0.43, logp: 3.14
	actor_loss: -345.87, sampled_q: 347.21
	critic_loss: 12.95, q1: 346.89, q2: 346.49, target_q: 346.39
	cql1_loss: 14.02, cql2_loss: 14.50
	cql_q1: 348.19, cql_next_q1: 347.57, random_q1: 338.21
	cql_q2: 347.85, cql_next_q2: 347.16, random_q2: 338.21
	logp_next_action: 3.23, cql_logp: 3.12, cql_logp_next_action: 3.09

# Step 330000: eval_reward = 93.62
	alpha_loss: 0.33, alpha: 0.43, logp: 3.39
	actor_loss: -327.76, sampled_q: 329.23
	critic_loss: 24.32, q1: 328.83, q2: 329.34, target_q: 328.73
	cql1_loss: 12.51, cql2_loss: 12.84
	cql_q1: 329.95, cql_next_q1: 329.01, random_q1: 318.93
	cql_q2: 330.67, cql_next_q2: 329.66, random_q2: 318.93
	logp_next_action: 3.11, cql_logp: 3.32, cql_logp_next_action: 3.28

# Step 340000: eval_reward = 88.21
	alpha_loss: -0.10, alpha: 0.43, logp: 2.88
	actor_loss: -330.23, sampled_q: 331.48
	critic_loss: 14.50, q1: 331.20, q2: 331.63, target_q: 330.87
	cql1_loss: 12.26, cql2_loss: 13.34
	cql_q1: 332.12, cql_next_q1: 331.24, random_q1: 322.51
	cql_q2: 332.79, cql_next_q2: 331.95, random_q2: 322.51
	logp_next_action: 3.06, cql_logp: 2.90, cql_logp_next_action: 2.80

# Step 350000: eval_reward = 81.67
	alpha_loss: -0.11, alpha: 0.44, logp: 2.87
	actor_loss: -331.04, sampled_q: 332.29
	critic_loss: 12.32, q1: 332.17, q2: 331.78, target_q: 332.26
	cql1_loss: 15.03, cql2_loss: 15.88
	cql_q1: 333.57, cql_next_q1: 332.72, random_q1: 323.16
	cql_q2: 333.20, cql_next_q2: 332.23, random_q2: 323.16
	logp_next_action: 3.00, cql_logp: 2.81, cql_logp_next_action: 2.85

# Step 360000: eval_reward = 108.30
	alpha_loss: -0.01, alpha: 0.44, logp: 2.98
	actor_loss: -332.52, sampled_q: 333.84
	critic_loss: 16.39, q1: 333.77, q2: 334.15, target_q: 334.89
	cql1_loss: 12.34, cql2_loss: 13.62
	cql_q1: 334.62, cql_next_q1: 333.95, random_q1: 324.58
	cql_q2: 335.35, cql_next_q2: 334.55, random_q2: 324.58
	logp_next_action: 2.81, cql_logp: 3.18, cql_logp_next_action: 3.05

# Step 370000: eval_reward = 71.45
	alpha_loss: 0.20, alpha: 0.45, logp: 3.25
	actor_loss: -330.82, sampled_q: 332.28
	critic_loss: 17.92, q1: 332.55, q2: 331.55, target_q: 331.87
	cql1_loss: 11.97, cql2_loss: 13.40
	cql_q1: 333.74, cql_next_q1: 332.60, random_q1: 321.55
	cql_q2: 332.87, cql_next_q2: 331.89, random_q2: 321.55
	logp_next_action: 3.06, cql_logp: 3.14, cql_logp_next_action: 2.99

# Step 380000: eval_reward = 107.70
	alpha_loss: -0.26, alpha: 0.44, logp: 2.68
	actor_loss: -331.10, sampled_q: 332.29
	critic_loss: 17.67, q1: 331.19, q2: 331.01, target_q: 332.12
	cql1_loss: 19.13, cql2_loss: 20.11
	cql_q1: 333.25, cql_next_q1: 332.04, random_q1: 322.60
	cql_q2: 333.28, cql_next_q2: 331.93, random_q2: 322.60
	logp_next_action: 2.98, cql_logp: 2.84, cql_logp_next_action: 2.96

# Step 390000: eval_reward = 108.21
	alpha_loss: -0.14, alpha: 0.45, logp: 2.83
	actor_loss: -332.61, sampled_q: 333.87
	critic_loss: 18.66, q1: 333.44, q2: 333.06, target_q: 332.52
	cql1_loss: 15.00, cql2_loss: 15.56
	cql_q1: 335.05, cql_next_q1: 334.41, random_q1: 324.64
	cql_q2: 334.75, cql_next_q2: 334.19, random_q2: 324.64
	logp_next_action: 2.90, cql_logp: 2.98, cql_logp_next_action: 3.03

# Step 400000: eval_reward = 51.87
	alpha_loss: -0.02, alpha: 0.46, logp: 2.98
	actor_loss: -319.80, sampled_q: 321.16
	critic_loss: 25.75, q1: 320.73, q2: 320.88, target_q: 321.27
	cql1_loss: 16.06, cql2_loss: 16.40
	cql_q1: 322.13, cql_next_q1: 321.31, random_q1: 312.31
	cql_q2: 322.28, cql_next_q2: 321.49, random_q2: 312.31
	logp_next_action: 2.95, cql_logp: 2.94, cql_logp_next_action: 2.93

# Step 410000: eval_reward = 99.68
	alpha_loss: 0.06, alpha: 0.46, logp: 3.08
	actor_loss: -326.47, sampled_q: 327.88
	critic_loss: 29.74, q1: 326.99, q2: 328.00, target_q: 327.78
	cql1_loss: 15.32, cql2_loss: 15.78
	cql_q1: 328.49, cql_next_q1: 327.85, random_q1: 318.23
	cql_q2: 329.54, cql_next_q2: 328.85, random_q2: 318.23
	logp_next_action: 3.26, cql_logp: 3.08, cql_logp_next_action: 3.12

# Step 420000: eval_reward = 106.71
	alpha_loss: 0.04, alpha: 0.46, logp: 3.05
	actor_loss: -316.65, sampled_q: 318.04
	critic_loss: 27.28, q1: 316.85, q2: 316.89, target_q: 316.93
	cql1_loss: 19.34, cql2_loss: 19.54
	cql_q1: 319.01, cql_next_q1: 318.09, random_q1: 308.73
	cql_q2: 319.20, cql_next_q2: 318.27, random_q2: 308.73
	logp_next_action: 2.69, cql_logp: 3.02, cql_logp_next_action: 2.86

# Step 430000: eval_reward = 107.95
	alpha_loss: -0.08, alpha: 0.46, logp: 2.90
	actor_loss: -326.45, sampled_q: 327.79
	critic_loss: 16.22, q1: 327.01, q2: 326.87, target_q: 327.59
	cql1_loss: 18.18, cql2_loss: 18.42
	cql_q1: 329.11, cql_next_q1: 328.12, random_q1: 317.42
	cql_q2: 328.95, cql_next_q2: 328.09, random_q2: 317.42
	logp_next_action: 3.30, cql_logp: 3.06, cql_logp_next_action: 2.99

# Step 440000: eval_reward = 109.38
	alpha_loss: -0.07, alpha: 0.47, logp: 2.91
	actor_loss: -328.60, sampled_q: 329.95
	critic_loss: 24.88, q1: 328.68, q2: 329.81, target_q: 328.14
	cql1_loss: 18.14, cql2_loss: 17.37
	cql_q1: 330.59, cql_next_q1: 329.67, random_q1: 319.68
	cql_q2: 331.71, cql_next_q2: 331.02, random_q2: 319.68
	logp_next_action: 2.90, cql_logp: 2.88, cql_logp_next_action: 2.94

# Step 450000: eval_reward = 93.45
	alpha_loss: -0.07, alpha: 0.47, logp: 2.91
	actor_loss: -328.21, sampled_q: 329.57
	critic_loss: 58.60, q1: 329.48, q2: 329.69, target_q: 328.83
	cql1_loss: 12.31, cql2_loss: 13.38
	cql_q1: 330.38, cql_next_q1: 329.76, random_q1: 319.79
	cql_q2: 330.93, cql_next_q2: 330.31, random_q2: 319.79
	logp_next_action: 3.04, cql_logp: 3.03, cql_logp_next_action: 3.16

# Step 460000: eval_reward = 106.90
	alpha_loss: 0.06, alpha: 0.47, logp: 3.08
	actor_loss: -326.02, sampled_q: 327.47
	critic_loss: 20.55, q1: 327.89, q2: 327.26, target_q: 327.51
	cql1_loss: 12.01, cql2_loss: 12.50
	cql_q1: 328.72, cql_next_q1: 327.99, random_q1: 318.45
	cql_q2: 328.04, cql_next_q2: 327.25, random_q2: 318.45
	logp_next_action: 2.81, cql_logp: 2.92, cql_logp_next_action: 2.92

# Step 470000: eval_reward = 105.93
	alpha_loss: -0.01, alpha: 0.46, logp: 2.99
	actor_loss: -317.80, sampled_q: 319.19
	critic_loss: 15.10, q1: 318.31, q2: 317.95, target_q: 318.78
	cql1_loss: 18.06, cql2_loss: 17.54
	cql_q1: 320.45, cql_next_q1: 319.74, random_q1: 309.09
	cql_q2: 320.05, cql_next_q2: 319.34, random_q2: 309.09
	logp_next_action: 3.31, cql_logp: 3.15, cql_logp_next_action: 3.21

# Step 480000: eval_reward = 99.12
	alpha_loss: 0.07, alpha: 0.47, logp: 3.10
	actor_loss: -318.11, sampled_q: 319.57
	critic_loss: 16.94, q1: 319.52, q2: 319.23, target_q: 319.79
	cql1_loss: 13.79, cql2_loss: 14.01
	cql_q1: 320.56, cql_next_q1: 319.44, random_q1: 310.33
	cql_q2: 320.43, cql_next_q2: 319.14, random_q2: 310.33
	logp_next_action: 3.21, cql_logp: 3.03, cql_logp_next_action: 3.04

# Step 490000: eval_reward = 84.49
	alpha_loss: 0.02, alpha: 0.48, logp: 3.03
	actor_loss: -325.42, sampled_q: 326.86
	critic_loss: 12.86, q1: 326.63, q2: 326.41, target_q: 325.90
	cql1_loss: 12.29, cql2_loss: 13.48
	cql_q1: 327.60, cql_next_q1: 326.53, random_q1: 317.78
	cql_q2: 327.59, cql_next_q2: 326.62, random_q2: 317.78
	logp_next_action: 2.78, cql_logp: 2.98, cql_logp_next_action: 2.88

# Step 500000: eval_reward = 107.66
	alpha_loss: 0.06, alpha: 0.48, logp: 3.08
	actor_loss: -319.65, sampled_q: 321.13
	critic_loss: 18.02, q1: 320.79, q2: 320.61, target_q: 321.28
	cql1_loss: 14.02, cql2_loss: 15.29
	cql_q1: 322.07, cql_next_q1: 320.66, random_q1: 311.27
	cql_q2: 322.36, cql_next_q2: 320.61, random_q2: 311.27
	logp_next_action: 2.99, cql_logp: 3.07, cql_logp_next_action: 2.88

# Step 510000: eval_reward = 107.63
	alpha_loss: -0.05, alpha: 0.48, logp: 2.93
	actor_loss: -325.30, sampled_q: 326.71
	critic_loss: 19.01, q1: 326.01, q2: 326.07, target_q: 326.32
	cql1_loss: 15.42, cql2_loss: 15.48
	cql_q1: 327.50, cql_next_q1: 326.56, random_q1: 317.01
	cql_q2: 327.61, cql_next_q2: 326.59, random_q2: 317.01
	logp_next_action: 2.73, cql_logp: 2.86, cql_logp_next_action: 2.86

# Step 520000: eval_reward = 107.98
	alpha_loss: 0.01, alpha: 0.48, logp: 3.02
	actor_loss: -324.92, sampled_q: 326.38
	critic_loss: 16.05, q1: 325.87, q2: 325.95, target_q: 326.03
	cql1_loss: 14.93, cql2_loss: 15.31
	cql_q1: 327.19, cql_next_q1: 326.32, random_q1: 317.09
	cql_q2: 327.45, cql_next_q2: 326.58, random_q2: 317.09
	logp_next_action: 2.71, cql_logp: 2.80, cql_logp_next_action: 2.72

# Step 530000: eval_reward = 106.37
	alpha_loss: -0.05, alpha: 0.48, logp: 2.93
	actor_loss: -319.91, sampled_q: 321.31
	critic_loss: 38.42, q1: 320.44, q2: 319.68, target_q: 319.77
	cql1_loss: 19.61, cql2_loss: 20.61
	cql_q1: 322.57, cql_next_q1: 321.79, random_q1: 311.90
	cql_q2: 322.09, cql_next_q2: 321.37, random_q2: 311.90
	logp_next_action: 3.13, cql_logp: 2.99, cql_logp_next_action: 3.12

# Step 540000: eval_reward = 107.60
	alpha_loss: 0.03, alpha: 0.48, logp: 3.04
	actor_loss: -330.63, sampled_q: 332.10
	critic_loss: 18.98, q1: 331.26, q2: 331.26, target_q: 331.25
	cql1_loss: 16.27, cql2_loss: 17.07
	cql_q1: 333.03, cql_next_q1: 332.23, random_q1: 322.69
	cql_q2: 333.31, cql_next_q2: 332.43, random_q2: 322.69
	logp_next_action: 3.19, cql_logp: 3.17, cql_logp_next_action: 3.13

# Step 550000: eval_reward = 94.30
	alpha_loss: 0.08, alpha: 0.48, logp: 3.10
	actor_loss: -317.30, sampled_q: 318.78
	critic_loss: 24.71, q1: 318.56, q2: 318.45, target_q: 318.58
	cql1_loss: 14.13, cql2_loss: 14.22
	cql_q1: 319.79, cql_next_q1: 318.57, random_q1: 308.66
	cql_q2: 319.65, cql_next_q2: 318.64, random_q2: 308.66
	logp_next_action: 2.76, cql_logp: 2.94, cql_logp_next_action: 2.73

# Step 560000: eval_reward = 108.55
	alpha_loss: 0.19, alpha: 0.49, logp: 3.26
	actor_loss: -317.89, sampled_q: 319.48
	critic_loss: 12.52, q1: 319.47, q2: 319.48, target_q: 319.46
	cql1_loss: 10.19, cql2_loss: 10.85
	cql_q1: 320.20, cql_next_q1: 319.47, random_q1: 308.60
	cql_q2: 320.47, cql_next_q2: 319.74, random_q2: 308.60
	logp_next_action: 3.03, cql_logp: 3.07, cql_logp_next_action: 3.15

# Step 570000: eval_reward = 106.21
	alpha_loss: 0.06, alpha: 0.49, logp: 3.08
	actor_loss: -325.37, sampled_q: 326.88
	critic_loss: 26.17, q1: 326.83, q2: 326.89, target_q: 327.15
	cql1_loss: 12.57, cql2_loss: 12.83
	cql_q1: 327.90, cql_next_q1: 326.91, random_q1: 317.53
	cql_q2: 328.09, cql_next_q2: 327.11, random_q2: 317.53
	logp_next_action: 2.83, cql_logp: 3.02, cql_logp_next_action: 2.85

# Step 580000: eval_reward = 104.21
	alpha_loss: 0.09, alpha: 0.49, logp: 3.12
	actor_loss: -330.81, sampled_q: 332.35
	critic_loss: 12.39, q1: 332.20, q2: 332.53, target_q: 331.99
	cql1_loss: 11.19, cql2_loss: 11.88
	cql_q1: 332.94, cql_next_q1: 332.12, random_q1: 322.48
	cql_q2: 333.50, cql_next_q2: 332.50, random_q2: 322.48
	logp_next_action: 3.02, cql_logp: 3.02, cql_logp_next_action: 3.01

# Step 590000: eval_reward = 108.38
	alpha_loss: -0.12, alpha: 0.50, logp: 2.83
	actor_loss: -309.18, sampled_q: 310.59
	critic_loss: 27.82, q1: 310.49, q2: 309.96, target_q: 309.68
	cql1_loss: 16.47, cql2_loss: 16.71
	cql_q1: 311.88, cql_next_q1: 311.27, random_q1: 302.49
	cql_q2: 311.39, cql_next_q2: 310.79, random_q2: 302.49
	logp_next_action: 2.89, cql_logp: 2.77, cql_logp_next_action: 2.81

# Step 600000: eval_reward = 99.19
	alpha_loss: 0.26, alpha: 0.49, logp: 3.36
	actor_loss: -323.31, sampled_q: 324.98
	critic_loss: 17.24, q1: 324.85, q2: 325.41, target_q: 326.31
	cql1_loss: 11.33, cql2_loss: 11.81
	cql_q1: 325.69, cql_next_q1: 324.70, random_q1: 313.56
	cql_q2: 326.39, cql_next_q2: 325.50, random_q2: 313.56
	logp_next_action: 3.54, cql_logp: 3.39, cql_logp_next_action: 3.43

# Step 610000: eval_reward = 107.99
	alpha_loss: -0.00, alpha: 0.49, logp: 2.99
	actor_loss: -328.43, sampled_q: 329.91
	critic_loss: 11.59, q1: 329.61, q2: 329.82, target_q: 329.36
	cql1_loss: 11.31, cql2_loss: 11.85
	cql_q1: 330.45, cql_next_q1: 329.60, random_q1: 319.86
	cql_q2: 330.84, cql_next_q2: 329.98, random_q2: 319.86
	logp_next_action: 3.13, cql_logp: 2.95, cql_logp_next_action: 3.05

# Step 620000: eval_reward = 107.80
	alpha_loss: 0.14, alpha: 0.50, logp: 3.20
	actor_loss: -307.95, sampled_q: 309.54
	critic_loss: 20.94, q1: 308.50, q2: 308.98, target_q: 308.60
	cql1_loss: 15.51, cql2_loss: 16.27
	cql_q1: 310.32, cql_next_q1: 309.43, random_q1: 298.88
	cql_q2: 310.79, cql_next_q2: 309.98, random_q2: 298.88
	logp_next_action: 3.17, cql_logp: 3.17, cql_logp_next_action: 3.28

# Step 630000: eval_reward = 108.26
	alpha_loss: -0.16, alpha: 0.50, logp: 2.77
	actor_loss: -326.39, sampled_q: 327.78
	critic_loss: 20.12, q1: 328.05, q2: 327.76, target_q: 326.83
	cql1_loss: 11.87, cql2_loss: 12.26
	cql_q1: 328.95, cql_next_q1: 328.14, random_q1: 317.97
	cql_q2: 328.64, cql_next_q2: 327.94, random_q2: 317.97
	logp_next_action: 2.71, cql_logp: 2.80, cql_logp_next_action: 2.82

# Step 640000: eval_reward = 107.91
	alpha_loss: 0.09, alpha: 0.50, logp: 3.13
	actor_loss: -315.04, sampled_q: 316.62
	critic_loss: 22.96, q1: 316.64, q2: 316.77, target_q: 316.31
	cql1_loss: 11.41, cql2_loss: 11.97
	cql_q1: 317.56, cql_next_q1: 316.71, random_q1: 305.59
	cql_q2: 317.74, cql_next_q2: 317.08, random_q2: 305.59
	logp_next_action: 3.06, cql_logp: 3.08, cql_logp_next_action: 3.02

# Step 650000: eval_reward = 110.10
	alpha_loss: 0.02, alpha: 0.51, logp: 3.02
	actor_loss: -323.46, sampled_q: 325.00
	critic_loss: 22.70, q1: 324.79, q2: 325.11, target_q: 324.80
	cql1_loss: 11.90, cql2_loss: 12.19
	cql_q1: 325.76, cql_next_q1: 325.00, random_q1: 314.63
	cql_q2: 326.03, cql_next_q2: 325.26, random_q2: 314.63
	logp_next_action: 2.90, cql_logp: 3.04, cql_logp_next_action: 2.97

# Step 660000: eval_reward = 108.22
	alpha_loss: -0.05, alpha: 0.51, logp: 2.93
	actor_loss: -309.86, sampled_q: 311.35
	critic_loss: 25.93, q1: 309.16, q2: 309.31, target_q: 308.86
	cql1_loss: 24.14, cql2_loss: 25.30
	cql_q1: 312.43, cql_next_q1: 310.82, random_q1: 301.01
	cql_q2: 312.63, cql_next_q2: 310.92, random_q2: 301.01
	logp_next_action: 2.91, cql_logp: 3.09, cql_logp_next_action: 3.04

# Step 670000: eval_reward = 106.57
	alpha_loss: 0.10, alpha: 0.51, logp: 3.15
	actor_loss: -328.06, sampled_q: 329.67
	critic_loss: 20.26, q1: 329.65, q2: 329.06, target_q: 328.55
	cql1_loss: 12.09, cql2_loss: 12.38
	cql_q1: 330.77, cql_next_q1: 329.72, random_q1: 318.98
	cql_q2: 330.32, cql_next_q2: 329.22, random_q2: 318.98
	logp_next_action: 3.13, cql_logp: 3.08, cql_logp_next_action: 3.01

# Step 680000: eval_reward = 106.79
	alpha_loss: -0.27, alpha: 0.50, logp: 2.61
	actor_loss: -312.15, sampled_q: 313.46
	critic_loss: 20.07, q1: 313.57, q2: 312.91, target_q: 312.89
	cql1_loss: 14.87, cql2_loss: 15.54
	cql_q1: 314.66, cql_next_q1: 313.94, random_q1: 305.12
	cql_q2: 314.06, cql_next_q2: 313.35, random_q2: 305.12
	logp_next_action: 2.43, cql_logp: 2.67, cql_logp_next_action: 2.58

# Step 690000: eval_reward = 106.80
	alpha_loss: 0.06, alpha: 0.51, logp: 3.09
	actor_loss: -313.76, sampled_q: 315.33
	critic_loss: 17.80, q1: 314.52, q2: 314.68, target_q: 313.85
	cql1_loss: 15.71, cql2_loss: 14.81
	cql_q1: 316.28, cql_next_q1: 314.48, random_q1: 304.73
	cql_q2: 316.25, cql_next_q2: 314.86, random_q2: 304.73
	logp_next_action: 2.77, cql_logp: 3.04, cql_logp_next_action: 2.94

# Step 700000: eval_reward = 109.33
	alpha_loss: 0.13, alpha: 0.51, logp: 3.19
	actor_loss: -315.56, sampled_q: 317.19
	critic_loss: 31.92, q1: 316.31, q2: 316.13, target_q: 316.47
	cql1_loss: 16.57, cql2_loss: 17.26
	cql_q1: 318.21, cql_next_q1: 317.07, random_q1: 306.20
	cql_q2: 318.14, cql_next_q2: 316.97, random_q2: 306.20
	logp_next_action: 2.86, cql_logp: 3.17, cql_logp_next_action: 3.11

# Step 710000: eval_reward = 99.87
	alpha_loss: -0.07, alpha: 0.51, logp: 2.89
	actor_loss: -310.72, sampled_q: 312.20
	critic_loss: 20.65, q1: 312.93, q2: 312.61, target_q: 313.53
	cql1_loss: 11.71, cql2_loss: 11.82
	cql_q1: 313.41, cql_next_q1: 312.58, random_q1: 303.22
	cql_q2: 313.24, cql_next_q2: 312.33, random_q2: 303.22
	logp_next_action: 2.75, cql_logp: 2.90, cql_logp_next_action: 2.86

# Step 720000: eval_reward = 99.16
	alpha_loss: 0.10, alpha: 0.51, logp: 3.15
	actor_loss: -311.18, sampled_q: 312.80
	critic_loss: 16.02, q1: 312.21, q2: 313.05, target_q: 312.37
	cql1_loss: 12.39, cql2_loss: 12.18
	cql_q1: 313.36, cql_next_q1: 312.56, random_q1: 302.67
	cql_q2: 314.19, cql_next_q2: 313.35, random_q2: 302.67
	logp_next_action: 3.09, cql_logp: 3.13, cql_logp_next_action: 3.04

# Step 730000: eval_reward = 103.33
	alpha_loss: 0.02, alpha: 0.51, logp: 3.03
	actor_loss: -309.36, sampled_q: 310.91
	critic_loss: 19.93, q1: 310.09, q2: 310.58, target_q: 310.15
	cql1_loss: 14.79, cql2_loss: 16.38
	cql_q1: 311.36, cql_next_q1: 310.07, random_q1: 300.33
	cql_q2: 312.27, cql_next_q2: 310.93, random_q2: 300.33
	logp_next_action: 2.68, cql_logp: 2.84, cql_logp_next_action: 2.75

# Step 740000: eval_reward = 107.75
	alpha_loss: 0.01, alpha: 0.51, logp: 3.01
	actor_loss: -312.96, sampled_q: 314.50
	critic_loss: 18.65, q1: 313.89, q2: 314.32, target_q: 314.57
	cql1_loss: 15.28, cql2_loss: 15.69
	cql_q1: 315.44, cql_next_q1: 314.41, random_q1: 304.43
	cql_q2: 315.81, cql_next_q2: 314.89, random_q2: 304.43
	logp_next_action: 2.77, cql_logp: 2.96, cql_logp_next_action: 2.90

# Step 750000: eval_reward = 110.03
	alpha_loss: -0.15, alpha: 0.52, logp: 2.77
	actor_loss: -303.31, sampled_q: 304.75
	critic_loss: 19.34, q1: 304.60, q2: 304.93, target_q: 304.55
	cql1_loss: 13.16, cql2_loss: 13.72
	cql_q1: 305.79, cql_next_q1: 304.99, random_q1: 294.77
	cql_q2: 306.11, cql_next_q2: 305.25, random_q2: 294.77
	logp_next_action: 2.80, cql_logp: 3.02, cql_logp_next_action: 2.80

# Step 760000: eval_reward = 107.98
	alpha_loss: -0.02, alpha: 0.52, logp: 2.97
	actor_loss: -311.30, sampled_q: 312.86
	critic_loss: 18.58, q1: 313.25, q2: 313.52, target_q: 313.43
	cql1_loss: 10.20, cql2_loss: 9.97
	cql_q1: 313.67, cql_next_q1: 312.82, random_q1: 302.63
	cql_q2: 314.04, cql_next_q2: 313.24, random_q2: 302.63
	logp_next_action: 3.27, cql_logp: 3.01, cql_logp_next_action: 3.22

# Step 770000: eval_reward = 107.34
	alpha_loss: -0.09, alpha: 0.52, logp: 2.87
	actor_loss: -314.41, sampled_q: 315.90
	critic_loss: 18.47, q1: 315.78, q2: 315.68, target_q: 314.89
	cql1_loss: 15.00, cql2_loss: 14.65
	cql_q1: 316.92, cql_next_q1: 316.24, random_q1: 306.96
	cql_q2: 316.69, cql_next_q2: 316.12, random_q2: 306.96
	logp_next_action: 2.97, cql_logp: 2.78, cql_logp_next_action: 3.00

# Step 780000: eval_reward = 106.73
	alpha_loss: -0.13, alpha: 0.53, logp: 2.80
	actor_loss: -309.84, sampled_q: 311.32
	critic_loss: 14.52, q1: 311.60, q2: 311.72, target_q: 312.03
	cql1_loss: 12.12, cql2_loss: 12.47
	cql_q1: 312.31, cql_next_q1: 311.56, random_q1: 302.16
	cql_q2: 312.49, cql_next_q2: 311.69, random_q2: 302.16
	logp_next_action: 2.69, cql_logp: 2.82, cql_logp_next_action: 2.73

# Step 790000: eval_reward = 107.26
	alpha_loss: 0.05, alpha: 0.52, logp: 3.08
	actor_loss: -311.66, sampled_q: 313.27
	critic_loss: 16.62, q1: 313.44, q2: 313.61, target_q: 313.21
	cql1_loss: 10.60, cql2_loss: 10.82
	cql_q1: 314.15, cql_next_q1: 313.14, random_q1: 302.33
	cql_q2: 314.44, cql_next_q2: 313.37, random_q2: 302.33
	logp_next_action: 3.04, cql_logp: 3.19, cql_logp_next_action: 3.08

# Step 800000: eval_reward = 109.96
	alpha_loss: 0.16, alpha: 0.53, logp: 3.25
	actor_loss: -319.87, sampled_q: 321.59
	critic_loss: 14.03, q1: 321.75, q2: 321.90, target_q: 321.56
	cql1_loss: 9.90, cql2_loss: 10.93
	cql_q1: 322.27, cql_next_q1: 320.72, random_q1: 311.52
	cql_q2: 322.72, cql_next_q2: 320.99, random_q2: 311.52
	logp_next_action: 2.78, cql_logp: 3.00, cql_logp_next_action: 2.86

# Step 810000: eval_reward = 109.01
	alpha_loss: 0.13, alpha: 0.53, logp: 3.20
	actor_loss: -310.45, sampled_q: 312.13
	critic_loss: 18.41, q1: 310.98, q2: 311.32, target_q: 311.38
	cql1_loss: 21.03, cql2_loss: 21.76
	cql_q1: 313.18, cql_next_q1: 311.26, random_q1: 301.72
	cql_q2: 313.88, cql_next_q2: 311.96, random_q2: 301.72
	logp_next_action: 3.15, cql_logp: 3.20, cql_logp_next_action: 3.22

# Step 820000: eval_reward = 108.20
	alpha_loss: 0.11, alpha: 0.52, logp: 3.17
	actor_loss: -305.71, sampled_q: 307.35
	critic_loss: 25.96, q1: 307.17, q2: 307.42, target_q: 307.45
	cql1_loss: 12.40, cql2_loss: 11.87
	cql_q1: 308.74, cql_next_q1: 307.87, random_q1: 295.55
	cql_q2: 308.66, cql_next_q2: 307.70, random_q2: 295.55
	logp_next_action: 3.41, cql_logp: 3.32, cql_logp_next_action: 3.38

# Step 830000: eval_reward = 109.04
	alpha_loss: -0.08, alpha: 0.53, logp: 2.88
	actor_loss: -308.69, sampled_q: 310.22
	critic_loss: 17.86, q1: 310.80, q2: 310.24, target_q: 309.57
	cql1_loss: 11.94, cql2_loss: 13.08
	cql_q1: 311.57, cql_next_q1: 310.24, random_q1: 301.02
	cql_q2: 311.00, cql_next_q2: 309.83, random_q2: 301.02
	logp_next_action: 2.92, cql_logp: 2.85, cql_logp_next_action: 2.81

# Step 840000: eval_reward = 109.01
	alpha_loss: -0.07, alpha: 0.53, logp: 2.89
	actor_loss: -304.49, sampled_q: 306.02
	critic_loss: 53.98, q1: 305.41, q2: 305.71, target_q: 305.26
	cql1_loss: 15.27, cql2_loss: 14.86
	cql_q1: 307.02, cql_next_q1: 306.14, random_q1: 294.57
	cql_q2: 307.14, cql_next_q2: 306.43, random_q2: 294.57
	logp_next_action: 2.75, cql_logp: 2.81, cql_logp_next_action: 2.80

# Step 850000: eval_reward = 109.40
	alpha_loss: -0.17, alpha: 0.53, logp: 2.73
	actor_loss: -307.99, sampled_q: 309.44
	critic_loss: 16.51, q1: 309.53, q2: 309.52, target_q: 309.89
	cql1_loss: 12.67, cql2_loss: 13.62
	cql_q1: 310.32, cql_next_q1: 309.38, random_q1: 300.40
	cql_q2: 310.56, cql_next_q2: 309.52, random_q2: 300.40
	logp_next_action: 2.98, cql_logp: 2.78, cql_logp_next_action: 2.88

# Step 860000: eval_reward = 106.62
	alpha_loss: -0.13, alpha: 0.53, logp: 2.79
	actor_loss: -303.95, sampled_q: 305.43
	critic_loss: 18.99, q1: 305.18, q2: 305.69, target_q: 305.74
	cql1_loss: 13.37, cql2_loss: 14.18
	cql_q1: 306.04, cql_next_q1: 305.27, random_q1: 295.84
	cql_q2: 306.80, cql_next_q2: 306.03, random_q2: 295.84
	logp_next_action: 2.81, cql_logp: 2.75, cql_logp_next_action: 2.84

# Step 870000: eval_reward = 109.34
	alpha_loss: -0.09, alpha: 0.53, logp: 2.86
	actor_loss: -299.04, sampled_q: 300.57
	critic_loss: 18.95, q1: 300.65, q2: 300.41, target_q: 300.38
	cql1_loss: 15.01, cql2_loss: 13.64
	cql_q1: 301.88, cql_next_q1: 300.45, random_q1: 291.85
	cql_q2: 301.59, cql_next_q2: 300.23, random_q2: 291.85
	logp_next_action: 2.51, cql_logp: 2.91, cql_logp_next_action: 2.70

# Step 880000: eval_reward = 108.51
	alpha_loss: -0.17, alpha: 0.54, logp: 2.72
	actor_loss: -313.73, sampled_q: 315.19
	critic_loss: 52.13, q1: 315.55, q2: 315.51, target_q: 314.56
	cql1_loss: 12.35, cql2_loss: 12.70
	cql_q1: 316.20, cql_next_q1: 315.33, random_q1: 305.28
	cql_q2: 316.19, cql_next_q2: 315.25, random_q2: 305.28
	logp_next_action: 3.02, cql_logp: 2.72, cql_logp_next_action: 2.97

# Step 890000: eval_reward = 108.99
	alpha_loss: 0.07, alpha: 0.53, logp: 3.11
	actor_loss: -305.68, sampled_q: 307.33
	critic_loss: 13.75, q1: 307.54, q2: 307.18, target_q: 307.43
	cql1_loss: 10.61, cql2_loss: 12.04
	cql_q1: 308.33, cql_next_q1: 307.46, random_q1: 295.90
	cql_q2: 308.11, cql_next_q2: 307.28, random_q2: 295.90
	logp_next_action: 3.35, cql_logp: 3.04, cql_logp_next_action: 3.30

# Step 900000: eval_reward = 107.09
	alpha_loss: -0.29, alpha: 0.53, logp: 2.54
	actor_loss: -296.23, sampled_q: 297.57
	critic_loss: 22.51, q1: 297.92, q2: 297.44, target_q: 298.84
	cql1_loss: 13.95, cql2_loss: 13.64
	cql_q1: 298.78, cql_next_q1: 297.97, random_q1: 288.37
	cql_q2: 298.29, cql_next_q2: 297.56, random_q2: 288.37
	logp_next_action: 2.88, cql_logp: 2.65, cql_logp_next_action: 2.81

# Step 910000: eval_reward = 107.86
	alpha_loss: 0.06, alpha: 0.53, logp: 3.09
	actor_loss: -297.22, sampled_q: 298.87
	critic_loss: 25.62, q1: 297.72, q2: 297.90, target_q: 298.00
	cql1_loss: 16.91, cql2_loss: 18.35
	cql_q1: 299.73, cql_next_q1: 298.33, random_q1: 287.94
	cql_q2: 300.28, cql_next_q2: 298.90, random_q2: 287.94
	logp_next_action: 3.03, cql_logp: 3.11, cql_logp_next_action: 2.95

# Step 920000: eval_reward = 107.95
	alpha_loss: -0.14, alpha: 0.54, logp: 2.77
	actor_loss: -294.41, sampled_q: 295.90
	critic_loss: 16.64, q1: 296.04, q2: 296.63, target_q: 295.59
	cql1_loss: 11.48, cql2_loss: 11.92
	cql_q1: 296.75, cql_next_q1: 295.80, random_q1: 285.86
	cql_q2: 297.52, cql_next_q2: 296.67, random_q2: 285.86
	logp_next_action: 2.79, cql_logp: 2.93, cql_logp_next_action: 2.71

# Step 930000: eval_reward = 107.23
	alpha_loss: 0.00, alpha: 0.54, logp: 3.00
	actor_loss: -306.14, sampled_q: 307.77
	critic_loss: 15.57, q1: 307.80, q2: 307.81, target_q: 308.27
	cql1_loss: 12.37, cql2_loss: 12.41
	cql_q1: 308.76, cql_next_q1: 307.82, random_q1: 297.32
	cql_q2: 308.72, cql_next_q2: 307.89, random_q2: 297.32
	logp_next_action: 2.68, cql_logp: 2.77, cql_logp_next_action: 2.66

# Step 940000: eval_reward = 108.45
	alpha_loss: -0.30, alpha: 0.54, logp: 2.52
	actor_loss: -304.94, sampled_q: 306.29
	critic_loss: 15.67, q1: 307.39, q2: 306.62, target_q: 307.27
	cql1_loss: 11.71, cql2_loss: 12.66
	cql_q1: 307.61, cql_next_q1: 307.18, random_q1: 296.70
	cql_q2: 307.06, cql_next_q2: 306.52, random_q2: 296.70
	logp_next_action: 2.73, cql_logp: 2.73, cql_logp_next_action: 2.69

# Step 950000: eval_reward = 107.56
	alpha_loss: -0.26, alpha: 0.54, logp: 2.59
	actor_loss: -306.32, sampled_q: 307.71
	critic_loss: 18.07, q1: 307.76, q2: 308.17, target_q: 308.01
	cql1_loss: 12.08, cql2_loss: 12.50
	cql_q1: 308.59, cql_next_q1: 307.36, random_q1: 299.04
	cql_q2: 309.06, cql_next_q2: 307.92, random_q2: 299.04
	logp_next_action: 2.48, cql_logp: 2.81, cql_logp_next_action: 2.76

# Step 955000: eval_reward = 108.73
	alpha_loss: -0.09, alpha: 0.54, logp: 2.86
	actor_loss: -308.00, sampled_q: 309.54
	critic_loss: 23.84, q1: 309.00, q2: 308.69, target_q: 308.52
	cql1_loss: 15.80, cql2_loss: 17.17
	cql_q1: 310.76, cql_next_q1: 309.86, random_q1: 298.73
	cql_q2: 310.78, cql_next_q2: 309.78, random_q2: 298.73
	logp_next_action: 3.38, cql_logp: 2.94, cql_logp_next_action: 3.15

# Step 960000: eval_reward = 107.81
	alpha_loss: 0.20, alpha: 0.54, logp: 3.33
	actor_loss: -309.82, sampled_q: 311.63
	critic_loss: 17.43, q1: 312.14, q2: 311.62, target_q: 310.89
	cql1_loss: 10.04, cql2_loss: 11.33
	cql_q1: 312.99, cql_next_q1: 312.00, random_q1: 301.12
	cql_q2: 312.65, cql_next_q2: 311.55, random_q2: 301.12
	logp_next_action: 3.02, cql_logp: 3.40, cql_logp_next_action: 3.25

# Step 965000: eval_reward = 108.00
	alpha_loss: -0.05, alpha: 0.53, logp: 2.91
	actor_loss: -310.34, sampled_q: 311.89
	critic_loss: 21.73, q1: 311.63, q2: 312.16, target_q: 311.79
	cql1_loss: 12.44, cql2_loss: 12.67
	cql_q1: 312.73, cql_next_q1: 311.60, random_q1: 302.19
	cql_q2: 313.43, cql_next_q2: 312.34, random_q2: 302.19
	logp_next_action: 3.16, cql_logp: 2.96, cql_logp_next_action: 2.98

# Step 970000: eval_reward = 108.26
	alpha_loss: -0.05, alpha: 0.54, logp: 2.92
	actor_loss: -316.72, sampled_q: 318.31
	critic_loss: 37.94, q1: 318.26, q2: 317.82, target_q: 317.85
	cql1_loss: 16.23, cql2_loss: 15.09
	cql_q1: 319.57, cql_next_q1: 318.25, random_q1: 308.03
	cql_q2: 319.26, cql_next_q2: 317.83, random_q2: 308.03
	logp_next_action: 2.75, cql_logp: 2.89, cql_logp_next_action: 2.87

# Step 975000: eval_reward = 109.25
	alpha_loss: -0.10, alpha: 0.55, logp: 2.84
	actor_loss: -301.21, sampled_q: 302.76
	critic_loss: 20.08, q1: 302.95, q2: 302.34, target_q: 302.71
	cql1_loss: 13.51, cql2_loss: 14.07
	cql_q1: 304.03, cql_next_q1: 302.95, random_q1: 293.36
	cql_q2: 303.43, cql_next_q2: 302.38, random_q2: 293.36
	logp_next_action: 2.66, cql_logp: 2.74, cql_logp_next_action: 2.80

# Step 980000: eval_reward = 107.81
	alpha_loss: 0.07, alpha: 0.54, logp: 3.11
	actor_loss: -298.19, sampled_q: 299.89
	critic_loss: 21.29, q1: 299.73, q2: 299.44, target_q: 298.88
	cql1_loss: 10.85, cql2_loss: 12.15
	cql_q1: 300.71, cql_next_q1: 299.83, random_q1: 288.73
	cql_q2: 300.64, cql_next_q2: 299.69, random_q2: 288.73
	logp_next_action: 3.20, cql_logp: 3.07, cql_logp_next_action: 3.29

# Step 985000: eval_reward = 108.48
	alpha_loss: -0.12, alpha: 0.54, logp: 2.81
	actor_loss: -304.99, sampled_q: 306.51
	critic_loss: 16.19, q1: 306.55, q2: 306.85, target_q: 306.13
	cql1_loss: 11.15, cql2_loss: 11.70
	cql_q1: 307.22, cql_next_q1: 306.11, random_q1: 295.96
	cql_q2: 307.71, cql_next_q2: 306.66, random_q2: 295.96
	logp_next_action: 2.85, cql_logp: 2.83, cql_logp_next_action: 2.73

# Step 990000: eval_reward = 107.98
	alpha_loss: 0.07, alpha: 0.54, logp: 3.11
	actor_loss: -297.69, sampled_q: 299.37
	critic_loss: 17.60, q1: 299.88, q2: 299.43, target_q: 300.25
	cql1_loss: 10.35, cql2_loss: 10.69
	cql_q1: 300.62, cql_next_q1: 299.67, random_q1: 289.45
	cql_q2: 300.32, cql_next_q2: 299.35, random_q2: 289.45
	logp_next_action: 3.25, cql_logp: 3.13, cql_logp_next_action: 3.08

# Step 995000: eval_reward = 108.44
	alpha_loss: -0.15, alpha: 0.54, logp: 2.75
	actor_loss: -303.20, sampled_q: 304.70
	critic_loss: 13.11, q1: 304.89, q2: 305.53, target_q: 305.01
	cql1_loss: 10.22, cql2_loss: 10.98
	cql_q1: 305.37, cql_next_q1: 304.26, random_q1: 294.31
	cql_q2: 306.28, cql_next_q2: 305.07, random_q2: 294.31
	logp_next_action: 2.70, cql_logp: 2.85, cql_logp_next_action: 2.61

# Step 1000000: eval_reward = 110.00
	alpha_loss: -0.28, alpha: 0.54, logp: 2.55
	actor_loss: -305.67, sampled_q: 307.05
	critic_loss: 37.22, q1: 307.45, q2: 307.19, target_q: 308.19
	cql1_loss: 12.76, cql2_loss: 12.44
	cql_q1: 308.45, cql_next_q1: 307.77, random_q1: 297.93
	cql_q2: 308.13, cql_next_q2: 307.41, random_q2: 297.93
	logp_next_action: 2.83, cql_logp: 2.81, cql_logp_next_action: 2.82

