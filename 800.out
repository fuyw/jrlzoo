Ray worker pid: 996974
Using seed 9337
[ BNN ] Name hopper-medium_sn_smv_1_0 | Observation dim 11 | Action dim: 3 | Hidden dim: 200
##################################################
sn: False
no_sn_last: False
gradient_penalty: 0.0
gradient_penalty_scale: 10.0
reward_classification: False
##################################################
Specified load dir /usr/local/data/yuweifu/jaxrl/benchmarks/combo/ray_combo/saved_models
[ BNN ] Initializing model: hopper-medium_sn_smv_1_0 | 7 networks | 5 elites
In _load_structure:
self.layers = [FC(output_dim=200, input_dim=14, activation='swish', weight_decay=2.5e-05, ensemble_size=7), FC(output_dim=200, input_dim=200, activation='swish', weight_decay=5e-05, ensemble_size=7), FC(output_dim=200, input_dim=200, activation='swish', weight_decay=7.5e-05, ensemble_size=7), FC(output_dim=200, input_dim=200, activation='swish', weight_decay=7.5e-05, ensemble_size=7), FC(output_dim=12, input_dim=200, activation=None, weight_decay=0.0001, ensemble_size=7)]
Model loaded from /usr/local/data/yuweifu/jaxrl/benchmarks/combo/ray_combo/saved_models.
Created an ensemble of 7 neural networks with variance predictions | Elites: 5
model.model_loaded = True
[ BNN ] Model: <combo.models.bnn.BNN object at 0x7f21906abb70>
[ Writer ] Log dir: /usr/local/data/yuweifu/jaxrl/benchmarks/combo/ray_combo/hopper/hopper_medium_nolip_len5_minq_3.0_lagrange_0.0_deterministic_backup_temp1.0_lr3e-5_3layers_normalize_for_fake_states_rollout_random_real0.5_iter2000_2000e3/seed:9337_2022-02-01_23-30-29tpbqfv48
[ combo ] Target entropy: -3
[ combo/off_policy ] Replay pool has size: 999981
[ combo ] Starting with pool size: 999981
[ combo ] log_dir: /usr/local/data/yuweifu/jaxrl/benchmarks/combo/ray_combo/hopper/hopper_medium_nolip_len5_minq_3.0_lagrange_0.0_deterministic_backup_temp1.0_lr3e-5_3layers_normalize_for_fake_states_rollout_random_real0.5_iter2000_2000e3/seed:9337_2022-02-01_23-30-29tpbqfv48 | ratio: 0.5
[ combo ] Training model at epoch 0 | freq 1000 | timestep 0 (total: 0)
[ BNN ] Training (998981, 14) | Holdout: (7, 1000, 14)

[F                                                                                                    
[F0 / 1 [                                                            ]   0% | 0.0 Hz
M0 : 0.0128593770787 | M1 : 0.0124265626072 | M2 : 0.0135116428136
M3 : 0.0086852796375 | M4 : 0.0072659398429 | M5 : 0.0062060030177
M6 : 0.0052579729817 | R0 : 0.0057276641018 | R1 : 0.0115444660186
R2 : 0.0045657786540 | R3 : 0.0079098679125 | R4 : 0.0027478309348
R5 : 0.0019422887125 | R6 : 0.0013818047009 | S0 : -10.30957412719
S1 : -9.837321281433 | S2 : -10.54869079589 | S3 : -10.68045616149
S4 : -10.96737384796 | S5 : -10.69919586181 | S6 : -10.78975677490
V0 : 0.0156066287308 | V1 : 0.0237643085420 | V2 : 0.0187558084726
V3 : 0.0259755980223 | V4 : 0.0154969310387 | V5 : 0.0139337806031
V6 : 0.0150157725438 | VR0 : 0.006673863623 | VR1 : 0.009531268849
VR2 : 0.004260474350 | VR3 : 0.004920206964 | VR4 : 0.001649016630
VR5 : 0.010112772695 | VR6 : 0.001282229437 | VS0 : -10.2554540634
VS1 : -9.94682407379 | VS2 : -10.6859445571 | VS3 : -10.5745773315
VS4 : -10.8447723388 | VS5 : -10.5750312805 | VS6 : -10.6185512542
T : 35.5634808540344
[F[F[F[F[F[F[F[F[F[F[F[F[F[F[F[F                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
                                                                                                    
[F[F[F[F[F[F[F[F[F[F[F[F[F[F[F[F[ Progress ] 0 / 1 | M0 : 0.0128593770787 | M1 : 0.0124265626072 | M2 : 0.0135116428136 | M3 : 0.0086852796375 | M4 : 0.0072659398429 | M5 : 0.0062060030177 | M6 : 0.0052579729817 | R0 : 0.0057276641018 | R1 : 0.0115444660186 | R2 : 0.0045657786540 | R3 : 0.0079098679125 | R4 : 0.0027478309348 | R5 : 0.0019422887125 | R6 : 0.0013818047009 | S0 : -10.30957412719 | S1 : -9.837321281433 | S2 : -10.54869079589 | S3 : -10.68045616149 | S4 : -10.96737384796 | S5 : -10.69919586181 | S6 : -10.78975677490 | V0 : 0.0156066287308 | V1 : 0.0237643085420 | V2 : 0.0187558084726 | V3 : 0.0259755980223 | V4 : 0.0154969310387 | V5 : 0.0139337806031 | V6 : 0.0150157725438 | VR0 : 0.006673863623 | VR1 : 0.009531268849 | VR2 : 0.004260474350 | VR3 : 0.004920206964 | VR4 : 0.001649016630 | VR5 : 0.010112772695 | VR6 : 0.001282229437 | VS0 : -10.2554540634 | VS1 : -9.94682407379 | VS2 : -10.6859445571 | VS3 : -10.5745773315 | VS4 : -10.8447723388 | VS5 : -10.5750312805 | VS6 : -10.6185512542 | T : 35.5634808540344 | None
Using 5 / 7 models: [5, 6, 4, 0, 2]
[ BNN ] Holdout [0.01393 0.01502 0.0155  0.01561 0.01876 0.02376 0.02598] {'val_loss': 0.015761783, 'val_r_loss': 0.0037571583, 'val_s_loss': -10.659776, 'val_train_s_loss_diff': 0.07731819}
MODEL: mlp
[ combo ] Loaded model, skipping save

Train epoch 0/3000 -- step 0

[F                                                                                                    
[F[ Model Length ] Epoch: 0 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Initializing new model pool with size 5.00e+05
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 0 -- model_size 0
[ Model Rollout ] Starting | Epoch: 0 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 0
[ Model Rollout ] Added: 49039 | Model pool: 49039 (max 500000) | Length: 4.9039 | Train rep: 1

Diagnostics -- iteration 1000
real_batch_obs: 1681.18, model_batch_obs: 1966.95
real_batch_act: 203.02, model_batch_act: 185.72
real_batch_rewards: 1278.18, model_batch_rewards: 1351.78
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 55.84
total_steps: 1000.00
Q-avg: 42.60, Q-max: 68.30, Q-min: -3.71
Q_loss1: 8.17, Q_loss2: 7.99, min_Q_loss1: 10.18, min_Q_loss2: 9.36

Train epoch 1/3000 -- step 2000

[F                                                                                                    
[F[ Model Length ] Epoch: 1 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 1000 -- model_size 49039
[ Model Rollout ] Starting | Epoch: 1 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 1001
[ Model Rollout ] Added: 49121 | Model pool: 98160 (max 500000) | Length: 4.9121 | Train rep: 1

Diagnostics -- iteration 2000
real_batch_obs: 1774.80, model_batch_obs: 2005.86
real_batch_act: 197.99, model_batch_act: 192.08
real_batch_rewards: 1248.11, model_batch_rewards: 1301.29
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 77.62
total_steps: 2000.00
Q-avg: 80.87, Q-max: 133.89, Q-min: -17.89
Q_loss1: 29.35, Q_loss2: 31.11, min_Q_loss1: 9.54, min_Q_loss2: 8.93

Train epoch 2/3000 -- step 3000

[F                                                                                                    
[F[ Model Length ] Epoch: 2 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 2000 -- model_size 98160
[ Model Rollout ] Starting | Epoch: 2 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 2002
[ Model Rollout ] Added: 48995 | Model pool: 147155 (max 500000) | Length: 4.8995 | Train rep: 1

Diagnostics -- iteration 3000
real_batch_obs: 1880.13, model_batch_obs: 1976.62
real_batch_act: 195.58, model_batch_act: 198.36
real_batch_rewards: 1332.19, model_batch_rewards: 1284.28
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 141.31
total_steps: 3000.00
Q-avg: 127.54, Q-max: 203.89, Q-min: -28.76
Q_loss1: 31.60, Q_loss2: 28.70, min_Q_loss1: -23.92, min_Q_loss2: -23.82

Train epoch 3/3000 -- step 4000

[F                                                                                                    
[F[ Model Length ] Epoch: 3 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 3000 -- model_size 147155
[ Model Rollout ] Starting | Epoch: 3 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 3003
[ Model Rollout ] Added: 49051 | Model pool: 196206 (max 500000) | Length: 4.9051 | Train rep: 1

Diagnostics -- iteration 4000
real_batch_obs: 1760.70, model_batch_obs: 1888.90
real_batch_act: 193.70, model_batch_act: 197.39
real_batch_rewards: 1279.25, model_batch_rewards: 1373.25
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 156.90
total_steps: 4000.00
Q-avg: 176.58, Q-max: 291.66, Q-min: -32.39
Q_loss1: 68.86, Q_loss2: 64.35, min_Q_loss1: 13.02, min_Q_loss2: 13.36

Train epoch 4/3000 -- step 5000

[F                                                                                                    
[F[ Model Length ] Epoch: 4 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 4000 -- model_size 196206
[ Model Rollout ] Starting | Epoch: 4 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 4004
[ Model Rollout ] Added: 49044 | Model pool: 245250 (max 500000) | Length: 4.9044 | Train rep: 1

Diagnostics -- iteration 5000
real_batch_obs: 1930.41, model_batch_obs: 1890.48
real_batch_act: 214.26, model_batch_act: 189.53
real_batch_rewards: 1362.08, model_batch_rewards: 1367.37
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 134.89
total_steps: 5000.00
Q-avg: 221.88, Q-max: 331.66, Q-min: 3.22
Q_loss1: 60.86, Q_loss2: 64.17, min_Q_loss1: -7.19, min_Q_loss2: -9.07

Train epoch 5/3000 -- step 6000

[F                                                                                                    
[F[ Model Length ] Epoch: 5 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 5000 -- model_size 245250
[ Model Rollout ] Starting | Epoch: 5 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 5005
[ Model Rollout ] Added: 48997 | Model pool: 294247 (max 500000) | Length: 4.8997 | Train rep: 1

Diagnostics -- iteration 6000
real_batch_obs: 1896.27, model_batch_obs: 1909.01
real_batch_act: 196.90, model_batch_act: 189.27
real_batch_rewards: 1372.39, model_batch_rewards: 3624.02
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 159.41
total_steps: 6000.00
Q-avg: 270.99, Q-max: 419.37, Q-min: -910.31
Q_loss1: 3752.39, Q_loss2: 5030.97, min_Q_loss1: -62.40, min_Q_loss2: -57.77

Train epoch 6/3000 -- step 7000

[F                                                                                                    
[F[ Model Length ] Epoch: 6 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 6000 -- model_size 294247
[ Model Rollout ] Starting | Epoch: 6 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 6006
[ Model Rollout ] Added: 49018 | Model pool: 343265 (max 500000) | Length: 4.9018 | Train rep: 1

Diagnostics -- iteration 7000
real_batch_obs: 1772.73, model_batch_obs: 1791.11
real_batch_act: 199.19, model_batch_act: 189.74
real_batch_rewards: 1340.40, model_batch_rewards: 1277.50
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 153.44
total_steps: 7000.00
Q-avg: 316.81, Q-max: 491.99, Q-min: -41.05
Q_loss1: 254.27, Q_loss2: 255.50, min_Q_loss1: -19.40, min_Q_loss2: -22.59

Train epoch 7/3000 -- step 8000

[F                                                                                                    
[F[ Model Length ] Epoch: 7 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 7000 -- model_size 343265
[ Model Rollout ] Starting | Epoch: 7 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 7007
[ Model Rollout ] Added: 49096 | Model pool: 392361 (max 500000) | Length: 4.9096 | Train rep: 1

Diagnostics -- iteration 8000
real_batch_obs: 1902.31, model_batch_obs: 1867.20
real_batch_act: 204.75, model_batch_act: 189.65
real_batch_rewards: 1321.03, model_batch_rewards: 1322.90
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 105.98
total_steps: 8000.00
Q-avg: 348.87, Q-max: 521.85, Q-min: -30.00
Q_loss1: 1527.95, Q_loss2: 1496.33, min_Q_loss1: -23.01, min_Q_loss2: -27.54

Train epoch 8/3000 -- step 9000

[F                                                                                                    
[F[ Model Length ] Epoch: 8 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 8000 -- model_size 392361
[ Model Rollout ] Starting | Epoch: 8 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 8008
[ Model Rollout ] Added: 49034 | Model pool: 441395 (max 500000) | Length: 4.9034 | Train rep: 1

Diagnostics -- iteration 9000
real_batch_obs: 1771.69, model_batch_obs: 1897.40
real_batch_act: 195.60, model_batch_act: 191.86
real_batch_rewards: 1370.68, model_batch_rewards: 1398.91
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 135.87
total_steps: 9000.00
Q-avg: 408.90, Q-max: 592.00, Q-min: 17.70
Q_loss1: 129.18, Q_loss2: 135.24, min_Q_loss1: -80.68, min_Q_loss2: -87.47

Train epoch 9/3000 -- step 10000

[F                                                                                                    
[F[ Model Length ] Epoch: 9 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 9000 -- model_size 441395
[ Model Rollout ] Starting | Epoch: 9 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 9009
[ Model Rollout ] Added: 49014 | Model pool: 490409 (max 500000) | Length: 4.9014 | Train rep: 1

Diagnostics -- iteration 10000
real_batch_obs: 1853.45, model_batch_obs: 1974.30
real_batch_act: 200.97, model_batch_act: 176.10
real_batch_rewards: 1343.36, model_batch_rewards: 1399.64
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 175.13
total_steps: 10000.00
Q-avg: 445.87, Q-max: 664.77, Q-min: 59.99
Q_loss1: 173.02, Q_loss2: 156.84, min_Q_loss1: 16.33, min_Q_loss2: 13.71

Train epoch 10/3000 -- step 11000

[F                                                                                                    
[F[ Model Length ] Epoch: 10 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 10000 -- model_size 490409
[ Model Rollout ] Starting | Epoch: 10 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 10010
[ Model Rollout ] Added: 49010 | Model pool: 500000 (max 500000) | Length: 4.901 | Train rep: 1

Diagnostics -- iteration 11000
real_batch_obs: 1868.85, model_batch_obs: 1884.80
real_batch_act: 200.69, model_batch_act: 190.37
real_batch_rewards: 1331.73, model_batch_rewards: 1304.19
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 447.94
total_steps: 11000.00
Q-avg: 479.59, Q-max: 735.95, Q-min: 17.21
Q_loss1: 683.90, Q_loss2: 645.14, min_Q_loss1: -5.51, min_Q_loss2: -8.01

Train epoch 11/3000 -- step 12000

[F                                                                                                    
[F[ Model Length ] Epoch: 11 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 11000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 11 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 11011
[ Model Rollout ] Added: 49021 | Model pool: 500000 (max 500000) | Length: 4.9021 | Train rep: 1

Diagnostics -- iteration 12000
real_batch_obs: 1684.41, model_batch_obs: 1939.75
real_batch_act: 185.13, model_batch_act: 198.33
real_batch_rewards: 1379.84, model_batch_rewards: 1332.26
real_batch_dones: 1.00, model_batch_dones: 4.00
evaluation/return-average: 506.86
total_steps: 12000.00
Q-avg: 501.48, Q-max: 778.73, Q-min: -12.89
Q_loss1: 485.65, Q_loss2: 510.67, min_Q_loss1: 71.34, min_Q_loss2: 76.31

Train epoch 12/3000 -- step 13000

[F                                                                                                    
[F[ Model Length ] Epoch: 12 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 12000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 12 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 12012
[ Model Rollout ] Added: 49047 | Model pool: 500000 (max 500000) | Length: 4.9047 | Train rep: 1

Diagnostics -- iteration 13000
real_batch_obs: 1892.88, model_batch_obs: 1938.39
real_batch_act: 200.62, model_batch_act: 191.66
real_batch_rewards: 1324.67, model_batch_rewards: 1356.70
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 388.79
total_steps: 13000.00
Q-avg: 551.12, Q-max: 851.78, Q-min: 1.17
Q_loss1: 369.31, Q_loss2: 398.89, min_Q_loss1: -83.20, min_Q_loss2: -85.57

Train epoch 13/3000 -- step 14000

[F                                                                                                    
[F[ Model Length ] Epoch: 13 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 13000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 13 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 13013
[ Model Rollout ] Added: 48941 | Model pool: 500000 (max 500000) | Length: 4.8941 | Train rep: 1

Diagnostics -- iteration 14000
real_batch_obs: 1747.82, model_batch_obs: 1936.61
real_batch_act: 198.00, model_batch_act: 188.33
real_batch_rewards: 1308.07, model_batch_rewards: 1326.28
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 393.72
total_steps: 14000.00
Q-avg: 572.98, Q-max: 835.79, Q-min: 56.18
Q_loss1: 301.49, Q_loss2: 319.95, min_Q_loss1: 84.23, min_Q_loss2: 79.01

Train epoch 14/3000 -- step 15000

[F                                                                                                    
[F[ Model Length ] Epoch: 14 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 14000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 14 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 14014
[ Model Rollout ] Added: 48987 | Model pool: 500000 (max 500000) | Length: 4.8987 | Train rep: 1

Diagnostics -- iteration 15000
real_batch_obs: 1832.84, model_batch_obs: 1851.23
real_batch_act: 192.50, model_batch_act: 188.32
real_batch_rewards: 1334.66, model_batch_rewards: 1310.56
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 421.09
total_steps: 15000.00
Q-avg: 604.96, Q-max: 897.45, Q-min: -24.35
Q_loss1: 374.69, Q_loss2: 394.67, min_Q_loss1: -14.66, min_Q_loss2: -16.66

Train epoch 15/3000 -- step 16000

[F                                                                                                    
[F[ Model Length ] Epoch: 15 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 15000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 15 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 15015
[ Model Rollout ] Added: 49030 | Model pool: 500000 (max 500000) | Length: 4.903 | Train rep: 1

Diagnostics -- iteration 16000
real_batch_obs: 1927.84, model_batch_obs: 1933.73
real_batch_act: 210.31, model_batch_act: 189.94
real_batch_rewards: 1357.47, model_batch_rewards: 1317.98
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 429.66
total_steps: 16000.00
Q-avg: 644.98, Q-max: 938.71, Q-min: 19.50
Q_loss1: 327.59, Q_loss2: 299.74, min_Q_loss1: -130.58, min_Q_loss2: -138.60

Train epoch 16/3000 -- step 17000

[F                                                                                                    
[F[ Model Length ] Epoch: 16 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 16000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 16 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 16016
[ Model Rollout ] Added: 49148 | Model pool: 500000 (max 500000) | Length: 4.9148 | Train rep: 1

Diagnostics -- iteration 17000
real_batch_obs: 1833.91, model_batch_obs: 1867.74
real_batch_act: 202.09, model_batch_act: 196.29
real_batch_rewards: 1350.63, model_batch_rewards: 1394.24
real_batch_dones: 2.00, model_batch_dones: 1.00
evaluation/return-average: 317.34
total_steps: 17000.00
Q-avg: 703.60, Q-max: 973.43, Q-min: -374.85
Q_loss1: 791.97, Q_loss2: 727.96, min_Q_loss1: 7.45, min_Q_loss2: 3.22

Train epoch 17/3000 -- step 18000

[F                                                                                                    
[F[ Model Length ] Epoch: 17 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 17000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 17 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 17017
[ Model Rollout ] Added: 49077 | Model pool: 500000 (max 500000) | Length: 4.9077 | Train rep: 1

Diagnostics -- iteration 18000
real_batch_obs: 1905.26, model_batch_obs: 2012.17
real_batch_act: 203.58, model_batch_act: 193.01
real_batch_rewards: 1356.36, model_batch_rewards: 1377.33
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 439.79
total_steps: 18000.00
Q-avg: 740.31, Q-max: 1007.33, Q-min: 16.26
Q_loss1: 305.83, Q_loss2: 305.67, min_Q_loss1: -83.13, min_Q_loss2: -81.26

Train epoch 18/3000 -- step 19000

[F                                                                                                    
[F[ Model Length ] Epoch: 18 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 18000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 18 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 18018
[ Model Rollout ] Added: 49069 | Model pool: 500000 (max 500000) | Length: 4.9069 | Train rep: 1

Diagnostics -- iteration 19000
real_batch_obs: 1775.80, model_batch_obs: 1978.32
real_batch_act: 204.66, model_batch_act: 189.59
real_batch_rewards: 1303.23, model_batch_rewards: 1365.39
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 463.93
total_steps: 19000.00
Q-avg: 736.05, Q-max: 1090.23, Q-min: -116.69
Q_loss1: 522.10, Q_loss2: 494.45, min_Q_loss1: -41.47, min_Q_loss2: -39.11

Train epoch 19/3000 -- step 20000

[F                                                                                                    
[F[ Model Length ] Epoch: 19 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 19000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 19 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 19019
[ Model Rollout ] Added: 49012 | Model pool: 500000 (max 500000) | Length: 4.9012 | Train rep: 1

Diagnostics -- iteration 20000
real_batch_obs: 1875.60, model_batch_obs: 1971.31
real_batch_act: 202.48, model_batch_act: 189.11
real_batch_rewards: 1379.63, model_batch_rewards: 1348.18
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 444.90
total_steps: 20000.00
Q-avg: 766.52, Q-max: 1084.98, Q-min: -106.33
Q_loss1: 404.73, Q_loss2: 317.65, min_Q_loss1: -165.15, min_Q_loss2: -158.43

Train epoch 20/3000 -- step 21000

[F                                                                                                    
[F[ Model Length ] Epoch: 20 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 20000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 20 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 20020
[ Model Rollout ] Added: 49005 | Model pool: 500000 (max 500000) | Length: 4.9005 | Train rep: 1

Diagnostics -- iteration 21000
real_batch_obs: 1834.08, model_batch_obs: 1806.00
real_batch_act: 207.58, model_batch_act: 199.32
real_batch_rewards: 1330.50, model_batch_rewards: 1325.44
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 557.61
total_steps: 21000.00
Q-avg: 784.19, Q-max: 1146.23, Q-min: 75.74
Q_loss1: 596.89, Q_loss2: 583.06, min_Q_loss1: -191.74, min_Q_loss2: -190.83

Train epoch 21/3000 -- step 22000

[F                                                                                                    
[F[ Model Length ] Epoch: 21 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 21000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 21 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 21021
[ Model Rollout ] Added: 49035 | Model pool: 500000 (max 500000) | Length: 4.9035 | Train rep: 1

Diagnostics -- iteration 22000
real_batch_obs: 1817.67, model_batch_obs: 1792.62
real_batch_act: 199.53, model_batch_act: 191.92
real_batch_rewards: 1291.74, model_batch_rewards: 1862.07
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 1005.10
total_steps: 22000.00
Q-avg: 820.69, Q-max: 1136.75, Q-min: -106.70
Q_loss1: 4174.67, Q_loss2: 4250.22, min_Q_loss1: -98.06, min_Q_loss2: -90.91

Train epoch 22/3000 -- step 23000

[F                                                                                                    
[F[ Model Length ] Epoch: 22 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 22000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 22 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 22022
[ Model Rollout ] Added: 49010 | Model pool: 500000 (max 500000) | Length: 4.901 | Train rep: 1

Diagnostics -- iteration 23000
real_batch_obs: 1843.24, model_batch_obs: 1876.13
real_batch_act: 192.54, model_batch_act: 183.80
real_batch_rewards: 1399.77, model_batch_rewards: 1359.86
real_batch_dones: 2.00, model_batch_dones: 3.00
evaluation/return-average: 1045.19
total_steps: 23000.00
Q-avg: 832.95, Q-max: 1235.33, Q-min: -95.52
Q_loss1: 2159.98, Q_loss2: 2164.87, min_Q_loss1: 5.83, min_Q_loss2: 7.78

Train epoch 23/3000 -- step 24000

[F                                                                                                    
[F[ Model Length ] Epoch: 23 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 23000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 23 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 23023
[ Model Rollout ] Added: 49036 | Model pool: 500000 (max 500000) | Length: 4.9036 | Train rep: 1

Diagnostics -- iteration 24000
real_batch_obs: 1895.93, model_batch_obs: 1855.92
real_batch_act: 195.24, model_batch_act: 199.00
real_batch_rewards: 1370.65, model_batch_rewards: 1420.50
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 664.85
total_steps: 24000.00
Q-avg: 922.28, Q-max: 1255.63, Q-min: -38.34
Q_loss1: 1462.49, Q_loss2: 1372.53, min_Q_loss1: -118.44, min_Q_loss2: -110.31

Train epoch 24/3000 -- step 25000

[F                                                                                                    
[F[ Model Length ] Epoch: 24 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 24000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 24 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 24024
[ Model Rollout ] Added: 49014 | Model pool: 500000 (max 500000) | Length: 4.9014 | Train rep: 1

Diagnostics -- iteration 25000
real_batch_obs: 1794.78, model_batch_obs: 1790.78
real_batch_act: 192.86, model_batch_act: 187.20
real_batch_rewards: 1365.56, model_batch_rewards: 1304.76
real_batch_dones: 2.00, model_batch_dones: 2.00
evaluation/return-average: 1156.00
total_steps: 25000.00
Q-avg: 901.45, Q-max: 1310.65, Q-min: -221.63
Q_loss1: 1180.98, Q_loss2: 1193.03, min_Q_loss1: 146.43, min_Q_loss2: 150.44

Train epoch 25/3000 -- step 26000

[F                                                                                                    
[F[ Model Length ] Epoch: 25 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 25000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 25 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 25025
[ Model Rollout ] Added: 49103 | Model pool: 500000 (max 500000) | Length: 4.9103 | Train rep: 1

Diagnostics -- iteration 26000
real_batch_obs: 2031.90, model_batch_obs: 1900.79
real_batch_act: 210.97, model_batch_act: 185.15
real_batch_rewards: 1369.38, model_batch_rewards: 1349.76
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 1128.50
total_steps: 26000.00
Q-avg: 951.77, Q-max: 1340.37, Q-min: -194.58
Q_loss1: 532.32, Q_loss2: 470.37, min_Q_loss1: -82.24, min_Q_loss2: -81.55

Train epoch 26/3000 -- step 27000

[F                                                                                                    
[F[ Model Length ] Epoch: 26 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 26000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 26 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 26026
[ Model Rollout ] Added: 49075 | Model pool: 500000 (max 500000) | Length: 4.9075 | Train rep: 1

Diagnostics -- iteration 27000
real_batch_obs: 1930.84, model_batch_obs: 1826.35
real_batch_act: 202.04, model_batch_act: 187.16
real_batch_rewards: 1386.50, model_batch_rewards: 1262.87
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 1401.24
total_steps: 27000.00
Q-avg: 976.79, Q-max: 1406.53, Q-min: -50.87
Q_loss1: 620.73, Q_loss2: 602.21, min_Q_loss1: -91.93, min_Q_loss2: -89.81

Train epoch 27/3000 -- step 28000

[F                                                                                                    
[F[ Model Length ] Epoch: 27 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 27000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 27 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 27027
[ Model Rollout ] Added: 49117 | Model pool: 500000 (max 500000) | Length: 4.9117 | Train rep: 1

Diagnostics -- iteration 28000
real_batch_obs: 1843.84, model_batch_obs: 1869.68
real_batch_act: 188.98, model_batch_act: 188.84
real_batch_rewards: 1335.61, model_batch_rewards: 1369.73
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 724.25
total_steps: 28000.00
Q-avg: 1028.58, Q-max: 1506.04, Q-min: -1736.01
Q_loss1: 1387.54, Q_loss2: 1399.09, min_Q_loss1: -210.42, min_Q_loss2: -202.99

Train epoch 28/3000 -- step 29000

[F                                                                                                    
[F[ Model Length ] Epoch: 28 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 28000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 28 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 28028
[ Model Rollout ] Added: 49000 | Model pool: 500000 (max 500000) | Length: 4.9 | Train rep: 1

Diagnostics -- iteration 29000
real_batch_obs: 1822.60, model_batch_obs: 2088.53
real_batch_act: 203.46, model_batch_act: 196.20
real_batch_rewards: 1336.51, model_batch_rewards: 2569.46
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 949.11
total_steps: 29000.00
Q-avg: 987.38, Q-max: 5202.10, Q-min: -64.60
Q_loss1: 85496.01, Q_loss2: 7695.44, min_Q_loss1: 18.60, min_Q_loss2: -98.51

Train epoch 29/3000 -- step 30000

[F                                                                                                    
[F[ Model Length ] Epoch: 29 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 29000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 29 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 29029
[ Model Rollout ] Added: 48971 | Model pool: 500000 (max 500000) | Length: 4.8971 | Train rep: 1

Diagnostics -- iteration 30000
real_batch_obs: 1910.82, model_batch_obs: 1915.73
real_batch_act: 201.70, model_batch_act: 193.62
real_batch_rewards: 1345.09, model_batch_rewards: 1355.86
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 583.11
total_steps: 30000.00
Q-avg: 1058.70, Q-max: 1540.26, Q-min: -24.46
Q_loss1: 765.55, Q_loss2: 815.01, min_Q_loss1: -204.65, min_Q_loss2: -191.83

Train epoch 30/3000 -- step 31000

[F                                                                                                    
[F[ Model Length ] Epoch: 30 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 30000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 30 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 30030
[ Model Rollout ] Added: 48984 | Model pool: 500000 (max 500000) | Length: 4.8984 | Train rep: 1

Diagnostics -- iteration 31000
real_batch_obs: 1797.86, model_batch_obs: 1952.72
real_batch_act: 197.15, model_batch_act: 189.40
real_batch_rewards: 1350.90, model_batch_rewards: 1347.45
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 633.68
total_steps: 31000.00
Q-avg: 1057.68, Q-max: 1576.97, Q-min: 24.57
Q_loss1: 1966.37, Q_loss2: 1972.46, min_Q_loss1: -132.12, min_Q_loss2: -138.49

Train epoch 31/3000 -- step 32000

[F                                                                                                    
[F[ Model Length ] Epoch: 31 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 31000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 31 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 31031
[ Model Rollout ] Added: 49128 | Model pool: 500000 (max 500000) | Length: 4.9128 | Train rep: 1

Diagnostics -- iteration 32000
real_batch_obs: 1900.51, model_batch_obs: 1824.41
real_batch_act: 187.32, model_batch_act: 205.94
real_batch_rewards: 1409.59, model_batch_rewards: 1368.42
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 373.25
total_steps: 32000.00
Q-avg: 1054.61, Q-max: 1718.89, Q-min: -105.93
Q_loss1: 1871.43, Q_loss2: 1736.10, min_Q_loss1: -242.65, min_Q_loss2: -251.80

Train epoch 32/3000 -- step 33000

[F                                                                                                    
[F[ Model Length ] Epoch: 32 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 32000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 32 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 32032
[ Model Rollout ] Added: 49079 | Model pool: 500000 (max 500000) | Length: 4.9079 | Train rep: 1

Diagnostics -- iteration 33000
real_batch_obs: 1909.65, model_batch_obs: 2024.30
real_batch_act: 217.91, model_batch_act: 195.86
real_batch_rewards: 1340.30, model_batch_rewards: 1413.24
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 225.37
total_steps: 33000.00
Q-avg: 1084.34, Q-max: 1701.22, Q-min: -102.66
Q_loss1: 735.46, Q_loss2: 697.86, min_Q_loss1: -275.76, min_Q_loss2: -276.20

Train epoch 33/3000 -- step 34000

[F                                                                                                    
[F[ Model Length ] Epoch: 33 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 33000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 33 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 33033
[ Model Rollout ] Added: 49075 | Model pool: 500000 (max 500000) | Length: 4.9075 | Train rep: 1

Diagnostics -- iteration 34000
real_batch_obs: 1749.07, model_batch_obs: 1835.16
real_batch_act: 196.57, model_batch_act: 201.33
real_batch_rewards: 1369.14, model_batch_rewards: 1376.18
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 196.08
total_steps: 34000.00
Q-avg: 1215.34, Q-max: 1883.26, Q-min: 80.03
Q_loss1: 918.49, Q_loss2: 862.88, min_Q_loss1: 54.28, min_Q_loss2: 56.94

Train epoch 34/3000 -- step 35000

[F                                                                                                    
[F[ Model Length ] Epoch: 34 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 34000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 34 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 34034
[ Model Rollout ] Added: 49066 | Model pool: 500000 (max 500000) | Length: 4.9066 | Train rep: 1

Diagnostics -- iteration 35000
real_batch_obs: 1799.03, model_batch_obs: 1750.66
real_batch_act: 196.57, model_batch_act: 202.87
real_batch_rewards: 1323.80, model_batch_rewards: 1304.03
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 388.73
total_steps: 35000.00
Q-avg: 1259.15, Q-max: 1877.81, Q-min: 165.73
Q_loss1: 3014.76, Q_loss2: 3006.84, min_Q_loss1: -13.10, min_Q_loss2: -5.43

Train epoch 35/3000 -- step 36000

[F                                                                                                    
[F[ Model Length ] Epoch: 35 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 35000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 35 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 35035
[ Model Rollout ] Added: 49096 | Model pool: 500000 (max 500000) | Length: 4.9096 | Train rep: 1

Diagnostics -- iteration 36000
real_batch_obs: 1796.85, model_batch_obs: 1974.56
real_batch_act: 202.30, model_batch_act: 192.41
real_batch_rewards: 1246.23, model_batch_rewards: 1336.35
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 234.36
total_steps: 36000.00
Q-avg: 1343.00, Q-max: 1950.97, Q-min: 57.89
Q_loss1: 786.03, Q_loss2: 746.32, min_Q_loss1: -32.19, min_Q_loss2: -36.75

Train epoch 36/3000 -- step 37000

[F                                                                                                    
[F[ Model Length ] Epoch: 36 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 36000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 36 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 36036
[ Model Rollout ] Added: 48989 | Model pool: 500000 (max 500000) | Length: 4.8989 | Train rep: 1

Diagnostics -- iteration 37000
real_batch_obs: 1843.60, model_batch_obs: 1893.31
real_batch_act: 192.44, model_batch_act: 193.13
real_batch_rewards: 1394.14, model_batch_rewards: 1410.69
real_batch_dones: 2.00, model_batch_dones: 1.00
evaluation/return-average: 497.74
total_steps: 37000.00
Q-avg: 1354.84, Q-max: 2057.89, Q-min: 27.53
Q_loss1: 8695.99, Q_loss2: 8753.81, min_Q_loss1: -184.83, min_Q_loss2: -198.21

Train epoch 37/3000 -- step 38000

[F                                                                                                    
[F[ Model Length ] Epoch: 37 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 37000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 37 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 37037
[ Model Rollout ] Added: 48983 | Model pool: 500000 (max 500000) | Length: 4.8983 | Train rep: 1

Diagnostics -- iteration 38000
real_batch_obs: 1737.97, model_batch_obs: 1917.32
real_batch_act: 190.13, model_batch_act: 201.28
real_batch_rewards: 1350.40, model_batch_rewards: 1343.35
real_batch_dones: 1.00, model_batch_dones: 4.00
evaluation/return-average: 236.68
total_steps: 38000.00
Q-avg: 1417.24, Q-max: 2048.07, Q-min: -25.00
Q_loss1: 3028.28, Q_loss2: 2987.57, min_Q_loss1: -138.92, min_Q_loss2: -135.87

Train epoch 38/3000 -- step 39000

[F                                                                                                    
[F[ Model Length ] Epoch: 38 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 38000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 38 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 38038
[ Model Rollout ] Added: 49035 | Model pool: 500000 (max 500000) | Length: 4.9035 | Train rep: 1

Diagnostics -- iteration 39000
real_batch_obs: 1831.69, model_batch_obs: 1866.67
real_batch_act: 202.58, model_batch_act: 195.70
real_batch_rewards: 1334.65, model_batch_rewards: 1279.76
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 247.84
total_steps: 39000.00
Q-avg: 1454.73, Q-max: 2216.86, Q-min: -135.96
Q_loss1: 1189.18, Q_loss2: 1419.70, min_Q_loss1: 181.96, min_Q_loss2: 182.26

Train epoch 39/3000 -- step 40000

[F                                                                                                    
[F[ Model Length ] Epoch: 39 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 39000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 39 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 39039
[ Model Rollout ] Added: 49010 | Model pool: 500000 (max 500000) | Length: 4.901 | Train rep: 1

Diagnostics -- iteration 40000
real_batch_obs: 1939.95, model_batch_obs: 1999.98
real_batch_act: 195.12, model_batch_act: 196.32
real_batch_rewards: 1337.26, model_batch_rewards: 1513.15
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 230.23
total_steps: 40000.00
Q-avg: 1525.48, Q-max: 2296.31, Q-min: 72.89
Q_loss1: 11230.17, Q_loss2: 11167.06, min_Q_loss1: -114.82, min_Q_loss2: -104.59

Train epoch 40/3000 -- step 41000

[F                                                                                                    
[F[ Model Length ] Epoch: 40 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 40000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 40 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 40040
[ Model Rollout ] Added: 49003 | Model pool: 500000 (max 500000) | Length: 4.9003 | Train rep: 1

Diagnostics -- iteration 41000
real_batch_obs: 1940.52, model_batch_obs: 1888.37
real_batch_act: 199.03, model_batch_act: 189.89
real_batch_rewards: 1352.79, model_batch_rewards: 1329.37
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 228.61
total_steps: 41000.00
Q-avg: 1581.42, Q-max: 2456.66, Q-min: -189.91
Q_loss1: 1187.49, Q_loss2: 1110.60, min_Q_loss1: -85.70, min_Q_loss2: -65.01

Train epoch 41/3000 -- step 42000

[F                                                                                                    
[F[ Model Length ] Epoch: 41 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 41000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 41 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 41041
[ Model Rollout ] Added: 49050 | Model pool: 500000 (max 500000) | Length: 4.905 | Train rep: 1

Diagnostics -- iteration 42000
real_batch_obs: 1912.97, model_batch_obs: 1915.14
real_batch_act: 209.24, model_batch_act: 187.66
real_batch_rewards: 1359.53, model_batch_rewards: 1355.87
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 438.87
total_steps: 42000.00
Q-avg: 1696.36, Q-max: 2717.25, Q-min: 150.55
Q_loss1: 1819.40, Q_loss2: 1473.55, min_Q_loss1: -221.12, min_Q_loss2: -210.78

Train epoch 42/3000 -- step 43000

[F                                                                                                    
[F[ Model Length ] Epoch: 42 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 42000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 42 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 42042
[ Model Rollout ] Added: 49106 | Model pool: 500000 (max 500000) | Length: 4.9106 | Train rep: 1

Diagnostics -- iteration 43000
real_batch_obs: 1741.25, model_batch_obs: 1938.75
real_batch_act: 185.07, model_batch_act: 187.48
real_batch_rewards: 1346.44, model_batch_rewards: 1357.97
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 197.87
total_steps: 43000.00
Q-avg: 1747.88, Q-max: 2723.75, Q-min: -138.22
Q_loss1: 1770.67, Q_loss2: 1423.76, min_Q_loss1: -322.97, min_Q_loss2: -303.18

Train epoch 43/3000 -- step 44000

[F                                                                                                    
[F[ Model Length ] Epoch: 43 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 43000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 43 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 43043
[ Model Rollout ] Added: 49074 | Model pool: 500000 (max 500000) | Length: 4.9074 | Train rep: 1

Diagnostics -- iteration 44000
real_batch_obs: 1837.82, model_batch_obs: 1933.01
real_batch_act: 207.52, model_batch_act: 193.74
real_batch_rewards: 1336.92, model_batch_rewards: 1354.04
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 265.25
total_steps: 44000.00
Q-avg: 1761.61, Q-max: 2887.60, Q-min: -491.22
Q_loss1: 9942.44, Q_loss2: 10383.95, min_Q_loss1: -512.08, min_Q_loss2: -516.63

Train epoch 44/3000 -- step 45000

[F                                                                                                    
[F[ Model Length ] Epoch: 44 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 44000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 44 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 44044
[ Model Rollout ] Added: 49069 | Model pool: 500000 (max 500000) | Length: 4.9069 | Train rep: 1

Diagnostics -- iteration 45000
real_batch_obs: 1901.38, model_batch_obs: 1903.45
real_batch_act: 192.32, model_batch_act: 188.95
real_batch_rewards: 1405.57, model_batch_rewards: 1335.51
real_batch_dones: 1.00, model_batch_dones: 4.00
evaluation/return-average: 435.01
total_steps: 45000.00
Q-avg: 1881.96, Q-max: 2939.70, Q-min: 40.64
Q_loss1: 7312.88, Q_loss2: 8331.34, min_Q_loss1: -436.21, min_Q_loss2: -419.10

Train epoch 45/3000 -- step 46000

[F                                                                                                    
[F[ Model Length ] Epoch: 45 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 45000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 45 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 45045
[ Model Rollout ] Added: 49073 | Model pool: 500000 (max 500000) | Length: 4.9073 | Train rep: 1

Diagnostics -- iteration 46000
real_batch_obs: 1926.84, model_batch_obs: 1945.12
real_batch_act: 201.49, model_batch_act: 189.98
real_batch_rewards: 1406.78, model_batch_rewards: 1346.00
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 238.14
total_steps: 46000.00
Q-avg: 1885.11, Q-max: 3066.42, Q-min: 125.80
Q_loss1: 2023.19, Q_loss2: 1654.41, min_Q_loss1: 323.61, min_Q_loss2: 334.85

Train epoch 46/3000 -- step 47000

[F                                                                                                    
[F[ Model Length ] Epoch: 46 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 46000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 46 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 46046
[ Model Rollout ] Added: 48929 | Model pool: 500000 (max 500000) | Length: 4.8929 | Train rep: 1

Diagnostics -- iteration 47000
real_batch_obs: 1858.52, model_batch_obs: 1923.07
real_batch_act: 189.52, model_batch_act: 192.18
real_batch_rewards: 1316.58, model_batch_rewards: 1384.60
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 445.73
total_steps: 47000.00
Q-avg: 2026.75, Q-max: 3412.78, Q-min: -404.68
Q_loss1: 3516.65, Q_loss2: 3746.51, min_Q_loss1: -739.84, min_Q_loss2: -741.34

Train epoch 47/3000 -- step 48000

[F                                                                                                    
[F[ Model Length ] Epoch: 47 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 47000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 47 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 47047
[ Model Rollout ] Added: 49028 | Model pool: 500000 (max 500000) | Length: 4.9028 | Train rep: 1

Diagnostics -- iteration 48000
real_batch_obs: 1750.36, model_batch_obs: 1903.83
real_batch_act: 189.05, model_batch_act: 181.02
real_batch_rewards: 1289.98, model_batch_rewards: 1314.46
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 198.63
total_steps: 48000.00
Q-avg: 2106.76, Q-max: 3358.21, Q-min: -593.26
Q_loss1: 1604.15, Q_loss2: 1580.51, min_Q_loss1: -183.60, min_Q_loss2: -201.41

Train epoch 48/3000 -- step 49000

[F                                                                                                    
[F[ Model Length ] Epoch: 48 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 48000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 48 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 48048
[ Model Rollout ] Added: 49022 | Model pool: 500000 (max 500000) | Length: 4.9022 | Train rep: 1

Diagnostics -- iteration 49000
real_batch_obs: 1814.54, model_batch_obs: 1966.45
real_batch_act: 194.48, model_batch_act: 178.68
real_batch_rewards: 1306.93, model_batch_rewards: 1361.90
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 236.06
total_steps: 49000.00
Q-avg: 2176.65, Q-max: 3899.42, Q-min: -161.88
Q_loss1: 1757.45, Q_loss2: 2172.44, min_Q_loss1: -230.09, min_Q_loss2: -214.86

Train epoch 49/3000 -- step 50000

[F                                                                                                    
[F[ Model Length ] Epoch: 49 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 49000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 49 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 49049
[ Model Rollout ] Added: 49081 | Model pool: 500000 (max 500000) | Length: 4.9081 | Train rep: 1

Diagnostics -- iteration 50000
real_batch_obs: 1768.67, model_batch_obs: 1897.12
real_batch_act: 208.39, model_batch_act: 194.71
real_batch_rewards: 1348.66, model_batch_rewards: 1390.18
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 460.79
total_steps: 50000.00
Q-avg: 2241.65, Q-max: 3858.96, Q-min: -673.22
Q_loss1: 15341.88, Q_loss2: 14636.49, min_Q_loss1: -356.90, min_Q_loss2: -354.84

Train epoch 50/3000 -- step 51000

[F                                                                                                    
[F[ Model Length ] Epoch: 50 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 50000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 50 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 50050
[ Model Rollout ] Added: 48941 | Model pool: 500000 (max 500000) | Length: 4.8941 | Train rep: 1

Diagnostics -- iteration 51000
real_batch_obs: 1851.14, model_batch_obs: 1816.64
real_batch_act: 203.17, model_batch_act: 187.36
real_batch_rewards: 1366.60, model_batch_rewards: 1383.91
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 210.57
total_steps: 51000.00
Q-avg: 2236.81, Q-max: 3831.35, Q-min: 75.14
Q_loss1: 1938.86, Q_loss2: 1569.18, min_Q_loss1: -336.36, min_Q_loss2: -327.98

Train epoch 51/3000 -- step 52000

[F                                                                                                    
[F[ Model Length ] Epoch: 51 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 51000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 51 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 51051
[ Model Rollout ] Added: 48965 | Model pool: 500000 (max 500000) | Length: 4.8965 | Train rep: 1

Diagnostics -- iteration 52000
real_batch_obs: 1864.63, model_batch_obs: 1839.39
real_batch_act: 204.49, model_batch_act: 192.72
real_batch_rewards: 1411.29, model_batch_rewards: 1337.81
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 108.85
total_steps: 52000.00
Q-avg: 2340.75, Q-max: 3925.18, Q-min: 164.12
Q_loss1: 10362.18, Q_loss2: 11025.23, min_Q_loss1: 25.26, min_Q_loss2: 21.47

Train epoch 52/3000 -- step 53000

[F                                                                                                    
[F[ Model Length ] Epoch: 52 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 52000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 52 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 52052
[ Model Rollout ] Added: 48945 | Model pool: 500000 (max 500000) | Length: 4.8945 | Train rep: 1

Diagnostics -- iteration 53000
real_batch_obs: 1903.52, model_batch_obs: 1852.19
real_batch_act: 204.61, model_batch_act: 201.38
real_batch_rewards: 1365.32, model_batch_rewards: 1323.82
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 293.09
total_steps: 53000.00
Q-avg: 2507.94, Q-max: 4184.26, Q-min: -139.30
Q_loss1: 5897.46, Q_loss2: 6059.14, min_Q_loss1: -578.61, min_Q_loss2: -567.59

Train epoch 53/3000 -- step 54000

[F                                                                                                    
[F[ Model Length ] Epoch: 53 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 53000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 53 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 53053
[ Model Rollout ] Added: 49015 | Model pool: 500000 (max 500000) | Length: 4.9015 | Train rep: 1

Diagnostics -- iteration 54000
real_batch_obs: 1742.64, model_batch_obs: 1942.34
real_batch_act: 200.54, model_batch_act: 178.44
real_batch_rewards: 1323.46, model_batch_rewards: 1416.65
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 115.15
total_steps: 54000.00
Q-avg: 2518.78, Q-max: 4655.93, Q-min: -8.99
Q_loss1: 1908.09, Q_loss2: 2001.75, min_Q_loss1: -558.72, min_Q_loss2: -542.82

Train epoch 54/3000 -- step 55000

[F                                                                                                    
[F[ Model Length ] Epoch: 54 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 54000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 54 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 54054
[ Model Rollout ] Added: 49068 | Model pool: 500000 (max 500000) | Length: 4.9068 | Train rep: 1

Diagnostics -- iteration 55000
real_batch_obs: 1840.47, model_batch_obs: 1828.95
real_batch_act: 197.20, model_batch_act: 184.29
real_batch_rewards: 1375.59, model_batch_rewards: 1381.13
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 213.63
total_steps: 55000.00
Q-avg: 2504.61, Q-max: 4401.75, Q-min: 112.29
Q_loss1: 2430.53, Q_loss2: 2390.85, min_Q_loss1: -932.56, min_Q_loss2: -935.99

Train epoch 55/3000 -- step 56000

[F                                                                                                    
[F[ Model Length ] Epoch: 55 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 55000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 55 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 55055
[ Model Rollout ] Added: 49072 | Model pool: 500000 (max 500000) | Length: 4.9072 | Train rep: 1

Diagnostics -- iteration 56000
real_batch_obs: 1877.65, model_batch_obs: 2006.13
real_batch_act: 207.88, model_batch_act: 191.74
real_batch_rewards: 1355.35, model_batch_rewards: 1380.61
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 113.85
total_steps: 56000.00
Q-avg: 2659.22, Q-max: 4559.48, Q-min: 193.20
Q_loss1: 2665.86, Q_loss2: 2417.98, min_Q_loss1: -3.75, min_Q_loss2: -17.52

Train epoch 56/3000 -- step 57000

[F                                                                                                    
[F[ Model Length ] Epoch: 56 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 56000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 56 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 56056
[ Model Rollout ] Added: 49075 | Model pool: 500000 (max 500000) | Length: 4.9075 | Train rep: 1

Diagnostics -- iteration 57000
real_batch_obs: 1859.02, model_batch_obs: 1837.88
real_batch_act: 191.69, model_batch_act: 202.47
real_batch_rewards: 1386.71, model_batch_rewards: 1354.83
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 144.34
total_steps: 57000.00
Q-avg: 2782.70, Q-max: 5126.82, Q-min: -250.31
Q_loss1: 5030.15, Q_loss2: 5757.63, min_Q_loss1: -331.87, min_Q_loss2: -339.96

Train epoch 57/3000 -- step 58000

[F                                                                                                    
[F[ Model Length ] Epoch: 57 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 57000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 57 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 57057
[ Model Rollout ] Added: 49078 | Model pool: 500000 (max 500000) | Length: 4.9078 | Train rep: 1

Diagnostics -- iteration 58000
real_batch_obs: 1776.01, model_batch_obs: 1921.03
real_batch_act: 201.79, model_batch_act: 202.30
real_batch_rewards: 1272.57, model_batch_rewards: 1313.22
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 232.79
total_steps: 58000.00
Q-avg: 2923.13, Q-max: 5508.38, Q-min: -140.88
Q_loss1: 5380.23, Q_loss2: 6137.57, min_Q_loss1: -263.13, min_Q_loss2: -234.54

Train epoch 58/3000 -- step 59000

[F                                                                                                    
[F[ Model Length ] Epoch: 58 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 58000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 58 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 58058
[ Model Rollout ] Added: 49001 | Model pool: 500000 (max 500000) | Length: 4.9001 | Train rep: 1

Diagnostics -- iteration 59000
real_batch_obs: 1830.08, model_batch_obs: 1966.02
real_batch_act: 193.78, model_batch_act: 198.66
real_batch_rewards: 1322.45, model_batch_rewards: 1323.96
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 224.88
total_steps: 59000.00
Q-avg: 3085.31, Q-max: 5194.95, Q-min: 243.04
Q_loss1: 19682.72, Q_loss2: 20028.87, min_Q_loss1: -612.83, min_Q_loss2: -611.47

Train epoch 59/3000 -- step 60000

[F                                                                                                    
[F[ Model Length ] Epoch: 59 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 59000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 59 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 59059
[ Model Rollout ] Added: 49025 | Model pool: 500000 (max 500000) | Length: 4.9025 | Train rep: 1

Diagnostics -- iteration 60000
real_batch_obs: 1912.11, model_batch_obs: 1909.74
real_batch_act: 193.79, model_batch_act: 188.82
real_batch_rewards: 1365.22, model_batch_rewards: 1367.45
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 207.33
total_steps: 60000.00
Q-avg: 2992.41, Q-max: 5320.52, Q-min: -1078.41
Q_loss1: 10097.64, Q_loss2: 11850.77, min_Q_loss1: -131.59, min_Q_loss2: -120.83

Train epoch 60/3000 -- step 61000

[F                                                                                                    
[F[ Model Length ] Epoch: 60 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 60000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 60 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 60060
[ Model Rollout ] Added: 48986 | Model pool: 500000 (max 500000) | Length: 4.8986 | Train rep: 1

Diagnostics -- iteration 61000
real_batch_obs: 1956.81, model_batch_obs: 1865.41
real_batch_act: 215.71, model_batch_act: 188.03
real_batch_rewards: 1383.76, model_batch_rewards: 1379.07
real_batch_dones: 3.00, model_batch_dones: 2.00
evaluation/return-average: 253.55
total_steps: 61000.00
Q-avg: 3087.96, Q-max: 5719.16, Q-min: -1210.86
Q_loss1: 3091.68, Q_loss2: 3003.03, min_Q_loss1: 887.97, min_Q_loss2: 892.22

Train epoch 61/3000 -- step 62000

[F                                                                                                    
[F[ Model Length ] Epoch: 61 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 61000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 61 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 61061
[ Model Rollout ] Added: 48998 | Model pool: 500000 (max 500000) | Length: 4.8998 | Train rep: 1

Diagnostics -- iteration 62000
real_batch_obs: 1959.17, model_batch_obs: 1911.43
real_batch_act: 192.79, model_batch_act: 191.47
real_batch_rewards: 1398.93, model_batch_rewards: 1334.38
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 234.28
total_steps: 62000.00
Q-avg: 3132.64, Q-max: 5515.77, Q-min: -141.82
Q_loss1: 2006.77, Q_loss2: 2736.88, min_Q_loss1: -118.94, min_Q_loss2: -100.19

Train epoch 62/3000 -- step 63000

[F                                                                                                    
[F[ Model Length ] Epoch: 62 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 62000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 62 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 62062
[ Model Rollout ] Added: 48986 | Model pool: 500000 (max 500000) | Length: 4.8986 | Train rep: 1

Diagnostics -- iteration 63000
real_batch_obs: 1946.52, model_batch_obs: 1887.98
real_batch_act: 199.74, model_batch_act: 177.06
real_batch_rewards: 1296.45, model_batch_rewards: 1376.29
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 465.36
total_steps: 63000.00
Q-avg: 3382.94, Q-max: 5481.70, Q-min: 253.81
Q_loss1: 2926.31, Q_loss2: 2701.73, min_Q_loss1: 363.44, min_Q_loss2: 365.79

Train epoch 63/3000 -- step 64000

[F                                                                                                    
[F[ Model Length ] Epoch: 63 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 63000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 63 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 63063
[ Model Rollout ] Added: 48986 | Model pool: 500000 (max 500000) | Length: 4.8986 | Train rep: 1

Diagnostics -- iteration 64000
real_batch_obs: 1948.84, model_batch_obs: 2024.93
real_batch_act: 210.60, model_batch_act: 185.52
real_batch_rewards: 1353.57, model_batch_rewards: 1429.98
real_batch_dones: 2.00, model_batch_dones: 2.00
evaluation/return-average: 169.71
total_steps: 64000.00
Q-avg: 3291.80, Q-max: 5674.95, Q-min: -336.15
Q_loss1: 12725.77, Q_loss2: 12820.50, min_Q_loss1: -313.96, min_Q_loss2: -327.46

Train epoch 64/3000 -- step 65000

[F                                                                                                    
[F[ Model Length ] Epoch: 64 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 64000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 64 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 64064
[ Model Rollout ] Added: 49051 | Model pool: 500000 (max 500000) | Length: 4.9051 | Train rep: 1

Diagnostics -- iteration 65000
real_batch_obs: 1826.97, model_batch_obs: 1848.39
real_batch_act: 189.96, model_batch_act: 192.07
real_batch_rewards: 1329.70, model_batch_rewards: 1789.33
real_batch_dones: 0.00, model_batch_dones: 5.00
evaluation/return-average: 335.18
total_steps: 65000.00
Q-avg: 3351.73, Q-max: 5712.56, Q-min: -728.02
Q_loss1: 1694.95, Q_loss2: 2362.84, min_Q_loss1: -1236.31, min_Q_loss2: -1212.59

Train epoch 65/3000 -- step 66000

[F                                                                                                    
[F[ Model Length ] Epoch: 65 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 65000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 65 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 65065
[ Model Rollout ] Added: 48996 | Model pool: 500000 (max 500000) | Length: 4.8996 | Train rep: 1

Diagnostics -- iteration 66000
real_batch_obs: 1837.90, model_batch_obs: 1860.02
real_batch_act: 197.25, model_batch_act: 190.50
real_batch_rewards: 1307.52, model_batch_rewards: 2287.89
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 331.74
total_steps: 66000.00
Q-avg: 3367.08, Q-max: 5882.51, Q-min: -1934.76
Q_loss1: 7317.16, Q_loss2: 6453.42, min_Q_loss1: -517.53, min_Q_loss2: -462.27

Train epoch 66/3000 -- step 67000

[F                                                                                                    
[F[ Model Length ] Epoch: 66 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 66000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 66 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 66066
[ Model Rollout ] Added: 49107 | Model pool: 500000 (max 500000) | Length: 4.9107 | Train rep: 1

Diagnostics -- iteration 67000
real_batch_obs: 1797.95, model_batch_obs: 1870.44
real_batch_act: 192.68, model_batch_act: 189.61
real_batch_rewards: 1322.64, model_batch_rewards: 1269.80
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 1567.55
total_steps: 67000.00
Q-avg: 3309.72, Q-max: 5950.78, Q-min: -557.06
Q_loss1: 7746.38, Q_loss2: 7008.40, min_Q_loss1: -466.37, min_Q_loss2: -415.13

Train epoch 67/3000 -- step 68000

[F                                                                                                    
[F[ Model Length ] Epoch: 67 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 67000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 67 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 67067
[ Model Rollout ] Added: 48921 | Model pool: 500000 (max 500000) | Length: 4.8921 | Train rep: 1

Diagnostics -- iteration 68000
real_batch_obs: 1754.36, model_batch_obs: 1906.14
real_batch_act: 196.87, model_batch_act: 195.40
real_batch_rewards: 1340.49, model_batch_rewards: 1334.94
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 251.75
total_steps: 68000.00
Q-avg: 3415.82, Q-max: 5891.35, Q-min: 287.62
Q_loss1: 2486.09, Q_loss2: 2505.34, min_Q_loss1: -243.65, min_Q_loss2: -213.33

Train epoch 68/3000 -- step 69000

[F                                                                                                    
[F[ Model Length ] Epoch: 68 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 68000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 68 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 68068
[ Model Rollout ] Added: 49020 | Model pool: 500000 (max 500000) | Length: 4.902 | Train rep: 1

Diagnostics -- iteration 69000
real_batch_obs: 1886.81, model_batch_obs: 1916.80
real_batch_act: 204.49, model_batch_act: 190.67
real_batch_rewards: 1364.07, model_batch_rewards: 1344.90
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 256.66
total_steps: 69000.00
Q-avg: 3268.64, Q-max: 5700.41, Q-min: -436.70
Q_loss1: 4671.45, Q_loss2: 4244.43, min_Q_loss1: -31.73, min_Q_loss2: -36.89

Train epoch 69/3000 -- step 70000

[F                                                                                                    
[F[ Model Length ] Epoch: 69 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 69000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 69 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 69069
[ Model Rollout ] Added: 49013 | Model pool: 500000 (max 500000) | Length: 4.9013 | Train rep: 1

Diagnostics -- iteration 70000
real_batch_obs: 1757.37, model_batch_obs: 1830.42
real_batch_act: 183.89, model_batch_act: 188.67
real_batch_rewards: 1314.89, model_batch_rewards: 3083.27
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 635.20
total_steps: 70000.00
Q-avg: 3366.18, Q-max: 5850.49, Q-min: -1232.96
Q_loss1: 4229.09, Q_loss2: 4371.87, min_Q_loss1: 290.17, min_Q_loss2: 291.82

Train epoch 70/3000 -- step 71000

[F                                                                                                    
[F[ Model Length ] Epoch: 70 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 70000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 70 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 70070
[ Model Rollout ] Added: 49066 | Model pool: 500000 (max 500000) | Length: 4.9066 | Train rep: 1

Diagnostics -- iteration 71000
real_batch_obs: 1694.42, model_batch_obs: 1938.91
real_batch_act: 202.70, model_batch_act: 199.84
real_batch_rewards: 1381.66, model_batch_rewards: 1432.65
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 238.90
total_steps: 71000.00
Q-avg: 3181.84, Q-max: 5930.99, Q-min: -1195.79
Q_loss1: 51784.25, Q_loss2: 50852.82, min_Q_loss1: -762.34, min_Q_loss2: -750.04

Train epoch 71/3000 -- step 72000

[F                                                                                                    
[F[ Model Length ] Epoch: 71 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 71000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 71 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 71071
[ Model Rollout ] Added: 49076 | Model pool: 500000 (max 500000) | Length: 4.9076 | Train rep: 1

Diagnostics -- iteration 72000
real_batch_obs: 1963.87, model_batch_obs: 1921.52
real_batch_act: 208.74, model_batch_act: 184.65
real_batch_rewards: 1309.07, model_batch_rewards: 1379.89
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 249.80
total_steps: 72000.00
Q-avg: 3221.43, Q-max: 6174.57, Q-min: 86.59
Q_loss1: 3782.08, Q_loss2: 3075.79, min_Q_loss1: -238.67, min_Q_loss2: -230.95

Train epoch 72/3000 -- step 73000

[F                                                                                                    
[F[ Model Length ] Epoch: 72 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 72000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 72 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 72072
[ Model Rollout ] Added: 48976 | Model pool: 500000 (max 500000) | Length: 4.8976 | Train rep: 1

Diagnostics -- iteration 73000
real_batch_obs: 1870.12, model_batch_obs: 1854.34
real_batch_act: 189.76, model_batch_act: 184.09
real_batch_rewards: 1349.52, model_batch_rewards: 1278.92
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 252.30
total_steps: 73000.00
Q-avg: 3228.59, Q-max: 5525.76, Q-min: -778.72
Q_loss1: 17468.90, Q_loss2: 22156.71, min_Q_loss1: 127.02, min_Q_loss2: 147.24

Train epoch 73/3000 -- step 74000

[F                                                                                                    
[F[ Model Length ] Epoch: 73 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 73000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 73 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 73073
[ Model Rollout ] Added: 49094 | Model pool: 500000 (max 500000) | Length: 4.9094 | Train rep: 1

Diagnostics -- iteration 74000
real_batch_obs: 1816.99, model_batch_obs: 1775.52
real_batch_act: 201.16, model_batch_act: 182.72
real_batch_rewards: 1304.57, model_batch_rewards: 1315.92
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 680.53
total_steps: 74000.00
Q-avg: 3280.29, Q-max: 5513.97, Q-min: -287.88
Q_loss1: 3839.97, Q_loss2: 4091.06, min_Q_loss1: -575.72, min_Q_loss2: -576.90

Train epoch 74/3000 -- step 75000

[F                                                                                                    
[F[ Model Length ] Epoch: 74 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 74000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 74 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 74074
[ Model Rollout ] Added: 49060 | Model pool: 500000 (max 500000) | Length: 4.906 | Train rep: 1

Diagnostics -- iteration 75000
real_batch_obs: 1753.20, model_batch_obs: 1837.48
real_batch_act: 193.09, model_batch_act: 198.08
real_batch_rewards: 1320.87, model_batch_rewards: 1291.51
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 243.02
total_steps: 75000.00
Q-avg: 3169.50, Q-max: 5524.78, Q-min: -131.73
Q_loss1: 9149.65, Q_loss2: 8668.26, min_Q_loss1: -526.13, min_Q_loss2: -509.38

Train epoch 75/3000 -- step 76000

[F                                                                                                    
[F[ Model Length ] Epoch: 75 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 75000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 75 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 75075
[ Model Rollout ] Added: 49054 | Model pool: 500000 (max 500000) | Length: 4.9054 | Train rep: 1

Diagnostics -- iteration 76000
real_batch_obs: 1961.82, model_batch_obs: 1797.23
real_batch_act: 196.95, model_batch_act: 181.98
real_batch_rewards: 1334.37, model_batch_rewards: 1244.29
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 301.65
total_steps: 76000.00
Q-avg: 3248.73, Q-max: 5537.16, Q-min: -122.88
Q_loss1: 5146.74, Q_loss2: 4862.62, min_Q_loss1: -211.48, min_Q_loss2: -228.60

Train epoch 76/3000 -- step 77000

[F                                                                                                    
[F[ Model Length ] Epoch: 76 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 76000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 76 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 76076
[ Model Rollout ] Added: 48991 | Model pool: 500000 (max 500000) | Length: 4.8991 | Train rep: 1

Diagnostics -- iteration 77000
real_batch_obs: 1925.38, model_batch_obs: 1770.96
real_batch_act: 200.33, model_batch_act: 195.21
real_batch_rewards: 1389.30, model_batch_rewards: 1388.49
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 236.18
total_steps: 77000.00
Q-avg: 3002.04, Q-max: 5616.51, Q-min: -405.44
Q_loss1: 6438.52, Q_loss2: 6029.99, min_Q_loss1: -873.88, min_Q_loss2: -888.76

Train epoch 77/3000 -- step 78000

[F                                                                                                    
[F[ Model Length ] Epoch: 77 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 77000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 77 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 77077
[ Model Rollout ] Added: 48981 | Model pool: 500000 (max 500000) | Length: 4.8981 | Train rep: 1

Diagnostics -- iteration 78000
real_batch_obs: 1862.82, model_batch_obs: 1819.53
real_batch_act: 194.36, model_batch_act: 188.19
real_batch_rewards: 1312.39, model_batch_rewards: 1284.80
real_batch_dones: 2.00, model_batch_dones: 1.00
evaluation/return-average: 293.65
total_steps: 78000.00
Q-avg: 3234.39, Q-max: 5310.32, Q-min: -215.41
Q_loss1: 3050.52, Q_loss2: 3298.46, min_Q_loss1: -300.43, min_Q_loss2: -325.57

Train epoch 78/3000 -- step 79000

[F                                                                                                    
[F[ Model Length ] Epoch: 78 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 78000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 78 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 78078
[ Model Rollout ] Added: 49098 | Model pool: 500000 (max 500000) | Length: 4.9098 | Train rep: 1

Diagnostics -- iteration 79000
real_batch_obs: 1731.53, model_batch_obs: 1890.34
real_batch_act: 188.29, model_batch_act: 190.59
real_batch_rewards: 1311.96, model_batch_rewards: 1373.86
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 246.70
total_steps: 79000.00
Q-avg: 2964.58, Q-max: 5194.67, Q-min: -731.29
Q_loss1: 2730.92, Q_loss2: 2625.42, min_Q_loss1: -231.61, min_Q_loss2: -255.84

Train epoch 79/3000 -- step 80000

[F                                                                                                    
[F[ Model Length ] Epoch: 79 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 79000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 79 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 79079
[ Model Rollout ] Added: 49035 | Model pool: 500000 (max 500000) | Length: 4.9035 | Train rep: 1

Diagnostics -- iteration 80000
real_batch_obs: 1951.74, model_batch_obs: 1923.63
real_batch_act: 203.34, model_batch_act: 192.75
real_batch_rewards: 1397.58, model_batch_rewards: 1355.42
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 248.96
total_steps: 80000.00
Q-avg: 2871.70, Q-max: 5314.07, Q-min: -238.83
Q_loss1: 2361.42, Q_loss2: 2996.35, min_Q_loss1: 256.37, min_Q_loss2: 248.86

Train epoch 80/3000 -- step 81000

[F                                                                                                    
[F[ Model Length ] Epoch: 80 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 80000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 80 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 80080
[ Model Rollout ] Added: 48944 | Model pool: 500000 (max 500000) | Length: 4.8944 | Train rep: 1

Diagnostics -- iteration 81000
real_batch_obs: 1949.04, model_batch_obs: 1870.62
real_batch_act: 208.23, model_batch_act: 192.75
real_batch_rewards: 1397.83, model_batch_rewards: 1325.45
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 274.30
total_steps: 81000.00
Q-avg: 3003.66, Q-max: 5052.42, Q-min: 62.99
Q_loss1: 9482.29, Q_loss2: 10066.39, min_Q_loss1: 118.28, min_Q_loss2: 111.21

Train epoch 81/3000 -- step 82000

[F                                                                                                    
[F[ Model Length ] Epoch: 81 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 81000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 81 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 81081
[ Model Rollout ] Added: 49108 | Model pool: 500000 (max 500000) | Length: 4.9108 | Train rep: 1

Diagnostics -- iteration 82000
real_batch_obs: 1850.59, model_batch_obs: 1795.56
real_batch_act: 211.77, model_batch_act: 187.67
real_batch_rewards: 1311.84, model_batch_rewards: 1293.85
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 246.09
total_steps: 82000.00
Q-avg: 2966.18, Q-max: 5098.40, Q-min: 133.77
Q_loss1: 5328.20, Q_loss2: 5567.05, min_Q_loss1: 137.36, min_Q_loss2: 124.59

Train epoch 82/3000 -- step 83000

[F                                                                                                    
[F[ Model Length ] Epoch: 82 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 82000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 82 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 82082
[ Model Rollout ] Added: 48987 | Model pool: 500000 (max 500000) | Length: 4.8987 | Train rep: 1

Diagnostics -- iteration 83000
real_batch_obs: 1893.07, model_batch_obs: 1993.56
real_batch_act: 203.07, model_batch_act: 190.92
real_batch_rewards: 1341.01, model_batch_rewards: 1400.61
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 236.98
total_steps: 83000.00
Q-avg: 2833.74, Q-max: 5212.14, Q-min: -1116.22
Q_loss1: 2316.55, Q_loss2: 2096.71, min_Q_loss1: -519.92, min_Q_loss2: -552.15

Train epoch 83/3000 -- step 84000

[F                                                                                                    
[F[ Model Length ] Epoch: 83 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 83000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 83 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 83083
[ Model Rollout ] Added: 49094 | Model pool: 500000 (max 500000) | Length: 4.9094 | Train rep: 1

Diagnostics -- iteration 84000
real_batch_obs: 1860.91, model_batch_obs: 1897.69
real_batch_act: 206.19, model_batch_act: 185.80
real_batch_rewards: 1372.85, model_batch_rewards: 1390.28
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 222.88
total_steps: 84000.00
Q-avg: 2723.57, Q-max: 4818.82, Q-min: 14.43
Q_loss1: 3716.63, Q_loss2: 3159.66, min_Q_loss1: -138.96, min_Q_loss2: -131.38

Train epoch 84/3000 -- step 85000

[F                                                                                                    
[F[ Model Length ] Epoch: 84 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 84000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 84 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 84084
[ Model Rollout ] Added: 49044 | Model pool: 500000 (max 500000) | Length: 4.9044 | Train rep: 1

Diagnostics -- iteration 85000
real_batch_obs: 1844.24, model_batch_obs: 1954.69
real_batch_act: 193.04, model_batch_act: 193.59
real_batch_rewards: 1370.15, model_batch_rewards: 1429.86
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 221.76
total_steps: 85000.00
Q-avg: 2548.47, Q-max: 4743.86, Q-min: -15.18
Q_loss1: 4064.26, Q_loss2: 4382.99, min_Q_loss1: -650.85, min_Q_loss2: -650.56

Train epoch 85/3000 -- step 86000

[F                                                                                                    
[F[ Model Length ] Epoch: 85 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 85000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 85 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 85085
[ Model Rollout ] Added: 49055 | Model pool: 500000 (max 500000) | Length: 4.9055 | Train rep: 1

Diagnostics -- iteration 86000
real_batch_obs: 1803.12, model_batch_obs: 1862.12
real_batch_act: 194.14, model_batch_act: 197.94
real_batch_rewards: 1339.37, model_batch_rewards: 1338.95
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 260.00
total_steps: 86000.00
Q-avg: 2790.32, Q-max: 4790.33, Q-min: -992.80
Q_loss1: 4146.98, Q_loss2: 4285.61, min_Q_loss1: -542.85, min_Q_loss2: -551.74

Train epoch 86/3000 -- step 87000

[F                                                                                                    
[F[ Model Length ] Epoch: 86 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 86000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 86 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 86086
[ Model Rollout ] Added: 48999 | Model pool: 500000 (max 500000) | Length: 4.8999 | Train rep: 1

Diagnostics -- iteration 87000
real_batch_obs: 1761.61, model_batch_obs: 1814.68
real_batch_act: 188.27, model_batch_act: 185.67
real_batch_rewards: 1369.76, model_batch_rewards: 1294.39
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 414.24
total_steps: 87000.00
Q-avg: 2561.84, Q-max: 4576.30, Q-min: -266.14
Q_loss1: 3469.62, Q_loss2: 3474.76, min_Q_loss1: 249.76, min_Q_loss2: 250.02

Train epoch 87/3000 -- step 88000

[F                                                                                                    
[F[ Model Length ] Epoch: 87 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 87000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 87 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 87087
[ Model Rollout ] Added: 49055 | Model pool: 500000 (max 500000) | Length: 4.9055 | Train rep: 1

Diagnostics -- iteration 88000
real_batch_obs: 1800.66, model_batch_obs: 1826.92
real_batch_act: 198.87, model_batch_act: 193.40
real_batch_rewards: 1360.97, model_batch_rewards: 1350.16
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 255.28
total_steps: 88000.00
Q-avg: 2700.29, Q-max: 5065.44, Q-min: -26.15
Q_loss1: 2428.19, Q_loss2: 2983.79, min_Q_loss1: -766.18, min_Q_loss2: -745.90

Train epoch 88/3000 -- step 89000

[F                                                                                                    
[F[ Model Length ] Epoch: 88 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 88000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 88 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 88088
[ Model Rollout ] Added: 48932 | Model pool: 500000 (max 500000) | Length: 4.8932 | Train rep: 1

Diagnostics -- iteration 89000
real_batch_obs: 1798.67, model_batch_obs: 1832.97
real_batch_act: 196.61, model_batch_act: 205.41
real_batch_rewards: 1353.82, model_batch_rewards: 1313.75
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 216.46
total_steps: 89000.00
Q-avg: 2482.02, Q-max: 4585.57, Q-min: -286.06
Q_loss1: 12426.82, Q_loss2: 14611.60, min_Q_loss1: -544.19, min_Q_loss2: -525.01

Train epoch 89/3000 -- step 90000

[F                                                                                                    
[F[ Model Length ] Epoch: 89 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 89000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 89 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 89089
[ Model Rollout ] Added: 49066 | Model pool: 500000 (max 500000) | Length: 4.9066 | Train rep: 1

Diagnostics -- iteration 90000
real_batch_obs: 1825.52, model_batch_obs: 1907.39
real_batch_act: 201.03, model_batch_act: 192.92
real_batch_rewards: 1327.72, model_batch_rewards: 1353.95
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 215.77
total_steps: 90000.00
Q-avg: 2623.38, Q-max: 4616.64, Q-min: -245.34
Q_loss1: 4887.79, Q_loss2: 4891.84, min_Q_loss1: 138.72, min_Q_loss2: 148.01

Train epoch 90/3000 -- step 91000

[F                                                                                                    
[F[ Model Length ] Epoch: 90 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 90000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 90 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 90090
[ Model Rollout ] Added: 48997 | Model pool: 500000 (max 500000) | Length: 4.8997 | Train rep: 1

Diagnostics -- iteration 91000
real_batch_obs: 1709.03, model_batch_obs: 1958.56
real_batch_act: 206.63, model_batch_act: 197.23
real_batch_rewards: 1390.84, model_batch_rewards: 1326.35
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 260.46
total_steps: 91000.00
Q-avg: 2406.15, Q-max: 4828.53, Q-min: -1807.97
Q_loss1: 2274.80, Q_loss2: 2735.79, min_Q_loss1: -402.15, min_Q_loss2: -418.54

Train epoch 91/3000 -- step 92000

[F                                                                                                    
[F[ Model Length ] Epoch: 91 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 91000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 91 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 91091
[ Model Rollout ] Added: 49027 | Model pool: 500000 (max 500000) | Length: 4.9027 | Train rep: 1

Diagnostics -- iteration 92000
real_batch_obs: 1881.70, model_batch_obs: 1939.36
real_batch_act: 200.92, model_batch_act: 186.66
real_batch_rewards: 1363.68, model_batch_rewards: 1310.46
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 302.60
total_steps: 92000.00
Q-avg: 2545.42, Q-max: 4478.16, Q-min: -321.70
Q_loss1: 4389.31, Q_loss2: 3413.57, min_Q_loss1: -419.01, min_Q_loss2: -454.80

Train epoch 92/3000 -- step 93000

[F                                                                                                    
[F[ Model Length ] Epoch: 92 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 92000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 92 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 92092
[ Model Rollout ] Added: 49065 | Model pool: 500000 (max 500000) | Length: 4.9065 | Train rep: 1

Diagnostics -- iteration 93000
real_batch_obs: 1878.57, model_batch_obs: 1823.25
real_batch_act: 195.69, model_batch_act: 193.44
real_batch_rewards: 1310.34, model_batch_rewards: 1331.83
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 219.71
total_steps: 93000.00
Q-avg: 2364.76, Q-max: 4446.70, Q-min: -208.61
Q_loss1: 2519.43, Q_loss2: 2506.89, min_Q_loss1: -276.76, min_Q_loss2: -256.32

Train epoch 93/3000 -- step 94000

[F                                                                                                    
[F[ Model Length ] Epoch: 93 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 93000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 93 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 93093
[ Model Rollout ] Added: 48985 | Model pool: 500000 (max 500000) | Length: 4.8985 | Train rep: 1

Diagnostics -- iteration 94000
real_batch_obs: 1869.25, model_batch_obs: 1956.87
real_batch_act: 201.05, model_batch_act: 197.59
real_batch_rewards: 1338.06, model_batch_rewards: 1344.01
real_batch_dones: 2.00, model_batch_dones: 2.00
evaluation/return-average: 217.13
total_steps: 94000.00
Q-avg: 2405.90, Q-max: 4415.75, Q-min: -403.24
Q_loss1: 1911.05, Q_loss2: 2381.62, min_Q_loss1: -191.91, min_Q_loss2: -191.01

Train epoch 94/3000 -- step 95000

[F                                                                                                    
[F[ Model Length ] Epoch: 94 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 94000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 94 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 94094
[ Model Rollout ] Added: 48979 | Model pool: 500000 (max 500000) | Length: 4.8979 | Train rep: 1

Diagnostics -- iteration 95000
real_batch_obs: 1970.44, model_batch_obs: 1876.65
real_batch_act: 200.06, model_batch_act: 201.50
real_batch_rewards: 1411.44, model_batch_rewards: 1363.48
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 200.77
total_steps: 95000.00
Q-avg: 2428.96, Q-max: 4538.48, Q-min: -407.61
Q_loss1: 4216.35, Q_loss2: 4850.81, min_Q_loss1: -117.96, min_Q_loss2: -126.46

Train epoch 95/3000 -- step 96000

[F                                                                                                    
[F[ Model Length ] Epoch: 95 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 95000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 95 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 95095
[ Model Rollout ] Added: 48987 | Model pool: 500000 (max 500000) | Length: 4.8987 | Train rep: 1

Diagnostics -- iteration 96000
real_batch_obs: 1937.10, model_batch_obs: 1858.06
real_batch_act: 201.90, model_batch_act: 202.40
real_batch_rewards: 1381.69, model_batch_rewards: 1316.35
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 208.76
total_steps: 96000.00
Q-avg: 2329.42, Q-max: 4298.98, Q-min: -1813.45
Q_loss1: 5455.82, Q_loss2: 7233.05, min_Q_loss1: -323.32, min_Q_loss2: -347.25

Train epoch 96/3000 -- step 97000

[F                                                                                                    
[F[ Model Length ] Epoch: 96 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 96000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 96 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 96096
[ Model Rollout ] Added: 48990 | Model pool: 500000 (max 500000) | Length: 4.899 | Train rep: 1

Diagnostics -- iteration 97000
real_batch_obs: 1969.44, model_batch_obs: 1847.50
real_batch_act: 208.17, model_batch_act: 186.55
real_batch_rewards: 1370.07, model_batch_rewards: 1362.40
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 227.74
total_steps: 97000.00
Q-avg: 2387.11, Q-max: 4268.55, Q-min: -298.48
Q_loss1: 1354.75, Q_loss2: 1752.86, min_Q_loss1: 202.88, min_Q_loss2: 201.22

Train epoch 97/3000 -- step 98000

[F                                                                                                    
[F[ Model Length ] Epoch: 97 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 97000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 97 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 97097
[ Model Rollout ] Added: 49097 | Model pool: 500000 (max 500000) | Length: 4.9097 | Train rep: 1

Diagnostics -- iteration 98000
real_batch_obs: 1899.36, model_batch_obs: 1894.29
real_batch_act: 200.85, model_batch_act: 198.69
real_batch_rewards: 1323.57, model_batch_rewards: 1417.52
real_batch_dones: 2.00, model_batch_dones: 2.00
evaluation/return-average: 223.85
total_steps: 98000.00
Q-avg: 2398.38, Q-max: 4257.79, Q-min: -525.15
Q_loss1: 6018.09, Q_loss2: 6030.35, min_Q_loss1: -188.44, min_Q_loss2: -215.44

Train epoch 98/3000 -- step 99000

[F                                                                                                    
[F[ Model Length ] Epoch: 98 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 98000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 98 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 98098
[ Model Rollout ] Added: 48995 | Model pool: 500000 (max 500000) | Length: 4.8995 | Train rep: 1

Diagnostics -- iteration 99000
real_batch_obs: 1832.25, model_batch_obs: 1884.06
real_batch_act: 193.47, model_batch_act: 201.32
real_batch_rewards: 1328.66, model_batch_rewards: 1377.61
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 218.36
total_steps: 99000.00
Q-avg: 2238.87, Q-max: 4024.71, Q-min: -452.86
Q_loss1: 2429.79, Q_loss2: 2204.82, min_Q_loss1: -1267.10, min_Q_loss2: -1270.27

Train epoch 99/3000 -- step 100000

[F                                                                                                    
[F[ Model Length ] Epoch: 99 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 99000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 99 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 99099
[ Model Rollout ] Added: 48964 | Model pool: 500000 (max 500000) | Length: 4.8964 | Train rep: 1

Diagnostics -- iteration 100000
real_batch_obs: 1905.16, model_batch_obs: 1898.62
real_batch_act: 206.35, model_batch_act: 195.09
real_batch_rewards: 1335.01, model_batch_rewards: 1389.35
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 205.62
total_steps: 100000.00
Q-avg: 2375.84, Q-max: 3989.60, Q-min: 74.66
Q_loss1: 1797.17, Q_loss2: 1434.24, min_Q_loss1: 88.86, min_Q_loss2: 57.95

Train epoch 100/3000 -- step 101000

[F                                                                                                    
[F[ Model Length ] Epoch: 100 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 100000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 100 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 100100
[ Model Rollout ] Added: 49044 | Model pool: 500000 (max 500000) | Length: 4.9044 | Train rep: 1

Diagnostics -- iteration 101000
real_batch_obs: 1805.67, model_batch_obs: 1835.11
real_batch_act: 194.56, model_batch_act: 187.19
real_batch_rewards: 1348.06, model_batch_rewards: 1259.28
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 243.53
total_steps: 101000.00
Q-avg: 2213.32, Q-max: 4045.96, Q-min: -739.05
Q_loss1: 3905.88, Q_loss2: 3628.37, min_Q_loss1: 206.16, min_Q_loss2: 180.27

Train epoch 101/3000 -- step 102000

[F                                                                                                    
[F[ Model Length ] Epoch: 101 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 101000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 101 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 101101
[ Model Rollout ] Added: 49068 | Model pool: 500000 (max 500000) | Length: 4.9068 | Train rep: 1

Diagnostics -- iteration 102000
real_batch_obs: 1792.86, model_batch_obs: 1810.46
real_batch_act: 202.94, model_batch_act: 199.40
real_batch_rewards: 1304.46, model_batch_rewards: 1325.78
real_batch_dones: 2.00, model_batch_dones: 3.00
evaluation/return-average: 230.97
total_steps: 102000.00
Q-avg: 2346.04, Q-max: 4201.61, Q-min: -44.38
Q_loss1: 7278.41, Q_loss2: 6721.53, min_Q_loss1: -185.65, min_Q_loss2: -206.44

Train epoch 102/3000 -- step 103000

[F                                                                                                    
[F[ Model Length ] Epoch: 102 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 102000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 102 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 102102
[ Model Rollout ] Added: 48975 | Model pool: 500000 (max 500000) | Length: 4.8975 | Train rep: 1

Diagnostics -- iteration 103000
real_batch_obs: 1895.11, model_batch_obs: 1891.09
real_batch_act: 200.51, model_batch_act: 186.41
real_batch_rewards: 1370.26, model_batch_rewards: 1621.83
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 285.77
total_steps: 103000.00
Q-avg: 2160.43, Q-max: 3860.70, Q-min: -786.16
Q_loss1: 3722.30, Q_loss2: 3455.74, min_Q_loss1: -660.35, min_Q_loss2: -653.88

Train epoch 103/3000 -- step 104000

[F                                                                                                    
[F[ Model Length ] Epoch: 103 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 103000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 103 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 103103
[ Model Rollout ] Added: 49064 | Model pool: 500000 (max 500000) | Length: 4.9064 | Train rep: 1

Diagnostics -- iteration 104000
real_batch_obs: 1913.96, model_batch_obs: 1918.48
real_batch_act: 194.29, model_batch_act: 193.26
real_batch_rewards: 1349.08, model_batch_rewards: 1362.64
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 321.19
total_steps: 104000.00
Q-avg: 2194.66, Q-max: 4006.91, Q-min: -451.60
Q_loss1: 8778.69, Q_loss2: 9857.95, min_Q_loss1: -161.70, min_Q_loss2: -145.81

Train epoch 104/3000 -- step 105000

[F                                                                                                    
[F[ Model Length ] Epoch: 104 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 104000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 104 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 104104
[ Model Rollout ] Added: 49033 | Model pool: 500000 (max 500000) | Length: 4.9033 | Train rep: 1

Diagnostics -- iteration 105000
real_batch_obs: 1855.03, model_batch_obs: 1816.32
real_batch_act: 198.35, model_batch_act: 190.87
real_batch_rewards: 1331.46, model_batch_rewards: 1301.44
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 320.66
total_steps: 105000.00
Q-avg: 2243.24, Q-max: 3983.86, Q-min: -726.92
Q_loss1: 2650.83, Q_loss2: 2685.10, min_Q_loss1: -407.29, min_Q_loss2: -411.06

Train epoch 105/3000 -- step 106000

[F                                                                                                    
[F[ Model Length ] Epoch: 105 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 105000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 105 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 105105
[ Model Rollout ] Added: 49022 | Model pool: 500000 (max 500000) | Length: 4.9022 | Train rep: 1

Diagnostics -- iteration 106000
real_batch_obs: 1845.03, model_batch_obs: 1917.83
real_batch_act: 202.68, model_batch_act: 190.76
real_batch_rewards: 1333.44, model_batch_rewards: 1296.19
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 174.96
total_steps: 106000.00
Q-avg: 2124.68, Q-max: 3819.94, Q-min: -823.67
Q_loss1: 10192.38, Q_loss2: 10821.21, min_Q_loss1: -883.70, min_Q_loss2: -874.78

Train epoch 106/3000 -- step 107000

[F                                                                                                    
[F[ Model Length ] Epoch: 106 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 106000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 106 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 106106
[ Model Rollout ] Added: 49028 | Model pool: 500000 (max 500000) | Length: 4.9028 | Train rep: 1

Diagnostics -- iteration 107000
real_batch_obs: 1831.66, model_batch_obs: 1844.56
real_batch_act: 196.35, model_batch_act: 191.14
real_batch_rewards: 1298.20, model_batch_rewards: 1413.39
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 238.35
total_steps: 107000.00
Q-avg: 2240.14, Q-max: 3915.25, Q-min: 11.42
Q_loss1: 839.71, Q_loss2: 796.77, min_Q_loss1: -366.82, min_Q_loss2: -374.50

Train epoch 107/3000 -- step 108000

[F                                                                                                    
[F[ Model Length ] Epoch: 107 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 107000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 107 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 107107
[ Model Rollout ] Added: 49066 | Model pool: 500000 (max 500000) | Length: 4.9066 | Train rep: 1

Diagnostics -- iteration 108000
real_batch_obs: 1876.09, model_batch_obs: 1937.82
real_batch_act: 195.00, model_batch_act: 190.35
real_batch_rewards: 1392.61, model_batch_rewards: 1364.78
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 318.28
total_steps: 108000.00
Q-avg: 2107.15, Q-max: 4040.69, Q-min: -399.03
Q_loss1: 944.39, Q_loss2: 1227.76, min_Q_loss1: 332.79, min_Q_loss2: 340.93

Train epoch 108/3000 -- step 109000

[F                                                                                                    
[F[ Model Length ] Epoch: 108 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 108000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 108 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 108108
[ Model Rollout ] Added: 49032 | Model pool: 500000 (max 500000) | Length: 4.9032 | Train rep: 1

Diagnostics -- iteration 109000
real_batch_obs: 1821.59, model_batch_obs: 1811.94
real_batch_act: 187.24, model_batch_act: 194.97
real_batch_rewards: 1307.33, model_batch_rewards: 1264.40
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 233.27
total_steps: 109000.00
Q-avg: 2152.01, Q-max: 3858.04, Q-min: -1312.60
Q_loss1: 2189.92, Q_loss2: 2984.64, min_Q_loss1: -594.70, min_Q_loss2: -601.08

Train epoch 109/3000 -- step 110000

[F                                                                                                    
[F[ Model Length ] Epoch: 109 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 109000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 109 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 109109
[ Model Rollout ] Added: 49055 | Model pool: 500000 (max 500000) | Length: 4.9055 | Train rep: 1

Diagnostics -- iteration 110000
real_batch_obs: 1714.70, model_batch_obs: 1929.22
real_batch_act: 197.49, model_batch_act: 188.10
real_batch_rewards: 1227.85, model_batch_rewards: 1343.48
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 239.04
total_steps: 110000.00
Q-avg: 2084.17, Q-max: 3743.28, Q-min: -1217.27
Q_loss1: 2398.98, Q_loss2: 2147.46, min_Q_loss1: -895.40, min_Q_loss2: -907.76

Train epoch 110/3000 -- step 111000

[F                                                                                                    
[F[ Model Length ] Epoch: 110 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 110000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 110 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 110110
[ Model Rollout ] Added: 49059 | Model pool: 500000 (max 500000) | Length: 4.9059 | Train rep: 1

Diagnostics -- iteration 111000
real_batch_obs: 1818.07, model_batch_obs: 1837.05
real_batch_act: 193.53, model_batch_act: 196.97
real_batch_rewards: 1389.81, model_batch_rewards: 1335.19
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 253.85
total_steps: 111000.00
Q-avg: 1962.05, Q-max: 3687.99, Q-min: -152.74
Q_loss1: 1781.26, Q_loss2: 1262.70, min_Q_loss1: -324.22, min_Q_loss2: -323.91

Train epoch 111/3000 -- step 112000

[F                                                                                                    
[F[ Model Length ] Epoch: 111 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 111000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 111 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 111111
[ Model Rollout ] Added: 49108 | Model pool: 500000 (max 500000) | Length: 4.9108 | Train rep: 1

Diagnostics -- iteration 112000
real_batch_obs: 1933.75, model_batch_obs: 1893.26
real_batch_act: 204.21, model_batch_act: 192.05
real_batch_rewards: 1355.45, model_batch_rewards: 1316.72
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 256.84
total_steps: 112000.00
Q-avg: 2089.41, Q-max: 3783.92, Q-min: -176.25
Q_loss1: 1341.69, Q_loss2: 1016.42, min_Q_loss1: -175.39, min_Q_loss2: -195.35

Train epoch 112/3000 -- step 113000

[F                                                                                                    
[F[ Model Length ] Epoch: 112 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 112000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 112 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 112112
[ Model Rollout ] Added: 49008 | Model pool: 500000 (max 500000) | Length: 4.9008 | Train rep: 1

Diagnostics -- iteration 113000
real_batch_obs: 1778.89, model_batch_obs: 1993.31
real_batch_act: 201.86, model_batch_act: 188.96
real_batch_rewards: 1329.32, model_batch_rewards: 1460.48
real_batch_dones: 0.00, model_batch_dones: 7.00
evaluation/return-average: 256.14
total_steps: 113000.00
Q-avg: 1995.58, Q-max: 3985.07, Q-min: -968.08
Q_loss1: 17893.35, Q_loss2: 18688.27, min_Q_loss1: -536.34, min_Q_loss2: -505.57

Train epoch 113/3000 -- step 114000

[F                                                                                                    
[F[ Model Length ] Epoch: 113 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 113000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 113 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 113113
[ Model Rollout ] Added: 49009 | Model pool: 500000 (max 500000) | Length: 4.9009 | Train rep: 1

Diagnostics -- iteration 114000
real_batch_obs: 1763.06, model_batch_obs: 1971.93
real_batch_act: 190.02, model_batch_act: 186.18
real_batch_rewards: 1327.98, model_batch_rewards: 1410.63
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 274.77
total_steps: 114000.00
Q-avg: 2061.04, Q-max: 3731.16, Q-min: -274.55
Q_loss1: 1519.15, Q_loss2: 1811.48, min_Q_loss1: -86.42, min_Q_loss2: -84.61

Train epoch 114/3000 -- step 115000

[F                                                                                                    
[F[ Model Length ] Epoch: 114 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 114000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 114 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 114114
[ Model Rollout ] Added: 49013 | Model pool: 500000 (max 500000) | Length: 4.9013 | Train rep: 1

Diagnostics -- iteration 115000
real_batch_obs: 1830.65, model_batch_obs: 1867.59
real_batch_act: 194.95, model_batch_act: 191.29
real_batch_rewards: 1343.20, model_batch_rewards: 1327.43
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 313.62
total_steps: 115000.00
Q-avg: 2005.72, Q-max: 3547.96, Q-min: -586.02
Q_loss1: 9717.03, Q_loss2: 9705.66, min_Q_loss1: -618.66, min_Q_loss2: -619.81

Train epoch 115/3000 -- step 116000

[F                                                                                                    
[F[ Model Length ] Epoch: 115 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 115000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 115 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 115115
[ Model Rollout ] Added: 49053 | Model pool: 500000 (max 500000) | Length: 4.9053 | Train rep: 1

Diagnostics -- iteration 116000
real_batch_obs: 1788.57, model_batch_obs: 1971.86
real_batch_act: 197.73, model_batch_act: 193.27
real_batch_rewards: 1333.12, model_batch_rewards: 1406.91
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 315.69
total_steps: 116000.00
Q-avg: 1892.02, Q-max: 3430.94, Q-min: -1891.09
Q_loss1: 1413.00, Q_loss2: 1790.12, min_Q_loss1: -1010.73, min_Q_loss2: -1014.59

Train epoch 116/3000 -- step 117000

[F                                                                                                    
[F[ Model Length ] Epoch: 116 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 116000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 116 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 116116
[ Model Rollout ] Added: 49078 | Model pool: 500000 (max 500000) | Length: 4.9078 | Train rep: 1

Diagnostics -- iteration 117000
real_batch_obs: 1894.27, model_batch_obs: 1847.14
real_batch_act: 202.92, model_batch_act: 195.30
real_batch_rewards: 1363.52, model_batch_rewards: 1344.46
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 251.71
total_steps: 117000.00
Q-avg: 1960.63, Q-max: 3608.74, Q-min: -113.78
Q_loss1: 8149.24, Q_loss2: 8059.63, min_Q_loss1: -5.81, min_Q_loss2: -7.12

Train epoch 117/3000 -- step 118000

[F                                                                                                    
[F[ Model Length ] Epoch: 117 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 117000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 117 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 117117
[ Model Rollout ] Added: 49054 | Model pool: 500000 (max 500000) | Length: 4.9054 | Train rep: 1

Diagnostics -- iteration 118000
real_batch_obs: 1742.51, model_batch_obs: 1889.28
real_batch_act: 202.99, model_batch_act: 191.11
real_batch_rewards: 1271.28, model_batch_rewards: 1440.42
real_batch_dones: 0.00, model_batch_dones: 5.00
evaluation/return-average: 349.96
total_steps: 118000.00
Q-avg: 1972.62, Q-max: 3477.66, Q-min: -1032.48
Q_loss1: 2878.30, Q_loss2: 2764.64, min_Q_loss1: -580.21, min_Q_loss2: -578.03

Train epoch 118/3000 -- step 119000

[F                                                                                                    
[F[ Model Length ] Epoch: 118 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 118000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 118 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 118118
[ Model Rollout ] Added: 48935 | Model pool: 500000 (max 500000) | Length: 4.8935 | Train rep: 1

Diagnostics -- iteration 119000
real_batch_obs: 1771.61, model_batch_obs: 1820.68
real_batch_act: 197.30, model_batch_act: 193.68
real_batch_rewards: 1370.56, model_batch_rewards: 1338.54
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 298.52
total_steps: 119000.00
Q-avg: 1824.09, Q-max: 3681.59, Q-min: -230.49
Q_loss1: 2344.15, Q_loss2: 2173.70, min_Q_loss1: -155.06, min_Q_loss2: -176.45

Train epoch 119/3000 -- step 120000

[F                                                                                                    
[F[ Model Length ] Epoch: 119 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 119000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 119 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 119119
[ Model Rollout ] Added: 49047 | Model pool: 500000 (max 500000) | Length: 4.9047 | Train rep: 1

Diagnostics -- iteration 120000
real_batch_obs: 1861.20, model_batch_obs: 1838.04
real_batch_act: 204.55, model_batch_act: 189.16
real_batch_rewards: 1380.39, model_batch_rewards: 1331.46
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 233.01
total_steps: 120000.00
Q-avg: 1952.78, Q-max: 3717.13, Q-min: -1220.79
Q_loss1: 1578.97, Q_loss2: 1487.15, min_Q_loss1: 83.66, min_Q_loss2: 53.19

Train epoch 120/3000 -- step 121000

[F                                                                                                    
[F[ Model Length ] Epoch: 120 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 120000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 120 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 120120
[ Model Rollout ] Added: 49028 | Model pool: 500000 (max 500000) | Length: 4.9028 | Train rep: 1

Diagnostics -- iteration 121000
real_batch_obs: 1919.51, model_batch_obs: 1918.77
real_batch_act: 199.03, model_batch_act: 197.58
real_batch_rewards: 1352.58, model_batch_rewards: 2675.73
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 207.75
total_steps: 121000.00
Q-avg: 1819.79, Q-max: 3505.26, Q-min: -559.92
Q_loss1: 6272.78, Q_loss2: 8759.59, min_Q_loss1: -660.44, min_Q_loss2: -645.40

Train epoch 121/3000 -- step 122000

[F                                                                                                    
[F[ Model Length ] Epoch: 121 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 121000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 121 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 121121
[ Model Rollout ] Added: 48967 | Model pool: 500000 (max 500000) | Length: 4.8967 | Train rep: 1

Diagnostics -- iteration 122000
real_batch_obs: 1821.06, model_batch_obs: 1884.35
real_batch_act: 205.59, model_batch_act: 184.61
real_batch_rewards: 1424.65, model_batch_rewards: 1335.81
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 232.61
total_steps: 122000.00
Q-avg: 1894.98, Q-max: 3629.50, Q-min: -138.47
Q_loss1: 1738.09, Q_loss2: 1589.14, min_Q_loss1: 49.85, min_Q_loss2: 31.32

Train epoch 122/3000 -- step 123000

[F                                                                                                    
[F[ Model Length ] Epoch: 122 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 122000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 122 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 122122
[ Model Rollout ] Added: 49113 | Model pool: 500000 (max 500000) | Length: 4.9113 | Train rep: 1

Diagnostics -- iteration 123000
real_batch_obs: 1799.54, model_batch_obs: 1941.90
real_batch_act: 205.05, model_batch_act: 193.67
real_batch_rewards: 1321.37, model_batch_rewards: 1359.03
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 241.18
total_steps: 123000.00
Q-avg: 1847.69, Q-max: 3427.03, Q-min: -1301.09
Q_loss1: 2174.84, Q_loss2: 2694.37, min_Q_loss1: -461.92, min_Q_loss2: -441.76

Train epoch 123/3000 -- step 124000

[F                                                                                                    
[F[ Model Length ] Epoch: 123 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 123000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 123 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 123123
[ Model Rollout ] Added: 49034 | Model pool: 500000 (max 500000) | Length: 4.9034 | Train rep: 1

Diagnostics -- iteration 124000
real_batch_obs: 1790.31, model_batch_obs: 1866.35
real_batch_act: 187.27, model_batch_act: 184.09
real_batch_rewards: 1322.88, model_batch_rewards: 1387.25
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 257.12
total_steps: 124000.00
Q-avg: 1871.11, Q-max: 3333.66, Q-min: -337.27
Q_loss1: 842.86, Q_loss2: 662.12, min_Q_loss1: -75.83, min_Q_loss2: -80.32

Train epoch 124/3000 -- step 125000

[F                                                                                                    
[F[ Model Length ] Epoch: 124 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 124000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 124 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 124124
[ Model Rollout ] Added: 49091 | Model pool: 500000 (max 500000) | Length: 4.9091 | Train rep: 1

Diagnostics -- iteration 125000
real_batch_obs: 1843.98, model_batch_obs: 1909.50
real_batch_act: 207.96, model_batch_act: 192.63
real_batch_rewards: 1336.79, model_batch_rewards: 1335.99
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 243.04
total_steps: 125000.00
Q-avg: 1809.70, Q-max: 3466.79, Q-min: -424.71
Q_loss1: 1086.12, Q_loss2: 1227.76, min_Q_loss1: -691.82, min_Q_loss2: -680.02

Train epoch 125/3000 -- step 126000

[F                                                                                                    
[F[ Model Length ] Epoch: 125 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 125000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 125 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 125125
[ Model Rollout ] Added: 48994 | Model pool: 500000 (max 500000) | Length: 4.8994 | Train rep: 1

Diagnostics -- iteration 126000
real_batch_obs: 1809.37, model_batch_obs: 1881.43
real_batch_act: 192.00, model_batch_act: 181.04
real_batch_rewards: 1322.63, model_batch_rewards: 1365.27
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 1056.08
total_steps: 126000.00
Q-avg: 1779.32, Q-max: 3432.56, Q-min: -1378.72
Q_loss1: 2089.96, Q_loss2: 1450.71, min_Q_loss1: -281.19, min_Q_loss2: -291.40

Train epoch 126/3000 -- step 127000

[F                                                                                                    
[F[ Model Length ] Epoch: 126 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 126000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 126 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 126126
[ Model Rollout ] Added: 49033 | Model pool: 500000 (max 500000) | Length: 4.9033 | Train rep: 1

Diagnostics -- iteration 127000
real_batch_obs: 1846.78, model_batch_obs: 1925.43
real_batch_act: 200.09, model_batch_act: 188.60
real_batch_rewards: 1300.52, model_batch_rewards: 1398.47
real_batch_dones: 2.00, model_batch_dones: 2.00
evaluation/return-average: 1060.03
total_steps: 127000.00
Q-avg: 1848.49, Q-max: 3350.11, Q-min: -117.13
Q_loss1: 1531.78, Q_loss2: 1663.64, min_Q_loss1: -501.45, min_Q_loss2: -497.92

Train epoch 127/3000 -- step 128000

[F                                                                                                    
[F[ Model Length ] Epoch: 127 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 127000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 127 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 127127
[ Model Rollout ] Added: 48996 | Model pool: 500000 (max 500000) | Length: 4.8996 | Train rep: 1

Diagnostics -- iteration 128000
real_batch_obs: 1864.14, model_batch_obs: 1838.11
real_batch_act: 213.58, model_batch_act: 197.43
real_batch_rewards: 1392.42, model_batch_rewards: 1358.75
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 1063.15
total_steps: 128000.00
Q-avg: 1754.77, Q-max: 3386.98, Q-min: -142.76
Q_loss1: 2835.00, Q_loss2: 3243.48, min_Q_loss1: 94.45, min_Q_loss2: 95.10

Train epoch 128/3000 -- step 129000

[F                                                                                                    
[F[ Model Length ] Epoch: 128 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 128000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 128 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 128128
[ Model Rollout ] Added: 49001 | Model pool: 500000 (max 500000) | Length: 4.9001 | Train rep: 1

Diagnostics -- iteration 129000
real_batch_obs: 1792.22, model_batch_obs: 1871.83
real_batch_act: 205.44, model_batch_act: 202.39
real_batch_rewards: 1324.43, model_batch_rewards: 1357.05
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 212.41
total_steps: 129000.00
Q-avg: 1854.01, Q-max: 3316.86, Q-min: -227.13
Q_loss1: 4511.82, Q_loss2: 4266.53, min_Q_loss1: -230.00, min_Q_loss2: -253.31

Train epoch 129/3000 -- step 130000

[F                                                                                                    
[F[ Model Length ] Epoch: 129 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 129000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 129 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 129129
[ Model Rollout ] Added: 49060 | Model pool: 500000 (max 500000) | Length: 4.906 | Train rep: 1

Diagnostics -- iteration 130000
real_batch_obs: 1836.21, model_batch_obs: 1952.89
real_batch_act: 195.06, model_batch_act: 202.28
real_batch_rewards: 1307.64, model_batch_rewards: 5210.46
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 276.57
total_steps: 130000.00
Q-avg: 1717.00, Q-max: 3423.91, Q-min: -2128.39
Q_loss1: 9627.99, Q_loss2: 7775.84, min_Q_loss1: -799.60, min_Q_loss2: -824.73

Train epoch 130/3000 -- step 131000

[F                                                                                                    
[F[ Model Length ] Epoch: 130 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 130000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 130 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 130130
[ Model Rollout ] Added: 49083 | Model pool: 500000 (max 500000) | Length: 4.9083 | Train rep: 1

Diagnostics -- iteration 131000
real_batch_obs: 1861.03, model_batch_obs: 1941.44
real_batch_act: 189.90, model_batch_act: 194.70
real_batch_rewards: 1316.78, model_batch_rewards: 1410.77
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 567.25
total_steps: 131000.00
Q-avg: 1753.74, Q-max: 3297.84, Q-min: -744.47
Q_loss1: 1620.24, Q_loss2: 1483.08, min_Q_loss1: -404.50, min_Q_loss2: -398.85

Train epoch 131/3000 -- step 132000

[F                                                                                                    
[F[ Model Length ] Epoch: 131 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 131000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 131 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 131131
[ Model Rollout ] Added: 49009 | Model pool: 500000 (max 500000) | Length: 4.9009 | Train rep: 1

Diagnostics -- iteration 132000
real_batch_obs: 1823.47, model_batch_obs: 1845.83
real_batch_act: 208.55, model_batch_act: 196.41
real_batch_rewards: 1312.22, model_batch_rewards: 1331.77
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 1192.82
total_steps: 132000.00
Q-avg: 1798.72, Q-max: 3271.15, Q-min: -343.61
Q_loss1: 1071.19, Q_loss2: 1266.33, min_Q_loss1: -305.63, min_Q_loss2: -315.57

Train epoch 132/3000 -- step 133000

[F                                                                                                    
[F[ Model Length ] Epoch: 132 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 132000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 132 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 132132
[ Model Rollout ] Added: 49036 | Model pool: 500000 (max 500000) | Length: 4.9036 | Train rep: 1

Diagnostics -- iteration 133000
real_batch_obs: 1863.31, model_batch_obs: 1832.01
real_batch_act: 197.34, model_batch_act: 184.29
real_batch_rewards: 1339.55, model_batch_rewards: 1259.49
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 347.40
total_steps: 133000.00
Q-avg: 1729.99, Q-max: 3326.82, Q-min: -975.19
Q_loss1: 1704.81, Q_loss2: 1724.19, min_Q_loss1: -290.94, min_Q_loss2: -278.59

Train epoch 133/3000 -- step 134000

[F                                                                                                    
[F[ Model Length ] Epoch: 133 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 133000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 133 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 133133
[ Model Rollout ] Added: 48973 | Model pool: 500000 (max 500000) | Length: 4.8973 | Train rep: 1

Diagnostics -- iteration 134000
real_batch_obs: 1892.42, model_batch_obs: 1832.18
real_batch_act: 206.07, model_batch_act: 188.40
real_batch_rewards: 1353.40, model_batch_rewards: 1466.25
real_batch_dones: 1.00, model_batch_dones: 4.00
evaluation/return-average: 686.24
total_steps: 134000.00
Q-avg: 1641.73, Q-max: 3145.93, Q-min: -1699.74
Q_loss1: 30684.74, Q_loss2: 30854.96, min_Q_loss1: -441.16, min_Q_loss2: -469.79

Train epoch 134/3000 -- step 135000

[F                                                                                                    
[F[ Model Length ] Epoch: 134 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 134000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 134 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 134134
[ Model Rollout ] Added: 49023 | Model pool: 500000 (max 500000) | Length: 4.9023 | Train rep: 1

Diagnostics -- iteration 135000
real_batch_obs: 1854.91, model_batch_obs: 1895.08
real_batch_act: 208.37, model_batch_act: 183.62
real_batch_rewards: 1344.79, model_batch_rewards: 1367.94
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 315.89
total_steps: 135000.00
Q-avg: 1704.29, Q-max: 3320.12, Q-min: -730.89
Q_loss1: 592.35, Q_loss2: 733.15, min_Q_loss1: -565.24, min_Q_loss2: -565.60

Train epoch 135/3000 -- step 136000

[F                                                                                                    
[F[ Model Length ] Epoch: 135 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 135000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 135 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 135135
[ Model Rollout ] Added: 48983 | Model pool: 500000 (max 500000) | Length: 4.8983 | Train rep: 1

Diagnostics -- iteration 136000
real_batch_obs: 1772.82, model_batch_obs: 1810.45
real_batch_act: 197.72, model_batch_act: 192.15
real_batch_rewards: 1325.61, model_batch_rewards: 1321.11
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 198.13
total_steps: 136000.00
Q-avg: 1787.18, Q-max: 3211.82, Q-min: -294.48
Q_loss1: 888.45, Q_loss2: 1056.40, min_Q_loss1: -190.54, min_Q_loss2: -181.45

Train epoch 136/3000 -- step 137000

[F                                                                                                    
[F[ Model Length ] Epoch: 136 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 136000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 136 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 136136
[ Model Rollout ] Added: 49028 | Model pool: 500000 (max 500000) | Length: 4.9028 | Train rep: 1

Diagnostics -- iteration 137000
real_batch_obs: 1871.53, model_batch_obs: 1981.92
real_batch_act: 204.65, model_batch_act: 191.91
real_batch_rewards: 1391.10, model_batch_rewards: 1383.00
real_batch_dones: 2.00, model_batch_dones: 2.00
evaluation/return-average: 174.59
total_steps: 137000.00
Q-avg: 1662.15, Q-max: 3224.30, Q-min: -1016.80
Q_loss1: 1166.77, Q_loss2: 1044.55, min_Q_loss1: 71.41, min_Q_loss2: 59.57

Train epoch 137/3000 -- step 138000

[F                                                                                                    
[F[ Model Length ] Epoch: 137 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 137000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 137 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 137137
[ Model Rollout ] Added: 49014 | Model pool: 500000 (max 500000) | Length: 4.9014 | Train rep: 1

Diagnostics -- iteration 138000
real_batch_obs: 1805.82, model_batch_obs: 1811.41
real_batch_act: 220.16, model_batch_act: 193.54
real_batch_rewards: 1334.16, model_batch_rewards: 1320.77
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 232.22
total_steps: 138000.00
Q-avg: 1758.62, Q-max: 2938.23, Q-min: -500.58
Q_loss1: 8570.77, Q_loss2: 8745.48, min_Q_loss1: -437.14, min_Q_loss2: -452.66

Train epoch 138/3000 -- step 139000

[F                                                                                                    
[F[ Model Length ] Epoch: 138 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 138000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 138 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 138138
[ Model Rollout ] Added: 48970 | Model pool: 500000 (max 500000) | Length: 4.897 | Train rep: 1

Diagnostics -- iteration 139000
real_batch_obs: 1794.79, model_batch_obs: 1847.00
real_batch_act: 202.83, model_batch_act: 191.13
real_batch_rewards: 1278.10, model_batch_rewards: 1376.64
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 157.66
total_steps: 139000.00
Q-avg: 1668.11, Q-max: 3048.48, Q-min: -1120.02
Q_loss1: 1350.80, Q_loss2: 1229.12, min_Q_loss1: -847.26, min_Q_loss2: -839.45

Train epoch 139/3000 -- step 140000

[F                                                                                                    
[F[ Model Length ] Epoch: 139 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 139000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 139 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 139139
[ Model Rollout ] Added: 48995 | Model pool: 500000 (max 500000) | Length: 4.8995 | Train rep: 1

Diagnostics -- iteration 140000
real_batch_obs: 1832.46, model_batch_obs: 1851.38
real_batch_act: 207.30, model_batch_act: 193.26
real_batch_rewards: 1323.97, model_batch_rewards: 1573.56
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 156.79
total_steps: 140000.00
Q-avg: 1737.34, Q-max: 3012.63, Q-min: -1249.64
Q_loss1: 8254.07, Q_loss2: 7849.51, min_Q_loss1: -381.49, min_Q_loss2: -385.76

Train epoch 140/3000 -- step 141000

[F                                                                                                    
[F[ Model Length ] Epoch: 140 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 140000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 140 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 140140
[ Model Rollout ] Added: 48998 | Model pool: 500000 (max 500000) | Length: 4.8998 | Train rep: 1

Diagnostics -- iteration 141000
real_batch_obs: 1807.73, model_batch_obs: 2004.40
real_batch_act: 201.84, model_batch_act: 197.11
real_batch_rewards: 1320.51, model_batch_rewards: 1369.69
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 179.36
total_steps: 141000.00
Q-avg: 1670.56, Q-max: 2874.50, Q-min: -977.89
Q_loss1: 2658.31, Q_loss2: 3110.59, min_Q_loss1: -651.51, min_Q_loss2: -660.87

Train epoch 141/3000 -- step 142000

[F                                                                                                    
[F[ Model Length ] Epoch: 141 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 141000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 141 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 141141
[ Model Rollout ] Added: 49048 | Model pool: 500000 (max 500000) | Length: 4.9048 | Train rep: 1

Diagnostics -- iteration 142000
real_batch_obs: 1763.65, model_batch_obs: 1966.77
real_batch_act: 193.41, model_batch_act: 192.12
real_batch_rewards: 1374.95, model_batch_rewards: 1305.78
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 1039.81
total_steps: 142000.00
Q-avg: 1630.84, Q-max: 2940.49, Q-min: -900.78
Q_loss1: 1115.72, Q_loss2: 1616.80, min_Q_loss1: -51.40, min_Q_loss2: -29.93

Train epoch 142/3000 -- step 143000

[F                                                                                                    
[F[ Model Length ] Epoch: 142 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 142000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 142 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 142142
[ Model Rollout ] Added: 49035 | Model pool: 500000 (max 500000) | Length: 4.9035 | Train rep: 1

Diagnostics -- iteration 143000
real_batch_obs: 1811.29, model_batch_obs: 2041.54
real_batch_act: 200.81, model_batch_act: 196.29
real_batch_rewards: 1362.36, model_batch_rewards: 1351.00
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 1041.18
total_steps: 143000.00
Q-avg: 1691.64, Q-max: 2898.92, Q-min: -768.83
Q_loss1: 1659.24, Q_loss2: 2018.66, min_Q_loss1: -80.98, min_Q_loss2: -69.86

Train epoch 143/3000 -- step 144000

[F                                                                                                    
[F[ Model Length ] Epoch: 143 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 143000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 143 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 143143
[ Model Rollout ] Added: 49093 | Model pool: 500000 (max 500000) | Length: 4.9093 | Train rep: 1

Diagnostics -- iteration 144000
real_batch_obs: 1783.59, model_batch_obs: 1914.44
real_batch_act: 193.35, model_batch_act: 190.85
real_batch_rewards: 1315.86, model_batch_rewards: 1460.17
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 1082.75
total_steps: 144000.00
Q-avg: 1625.95, Q-max: 2959.27, Q-min: -1221.03
Q_loss1: 1906.50, Q_loss2: 1905.49, min_Q_loss1: -593.55, min_Q_loss2: -603.88

Train epoch 144/3000 -- step 145000

[F                                                                                                    
[F[ Model Length ] Epoch: 144 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 144000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 144 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 144144
[ Model Rollout ] Added: 49034 | Model pool: 500000 (max 500000) | Length: 4.9034 | Train rep: 1

Diagnostics -- iteration 145000
real_batch_obs: 1843.10, model_batch_obs: 1895.07
real_batch_act: 200.91, model_batch_act: 179.75
real_batch_rewards: 1365.60, model_batch_rewards: 1410.53
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 217.84
total_steps: 145000.00
Q-avg: 1555.22, Q-max: 2837.60, Q-min: -70.58
Q_loss1: 2838.96, Q_loss2: 3186.91, min_Q_loss1: -222.37, min_Q_loss2: -218.94

Train epoch 145/3000 -- step 146000

[F                                                                                                    
[F[ Model Length ] Epoch: 145 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 145000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 145 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 145145
[ Model Rollout ] Added: 49041 | Model pool: 500000 (max 500000) | Length: 4.9041 | Train rep: 1

Diagnostics -- iteration 146000
real_batch_obs: 1814.48, model_batch_obs: 1853.00
real_batch_act: 198.57, model_batch_act: 186.66
real_batch_rewards: 1308.62, model_batch_rewards: 1289.39
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 1053.93
total_steps: 146000.00
Q-avg: 1644.28, Q-max: 2924.23, Q-min: -668.05
Q_loss1: 1663.59, Q_loss2: 1796.54, min_Q_loss1: 138.83, min_Q_loss2: 129.98

Train epoch 146/3000 -- step 147000

[F                                                                                                    
[F[ Model Length ] Epoch: 146 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 146000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 146 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 146146
[ Model Rollout ] Added: 48988 | Model pool: 500000 (max 500000) | Length: 4.8988 | Train rep: 1

Diagnostics -- iteration 147000
real_batch_obs: 1847.36, model_batch_obs: 1926.12
real_batch_act: 188.03, model_batch_act: 192.94
real_batch_rewards: 1353.53, model_batch_rewards: 1306.17
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 549.01
total_steps: 147000.00
Q-avg: 1567.25, Q-max: 2713.46, Q-min: -737.07
Q_loss1: 1857.53, Q_loss2: 2287.07, min_Q_loss1: -3.01, min_Q_loss2: 8.50

Train epoch 147/3000 -- step 148000

[F                                                                                                    
[F[ Model Length ] Epoch: 147 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 147000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 147 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 147147
[ Model Rollout ] Added: 49107 | Model pool: 500000 (max 500000) | Length: 4.9107 | Train rep: 1

Diagnostics -- iteration 148000
real_batch_obs: 1857.04, model_batch_obs: 1946.18
real_batch_act: 198.69, model_batch_act: 178.89
real_batch_rewards: 1315.53, model_batch_rewards: 1329.30
real_batch_dones: 2.00, model_batch_dones: 3.00
evaluation/return-average: 226.25
total_steps: 148000.00
Q-avg: 1611.93, Q-max: 2687.65, Q-min: -839.46
Q_loss1: 2195.47, Q_loss2: 1923.39, min_Q_loss1: -337.79, min_Q_loss2: -329.76

Train epoch 148/3000 -- step 149000

[F                                                                                                    
[F[ Model Length ] Epoch: 148 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 148000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 148 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 148148
[ Model Rollout ] Added: 49070 | Model pool: 500000 (max 500000) | Length: 4.907 | Train rep: 1

Diagnostics -- iteration 149000
real_batch_obs: 1831.16, model_batch_obs: 1832.88
real_batch_act: 206.72, model_batch_act: 192.90
real_batch_rewards: 1407.92, model_batch_rewards: 1358.10
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 235.79
total_steps: 149000.00
Q-avg: 1600.26, Q-max: 2869.51, Q-min: -760.01
Q_loss1: 448.04, Q_loss2: 417.05, min_Q_loss1: 266.19, min_Q_loss2: 262.18

Train epoch 149/3000 -- step 150000

[F                                                                                                    
[F[ Model Length ] Epoch: 149 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 149000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 149 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 149149
[ Model Rollout ] Added: 49023 | Model pool: 500000 (max 500000) | Length: 4.9023 | Train rep: 1

Diagnostics -- iteration 150000
real_batch_obs: 1811.28, model_batch_obs: 1858.23
real_batch_act: 211.53, model_batch_act: 194.73
real_batch_rewards: 1336.65, model_batch_rewards: 1581.33
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 1052.45
total_steps: 150000.00
Q-avg: 1522.18, Q-max: 2662.45, Q-min: -1099.77
Q_loss1: 6670.36, Q_loss2: 6736.44, min_Q_loss1: -263.36, min_Q_loss2: -259.98

Train epoch 150/3000 -- step 151000

[F                                                                                                    
[F[ Model Length ] Epoch: 150 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 150000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 150 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 150150
[ Model Rollout ] Added: 49006 | Model pool: 500000 (max 500000) | Length: 4.9006 | Train rep: 1

Diagnostics -- iteration 151000
real_batch_obs: 1961.23, model_batch_obs: 1852.72
real_batch_act: 214.98, model_batch_act: 195.22
real_batch_rewards: 1343.82, model_batch_rewards: 1415.04
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 1272.56
total_steps: 151000.00
Q-avg: 1540.30, Q-max: 2615.88, Q-min: -1902.23
Q_loss1: 6561.13, Q_loss2: 5357.98, min_Q_loss1: 176.48, min_Q_loss2: 193.65

Train epoch 151/3000 -- step 152000

[F                                                                                                    
[F[ Model Length ] Epoch: 151 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 151000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 151 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 151151
[ Model Rollout ] Added: 49081 | Model pool: 500000 (max 500000) | Length: 4.9081 | Train rep: 1

Diagnostics -- iteration 152000
real_batch_obs: 1881.89, model_batch_obs: 1728.24
real_batch_act: 200.60, model_batch_act: 198.96
real_batch_rewards: 1342.49, model_batch_rewards: 1262.07
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 192.77
total_steps: 152000.00
Q-avg: 1548.01, Q-max: 2658.35, Q-min: -802.13
Q_loss1: 835.68, Q_loss2: 843.02, min_Q_loss1: -222.14, min_Q_loss2: -237.71

Train epoch 152/3000 -- step 153000

[F                                                                                                    
[F[ Model Length ] Epoch: 152 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 152000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 152 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 152152
[ Model Rollout ] Added: 49052 | Model pool: 500000 (max 500000) | Length: 4.9052 | Train rep: 1

Diagnostics -- iteration 153000
real_batch_obs: 1876.15, model_batch_obs: 1811.33
real_batch_act: 209.43, model_batch_act: 191.37
real_batch_rewards: 1325.42, model_batch_rewards: 1335.51
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 795.55
total_steps: 153000.00
Q-avg: 1536.77, Q-max: 2568.41, Q-min: -262.77
Q_loss1: 2044.05, Q_loss2: 2410.51, min_Q_loss1: -125.95, min_Q_loss2: -130.55

Train epoch 153/3000 -- step 154000

[F                                                                                                    
[F[ Model Length ] Epoch: 153 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 153000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 153 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 153153
[ Model Rollout ] Added: 49049 | Model pool: 500000 (max 500000) | Length: 4.9049 | Train rep: 1

Diagnostics -- iteration 154000
real_batch_obs: 1940.65, model_batch_obs: 1879.06
real_batch_act: 209.44, model_batch_act: 190.54
real_batch_rewards: 1344.08, model_batch_rewards: 1391.36
real_batch_dones: 3.00, model_batch_dones: 2.00
evaluation/return-average: 222.94
total_steps: 154000.00
Q-avg: 1504.68, Q-max: 2569.26, Q-min: -741.28
Q_loss1: 3281.30, Q_loss2: 2824.30, min_Q_loss1: -970.61, min_Q_loss2: -977.41

Train epoch 154/3000 -- step 155000

[F                                                                                                    
[F[ Model Length ] Epoch: 154 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 154000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 154 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 154154
[ Model Rollout ] Added: 49045 | Model pool: 500000 (max 500000) | Length: 4.9045 | Train rep: 1

Diagnostics -- iteration 155000
real_batch_obs: 1864.24, model_batch_obs: 1900.91
real_batch_act: 207.79, model_batch_act: 198.47
real_batch_rewards: 1318.33, model_batch_rewards: 1392.59
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 221.31
total_steps: 155000.00
Q-avg: 1485.44, Q-max: 2657.41, Q-min: -1922.62
Q_loss1: 8901.03, Q_loss2: 8207.09, min_Q_loss1: -423.38, min_Q_loss2: -420.29

Train epoch 155/3000 -- step 156000

[F                                                                                                    
[F[ Model Length ] Epoch: 155 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 155000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 155 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 155155
[ Model Rollout ] Added: 49012 | Model pool: 500000 (max 500000) | Length: 4.9012 | Train rep: 1

Diagnostics -- iteration 156000
real_batch_obs: 1881.96, model_batch_obs: 1857.82
real_batch_act: 198.09, model_batch_act: 196.14
real_batch_rewards: 1320.53, model_batch_rewards: 1294.74
real_batch_dones: 2.00, model_batch_dones: 0.00
evaluation/return-average: 179.34
total_steps: 156000.00
Q-avg: 1519.81, Q-max: 2627.38, Q-min: -157.00
Q_loss1: 706.89, Q_loss2: 829.87, min_Q_loss1: -182.57, min_Q_loss2: -189.22

Train epoch 156/3000 -- step 157000

[F                                                                                                    
[F[ Model Length ] Epoch: 156 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 156000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 156 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 156156
[ Model Rollout ] Added: 49021 | Model pool: 500000 (max 500000) | Length: 4.9021 | Train rep: 1

Diagnostics -- iteration 157000
real_batch_obs: 1825.61, model_batch_obs: 1880.68
real_batch_act: 195.46, model_batch_act: 183.28
real_batch_rewards: 1379.63, model_batch_rewards: 1301.86
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 206.95
total_steps: 157000.00
Q-avg: 1457.48, Q-max: 2449.34, Q-min: -290.28
Q_loss1: 893.77, Q_loss2: 971.43, min_Q_loss1: -82.70, min_Q_loss2: -80.73

Train epoch 157/3000 -- step 158000

[F                                                                                                    
[F[ Model Length ] Epoch: 157 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 157000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 157 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 157157
[ Model Rollout ] Added: 49038 | Model pool: 500000 (max 500000) | Length: 4.9038 | Train rep: 1

Diagnostics -- iteration 158000
real_batch_obs: 1766.29, model_batch_obs: 1896.16
real_batch_act: 192.85, model_batch_act: 177.47
real_batch_rewards: 1287.14, model_batch_rewards: 1385.42
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 227.38
total_steps: 158000.00
Q-avg: 1400.65, Q-max: 2474.04, Q-min: -683.37
Q_loss1: 983.28, Q_loss2: 1207.34, min_Q_loss1: -662.29, min_Q_loss2: -664.12

Train epoch 158/3000 -- step 159000

[F                                                                                                    
[F[ Model Length ] Epoch: 158 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 158000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 158 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 158158
[ Model Rollout ] Added: 48964 | Model pool: 500000 (max 500000) | Length: 4.8964 | Train rep: 1

Diagnostics -- iteration 159000
real_batch_obs: 1808.29, model_batch_obs: 1864.26
real_batch_act: 186.12, model_batch_act: 190.24
real_batch_rewards: 1315.54, model_batch_rewards: 1343.76
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 250.14
total_steps: 159000.00
Q-avg: 1430.42, Q-max: 2346.09, Q-min: -926.54
Q_loss1: 472.01, Q_loss2: 481.15, min_Q_loss1: -146.17, min_Q_loss2: -139.00

Train epoch 159/3000 -- step 160000

[F                                                                                                    
[F[ Model Length ] Epoch: 159 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 159000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 159 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 159159
[ Model Rollout ] Added: 48989 | Model pool: 500000 (max 500000) | Length: 4.8989 | Train rep: 1

Diagnostics -- iteration 160000
real_batch_obs: 1866.17, model_batch_obs: 1886.89
real_batch_act: 202.68, model_batch_act: 192.64
real_batch_rewards: 1336.89, model_batch_rewards: 1435.70
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 238.61
total_steps: 160000.00
Q-avg: 1465.30, Q-max: 2400.04, Q-min: -1942.70
Q_loss1: 8092.55, Q_loss2: 9773.31, min_Q_loss1: -152.59, min_Q_loss2: -153.27

Train epoch 160/3000 -- step 161000

[F                                                                                                    
[F[ Model Length ] Epoch: 160 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 160000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 160 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 160160
[ Model Rollout ] Added: 49011 | Model pool: 500000 (max 500000) | Length: 4.9011 | Train rep: 1

Diagnostics -- iteration 161000
real_batch_obs: 1842.06, model_batch_obs: 1843.95
real_batch_act: 202.14, model_batch_act: 200.07
real_batch_rewards: 1363.99, model_batch_rewards: 1312.55
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 246.33
total_steps: 161000.00
Q-avg: 1353.12, Q-max: 2342.67, Q-min: -770.49
Q_loss1: 1035.40, Q_loss2: 1417.77, min_Q_loss1: -332.81, min_Q_loss2: -331.18

Train epoch 161/3000 -- step 162000

[F                                                                                                    
[F[ Model Length ] Epoch: 161 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 161000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 161 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 161161
[ Model Rollout ] Added: 48976 | Model pool: 500000 (max 500000) | Length: 4.8976 | Train rep: 1

Diagnostics -- iteration 162000
real_batch_obs: 1887.17, model_batch_obs: 1988.73
real_batch_act: 207.71, model_batch_act: 191.82
real_batch_rewards: 1364.92, model_batch_rewards: 1402.03
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 239.92
total_steps: 162000.00
Q-avg: 1464.63, Q-max: 2305.19, Q-min: -196.90
Q_loss1: 405.16, Q_loss2: 534.79, min_Q_loss1: -152.86, min_Q_loss2: -159.25

Train epoch 162/3000 -- step 163000

[F                                                                                                    
[F[ Model Length ] Epoch: 162 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 162000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 162 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 162162
[ Model Rollout ] Added: 49026 | Model pool: 500000 (max 500000) | Length: 4.9026 | Train rep: 1

Diagnostics -- iteration 163000
real_batch_obs: 1819.40, model_batch_obs: 1874.04
real_batch_act: 191.59, model_batch_act: 202.36
real_batch_rewards: 1363.78, model_batch_rewards: 1403.76
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 233.13
total_steps: 163000.00
Q-avg: 1325.21, Q-max: 2313.67, Q-min: -350.27
Q_loss1: 670.48, Q_loss2: 516.93, min_Q_loss1: -158.87, min_Q_loss2: -148.95

Train epoch 163/3000 -- step 164000

[F                                                                                                    
[F[ Model Length ] Epoch: 163 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 163000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 163 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 163163
[ Model Rollout ] Added: 49074 | Model pool: 500000 (max 500000) | Length: 4.9074 | Train rep: 1

Diagnostics -- iteration 164000
real_batch_obs: 1774.23, model_batch_obs: 1921.44
real_batch_act: 192.30, model_batch_act: 178.83
real_batch_rewards: 1348.97, model_batch_rewards: 1362.62
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 215.08
total_steps: 164000.00
Q-avg: 1359.45, Q-max: 2293.28, Q-min: -284.04
Q_loss1: 1810.03, Q_loss2: 842.30, min_Q_loss1: -138.19, min_Q_loss2: -126.36

Train epoch 164/3000 -- step 165000

[F                                                                                                    
[F[ Model Length ] Epoch: 164 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 164000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 164 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 164164
[ Model Rollout ] Added: 48947 | Model pool: 500000 (max 500000) | Length: 4.8947 | Train rep: 1

Diagnostics -- iteration 165000
real_batch_obs: 1848.16, model_batch_obs: 1842.98
real_batch_act: 189.87, model_batch_act: 192.53
real_batch_rewards: 1366.24, model_batch_rewards: 1318.70
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 232.24
total_steps: 165000.00
Q-avg: 1324.23, Q-max: 2273.47, Q-min: -239.51
Q_loss1: 1758.08, Q_loss2: 1265.43, min_Q_loss1: -300.98, min_Q_loss2: -304.87

Train epoch 165/3000 -- step 166000

[F                                                                                                    
[F[ Model Length ] Epoch: 165 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 165000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 165 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 165165
[ Model Rollout ] Added: 49007 | Model pool: 500000 (max 500000) | Length: 4.9007 | Train rep: 1

Diagnostics -- iteration 166000
real_batch_obs: 1904.39, model_batch_obs: 1992.97
real_batch_act: 201.53, model_batch_act: 196.14
real_batch_rewards: 1357.98, model_batch_rewards: 1331.38
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 218.01
total_steps: 166000.00
Q-avg: 1393.10, Q-max: 2241.00, Q-min: -526.10
Q_loss1: 9931.39, Q_loss2: 9772.06, min_Q_loss1: -86.63, min_Q_loss2: -85.30

Train epoch 166/3000 -- step 167000

[F                                                                                                    
[F[ Model Length ] Epoch: 166 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 166000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 166 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 166166
[ Model Rollout ] Added: 48986 | Model pool: 500000 (max 500000) | Length: 4.8986 | Train rep: 1

Diagnostics -- iteration 167000
real_batch_obs: 1915.93, model_batch_obs: 1869.94
real_batch_act: 210.11, model_batch_act: 190.33
real_batch_rewards: 1366.30, model_batch_rewards: 1320.58
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 233.09
total_steps: 167000.00
Q-avg: 1366.12, Q-max: 2135.45, Q-min: -962.72
Q_loss1: 1605.97, Q_loss2: 1423.13, min_Q_loss1: -250.16, min_Q_loss2: -251.07

Train epoch 167/3000 -- step 168000

[F                                                                                                    
[F[ Model Length ] Epoch: 167 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 167000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 167 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 167167
[ Model Rollout ] Added: 48961 | Model pool: 500000 (max 500000) | Length: 4.8961 | Train rep: 1

Diagnostics -- iteration 168000
real_batch_obs: 1780.13, model_batch_obs: 1907.62
real_batch_act: 203.81, model_batch_act: 187.14
real_batch_rewards: 1328.80, model_batch_rewards: 1307.61
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 231.02
total_steps: 168000.00
Q-avg: 1346.41, Q-max: 2206.91, Q-min: -614.37
Q_loss1: 564.22, Q_loss2: 789.23, min_Q_loss1: -329.65, min_Q_loss2: -314.39

Train epoch 168/3000 -- step 169000

[F                                                                                                    
[F[ Model Length ] Epoch: 168 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 168000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 168 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 168168
[ Model Rollout ] Added: 49079 | Model pool: 500000 (max 500000) | Length: 4.9079 | Train rep: 1

Diagnostics -- iteration 169000
real_batch_obs: 1884.68, model_batch_obs: 1862.73
real_batch_act: 197.62, model_batch_act: 195.14
real_batch_rewards: 1294.64, model_batch_rewards: 1367.88
real_batch_dones: 2.00, model_batch_dones: 1.00
evaluation/return-average: 250.20
total_steps: 169000.00
Q-avg: 1400.81, Q-max: 2168.55, Q-min: -149.73
Q_loss1: 1077.12, Q_loss2: 1008.40, min_Q_loss1: -407.78, min_Q_loss2: -407.98

Train epoch 169/3000 -- step 170000

[F                                                                                                    
[F[ Model Length ] Epoch: 169 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 169000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 169 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 169169
[ Model Rollout ] Added: 49055 | Model pool: 500000 (max 500000) | Length: 4.9055 | Train rep: 1

Diagnostics -- iteration 170000
real_batch_obs: 1695.20, model_batch_obs: 1969.23
real_batch_act: 185.37, model_batch_act: 192.17
real_batch_rewards: 1332.84, model_batch_rewards: 1443.72
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 249.02
total_steps: 170000.00
Q-avg: 1349.82, Q-max: 2254.81, Q-min: -984.25
Q_loss1: 3059.34, Q_loss2: 2846.83, min_Q_loss1: -485.67, min_Q_loss2: -475.64

Train epoch 170/3000 -- step 171000

[F                                                                                                    
[F[ Model Length ] Epoch: 170 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 170000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 170 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 170170
[ Model Rollout ] Added: 49031 | Model pool: 500000 (max 500000) | Length: 4.9031 | Train rep: 1

Diagnostics -- iteration 171000
real_batch_obs: 1866.26, model_batch_obs: 1867.46
real_batch_act: 193.15, model_batch_act: 196.48
real_batch_rewards: 1286.06, model_batch_rewards: 1404.08
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 255.25
total_steps: 171000.00
Q-avg: 1420.94, Q-max: 2166.26, Q-min: -389.34
Q_loss1: 8098.62, Q_loss2: 8284.07, min_Q_loss1: -548.65, min_Q_loss2: -535.84

Train epoch 171/3000 -- step 172000

[F                                                                                                    
[F[ Model Length ] Epoch: 171 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 171000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 171 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 171171
[ Model Rollout ] Added: 48985 | Model pool: 500000 (max 500000) | Length: 4.8985 | Train rep: 1

Diagnostics -- iteration 172000
real_batch_obs: 1804.29, model_batch_obs: 1882.83
real_batch_act: 197.13, model_batch_act: 192.69
real_batch_rewards: 1408.37, model_batch_rewards: 1361.88
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 241.28
total_steps: 172000.00
Q-avg: 1261.23, Q-max: 2163.47, Q-min: -1299.11
Q_loss1: 5672.23, Q_loss2: 6378.73, min_Q_loss1: -229.53, min_Q_loss2: -206.26

Train epoch 172/3000 -- step 173000

[F                                                                                                    
[F[ Model Length ] Epoch: 172 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 172000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 172 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 172172
[ Model Rollout ] Added: 48986 | Model pool: 500000 (max 500000) | Length: 4.8986 | Train rep: 1

Diagnostics -- iteration 173000
real_batch_obs: 1885.11, model_batch_obs: 1872.91
real_batch_act: 197.48, model_batch_act: 190.62
real_batch_rewards: 1350.45, model_batch_rewards: 1351.90
real_batch_dones: 2.00, model_batch_dones: 1.00
evaluation/return-average: 251.14
total_steps: 173000.00
Q-avg: 1269.14, Q-max: 2102.54, Q-min: -1255.54
Q_loss1: 8757.59, Q_loss2: 8447.63, min_Q_loss1: -291.27, min_Q_loss2: -270.05

Train epoch 173/3000 -- step 174000

[F                                                                                                    
[F[ Model Length ] Epoch: 173 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 173000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 173 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 173173
[ Model Rollout ] Added: 48908 | Model pool: 500000 (max 500000) | Length: 4.8908 | Train rep: 1

Diagnostics -- iteration 174000
real_batch_obs: 1765.10, model_batch_obs: 1819.40
real_batch_act: 195.81, model_batch_act: 189.34
real_batch_rewards: 1354.91, model_batch_rewards: 1408.02
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 239.68
total_steps: 174000.00
Q-avg: 1302.00, Q-max: 2132.75, Q-min: -525.76
Q_loss1: 520.89, Q_loss2: 483.12, min_Q_loss1: -150.62, min_Q_loss2: -146.38

Train epoch 174/3000 -- step 175000

[F                                                                                                    
[F[ Model Length ] Epoch: 174 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 174000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 174 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 174174
[ Model Rollout ] Added: 49056 | Model pool: 500000 (max 500000) | Length: 4.9056 | Train rep: 1

Diagnostics -- iteration 175000
real_batch_obs: 1928.71, model_batch_obs: 1801.92
real_batch_act: 199.38, model_batch_act: 195.83
real_batch_rewards: 1362.47, model_batch_rewards: 1325.83
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 246.18
total_steps: 175000.00
Q-avg: 1351.37, Q-max: 2157.82, Q-min: -756.46
Q_loss1: 683.30, Q_loss2: 684.55, min_Q_loss1: 8.16, min_Q_loss2: 7.33

Train epoch 175/3000 -- step 176000

[F                                                                                                    
[F[ Model Length ] Epoch: 175 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 175000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 175 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 175175
[ Model Rollout ] Added: 48940 | Model pool: 500000 (max 500000) | Length: 4.894 | Train rep: 1

Diagnostics -- iteration 176000
real_batch_obs: 1770.28, model_batch_obs: 1790.00
real_batch_act: 187.56, model_batch_act: 190.59
real_batch_rewards: 1307.94, model_batch_rewards: 1321.51
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 239.54
total_steps: 176000.00
Q-avg: 1411.44, Q-max: 2040.36, Q-min: -1409.19
Q_loss1: 372.48, Q_loss2: 493.42, min_Q_loss1: -475.32, min_Q_loss2: -479.17

Train epoch 176/3000 -- step 177000

[F                                                                                                    
[F[ Model Length ] Epoch: 176 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 176000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 176 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 176176
[ Model Rollout ] Added: 49031 | Model pool: 500000 (max 500000) | Length: 4.9031 | Train rep: 1

Diagnostics -- iteration 177000
real_batch_obs: 1846.55, model_batch_obs: 1931.53
real_batch_act: 202.59, model_batch_act: 196.61
real_batch_rewards: 1312.18, model_batch_rewards: 1387.80
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 244.35
total_steps: 177000.00
Q-avg: 1254.71, Q-max: 2011.30, Q-min: -2032.93
Q_loss1: 4982.17, Q_loss2: 5489.23, min_Q_loss1: -547.18, min_Q_loss2: -533.48

Train epoch 177/3000 -- step 178000

[F                                                                                                    
[F[ Model Length ] Epoch: 177 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 177000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 177 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 177177
[ Model Rollout ] Added: 48933 | Model pool: 500000 (max 500000) | Length: 4.8933 | Train rep: 1

Diagnostics -- iteration 178000
real_batch_obs: 1904.84, model_batch_obs: 1861.43
real_batch_act: 195.82, model_batch_act: 199.55
real_batch_rewards: 1319.84, model_batch_rewards: 1321.41
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 250.02
total_steps: 178000.00
Q-avg: 1338.43, Q-max: 2126.19, Q-min: -373.51
Q_loss1: 864.74, Q_loss2: 1151.46, min_Q_loss1: -48.66, min_Q_loss2: -34.00

Train epoch 178/3000 -- step 179000

[F                                                                                                    
[F[ Model Length ] Epoch: 178 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 178000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 178 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 178178
[ Model Rollout ] Added: 49001 | Model pool: 500000 (max 500000) | Length: 4.9001 | Train rep: 1

Diagnostics -- iteration 179000
real_batch_obs: 1832.06, model_batch_obs: 1960.41
real_batch_act: 196.05, model_batch_act: 188.45
real_batch_rewards: 1353.22, model_batch_rewards: 1379.23
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 254.18
total_steps: 179000.00
Q-avg: 1331.35, Q-max: 1997.97, Q-min: -661.04
Q_loss1: 863.96, Q_loss2: 652.70, min_Q_loss1: -171.60, min_Q_loss2: -167.46

Train epoch 179/3000 -- step 180000

[F                                                                                                    
[F[ Model Length ] Epoch: 179 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 179000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 179 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 179179
[ Model Rollout ] Added: 49074 | Model pool: 500000 (max 500000) | Length: 4.9074 | Train rep: 1

Diagnostics -- iteration 180000
real_batch_obs: 1764.37, model_batch_obs: 1929.39
real_batch_act: 204.20, model_batch_act: 190.67
real_batch_rewards: 1330.66, model_batch_rewards: 1325.62
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 237.38
total_steps: 180000.00
Q-avg: 1319.52, Q-max: 2028.56, Q-min: -892.08
Q_loss1: 1334.88, Q_loss2: 1454.80, min_Q_loss1: -563.31, min_Q_loss2: -569.12

Train epoch 180/3000 -- step 181000

[F                                                                                                    
[F[ Model Length ] Epoch: 180 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 180000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 180 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 180180
[ Model Rollout ] Added: 48882 | Model pool: 500000 (max 500000) | Length: 4.8882 | Train rep: 1

Diagnostics -- iteration 181000
real_batch_obs: 1871.04, model_batch_obs: 2036.00
real_batch_act: 189.26, model_batch_act: 199.97
real_batch_rewards: 1396.47, model_batch_rewards: 1375.75
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 256.34
total_steps: 181000.00
Q-avg: 1282.20, Q-max: 1983.20, Q-min: -631.25
Q_loss1: 1540.71, Q_loss2: 1493.18, min_Q_loss1: -102.34, min_Q_loss2: -90.73

Train epoch 181/3000 -- step 182000

[F                                                                                                    
[F[ Model Length ] Epoch: 181 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 181000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 181 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 181181
[ Model Rollout ] Added: 48992 | Model pool: 500000 (max 500000) | Length: 4.8992 | Train rep: 1

Diagnostics -- iteration 182000
real_batch_obs: 1878.27, model_batch_obs: 1881.59
real_batch_act: 195.26, model_batch_act: 192.51
real_batch_rewards: 1284.48, model_batch_rewards: 1330.73
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 246.02
total_steps: 182000.00
Q-avg: 1304.52, Q-max: 1958.04, Q-min: -1428.96
Q_loss1: 2059.61, Q_loss2: 1960.04, min_Q_loss1: -505.67, min_Q_loss2: -490.72

Train epoch 182/3000 -- step 183000

[F                                                                                                    
[F[ Model Length ] Epoch: 182 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 182000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 182 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 182182
[ Model Rollout ] Added: 49046 | Model pool: 500000 (max 500000) | Length: 4.9046 | Train rep: 1

Diagnostics -- iteration 183000
real_batch_obs: 1749.63, model_batch_obs: 1947.64
real_batch_act: 200.42, model_batch_act: 190.03
real_batch_rewards: 1297.03, model_batch_rewards: 1377.93
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 246.82
total_steps: 183000.00
Q-avg: 1266.90, Q-max: 1941.62, Q-min: -381.69
Q_loss1: 847.91, Q_loss2: 874.84, min_Q_loss1: -413.71, min_Q_loss2: -387.27

Train epoch 183/3000 -- step 184000

[F                                                                                                    
[F[ Model Length ] Epoch: 183 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 183000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 183 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 183183
[ Model Rollout ] Added: 48979 | Model pool: 500000 (max 500000) | Length: 4.8979 | Train rep: 1

Diagnostics -- iteration 184000
real_batch_obs: 1802.34, model_batch_obs: 1845.93
real_batch_act: 195.76, model_batch_act: 177.40
real_batch_rewards: 1326.95, model_batch_rewards: 1327.02
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 263.28
total_steps: 184000.00
Q-avg: 1294.59, Q-max: 1931.19, Q-min: -764.27
Q_loss1: 6338.80, Q_loss2: 7056.46, min_Q_loss1: -370.84, min_Q_loss2: -382.32

Train epoch 184/3000 -- step 185000

[F                                                                                                    
[F[ Model Length ] Epoch: 184 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 184000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 184 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 184184
[ Model Rollout ] Added: 49033 | Model pool: 500000 (max 500000) | Length: 4.9033 | Train rep: 1

Diagnostics -- iteration 185000
real_batch_obs: 1814.80, model_batch_obs: 1938.69
real_batch_act: 202.93, model_batch_act: 195.23
real_batch_rewards: 1346.37, model_batch_rewards: 1353.04
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 244.12
total_steps: 185000.00
Q-avg: 1292.07, Q-max: 1894.97, Q-min: -1204.38
Q_loss1: 475.27, Q_loss2: 554.01, min_Q_loss1: -79.11, min_Q_loss2: -82.58

Train epoch 185/3000 -- step 186000

[F                                                                                                    
[F[ Model Length ] Epoch: 185 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 185000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 185 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 185185
[ Model Rollout ] Added: 48951 | Model pool: 500000 (max 500000) | Length: 4.8951 | Train rep: 1

Diagnostics -- iteration 186000
real_batch_obs: 1918.75, model_batch_obs: 1891.66
real_batch_act: 195.01, model_batch_act: 187.15
real_batch_rewards: 1298.65, model_batch_rewards: 1313.35
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 263.83
total_steps: 186000.00
Q-avg: 1262.43, Q-max: 1962.92, Q-min: -307.27
Q_loss1: 504.35, Q_loss2: 542.43, min_Q_loss1: -170.33, min_Q_loss2: -173.30

Train epoch 186/3000 -- step 187000

[F                                                                                                    
[F[ Model Length ] Epoch: 186 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 186000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 186 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 186186
[ Model Rollout ] Added: 49061 | Model pool: 500000 (max 500000) | Length: 4.9061 | Train rep: 1

Diagnostics -- iteration 187000
real_batch_obs: 1824.39, model_batch_obs: 1841.40
real_batch_act: 189.91, model_batch_act: 196.75
real_batch_rewards: 1331.67, model_batch_rewards: 1305.90
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 264.23
total_steps: 187000.00
Q-avg: 1241.78, Q-max: 1976.06, Q-min: -278.61
Q_loss1: 609.23, Q_loss2: 536.37, min_Q_loss1: 2.81, min_Q_loss2: 16.30

Train epoch 187/3000 -- step 188000

[F                                                                                                    
[F[ Model Length ] Epoch: 187 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 187000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 187 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 187187
[ Model Rollout ] Added: 48987 | Model pool: 500000 (max 500000) | Length: 4.8987 | Train rep: 1

Diagnostics -- iteration 188000
real_batch_obs: 1803.26, model_batch_obs: 1830.07
real_batch_act: 206.93, model_batch_act: 181.54
real_batch_rewards: 1355.54, model_batch_rewards: 1320.25
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 250.59
total_steps: 188000.00
Q-avg: 1287.55, Q-max: 1979.48, Q-min: -1366.24
Q_loss1: 589.69, Q_loss2: 523.62, min_Q_loss1: 48.96, min_Q_loss2: 52.46

Train epoch 188/3000 -- step 189000

[F                                                                                                    
[F[ Model Length ] Epoch: 188 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 188000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 188 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 188188
[ Model Rollout ] Added: 49142 | Model pool: 500000 (max 500000) | Length: 4.9142 | Train rep: 1

Diagnostics -- iteration 189000
real_batch_obs: 1763.56, model_batch_obs: 1881.52
real_batch_act: 191.44, model_batch_act: 191.38
real_batch_rewards: 1316.09, model_batch_rewards: 1336.80
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 249.77
total_steps: 189000.00
Q-avg: 1299.97, Q-max: 2076.51, Q-min: -143.14
Q_loss1: 329.33, Q_loss2: 361.99, min_Q_loss1: 64.23, min_Q_loss2: 64.99

Train epoch 189/3000 -- step 190000

[F                                                                                                    
[F[ Model Length ] Epoch: 189 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 189000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 189 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 189189
[ Model Rollout ] Added: 49018 | Model pool: 500000 (max 500000) | Length: 4.9018 | Train rep: 1

Diagnostics -- iteration 190000
real_batch_obs: 1858.32, model_batch_obs: 1905.47
real_batch_act: 207.97, model_batch_act: 193.60
real_batch_rewards: 1358.17, model_batch_rewards: 1322.37
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 241.07
total_steps: 190000.00
Q-avg: 1281.41, Q-max: 2038.39, Q-min: -536.25
Q_loss1: 444.57, Q_loss2: 548.74, min_Q_loss1: -204.83, min_Q_loss2: -208.77

Train epoch 190/3000 -- step 191000

[F                                                                                                    
[F[ Model Length ] Epoch: 190 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 190000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 190 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 190190
[ Model Rollout ] Added: 48979 | Model pool: 500000 (max 500000) | Length: 4.8979 | Train rep: 1

Diagnostics -- iteration 191000
real_batch_obs: 1897.67, model_batch_obs: 1943.65
real_batch_act: 205.97, model_batch_act: 190.57
real_batch_rewards: 1358.29, model_batch_rewards: 1397.73
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 247.39
total_steps: 191000.00
Q-avg: 1184.64, Q-max: 1827.62, Q-min: -2726.35
Q_loss1: 1075.18, Q_loss2: 1150.90, min_Q_loss1: -324.38, min_Q_loss2: -327.37

Train epoch 191/3000 -- step 192000

[F                                                                                                    
[F[ Model Length ] Epoch: 191 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 191000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 191 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 191191
[ Model Rollout ] Added: 48980 | Model pool: 500000 (max 500000) | Length: 4.898 | Train rep: 1

Diagnostics -- iteration 192000
real_batch_obs: 1821.30, model_batch_obs: 1834.19
real_batch_act: 203.94, model_batch_act: 193.23
real_batch_rewards: 1343.57, model_batch_rewards: 1303.30
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 248.87
total_steps: 192000.00
Q-avg: 1280.12, Q-max: 1887.66, Q-min: -193.01
Q_loss1: 1221.16, Q_loss2: 1215.48, min_Q_loss1: 4.39, min_Q_loss2: 3.68

Train epoch 192/3000 -- step 193000

[F                                                                                                    
[F[ Model Length ] Epoch: 192 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 192000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 192 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 192192
[ Model Rollout ] Added: 49059 | Model pool: 500000 (max 500000) | Length: 4.9059 | Train rep: 1

Diagnostics -- iteration 193000
real_batch_obs: 1888.22, model_batch_obs: 1968.65
real_batch_act: 207.37, model_batch_act: 189.87
real_batch_rewards: 1382.83, model_batch_rewards: 1329.13
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 266.20
total_steps: 193000.00
Q-avg: 1229.08, Q-max: 1986.20, Q-min: -550.43
Q_loss1: 248.46, Q_loss2: 276.89, min_Q_loss1: 76.36, min_Q_loss2: 86.35

Train epoch 193/3000 -- step 194000

[F                                                                                                    
[F[ Model Length ] Epoch: 193 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 193000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 193 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 193193
[ Model Rollout ] Added: 49077 | Model pool: 500000 (max 500000) | Length: 4.9077 | Train rep: 1

Diagnostics -- iteration 194000
real_batch_obs: 1818.38, model_batch_obs: 1991.81
real_batch_act: 204.12, model_batch_act: 202.93
real_batch_rewards: 1317.12, model_batch_rewards: 1381.36
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 258.91
total_steps: 194000.00
Q-avg: 1240.52, Q-max: 1923.21, Q-min: -825.08
Q_loss1: 1007.26, Q_loss2: 777.16, min_Q_loss1: -116.21, min_Q_loss2: -119.11

Train epoch 194/3000 -- step 195000

[F                                                                                                    
[F[ Model Length ] Epoch: 194 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 194000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 194 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 194194
[ Model Rollout ] Added: 49069 | Model pool: 500000 (max 500000) | Length: 4.9069 | Train rep: 1

Diagnostics -- iteration 195000
real_batch_obs: 1802.77, model_batch_obs: 1908.66
real_batch_act: 192.36, model_batch_act: 183.83
real_batch_rewards: 1294.81, model_batch_rewards: 1332.79
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 248.13
total_steps: 195000.00
Q-avg: 1244.99, Q-max: 1990.86, Q-min: -1265.85
Q_loss1: 2245.38, Q_loss2: 877.30, min_Q_loss1: -699.72, min_Q_loss2: -684.60

Train epoch 195/3000 -- step 196000

[F                                                                                                    
[F[ Model Length ] Epoch: 195 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 195000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 195 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 195195
[ Model Rollout ] Added: 48966 | Model pool: 500000 (max 500000) | Length: 4.8966 | Train rep: 1

Diagnostics -- iteration 196000
real_batch_obs: 1903.11, model_batch_obs: 1904.88
real_batch_act: 193.96, model_batch_act: 187.70
real_batch_rewards: 1382.73, model_batch_rewards: 1358.38
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 239.22
total_steps: 196000.00
Q-avg: 1254.02, Q-max: 1915.70, Q-min: -1003.51
Q_loss1: 3048.31, Q_loss2: 2408.55, min_Q_loss1: -117.60, min_Q_loss2: -126.67

Train epoch 196/3000 -- step 197000

[F                                                                                                    
[F[ Model Length ] Epoch: 196 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 196000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 196 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 196196
[ Model Rollout ] Added: 48980 | Model pool: 500000 (max 500000) | Length: 4.898 | Train rep: 1

Diagnostics -- iteration 197000
real_batch_obs: 1842.92, model_batch_obs: 1824.24
real_batch_act: 203.73, model_batch_act: 187.23
real_batch_rewards: 1379.13, model_batch_rewards: 1344.88
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 223.71
total_steps: 197000.00
Q-avg: 1168.70, Q-max: 1932.84, Q-min: -256.60
Q_loss1: 815.58, Q_loss2: 718.95, min_Q_loss1: -305.59, min_Q_loss2: -297.12

Train epoch 197/3000 -- step 198000

[F                                                                                                    
[F[ Model Length ] Epoch: 197 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 197000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 197 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 197197
[ Model Rollout ] Added: 49133 | Model pool: 500000 (max 500000) | Length: 4.9133 | Train rep: 1

Diagnostics -- iteration 198000
real_batch_obs: 1852.33, model_batch_obs: 1880.11
real_batch_act: 208.68, model_batch_act: 190.76
real_batch_rewards: 1321.98, model_batch_rewards: 1399.23
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 236.46
total_steps: 198000.00
Q-avg: 1193.74, Q-max: 1915.44, Q-min: -573.97
Q_loss1: 1245.76, Q_loss2: 2943.53, min_Q_loss1: 68.41, min_Q_loss2: 68.83

Train epoch 198/3000 -- step 199000

[F                                                                                                    
[F[ Model Length ] Epoch: 198 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 198000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 198 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 198198
[ Model Rollout ] Added: 49115 | Model pool: 500000 (max 500000) | Length: 4.9115 | Train rep: 1

Diagnostics -- iteration 199000
real_batch_obs: 1801.00, model_batch_obs: 1909.98
real_batch_act: 200.55, model_batch_act: 192.35
real_batch_rewards: 1298.41, model_batch_rewards: 1268.66
real_batch_dones: 2.00, model_batch_dones: 3.00
evaluation/return-average: 243.35
total_steps: 199000.00
Q-avg: 1187.50, Q-max: 1946.58, Q-min: -603.99
Q_loss1: 401.58, Q_loss2: 345.77, min_Q_loss1: -275.86, min_Q_loss2: -274.27

Train epoch 199/3000 -- step 200000

[F                                                                                                    
[F[ Model Length ] Epoch: 199 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 199000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 199 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 199199
[ Model Rollout ] Added: 49032 | Model pool: 500000 (max 500000) | Length: 4.9032 | Train rep: 1

Diagnostics -- iteration 200000
real_batch_obs: 1838.08, model_batch_obs: 1896.69
real_batch_act: 202.14, model_batch_act: 191.52
real_batch_rewards: 1368.41, model_batch_rewards: 1347.39
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 238.69
total_steps: 200000.00
Q-avg: 1202.08, Q-max: 1851.86, Q-min: -90.92
Q_loss1: 774.46, Q_loss2: 563.86, min_Q_loss1: 41.14, min_Q_loss2: 37.87

Train epoch 200/3000 -- step 201000

[F                                                                                                    
[F[ Model Length ] Epoch: 200 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 200000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 200 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 200200
[ Model Rollout ] Added: 49010 | Model pool: 500000 (max 500000) | Length: 4.901 | Train rep: 1

Diagnostics -- iteration 201000
real_batch_obs: 1853.55, model_batch_obs: 1883.00
real_batch_act: 200.21, model_batch_act: 186.62
real_batch_rewards: 1352.24, model_batch_rewards: 1344.50
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 254.74
total_steps: 201000.00
Q-avg: 1242.26, Q-max: 1864.62, Q-min: -496.97
Q_loss1: 480.13, Q_loss2: 598.96, min_Q_loss1: -249.48, min_Q_loss2: -257.58

Train epoch 201/3000 -- step 202000

[F                                                                                                    
[F[ Model Length ] Epoch: 201 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 201000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 201 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 201201
[ Model Rollout ] Added: 49038 | Model pool: 500000 (max 500000) | Length: 4.9038 | Train rep: 1

Diagnostics -- iteration 202000
real_batch_obs: 1855.24, model_batch_obs: 1909.77
real_batch_act: 198.93, model_batch_act: 184.33
real_batch_rewards: 1387.78, model_batch_rewards: 1354.56
real_batch_dones: 0.00, model_batch_dones: 5.00
evaluation/return-average: 240.73
total_steps: 202000.00
Q-avg: 1230.04, Q-max: 1885.25, Q-min: -343.55
Q_loss1: 2538.69, Q_loss2: 3111.89, min_Q_loss1: -242.86, min_Q_loss2: -237.15

Train epoch 202/3000 -- step 203000

[F                                                                                                    
[F[ Model Length ] Epoch: 202 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 202000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 202 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 202202
[ Model Rollout ] Added: 49066 | Model pool: 500000 (max 500000) | Length: 4.9066 | Train rep: 1

Diagnostics -- iteration 203000
real_batch_obs: 1861.56, model_batch_obs: 1937.86
real_batch_act: 201.87, model_batch_act: 193.27
real_batch_rewards: 1302.17, model_batch_rewards: 1394.46
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 237.12
total_steps: 203000.00
Q-avg: 1223.67, Q-max: 1934.10, Q-min: -233.85
Q_loss1: 287.82, Q_loss2: 254.46, min_Q_loss1: -97.59, min_Q_loss2: -93.14

Train epoch 203/3000 -- step 204000

[F                                                                                                    
[F[ Model Length ] Epoch: 203 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 203000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 203 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 203203
[ Model Rollout ] Added: 49103 | Model pool: 500000 (max 500000) | Length: 4.9103 | Train rep: 1

Diagnostics -- iteration 204000
real_batch_obs: 1846.34, model_batch_obs: 1843.27
real_batch_act: 204.64, model_batch_act: 184.44
real_batch_rewards: 1373.77, model_batch_rewards: 1287.76
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 222.69
total_steps: 204000.00
Q-avg: 1215.45, Q-max: 1933.62, Q-min: -654.32
Q_loss1: 2708.78, Q_loss2: 2759.56, min_Q_loss1: -169.23, min_Q_loss2: -161.37

Train epoch 204/3000 -- step 205000

[F                                                                                                    
[F[ Model Length ] Epoch: 204 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 204000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 204 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 204204
[ Model Rollout ] Added: 49031 | Model pool: 500000 (max 500000) | Length: 4.9031 | Train rep: 1

Diagnostics -- iteration 205000
real_batch_obs: 1984.70, model_batch_obs: 1937.17
real_batch_act: 204.65, model_batch_act: 190.38
real_batch_rewards: 1345.03, model_batch_rewards: 1376.86
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 231.69
total_steps: 205000.00
Q-avg: 1182.78, Q-max: 1888.00, Q-min: -748.69
Q_loss1: 2324.45, Q_loss2: 2100.24, min_Q_loss1: -308.64, min_Q_loss2: -302.65

Train epoch 205/3000 -- step 206000

[F                                                                                                    
[F[ Model Length ] Epoch: 205 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 205000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 205 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 205205
[ Model Rollout ] Added: 49014 | Model pool: 500000 (max 500000) | Length: 4.9014 | Train rep: 1

Diagnostics -- iteration 206000
real_batch_obs: 1906.00, model_batch_obs: 1946.28
real_batch_act: 201.10, model_batch_act: 190.87
real_batch_rewards: 1350.07, model_batch_rewards: 1344.68
real_batch_dones: 1.00, model_batch_dones: 4.00
evaluation/return-average: 269.27
total_steps: 206000.00
Q-avg: 1173.09, Q-max: 1905.21, Q-min: -455.37
Q_loss1: 863.20, Q_loss2: 837.46, min_Q_loss1: -429.51, min_Q_loss2: -429.16

Train epoch 206/3000 -- step 207000

[F                                                                                                    
[F[ Model Length ] Epoch: 206 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 206000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 206 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 206206
[ Model Rollout ] Added: 49071 | Model pool: 500000 (max 500000) | Length: 4.9071 | Train rep: 1

Diagnostics -- iteration 207000
real_batch_obs: 1919.46, model_batch_obs: 1893.93
real_batch_act: 193.17, model_batch_act: 194.63
real_batch_rewards: 1407.57, model_batch_rewards: 1267.43
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 262.73
total_steps: 207000.00
Q-avg: 1210.10, Q-max: 1942.53, Q-min: -258.28
Q_loss1: 598.65, Q_loss2: 556.88, min_Q_loss1: -76.10, min_Q_loss2: -55.03

Train epoch 207/3000 -- step 208000

[F                                                                                                    
[F[ Model Length ] Epoch: 207 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 207000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 207 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 207207
[ Model Rollout ] Added: 49082 | Model pool: 500000 (max 500000) | Length: 4.9082 | Train rep: 1

Diagnostics -- iteration 208000
real_batch_obs: 1784.73, model_batch_obs: 1901.80
real_batch_act: 192.14, model_batch_act: 200.52
real_batch_rewards: 1333.81, model_batch_rewards: 1356.65
real_batch_dones: 2.00, model_batch_dones: 2.00
evaluation/return-average: 262.94
total_steps: 208000.00
Q-avg: 1219.01, Q-max: 1983.28, Q-min: -331.91
Q_loss1: 939.33, Q_loss2: 933.50, min_Q_loss1: -151.41, min_Q_loss2: -160.01

Train epoch 208/3000 -- step 209000

[F                                                                                                    
[F[ Model Length ] Epoch: 208 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 208000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 208 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 208208
[ Model Rollout ] Added: 48994 | Model pool: 500000 (max 500000) | Length: 4.8994 | Train rep: 1

Diagnostics -- iteration 209000
real_batch_obs: 1903.38, model_batch_obs: 1894.14
real_batch_act: 196.62, model_batch_act: 188.87
real_batch_rewards: 1351.82, model_batch_rewards: 1335.10
real_batch_dones: 0.00, model_batch_dones: 5.00
evaluation/return-average: 242.61
total_steps: 209000.00
Q-avg: 1187.91, Q-max: 1850.86, Q-min: -95.80
Q_loss1: 195.64, Q_loss2: 231.52, min_Q_loss1: -278.27, min_Q_loss2: -279.94

Train epoch 209/3000 -- step 210000

[F                                                                                                    
[F[ Model Length ] Epoch: 209 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 209000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 209 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 209209
[ Model Rollout ] Added: 49047 | Model pool: 500000 (max 500000) | Length: 4.9047 | Train rep: 1

Diagnostics -- iteration 210000
real_batch_obs: 1888.57, model_batch_obs: 1918.38
real_batch_act: 198.01, model_batch_act: 181.95
real_batch_rewards: 1387.78, model_batch_rewards: 1344.74
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 258.93
total_steps: 210000.00
Q-avg: 1210.34, Q-max: 1869.07, Q-min: 9.47
Q_loss1: 754.28, Q_loss2: 652.54, min_Q_loss1: -105.67, min_Q_loss2: -105.03

Train epoch 210/3000 -- step 211000

[F                                                                                                    
[F[ Model Length ] Epoch: 210 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 210000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 210 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 210210
[ Model Rollout ] Added: 48903 | Model pool: 500000 (max 500000) | Length: 4.8903 | Train rep: 1

Diagnostics -- iteration 211000
real_batch_obs: 1829.74, model_batch_obs: 1898.16
real_batch_act: 199.09, model_batch_act: 193.03
real_batch_rewards: 1376.83, model_batch_rewards: 1346.98
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 331.58
total_steps: 211000.00
Q-avg: 1161.40, Q-max: 1908.19, Q-min: -605.64
Q_loss1: 5053.31, Q_loss2: 4934.56, min_Q_loss1: -36.40, min_Q_loss2: -20.50

Train epoch 211/3000 -- step 212000

[F                                                                                                    
[F[ Model Length ] Epoch: 211 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 211000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 211 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 211211
[ Model Rollout ] Added: 49028 | Model pool: 500000 (max 500000) | Length: 4.9028 | Train rep: 1

Diagnostics -- iteration 212000
real_batch_obs: 1903.11, model_batch_obs: 1913.99
real_batch_act: 194.09, model_batch_act: 181.90
real_batch_rewards: 1331.47, model_batch_rewards: 1308.13
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 321.30
total_steps: 212000.00
Q-avg: 1214.87, Q-max: 1834.44, Q-min: -789.02
Q_loss1: 794.69, Q_loss2: 725.90, min_Q_loss1: -120.55, min_Q_loss2: -108.62

Train epoch 212/3000 -- step 213000

[F                                                                                                    
[F[ Model Length ] Epoch: 212 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 212000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 212 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 212212
[ Model Rollout ] Added: 48979 | Model pool: 500000 (max 500000) | Length: 4.8979 | Train rep: 1

Diagnostics -- iteration 213000
real_batch_obs: 1915.27, model_batch_obs: 1907.87
real_batch_act: 199.50, model_batch_act: 187.88
real_batch_rewards: 1423.79, model_batch_rewards: 1416.37
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 264.61
total_steps: 213000.00
Q-avg: 1171.14, Q-max: 1861.57, Q-min: -1123.22
Q_loss1: 1921.57, Q_loss2: 1715.63, min_Q_loss1: -14.77, min_Q_loss2: -27.44

Train epoch 213/3000 -- step 214000

[F                                                                                                    
[F[ Model Length ] Epoch: 213 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 213000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 213 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 213213
[ Model Rollout ] Added: 49058 | Model pool: 500000 (max 500000) | Length: 4.9058 | Train rep: 1

Diagnostics -- iteration 214000
real_batch_obs: 1855.74, model_batch_obs: 1882.35
real_batch_act: 198.48, model_batch_act: 191.20
real_batch_rewards: 1412.35, model_batch_rewards: 1293.70
real_batch_dones: 2.00, model_batch_dones: 6.00
evaluation/return-average: 230.41
total_steps: 214000.00
Q-avg: 1131.95, Q-max: 1862.37, Q-min: -1205.52
Q_loss1: 1087.39, Q_loss2: 1163.21, min_Q_loss1: -497.42, min_Q_loss2: -487.98

Train epoch 214/3000 -- step 215000

[F                                                                                                    
[F[ Model Length ] Epoch: 214 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 214000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 214 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 214214
[ Model Rollout ] Added: 49043 | Model pool: 500000 (max 500000) | Length: 4.9043 | Train rep: 1

Diagnostics -- iteration 215000
real_batch_obs: 1814.26, model_batch_obs: 1878.26
real_batch_act: 197.62, model_batch_act: 194.38
real_batch_rewards: 1336.27, model_batch_rewards: 1311.24
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 218.73
total_steps: 215000.00
Q-avg: 1199.88, Q-max: 1887.49, Q-min: -697.48
Q_loss1: 3434.61, Q_loss2: 3579.26, min_Q_loss1: -142.73, min_Q_loss2: -145.11

Train epoch 215/3000 -- step 216000

[F                                                                                                    
[F[ Model Length ] Epoch: 215 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 215000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 215 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 215215
[ Model Rollout ] Added: 48974 | Model pool: 500000 (max 500000) | Length: 4.8974 | Train rep: 1

Diagnostics -- iteration 216000
real_batch_obs: 1878.36, model_batch_obs: 1991.87
real_batch_act: 192.45, model_batch_act: 188.93
real_batch_rewards: 1352.83, model_batch_rewards: 1375.75
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 242.48
total_steps: 216000.00
Q-avg: 1202.52, Q-max: 1913.12, Q-min: -593.35
Q_loss1: 729.35, Q_loss2: 965.02, min_Q_loss1: -324.76, min_Q_loss2: -326.52

Train epoch 216/3000 -- step 217000

[F                                                                                                    
[F[ Model Length ] Epoch: 216 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 216000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 216 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 216216
[ Model Rollout ] Added: 48963 | Model pool: 500000 (max 500000) | Length: 4.8963 | Train rep: 1

Diagnostics -- iteration 217000
real_batch_obs: 1861.69, model_batch_obs: 1914.88
real_batch_act: 198.26, model_batch_act: 190.24
real_batch_rewards: 1408.12, model_batch_rewards: 1339.23
real_batch_dones: 2.00, model_batch_dones: 1.00
evaluation/return-average: 260.78
total_steps: 217000.00
Q-avg: 1250.33, Q-max: 1957.71, Q-min: -1007.97
Q_loss1: 376.94, Q_loss2: 517.29, min_Q_loss1: -34.49, min_Q_loss2: -38.27

Train epoch 217/3000 -- step 218000

[F                                                                                                    
[F[ Model Length ] Epoch: 217 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 217000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 217 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 217217
[ Model Rollout ] Added: 49095 | Model pool: 500000 (max 500000) | Length: 4.9095 | Train rep: 1

Diagnostics -- iteration 218000
real_batch_obs: 1782.71, model_batch_obs: 1820.26
real_batch_act: 195.99, model_batch_act: 190.37
real_batch_rewards: 1295.12, model_batch_rewards: 1283.53
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 249.56
total_steps: 218000.00
Q-avg: 1223.37, Q-max: 1849.09, Q-min: -16.06
Q_loss1: 546.81, Q_loss2: 524.98, min_Q_loss1: -246.82, min_Q_loss2: -239.47

Train epoch 218/3000 -- step 219000

[F                                                                                                    
[F[ Model Length ] Epoch: 218 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 218000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 218 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 218218
[ Model Rollout ] Added: 49034 | Model pool: 500000 (max 500000) | Length: 4.9034 | Train rep: 1

Diagnostics -- iteration 219000
real_batch_obs: 1746.86, model_batch_obs: 1805.16
real_batch_act: 200.83, model_batch_act: 181.00
real_batch_rewards: 1331.94, model_batch_rewards: 1333.23
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 251.93
total_steps: 219000.00
Q-avg: 1201.30, Q-max: 1833.82, Q-min: -619.53
Q_loss1: 876.15, Q_loss2: 1166.12, min_Q_loss1: -134.37, min_Q_loss2: -133.87

Train epoch 219/3000 -- step 220000

[F                                                                                                    
[F[ Model Length ] Epoch: 219 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 219000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 219 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 219219
[ Model Rollout ] Added: 49038 | Model pool: 500000 (max 500000) | Length: 4.9038 | Train rep: 1

Diagnostics -- iteration 220000
real_batch_obs: 1727.76, model_batch_obs: 1936.58
real_batch_act: 192.77, model_batch_act: 191.04
real_batch_rewards: 1276.05, model_batch_rewards: 1340.64
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 242.38
total_steps: 220000.00
Q-avg: 1226.12, Q-max: 1887.46, Q-min: -256.92
Q_loss1: 813.28, Q_loss2: 860.97, min_Q_loss1: -49.93, min_Q_loss2: -50.21

Train epoch 220/3000 -- step 221000

[F                                                                                                    
[F[ Model Length ] Epoch: 220 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 220000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 220 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 220220
[ Model Rollout ] Added: 48996 | Model pool: 500000 (max 500000) | Length: 4.8996 | Train rep: 1

Diagnostics -- iteration 221000
real_batch_obs: 1802.59, model_batch_obs: 1872.02
real_batch_act: 198.02, model_batch_act: 189.05
real_batch_rewards: 1310.70, model_batch_rewards: 1355.74
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 269.18
total_steps: 221000.00
Q-avg: 1233.54, Q-max: 1885.50, Q-min: -46.59
Q_loss1: 652.39, Q_loss2: 377.01, min_Q_loss1: -516.14, min_Q_loss2: -509.58

Train epoch 221/3000 -- step 222000

[F                                                                                                    
[F[ Model Length ] Epoch: 221 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 221000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 221 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 221221
[ Model Rollout ] Added: 49117 | Model pool: 500000 (max 500000) | Length: 4.9117 | Train rep: 1

Diagnostics -- iteration 222000
real_batch_obs: 1873.59, model_batch_obs: 1961.10
real_batch_act: 202.60, model_batch_act: 202.50
real_batch_rewards: 1322.17, model_batch_rewards: 1309.66
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 257.64
total_steps: 222000.00
Q-avg: 1187.87, Q-max: 1852.63, Q-min: -383.95
Q_loss1: 1388.21, Q_loss2: 1414.57, min_Q_loss1: -112.85, min_Q_loss2: -95.04

Train epoch 222/3000 -- step 223000

[F                                                                                                    
[F[ Model Length ] Epoch: 222 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 222000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 222 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 222222
[ Model Rollout ] Added: 49031 | Model pool: 500000 (max 500000) | Length: 4.9031 | Train rep: 1

Diagnostics -- iteration 223000
real_batch_obs: 1905.66, model_batch_obs: 1824.90
real_batch_act: 196.60, model_batch_act: 182.51
real_batch_rewards: 1365.41, model_batch_rewards: 1352.41
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 249.31
total_steps: 223000.00
Q-avg: 1166.95, Q-max: 1818.96, Q-min: -537.87
Q_loss1: 1480.33, Q_loss2: 1618.75, min_Q_loss1: -89.59, min_Q_loss2: -94.35

Train epoch 223/3000 -- step 224000

[F                                                                                                    
[F[ Model Length ] Epoch: 223 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 223000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 223 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 223223
[ Model Rollout ] Added: 48954 | Model pool: 500000 (max 500000) | Length: 4.8954 | Train rep: 1

Diagnostics -- iteration 224000
real_batch_obs: 1734.03, model_batch_obs: 1893.59
real_batch_act: 199.58, model_batch_act: 190.03
real_batch_rewards: 1336.62, model_batch_rewards: 1249.71
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 250.39
total_steps: 224000.00
Q-avg: 1207.86, Q-max: 1855.25, Q-min: -366.29
Q_loss1: 3324.48, Q_loss2: 3333.77, min_Q_loss1: -116.59, min_Q_loss2: -124.33

Train epoch 224/3000 -- step 225000

[F                                                                                                    
[F[ Model Length ] Epoch: 224 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 224000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 224 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 224224
[ Model Rollout ] Added: 49051 | Model pool: 500000 (max 500000) | Length: 4.9051 | Train rep: 1

Diagnostics -- iteration 225000
real_batch_obs: 1831.41, model_batch_obs: 1915.54
real_batch_act: 192.97, model_batch_act: 196.38
real_batch_rewards: 1372.85, model_batch_rewards: 1325.80
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 258.79
total_steps: 225000.00
Q-avg: 1161.79, Q-max: 1784.90, Q-min: -731.52
Q_loss1: 763.13, Q_loss2: 790.54, min_Q_loss1: -49.96, min_Q_loss2: -49.13

Train epoch 225/3000 -- step 226000

[F                                                                                                    
[F[ Model Length ] Epoch: 225 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 225000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 225 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 225225
[ Model Rollout ] Added: 49039 | Model pool: 500000 (max 500000) | Length: 4.9039 | Train rep: 1

Diagnostics -- iteration 226000
real_batch_obs: 1803.13, model_batch_obs: 1953.90
real_batch_act: 200.67, model_batch_act: 187.07
real_batch_rewards: 1373.71, model_batch_rewards: 1319.62
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 268.71
total_steps: 226000.00
Q-avg: 1179.93, Q-max: 1820.00, Q-min: -250.37
Q_loss1: 960.46, Q_loss2: 1044.26, min_Q_loss1: 151.20, min_Q_loss2: 145.43

Train epoch 226/3000 -- step 227000

[F                                                                                                    
[F[ Model Length ] Epoch: 226 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 226000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 226 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 226226
[ Model Rollout ] Added: 49038 | Model pool: 500000 (max 500000) | Length: 4.9038 | Train rep: 1

Diagnostics -- iteration 227000
real_batch_obs: 1808.09, model_batch_obs: 1866.91
real_batch_act: 179.29, model_batch_act: 183.56
real_batch_rewards: 1346.66, model_batch_rewards: 1352.80
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 338.36
total_steps: 227000.00
Q-avg: 1210.80, Q-max: 1861.99, Q-min: -622.49
Q_loss1: 380.52, Q_loss2: 295.80, min_Q_loss1: -291.46, min_Q_loss2: -290.48

Train epoch 227/3000 -- step 228000

[F                                                                                                    
[F[ Model Length ] Epoch: 227 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 227000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 227 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 227227
[ Model Rollout ] Added: 49040 | Model pool: 500000 (max 500000) | Length: 4.904 | Train rep: 1

Diagnostics -- iteration 228000
real_batch_obs: 1915.26, model_batch_obs: 1986.82
real_batch_act: 201.95, model_batch_act: 180.70
real_batch_rewards: 1385.62, model_batch_rewards: 1306.87
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 263.22
total_steps: 228000.00
Q-avg: 1156.54, Q-max: 1839.89, Q-min: -46.04
Q_loss1: 453.67, Q_loss2: 520.82, min_Q_loss1: -125.00, min_Q_loss2: -113.52

Train epoch 228/3000 -- step 229000

[F                                                                                                    
[F[ Model Length ] Epoch: 228 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 228000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 228 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 228228
[ Model Rollout ] Added: 48983 | Model pool: 500000 (max 500000) | Length: 4.8983 | Train rep: 1

Diagnostics -- iteration 229000
real_batch_obs: 1859.83, model_batch_obs: 1939.28
real_batch_act: 208.69, model_batch_act: 189.65
real_batch_rewards: 1301.16, model_batch_rewards: 1281.59
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 257.83
total_steps: 229000.00
Q-avg: 1235.69, Q-max: 1741.04, Q-min: -467.94
Q_loss1: 573.78, Q_loss2: 504.15, min_Q_loss1: -87.12, min_Q_loss2: -73.30

Train epoch 229/3000 -- step 230000

[F                                                                                                    
[F[ Model Length ] Epoch: 229 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 229000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 229 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 229229
[ Model Rollout ] Added: 48960 | Model pool: 500000 (max 500000) | Length: 4.896 | Train rep: 1

Diagnostics -- iteration 230000
real_batch_obs: 1849.29, model_batch_obs: 1977.30
real_batch_act: 187.10, model_batch_act: 186.87
real_batch_rewards: 1267.19, model_batch_rewards: 1997.71
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 260.19
total_steps: 230000.00
Q-avg: 1157.87, Q-max: 1845.38, Q-min: -1063.41
Q_loss1: 1111.05, Q_loss2: 891.75, min_Q_loss1: -449.36, min_Q_loss2: -439.96

Train epoch 230/3000 -- step 231000

[F                                                                                                    
[F[ Model Length ] Epoch: 230 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 230000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 230 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 230230
[ Model Rollout ] Added: 49032 | Model pool: 500000 (max 500000) | Length: 4.9032 | Train rep: 1

Diagnostics -- iteration 231000
real_batch_obs: 1827.50, model_batch_obs: 1925.88
real_batch_act: 207.21, model_batch_act: 188.74
real_batch_rewards: 1332.20, model_batch_rewards: 1358.67
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 279.22
total_steps: 231000.00
Q-avg: 1219.31, Q-max: 1748.34, Q-min: -879.45
Q_loss1: 2294.60, Q_loss2: 2168.14, min_Q_loss1: -297.63, min_Q_loss2: -304.91

Train epoch 231/3000 -- step 232000

[F                                                                                                    
[F[ Model Length ] Epoch: 231 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 231000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 231 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 231231
[ Model Rollout ] Added: 49033 | Model pool: 500000 (max 500000) | Length: 4.9033 | Train rep: 1

Diagnostics -- iteration 232000
real_batch_obs: 1691.95, model_batch_obs: 1873.50
real_batch_act: 204.38, model_batch_act: 202.71
real_batch_rewards: 1331.65, model_batch_rewards: 1282.51
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 260.34
total_steps: 232000.00
Q-avg: 1151.62, Q-max: 1764.04, Q-min: -1637.15
Q_loss1: 1265.71, Q_loss2: 1379.18, min_Q_loss1: -223.70, min_Q_loss2: -217.00

Train epoch 232/3000 -- step 233000

[F                                                                                                    
[F[ Model Length ] Epoch: 232 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 232000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 232 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 232232
[ Model Rollout ] Added: 49087 | Model pool: 500000 (max 500000) | Length: 4.9087 | Train rep: 1

Diagnostics -- iteration 233000
real_batch_obs: 1741.68, model_batch_obs: 1952.86
real_batch_act: 205.73, model_batch_act: 188.92
real_batch_rewards: 1280.52, model_batch_rewards: 1327.29
real_batch_dones: 1.00, model_batch_dones: 4.00
evaluation/return-average: 285.93
total_steps: 233000.00
Q-avg: 1165.62, Q-max: 1769.72, Q-min: -1063.24
Q_loss1: 1279.47, Q_loss2: 848.27, min_Q_loss1: -139.41, min_Q_loss2: -143.16

Train epoch 233/3000 -- step 234000

[F                                                                                                    
[F[ Model Length ] Epoch: 233 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 233000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 233 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 233233
[ Model Rollout ] Added: 49065 | Model pool: 500000 (max 500000) | Length: 4.9065 | Train rep: 1

Diagnostics -- iteration 234000
real_batch_obs: 1931.66, model_batch_obs: 1857.48
real_batch_act: 202.05, model_batch_act: 189.71
real_batch_rewards: 1418.75, model_batch_rewards: 1331.51
real_batch_dones: 1.00, model_batch_dones: 5.00
evaluation/return-average: 257.09
total_steps: 234000.00
Q-avg: 1130.75, Q-max: 1740.04, Q-min: -704.23
Q_loss1: 1126.21, Q_loss2: 1172.21, min_Q_loss1: -312.94, min_Q_loss2: -311.99

Train epoch 234/3000 -- step 235000

[F                                                                                                    
[F[ Model Length ] Epoch: 234 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 234000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 234 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 234234
[ Model Rollout ] Added: 49070 | Model pool: 500000 (max 500000) | Length: 4.907 | Train rep: 1

Diagnostics -- iteration 235000
real_batch_obs: 1872.60, model_batch_obs: 1867.06
real_batch_act: 193.85, model_batch_act: 184.69
real_batch_rewards: 1316.43, model_batch_rewards: 1348.22
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 257.46
total_steps: 235000.00
Q-avg: 1189.65, Q-max: 1743.15, Q-min: -561.59
Q_loss1: 646.36, Q_loss2: 501.45, min_Q_loss1: -216.79, min_Q_loss2: -218.17

Train epoch 235/3000 -- step 236000

[F                                                                                                    
[F[ Model Length ] Epoch: 235 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 235000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 235 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 235235
[ Model Rollout ] Added: 49026 | Model pool: 500000 (max 500000) | Length: 4.9026 | Train rep: 1

Diagnostics -- iteration 236000
real_batch_obs: 1904.18, model_batch_obs: 1889.37
real_batch_act: 205.55, model_batch_act: 192.26
real_batch_rewards: 1324.97, model_batch_rewards: 1306.44
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 244.48
total_steps: 236000.00
Q-avg: 1157.37, Q-max: 1859.85, Q-min: -1372.74
Q_loss1: 7905.09, Q_loss2: 8082.51, min_Q_loss1: -109.82, min_Q_loss2: -101.42

Train epoch 236/3000 -- step 237000

[F                                                                                                    
[F[ Model Length ] Epoch: 236 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 236000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 236 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 236236
[ Model Rollout ] Added: 49002 | Model pool: 500000 (max 500000) | Length: 4.9002 | Train rep: 1

Diagnostics -- iteration 237000
real_batch_obs: 1850.02, model_batch_obs: 2002.36
real_batch_act: 194.79, model_batch_act: 203.28
real_batch_rewards: 1348.64, model_batch_rewards: 1359.53
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 237.45
total_steps: 237000.00
Q-avg: 1145.84, Q-max: 1715.16, Q-min: -983.12
Q_loss1: 664.80, Q_loss2: 723.48, min_Q_loss1: -104.61, min_Q_loss2: -101.21

Train epoch 237/3000 -- step 238000

[F                                                                                                    
[F[ Model Length ] Epoch: 237 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 237000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 237 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 237237
[ Model Rollout ] Added: 48901 | Model pool: 500000 (max 500000) | Length: 4.8901 | Train rep: 1

Diagnostics -- iteration 238000
real_batch_obs: 1863.81, model_batch_obs: 1928.58
real_batch_act: 197.05, model_batch_act: 190.02
real_batch_rewards: 1377.93, model_batch_rewards: 1301.06
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 271.69
total_steps: 238000.00
Q-avg: 1131.01, Q-max: 1736.09, Q-min: -533.12
Q_loss1: 3701.79, Q_loss2: 3994.18, min_Q_loss1: 119.54, min_Q_loss2: 118.89

Train epoch 238/3000 -- step 239000

[F                                                                                                    
[F[ Model Length ] Epoch: 238 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 238000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 238 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 238238
[ Model Rollout ] Added: 49063 | Model pool: 500000 (max 500000) | Length: 4.9063 | Train rep: 1

Diagnostics -- iteration 239000
real_batch_obs: 1897.77, model_batch_obs: 1942.30
real_batch_act: 204.36, model_batch_act: 181.48
real_batch_rewards: 1330.48, model_batch_rewards: 2783.02
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 255.69
total_steps: 239000.00
Q-avg: 1160.59, Q-max: 1787.64, Q-min: -1574.13
Q_loss1: 320.21, Q_loss2: 385.95, min_Q_loss1: -276.84, min_Q_loss2: -278.41

Train epoch 239/3000 -- step 240000

[F                                                                                                    
[F[ Model Length ] Epoch: 239 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 239000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 239 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 239239
[ Model Rollout ] Added: 49006 | Model pool: 500000 (max 500000) | Length: 4.9006 | Train rep: 1

Diagnostics -- iteration 240000
real_batch_obs: 1867.26, model_batch_obs: 1861.19
real_batch_act: 207.01, model_batch_act: 194.95
real_batch_rewards: 1357.94, model_batch_rewards: 1344.94
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 268.91
total_steps: 240000.00
Q-avg: 1134.90, Q-max: 1735.19, Q-min: -701.48
Q_loss1: 785.75, Q_loss2: 907.86, min_Q_loss1: -214.59, min_Q_loss2: -215.04

Train epoch 240/3000 -- step 241000

[F                                                                                                    
[F[ Model Length ] Epoch: 240 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 240000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 240 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 240240
[ Model Rollout ] Added: 49065 | Model pool: 500000 (max 500000) | Length: 4.9065 | Train rep: 1

Diagnostics -- iteration 241000
real_batch_obs: 1883.93, model_batch_obs: 1890.38
real_batch_act: 201.48, model_batch_act: 200.92
real_batch_rewards: 1371.24, model_batch_rewards: 1337.87
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 277.51
total_steps: 241000.00
Q-avg: 1152.57, Q-max: 1742.09, Q-min: -1.31
Q_loss1: 180.54, Q_loss2: 231.50, min_Q_loss1: 41.13, min_Q_loss2: 47.44

Train epoch 241/3000 -- step 242000

[F                                                                                                    
[F[ Model Length ] Epoch: 241 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 241000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 241 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 241241
[ Model Rollout ] Added: 49056 | Model pool: 500000 (max 500000) | Length: 4.9056 | Train rep: 1

Diagnostics -- iteration 242000
real_batch_obs: 1870.54, model_batch_obs: 2016.95
real_batch_act: 189.38, model_batch_act: 190.70
real_batch_rewards: 1349.47, model_batch_rewards: 1399.36
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 280.88
total_steps: 242000.00
Q-avg: 1144.36, Q-max: 1723.16, Q-min: -836.17
Q_loss1: 335.60, Q_loss2: 397.06, min_Q_loss1: -111.76, min_Q_loss2: -116.63

Train epoch 242/3000 -- step 243000

[F                                                                                                    
[F[ Model Length ] Epoch: 242 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 242000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 242 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 242242
[ Model Rollout ] Added: 49102 | Model pool: 500000 (max 500000) | Length: 4.9102 | Train rep: 1

Diagnostics -- iteration 243000
real_batch_obs: 1697.02, model_batch_obs: 1894.49
real_batch_act: 213.38, model_batch_act: 192.54
real_batch_rewards: 1306.64, model_batch_rewards: 1403.34
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 266.37
total_steps: 243000.00
Q-avg: 1125.00, Q-max: 1746.36, Q-min: -787.76
Q_loss1: 790.46, Q_loss2: 1103.10, min_Q_loss1: -305.39, min_Q_loss2: -303.59

Train epoch 243/3000 -- step 244000

[F                                                                                                    
[F[ Model Length ] Epoch: 243 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 243000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 243 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 243243
[ Model Rollout ] Added: 49000 | Model pool: 500000 (max 500000) | Length: 4.9 | Train rep: 1

Diagnostics -- iteration 244000
real_batch_obs: 1877.55, model_batch_obs: 1945.61
real_batch_act: 200.20, model_batch_act: 182.70
real_batch_rewards: 1369.46, model_batch_rewards: 1306.67
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 284.76
total_steps: 244000.00
Q-avg: 1151.28, Q-max: 1749.89, Q-min: -101.88
Q_loss1: 195.29, Q_loss2: 193.56, min_Q_loss1: -211.74, min_Q_loss2: -206.35

Train epoch 244/3000 -- step 245000

[F                                                                                                    
[F[ Model Length ] Epoch: 244 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 244000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 244 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 244244
[ Model Rollout ] Added: 49006 | Model pool: 500000 (max 500000) | Length: 4.9006 | Train rep: 1

Diagnostics -- iteration 245000
real_batch_obs: 1906.92, model_batch_obs: 1912.19
real_batch_act: 197.03, model_batch_act: 196.91
real_batch_rewards: 1305.84, model_batch_rewards: 1350.58
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 289.98
total_steps: 245000.00
Q-avg: 1176.40, Q-max: 1740.46, Q-min: -717.04
Q_loss1: 1274.47, Q_loss2: 845.29, min_Q_loss1: -210.47, min_Q_loss2: -216.38

Train epoch 245/3000 -- step 246000

[F                                                                                                    
[F[ Model Length ] Epoch: 245 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 245000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 245 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 245245
[ Model Rollout ] Added: 49090 | Model pool: 500000 (max 500000) | Length: 4.909 | Train rep: 1

Diagnostics -- iteration 246000
real_batch_obs: 1820.48, model_batch_obs: 1850.06
real_batch_act: 199.93, model_batch_act: 190.00
real_batch_rewards: 1413.86, model_batch_rewards: 1371.02
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 270.39
total_steps: 246000.00
Q-avg: 1096.17, Q-max: 1752.17, Q-min: -607.21
Q_loss1: 2857.12, Q_loss2: 2825.94, min_Q_loss1: -96.27, min_Q_loss2: -101.96

Train epoch 246/3000 -- step 247000

[F                                                                                                    
[F[ Model Length ] Epoch: 246 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 246000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 246 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 246246
[ Model Rollout ] Added: 49030 | Model pool: 500000 (max 500000) | Length: 4.903 | Train rep: 1

Diagnostics -- iteration 247000
real_batch_obs: 1792.07, model_batch_obs: 1824.84
real_batch_act: 200.39, model_batch_act: 189.03
real_batch_rewards: 1268.60, model_batch_rewards: 1370.41
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 276.57
total_steps: 247000.00
Q-avg: 1142.42, Q-max: 1768.67, Q-min: -952.59
Q_loss1: 1065.52, Q_loss2: 1159.15, min_Q_loss1: -237.38, min_Q_loss2: -238.85

Train epoch 247/3000 -- step 248000

[F                                                                                                    
[F[ Model Length ] Epoch: 247 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 247000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 247 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 247247
[ Model Rollout ] Added: 49059 | Model pool: 500000 (max 500000) | Length: 4.9059 | Train rep: 1

Diagnostics -- iteration 248000
real_batch_obs: 1774.80, model_batch_obs: 1827.87
real_batch_act: 187.26, model_batch_act: 194.05
real_batch_rewards: 1321.92, model_batch_rewards: 1385.36
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 276.42
total_steps: 248000.00
Q-avg: 1142.99, Q-max: 1765.60, Q-min: -35.24
Q_loss1: 144.73, Q_loss2: 181.28, min_Q_loss1: -431.84, min_Q_loss2: -422.35

Train epoch 248/3000 -- step 249000

[F                                                                                                    
[F[ Model Length ] Epoch: 248 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 248000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 248 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 248248
[ Model Rollout ] Added: 49053 | Model pool: 500000 (max 500000) | Length: 4.9053 | Train rep: 1

Diagnostics -- iteration 249000
real_batch_obs: 1814.82, model_batch_obs: 1961.84
real_batch_act: 197.43, model_batch_act: 188.19
real_batch_rewards: 1316.38, model_batch_rewards: 1356.25
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 368.85
total_steps: 249000.00
Q-avg: 1110.98, Q-max: 1716.02, Q-min: -663.38
Q_loss1: 596.72, Q_loss2: 396.59, min_Q_loss1: -303.22, min_Q_loss2: -308.05

Train epoch 249/3000 -- step 250000

[F                                                                                                    
[F[ Model Length ] Epoch: 249 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 249000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 249 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 249249
[ Model Rollout ] Added: 48934 | Model pool: 500000 (max 500000) | Length: 4.8934 | Train rep: 1

Diagnostics -- iteration 250000
real_batch_obs: 1871.37, model_batch_obs: 1862.18
real_batch_act: 197.20, model_batch_act: 179.73
real_batch_rewards: 1349.16, model_batch_rewards: 1342.17
real_batch_dones: 2.00, model_batch_dones: 0.00
evaluation/return-average: 284.82
total_steps: 250000.00
Q-avg: 1133.62, Q-max: 1738.92, Q-min: -293.45
Q_loss1: 292.64, Q_loss2: 230.91, min_Q_loss1: -235.80, min_Q_loss2: -240.10

Train epoch 250/3000 -- step 251000

[F                                                                                                    
[F[ Model Length ] Epoch: 250 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 250000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 250 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 250250
[ Model Rollout ] Added: 49043 | Model pool: 500000 (max 500000) | Length: 4.9043 | Train rep: 1

Diagnostics -- iteration 251000
real_batch_obs: 1829.06, model_batch_obs: 1844.42
real_batch_act: 196.52, model_batch_act: 197.43
real_batch_rewards: 1334.12, model_batch_rewards: 1378.85
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 291.46
total_steps: 251000.00
Q-avg: 1148.12, Q-max: 1760.30, Q-min: -18.78
Q_loss1: 165.61, Q_loss2: 184.36, min_Q_loss1: -340.52, min_Q_loss2: -349.14

Train epoch 251/3000 -- step 252000

[F                                                                                                    
[F[ Model Length ] Epoch: 251 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 251000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 251 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 251251
[ Model Rollout ] Added: 49098 | Model pool: 500000 (max 500000) | Length: 4.9098 | Train rep: 1

Diagnostics -- iteration 252000
real_batch_obs: 1885.66, model_batch_obs: 1965.32
real_batch_act: 205.90, model_batch_act: 186.28
real_batch_rewards: 1363.45, model_batch_rewards: 2825.67
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 289.00
total_steps: 252000.00
Q-avg: 1088.99, Q-max: 1677.60, Q-min: -2231.86
Q_loss1: 1697.63, Q_loss2: 1389.40, min_Q_loss1: -171.29, min_Q_loss2: -177.87

Train epoch 252/3000 -- step 253000

[F                                                                                                    
[F[ Model Length ] Epoch: 252 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 252000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 252 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 252252
[ Model Rollout ] Added: 49035 | Model pool: 500000 (max 500000) | Length: 4.9035 | Train rep: 1

Diagnostics -- iteration 253000
real_batch_obs: 1837.05, model_batch_obs: 1958.81
real_batch_act: 190.90, model_batch_act: 191.09
real_batch_rewards: 1326.79, model_batch_rewards: 1344.62
real_batch_dones: 0.00, model_batch_dones: 6.00
evaluation/return-average: 276.63
total_steps: 253000.00
Q-avg: 1119.43, Q-max: 1699.23, Q-min: -503.46
Q_loss1: 2548.96, Q_loss2: 2656.12, min_Q_loss1: -400.80, min_Q_loss2: -407.88

Train epoch 253/3000 -- step 254000

[F                                                                                                    
[F[ Model Length ] Epoch: 253 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 253000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 253 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 253253
[ Model Rollout ] Added: 49013 | Model pool: 500000 (max 500000) | Length: 4.9013 | Train rep: 1

Diagnostics -- iteration 254000
real_batch_obs: 1926.17, model_batch_obs: 1854.98
real_batch_act: 206.95, model_batch_act: 195.66
real_batch_rewards: 1357.91, model_batch_rewards: 1333.77
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 266.88
total_steps: 254000.00
Q-avg: 1098.27, Q-max: 1711.68, Q-min: -607.87
Q_loss1: 618.67, Q_loss2: 467.31, min_Q_loss1: -403.91, min_Q_loss2: -397.33

Train epoch 254/3000 -- step 255000

[F                                                                                                    
[F[ Model Length ] Epoch: 254 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 254000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 254 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 254254
[ Model Rollout ] Added: 48997 | Model pool: 500000 (max 500000) | Length: 4.8997 | Train rep: 1

Diagnostics -- iteration 255000
real_batch_obs: 1808.23, model_batch_obs: 1882.44
real_batch_act: 201.12, model_batch_act: 197.44
real_batch_rewards: 1371.30, model_batch_rewards: 3148.31
real_batch_dones: 2.00, model_batch_dones: 6.00
evaluation/return-average: 275.32
total_steps: 255000.00
Q-avg: 1033.32, Q-max: 1716.45, Q-min: -3303.37
Q_loss1: 4767.70, Q_loss2: 4503.73, min_Q_loss1: -226.23, min_Q_loss2: -219.60

Train epoch 255/3000 -- step 256000

[F                                                                                                    
[F[ Model Length ] Epoch: 255 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 255000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 255 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 255255
[ Model Rollout ] Added: 48943 | Model pool: 500000 (max 500000) | Length: 4.8943 | Train rep: 1

Diagnostics -- iteration 256000
real_batch_obs: 1701.68, model_batch_obs: 1969.21
real_batch_act: 188.14, model_batch_act: 198.52
real_batch_rewards: 1296.54, model_batch_rewards: 1350.74
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 265.49
total_steps: 256000.00
Q-avg: 1111.72, Q-max: 1731.33, Q-min: -72.63
Q_loss1: 585.33, Q_loss2: 468.17, min_Q_loss1: -19.13, min_Q_loss2: -10.08

Train epoch 256/3000 -- step 257000

[F                                                                                                    
[F[ Model Length ] Epoch: 256 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 256000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 256 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 256256
[ Model Rollout ] Added: 49045 | Model pool: 500000 (max 500000) | Length: 4.9045 | Train rep: 1

Diagnostics -- iteration 257000
real_batch_obs: 1801.91, model_batch_obs: 1833.69
real_batch_act: 203.87, model_batch_act: 193.09
real_batch_rewards: 1344.80, model_batch_rewards: 1270.32
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 266.21
total_steps: 257000.00
Q-avg: 1146.89, Q-max: 1786.00, Q-min: -646.82
Q_loss1: 1511.84, Q_loss2: 1278.31, min_Q_loss1: -7.00, min_Q_loss2: -10.97

Train epoch 257/3000 -- step 258000

[F                                                                                                    
[F[ Model Length ] Epoch: 257 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 257000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 257 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 257257
[ Model Rollout ] Added: 48975 | Model pool: 500000 (max 500000) | Length: 4.8975 | Train rep: 1

Diagnostics -- iteration 258000
real_batch_obs: 1953.99, model_batch_obs: 1862.91
real_batch_act: 200.11, model_batch_act: 190.84
real_batch_rewards: 1407.31, model_batch_rewards: 1370.58
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 278.74
total_steps: 258000.00
Q-avg: 1105.32, Q-max: 1788.35, Q-min: -668.13
Q_loss1: 2991.36, Q_loss2: 3440.46, min_Q_loss1: -149.05, min_Q_loss2: -146.46

Train epoch 258/3000 -- step 259000

[F                                                                                                    
[F[ Model Length ] Epoch: 258 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 258000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 258 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 258258
[ Model Rollout ] Added: 49040 | Model pool: 500000 (max 500000) | Length: 4.904 | Train rep: 1

Diagnostics -- iteration 259000
real_batch_obs: 1921.50, model_batch_obs: 1907.66
real_batch_act: 204.70, model_batch_act: 192.95
real_batch_rewards: 1372.17, model_batch_rewards: 1386.65
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 267.19
total_steps: 259000.00
Q-avg: 1110.92, Q-max: 1788.67, Q-min: -289.01
Q_loss1: 1081.08, Q_loss2: 1560.20, min_Q_loss1: 3.91, min_Q_loss2: -3.54

Train epoch 259/3000 -- step 260000

[F                                                                                                    
[F[ Model Length ] Epoch: 259 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 259000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 259 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 259259
[ Model Rollout ] Added: 48993 | Model pool: 500000 (max 500000) | Length: 4.8993 | Train rep: 1

Diagnostics -- iteration 260000
real_batch_obs: 1769.51, model_batch_obs: 1842.70
real_batch_act: 192.90, model_batch_act: 190.99
real_batch_rewards: 1304.28, model_batch_rewards: 1286.78
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 262.44
total_steps: 260000.00
Q-avg: 1163.93, Q-max: 1839.27, Q-min: -485.97
Q_loss1: 1518.27, Q_loss2: 2558.87, min_Q_loss1: -262.96, min_Q_loss2: -269.86

Train epoch 260/3000 -- step 261000

[F                                                                                                    
[F[ Model Length ] Epoch: 260 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 260000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 260 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 260260
[ Model Rollout ] Added: 49083 | Model pool: 500000 (max 500000) | Length: 4.9083 | Train rep: 1

Diagnostics -- iteration 261000
real_batch_obs: 1955.61, model_batch_obs: 1834.22
real_batch_act: 206.83, model_batch_act: 193.37
real_batch_rewards: 1410.04, model_batch_rewards: 1312.80
real_batch_dones: 0.00, model_batch_dones: 5.00
evaluation/return-average: 268.86
total_steps: 261000.00
Q-avg: 1065.73, Q-max: 1775.56, Q-min: -1133.26
Q_loss1: 3224.77, Q_loss2: 3899.87, min_Q_loss1: 5.93, min_Q_loss2: -3.93

Train epoch 261/3000 -- step 262000

[F                                                                                                    
[F[ Model Length ] Epoch: 261 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 261000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 261 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 261261
[ Model Rollout ] Added: 48936 | Model pool: 500000 (max 500000) | Length: 4.8936 | Train rep: 1

Diagnostics -- iteration 262000
real_batch_obs: 1875.25, model_batch_obs: 1892.06
real_batch_act: 197.93, model_batch_act: 194.88
real_batch_rewards: 1303.87, model_batch_rewards: 1324.47
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 267.58
total_steps: 262000.00
Q-avg: 1166.22, Q-max: 1801.76, Q-min: -283.62
Q_loss1: 455.85, Q_loss2: 389.52, min_Q_loss1: -342.52, min_Q_loss2: -355.78

Train epoch 262/3000 -- step 263000

[F                                                                                                    
[F[ Model Length ] Epoch: 262 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 262000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 262 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 262262
[ Model Rollout ] Added: 49054 | Model pool: 500000 (max 500000) | Length: 4.9054 | Train rep: 1

Diagnostics -- iteration 263000
real_batch_obs: 1837.38, model_batch_obs: 1848.81
real_batch_act: 182.91, model_batch_act: 194.86
real_batch_rewards: 1331.93, model_batch_rewards: 1355.53
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 253.65
total_steps: 263000.00
Q-avg: 1077.32, Q-max: 1803.19, Q-min: -810.47
Q_loss1: 2606.20, Q_loss2: 2777.77, min_Q_loss1: -554.97, min_Q_loss2: -551.75

Train epoch 263/3000 -- step 264000

[F                                                                                                    
[F[ Model Length ] Epoch: 263 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 263000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 263 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 263263
[ Model Rollout ] Added: 48929 | Model pool: 500000 (max 500000) | Length: 4.8929 | Train rep: 1

Diagnostics -- iteration 264000
real_batch_obs: 1685.35, model_batch_obs: 1844.55
real_batch_act: 195.93, model_batch_act: 188.43
real_batch_rewards: 1314.25, model_batch_rewards: 1245.58
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 261.65
total_steps: 264000.00
Q-avg: 1133.07, Q-max: 1867.41, Q-min: -88.05
Q_loss1: 2034.64, Q_loss2: 1760.48, min_Q_loss1: -1.06, min_Q_loss2: -0.91

Train epoch 264/3000 -- step 265000

[F                                                                                                    
[F[ Model Length ] Epoch: 264 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 264000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 264 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 264264
[ Model Rollout ] Added: 49020 | Model pool: 500000 (max 500000) | Length: 4.902 | Train rep: 1

Diagnostics -- iteration 265000
real_batch_obs: 1832.64, model_batch_obs: 1859.41
real_batch_act: 193.21, model_batch_act: 198.88
real_batch_rewards: 1355.09, model_batch_rewards: 1313.99
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 268.83
total_steps: 265000.00
Q-avg: 1097.78, Q-max: 1805.20, Q-min: -477.73
Q_loss1: 1187.50, Q_loss2: 1439.80, min_Q_loss1: -121.66, min_Q_loss2: -125.26

Train epoch 265/3000 -- step 266000

[F                                                                                                    
[F[ Model Length ] Epoch: 265 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 265000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 265 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 265265
[ Model Rollout ] Added: 49139 | Model pool: 500000 (max 500000) | Length: 4.9139 | Train rep: 1

Diagnostics -- iteration 266000
real_batch_obs: 1819.36, model_batch_obs: 1852.03
real_batch_act: 213.83, model_batch_act: 188.25
real_batch_rewards: 1338.14, model_batch_rewards: 1368.32
real_batch_dones: 2.00, model_batch_dones: 5.00
evaluation/return-average: 273.45
total_steps: 266000.00
Q-avg: 1060.12, Q-max: 1849.29, Q-min: -243.25
Q_loss1: 399.88, Q_loss2: 357.10, min_Q_loss1: -396.12, min_Q_loss2: -396.41

Train epoch 266/3000 -- step 267000

[F                                                                                                    
[F[ Model Length ] Epoch: 266 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 266000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 266 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 266266
[ Model Rollout ] Added: 49041 | Model pool: 500000 (max 500000) | Length: 4.9041 | Train rep: 1

Diagnostics -- iteration 267000
real_batch_obs: 1872.41, model_batch_obs: 1878.73
real_batch_act: 194.78, model_batch_act: 197.01
real_batch_rewards: 1395.66, model_batch_rewards: 1339.98
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 268.78
total_steps: 267000.00
Q-avg: 1102.92, Q-max: 1871.33, Q-min: -308.51
Q_loss1: 2122.85, Q_loss2: 1907.31, min_Q_loss1: -267.41, min_Q_loss2: -274.66

Train epoch 267/3000 -- step 268000

[F                                                                                                    
[F[ Model Length ] Epoch: 267 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 267000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 267 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 267267
[ Model Rollout ] Added: 49074 | Model pool: 500000 (max 500000) | Length: 4.9074 | Train rep: 1

Diagnostics -- iteration 268000
real_batch_obs: 1767.30, model_batch_obs: 1814.31
real_batch_act: 189.91, model_batch_act: 199.46
real_batch_rewards: 1260.32, model_batch_rewards: 1331.23
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 269.68
total_steps: 268000.00
Q-avg: 1119.68, Q-max: 1942.22, Q-min: -210.16
Q_loss1: 1386.30, Q_loss2: 1681.27, min_Q_loss1: -346.91, min_Q_loss2: -331.80

Train epoch 268/3000 -- step 269000

[F                                                                                                    
[F[ Model Length ] Epoch: 268 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 268000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 268 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 268268
[ Model Rollout ] Added: 48934 | Model pool: 500000 (max 500000) | Length: 4.8934 | Train rep: 1

Diagnostics -- iteration 269000
real_batch_obs: 1836.94, model_batch_obs: 1902.83
real_batch_act: 210.17, model_batch_act: 194.39
real_batch_rewards: 1375.75, model_batch_rewards: 1380.45
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 259.29
total_steps: 269000.00
Q-avg: 1123.62, Q-max: 1851.84, Q-min: -25.84
Q_loss1: 840.53, Q_loss2: 876.70, min_Q_loss1: -372.78, min_Q_loss2: -388.86

Train epoch 269/3000 -- step 270000

[F                                                                                                    
[F[ Model Length ] Epoch: 269 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 269000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 269 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 269269
[ Model Rollout ] Added: 48916 | Model pool: 500000 (max 500000) | Length: 4.8916 | Train rep: 1

Diagnostics -- iteration 270000
real_batch_obs: 1854.62, model_batch_obs: 1931.08
real_batch_act: 200.62, model_batch_act: 187.09
real_batch_rewards: 1365.02, model_batch_rewards: 1347.11
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 263.86
total_steps: 270000.00
Q-avg: 1111.48, Q-max: 1882.15, Q-min: -105.17
Q_loss1: 845.98, Q_loss2: 830.23, min_Q_loss1: -249.83, min_Q_loss2: -248.84

Train epoch 270/3000 -- step 271000

[F                                                                                                    
[F[ Model Length ] Epoch: 270 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 270000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 270 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 270270
[ Model Rollout ] Added: 49037 | Model pool: 500000 (max 500000) | Length: 4.9037 | Train rep: 1

Diagnostics -- iteration 271000
real_batch_obs: 1781.91, model_batch_obs: 1833.54
real_batch_act: 188.55, model_batch_act: 192.80
real_batch_rewards: 1389.09, model_batch_rewards: 1305.83
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 257.96
total_steps: 271000.00
Q-avg: 1059.95, Q-max: 1803.39, Q-min: -424.88
Q_loss1: 1188.72, Q_loss2: 1198.98, min_Q_loss1: -447.98, min_Q_loss2: -467.74

Train epoch 271/3000 -- step 272000

[F                                                                                                    
[F[ Model Length ] Epoch: 271 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 271000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 271 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 271271
[ Model Rollout ] Added: 49050 | Model pool: 500000 (max 500000) | Length: 4.905 | Train rep: 1

Diagnostics -- iteration 272000
real_batch_obs: 1891.97, model_batch_obs: 1866.32
real_batch_act: 206.91, model_batch_act: 197.99
real_batch_rewards: 1341.05, model_batch_rewards: 1334.22
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 244.39
total_steps: 272000.00
Q-avg: 1174.14, Q-max: 1856.41, Q-min: -98.25
Q_loss1: 277.56, Q_loss2: 358.77, min_Q_loss1: -65.71, min_Q_loss2: -59.96

Train epoch 272/3000 -- step 273000

[F                                                                                                    
[F[ Model Length ] Epoch: 272 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 272000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 272 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 272272
[ Model Rollout ] Added: 48987 | Model pool: 500000 (max 500000) | Length: 4.8987 | Train rep: 1

Diagnostics -- iteration 273000
real_batch_obs: 1655.36, model_batch_obs: 1867.97
real_batch_act: 190.07, model_batch_act: 193.05
real_batch_rewards: 1305.56, model_batch_rewards: 1288.86
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 260.39
total_steps: 273000.00
Q-avg: 1121.48, Q-max: 1865.50, Q-min: -190.60
Q_loss1: 1874.33, Q_loss2: 1558.94, min_Q_loss1: -36.23, min_Q_loss2: -33.90

Train epoch 273/3000 -- step 274000

[F                                                                                                    
[F[ Model Length ] Epoch: 273 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 273000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 273 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 273273
[ Model Rollout ] Added: 49058 | Model pool: 500000 (max 500000) | Length: 4.9058 | Train rep: 1

Diagnostics -- iteration 274000
real_batch_obs: 1848.44, model_batch_obs: 1822.88
real_batch_act: 187.46, model_batch_act: 194.06
real_batch_rewards: 1322.02, model_batch_rewards: 1357.03
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 263.80
total_steps: 274000.00
Q-avg: 1118.83, Q-max: 1801.11, Q-min: -306.18
Q_loss1: 615.26, Q_loss2: 622.15, min_Q_loss1: -187.47, min_Q_loss2: -180.22

Train epoch 274/3000 -- step 275000

[F                                                                                                    
[F[ Model Length ] Epoch: 274 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 274000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 274 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 274274
[ Model Rollout ] Added: 49045 | Model pool: 500000 (max 500000) | Length: 4.9045 | Train rep: 1

Diagnostics -- iteration 275000
real_batch_obs: 1800.86, model_batch_obs: 1857.42
real_batch_act: 197.77, model_batch_act: 200.00
real_batch_rewards: 1384.08, model_batch_rewards: 1315.41
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 251.34
total_steps: 275000.00
Q-avg: 1106.07, Q-max: 1835.67, Q-min: -81.31
Q_loss1: 453.48, Q_loss2: 599.26, min_Q_loss1: -95.02, min_Q_loss2: -93.30

Train epoch 275/3000 -- step 276000

[F                                                                                                    
[F[ Model Length ] Epoch: 275 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 275000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 275 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 275275
[ Model Rollout ] Added: 49017 | Model pool: 500000 (max 500000) | Length: 4.9017 | Train rep: 1

Diagnostics -- iteration 276000
real_batch_obs: 1868.33, model_batch_obs: 1939.39
real_batch_act: 192.65, model_batch_act: 185.17
real_batch_rewards: 1344.35, model_batch_rewards: 1388.53
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 256.54
total_steps: 276000.00
Q-avg: 1112.95, Q-max: 1779.21, Q-min: -780.42
Q_loss1: 390.86, Q_loss2: 301.58, min_Q_loss1: -278.11, min_Q_loss2: -271.54

Train epoch 276/3000 -- step 277000

[F                                                                                                    
[F[ Model Length ] Epoch: 276 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 276000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 276 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 276276
[ Model Rollout ] Added: 48996 | Model pool: 500000 (max 500000) | Length: 4.8996 | Train rep: 1

Diagnostics -- iteration 277000
real_batch_obs: 1824.54, model_batch_obs: 1827.03
real_batch_act: 204.54, model_batch_act: 193.85
real_batch_rewards: 1385.75, model_batch_rewards: 1362.43
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 265.12
total_steps: 277000.00
Q-avg: 1133.39, Q-max: 1892.53, Q-min: -207.90
Q_loss1: 1099.69, Q_loss2: 577.81, min_Q_loss1: -362.09, min_Q_loss2: -363.28

Train epoch 277/3000 -- step 278000

[F                                                                                                    
[F[ Model Length ] Epoch: 277 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 277000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 277 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 277277
[ Model Rollout ] Added: 49069 | Model pool: 500000 (max 500000) | Length: 4.9069 | Train rep: 1

Diagnostics -- iteration 278000
real_batch_obs: 1769.80, model_batch_obs: 1854.74
real_batch_act: 194.09, model_batch_act: 191.53
real_batch_rewards: 1340.78, model_batch_rewards: 1331.73
real_batch_dones: 1.00, model_batch_dones: 4.00
evaluation/return-average: 255.92
total_steps: 278000.00
Q-avg: 1117.65, Q-max: 1885.98, Q-min: -552.36
Q_loss1: 479.44, Q_loss2: 434.27, min_Q_loss1: -47.92, min_Q_loss2: -44.77

Train epoch 278/3000 -- step 279000

[F                                                                                                    
[F[ Model Length ] Epoch: 278 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 278000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 278 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 278278
[ Model Rollout ] Added: 48981 | Model pool: 500000 (max 500000) | Length: 4.8981 | Train rep: 1

Diagnostics -- iteration 279000
real_batch_obs: 1724.53, model_batch_obs: 1905.94
real_batch_act: 202.69, model_batch_act: 186.19
real_batch_rewards: 1295.02, model_batch_rewards: 1327.06
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 244.93
total_steps: 279000.00
Q-avg: 1112.17, Q-max: 1812.02, Q-min: -723.93
Q_loss1: 224.83, Q_loss2: 278.58, min_Q_loss1: -203.27, min_Q_loss2: -202.99

Train epoch 279/3000 -- step 280000

[F                                                                                                    
[F[ Model Length ] Epoch: 279 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 279000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 279 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 279279
[ Model Rollout ] Added: 48965 | Model pool: 500000 (max 500000) | Length: 4.8965 | Train rep: 1

Diagnostics -- iteration 280000
real_batch_obs: 1788.71, model_batch_obs: 1896.93
real_batch_act: 182.76, model_batch_act: 196.75
real_batch_rewards: 1313.13, model_batch_rewards: 1374.85
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 260.12
total_steps: 280000.00
Q-avg: 1129.33, Q-max: 1900.16, Q-min: -445.91
Q_loss1: 2176.79, Q_loss2: 1861.11, min_Q_loss1: -242.66, min_Q_loss2: -245.12

Train epoch 280/3000 -- step 281000

[F                                                                                                    
[F[ Model Length ] Epoch: 280 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 280000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 280 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 280280
[ Model Rollout ] Added: 49070 | Model pool: 500000 (max 500000) | Length: 4.907 | Train rep: 1

Diagnostics -- iteration 281000
real_batch_obs: 1755.98, model_batch_obs: 1834.15
real_batch_act: 205.93, model_batch_act: 197.34
real_batch_rewards: 1259.44, model_batch_rewards: 1359.56
real_batch_dones: 0.00, model_batch_dones: 5.00
evaluation/return-average: 260.41
total_steps: 281000.00
Q-avg: 1139.32, Q-max: 1919.03, Q-min: -197.43
Q_loss1: 2777.28, Q_loss2: 2833.13, min_Q_loss1: -250.58, min_Q_loss2: -234.96

Train epoch 281/3000 -- step 282000

[F                                                                                                    
[F[ Model Length ] Epoch: 281 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 281000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 281 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 281281
[ Model Rollout ] Added: 49105 | Model pool: 500000 (max 500000) | Length: 4.9105 | Train rep: 1

Diagnostics -- iteration 282000
real_batch_obs: 1799.60, model_batch_obs: 1848.03
real_batch_act: 200.96, model_batch_act: 175.25
real_batch_rewards: 1283.06, model_batch_rewards: 1343.62
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 252.59
total_steps: 282000.00
Q-avg: 1211.90, Q-max: 1982.20, Q-min: -190.68
Q_loss1: 153.76, Q_loss2: 181.41, min_Q_loss1: -137.08, min_Q_loss2: -129.79

Train epoch 282/3000 -- step 283000

[F                                                                                                    
[F[ Model Length ] Epoch: 282 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 282000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 282 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 282282
[ Model Rollout ] Added: 49099 | Model pool: 500000 (max 500000) | Length: 4.9099 | Train rep: 1

Diagnostics -- iteration 283000
real_batch_obs: 1853.56, model_batch_obs: 1921.81
real_batch_act: 192.37, model_batch_act: 193.53
real_batch_rewards: 1330.02, model_batch_rewards: 1315.32
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 272.05
total_steps: 283000.00
Q-avg: 1160.89, Q-max: 1860.60, Q-min: -287.00
Q_loss1: 4538.44, Q_loss2: 4526.90, min_Q_loss1: -169.82, min_Q_loss2: -162.41

Train epoch 283/3000 -- step 284000

[F                                                                                                    
[F[ Model Length ] Epoch: 283 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 283000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 283 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 283283
[ Model Rollout ] Added: 48954 | Model pool: 500000 (max 500000) | Length: 4.8954 | Train rep: 1

Diagnostics -- iteration 284000
real_batch_obs: 1707.78, model_batch_obs: 1869.57
real_batch_act: 193.02, model_batch_act: 198.56
real_batch_rewards: 1314.66, model_batch_rewards: 1336.06
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 263.67
total_steps: 284000.00
Q-avg: 1147.45, Q-max: 1864.24, Q-min: -98.03
Q_loss1: 902.44, Q_loss2: 861.62, min_Q_loss1: -131.86, min_Q_loss2: -129.57

Train epoch 284/3000 -- step 285000

[F                                                                                                    
[F[ Model Length ] Epoch: 284 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 284000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 284 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 284284
[ Model Rollout ] Added: 48990 | Model pool: 500000 (max 500000) | Length: 4.899 | Train rep: 1

Diagnostics -- iteration 285000
real_batch_obs: 1825.67, model_batch_obs: 1947.38
real_batch_act: 196.42, model_batch_act: 188.46
real_batch_rewards: 1388.81, model_batch_rewards: 1302.69
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 280.93
total_steps: 285000.00
Q-avg: 1170.05, Q-max: 1859.32, Q-min: -925.01
Q_loss1: 537.98, Q_loss2: 541.23, min_Q_loss1: -117.32, min_Q_loss2: -124.68

Train epoch 285/3000 -- step 286000

[F                                                                                                    
[F[ Model Length ] Epoch: 285 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 285000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 285 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 285285
[ Model Rollout ] Added: 49028 | Model pool: 500000 (max 500000) | Length: 4.9028 | Train rep: 1

Diagnostics -- iteration 286000
real_batch_obs: 1742.65, model_batch_obs: 1887.60
real_batch_act: 183.81, model_batch_act: 194.84
real_batch_rewards: 1332.85, model_batch_rewards: 1328.14
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 274.22
total_steps: 286000.00
Q-avg: 1134.99, Q-max: 1834.93, Q-min: -382.31
Q_loss1: 2459.14, Q_loss2: 2714.95, min_Q_loss1: -73.17, min_Q_loss2: -83.08

Train epoch 286/3000 -- step 287000

[F                                                                                                    
[F[ Model Length ] Epoch: 286 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 286000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 286 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 286286
[ Model Rollout ] Added: 48962 | Model pool: 500000 (max 500000) | Length: 4.8962 | Train rep: 1

Diagnostics -- iteration 287000
real_batch_obs: 1723.75, model_batch_obs: 1831.14
real_batch_act: 206.66, model_batch_act: 185.03
real_batch_rewards: 1333.15, model_batch_rewards: 1310.84
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 290.77
total_steps: 287000.00
Q-avg: 1168.68, Q-max: 1846.07, Q-min: -79.21
Q_loss1: 530.33, Q_loss2: 659.02, min_Q_loss1: -324.86, min_Q_loss2: -331.07

Train epoch 287/3000 -- step 288000

[F                                                                                                    
[F[ Model Length ] Epoch: 287 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 287000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 287 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 287287
[ Model Rollout ] Added: 48964 | Model pool: 500000 (max 500000) | Length: 4.8964 | Train rep: 1

Diagnostics -- iteration 288000
real_batch_obs: 1912.48, model_batch_obs: 1944.67
real_batch_act: 194.36, model_batch_act: 186.37
real_batch_rewards: 1347.49, model_batch_rewards: 1387.95
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 292.52
total_steps: 288000.00
Q-avg: 1180.32, Q-max: 1847.47, Q-min: -11.84
Q_loss1: 479.98, Q_loss2: 435.32, min_Q_loss1: -204.19, min_Q_loss2: -207.43

Train epoch 288/3000 -- step 289000

[F                                                                                                    
[F[ Model Length ] Epoch: 288 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 288000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 288 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 288288
[ Model Rollout ] Added: 49034 | Model pool: 500000 (max 500000) | Length: 4.9034 | Train rep: 1

Diagnostics -- iteration 289000
real_batch_obs: 1831.73, model_batch_obs: 1854.00
real_batch_act: 202.38, model_batch_act: 191.82
real_batch_rewards: 1399.44, model_batch_rewards: 1368.86
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 257.67
total_steps: 289000.00
Q-avg: 1178.13, Q-max: 1835.03, Q-min: -1209.63
Q_loss1: 851.41, Q_loss2: 783.36, min_Q_loss1: 43.93, min_Q_loss2: 45.37

Train epoch 289/3000 -- step 290000

[F                                                                                                    
[F[ Model Length ] Epoch: 289 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 289000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 289 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 289289
[ Model Rollout ] Added: 49001 | Model pool: 500000 (max 500000) | Length: 4.9001 | Train rep: 1

Diagnostics -- iteration 290000
real_batch_obs: 1807.35, model_batch_obs: 1931.35
real_batch_act: 198.87, model_batch_act: 187.61
real_batch_rewards: 1367.77, model_batch_rewards: 1394.76
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 262.71
total_steps: 290000.00
Q-avg: 1089.61, Q-max: 1855.37, Q-min: -41.56
Q_loss1: 302.69, Q_loss2: 129.54, min_Q_loss1: -265.35, min_Q_loss2: -270.93

Train epoch 290/3000 -- step 291000

[F                                                                                                    
[F[ Model Length ] Epoch: 290 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 290000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 290 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 290290
[ Model Rollout ] Added: 49043 | Model pool: 500000 (max 500000) | Length: 4.9043 | Train rep: 1

Diagnostics -- iteration 291000
real_batch_obs: 1795.19, model_batch_obs: 1767.23
real_batch_act: 198.26, model_batch_act: 187.14
real_batch_rewards: 1352.34, model_batch_rewards: 1367.87
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 272.57
total_steps: 291000.00
Q-avg: 1152.40, Q-max: 1868.90, Q-min: -126.31
Q_loss1: 186.02, Q_loss2: 187.48, min_Q_loss1: -139.14, min_Q_loss2: -129.78

Train epoch 291/3000 -- step 292000

[F                                                                                                    
[F[ Model Length ] Epoch: 291 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 291000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 291 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 291291
[ Model Rollout ] Added: 49069 | Model pool: 500000 (max 500000) | Length: 4.9069 | Train rep: 1

Diagnostics -- iteration 292000
real_batch_obs: 1798.44, model_batch_obs: 1918.51
real_batch_act: 201.23, model_batch_act: 189.89
real_batch_rewards: 1357.76, model_batch_rewards: 1378.98
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 268.94
total_steps: 292000.00
Q-avg: 1086.55, Q-max: 1801.15, Q-min: -29.98
Q_loss1: 1109.41, Q_loss2: 1373.40, min_Q_loss1: -195.68, min_Q_loss2: -195.89

Train epoch 292/3000 -- step 293000

[F                                                                                                    
[F[ Model Length ] Epoch: 292 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 292000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 292 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 292292
[ Model Rollout ] Added: 49112 | Model pool: 500000 (max 500000) | Length: 4.9112 | Train rep: 1

Diagnostics -- iteration 293000
real_batch_obs: 1831.59, model_batch_obs: 1980.25
real_batch_act: 191.62, model_batch_act: 192.67
real_batch_rewards: 1357.66, model_batch_rewards: 1400.38
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 277.91
total_steps: 293000.00
Q-avg: 1097.26, Q-max: 1806.40, Q-min: -1040.40
Q_loss1: 1281.80, Q_loss2: 1273.02, min_Q_loss1: -468.48, min_Q_loss2: -481.04

Train epoch 293/3000 -- step 294000

[F                                                                                                    
[F[ Model Length ] Epoch: 293 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 293000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 293 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 293293
[ Model Rollout ] Added: 48987 | Model pool: 500000 (max 500000) | Length: 4.8987 | Train rep: 1

Diagnostics -- iteration 294000
real_batch_obs: 1838.29, model_batch_obs: 1839.11
real_batch_act: 203.95, model_batch_act: 190.12
real_batch_rewards: 1306.54, model_batch_rewards: 1333.86
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 268.89
total_steps: 294000.00
Q-avg: 1126.52, Q-max: 1784.58, Q-min: -665.18
Q_loss1: 801.48, Q_loss2: 635.89, min_Q_loss1: 76.64, min_Q_loss2: 64.39

Train epoch 294/3000 -- step 295000

[F                                                                                                    
[F[ Model Length ] Epoch: 294 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 294000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 294 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 294294
[ Model Rollout ] Added: 49093 | Model pool: 500000 (max 500000) | Length: 4.9093 | Train rep: 1

Diagnostics -- iteration 295000
real_batch_obs: 1874.61, model_batch_obs: 1768.09
real_batch_act: 190.93, model_batch_act: 192.51
real_batch_rewards: 1374.27, model_batch_rewards: 1398.31
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 281.93
total_steps: 295000.00
Q-avg: 1121.55, Q-max: 1849.96, Q-min: -805.44
Q_loss1: 767.96, Q_loss2: 724.51, min_Q_loss1: -73.85, min_Q_loss2: -78.21

Train epoch 295/3000 -- step 296000

[F                                                                                                    
[F[ Model Length ] Epoch: 295 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 295000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 295 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 295295
[ Model Rollout ] Added: 48999 | Model pool: 500000 (max 500000) | Length: 4.8999 | Train rep: 1

Diagnostics -- iteration 296000
real_batch_obs: 1846.69, model_batch_obs: 2000.52
real_batch_act: 204.85, model_batch_act: 193.78
real_batch_rewards: 1331.58, model_batch_rewards: 1383.64
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 275.35
total_steps: 296000.00
Q-avg: 1147.74, Q-max: 1804.90, Q-min: -183.86
Q_loss1: 385.76, Q_loss2: 505.69, min_Q_loss1: -243.49, min_Q_loss2: -237.72

Train epoch 296/3000 -- step 297000

[F                                                                                                    
[F[ Model Length ] Epoch: 296 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 296000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 296 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 296296
[ Model Rollout ] Added: 49027 | Model pool: 500000 (max 500000) | Length: 4.9027 | Train rep: 1

Diagnostics -- iteration 297000
real_batch_obs: 1841.76, model_batch_obs: 1873.01
real_batch_act: 195.97, model_batch_act: 197.84
real_batch_rewards: 1362.70, model_batch_rewards: 1305.03
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 275.04
total_steps: 297000.00
Q-avg: 1157.75, Q-max: 1837.11, Q-min: 14.01
Q_loss1: 207.79, Q_loss2: 201.64, min_Q_loss1: 6.82, min_Q_loss2: 7.02

Train epoch 297/3000 -- step 298000

[F                                                                                                    
[F[ Model Length ] Epoch: 297 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 297000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 297 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 297297
[ Model Rollout ] Added: 49069 | Model pool: 500000 (max 500000) | Length: 4.9069 | Train rep: 1

Diagnostics -- iteration 298000
real_batch_obs: 1774.18, model_batch_obs: 1866.93
real_batch_act: 188.80, model_batch_act: 192.89
real_batch_rewards: 1313.30, model_batch_rewards: 1337.95
real_batch_dones: 1.00, model_batch_dones: 4.00
evaluation/return-average: 272.23
total_steps: 298000.00
Q-avg: 1106.45, Q-max: 1846.09, Q-min: -59.90
Q_loss1: 641.30, Q_loss2: 812.77, min_Q_loss1: -409.78, min_Q_loss2: -415.68

Train epoch 298/3000 -- step 299000

[F                                                                                                    
[F[ Model Length ] Epoch: 298 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 298000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 298 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 298298
[ Model Rollout ] Added: 48999 | Model pool: 500000 (max 500000) | Length: 4.8999 | Train rep: 1

Diagnostics -- iteration 299000
real_batch_obs: 1805.05, model_batch_obs: 1796.47
real_batch_act: 213.78, model_batch_act: 182.55
real_batch_rewards: 1313.54, model_batch_rewards: 1307.07
real_batch_dones: 1.00, model_batch_dones: 4.00
evaluation/return-average: 260.77
total_steps: 299000.00
Q-avg: 1150.58, Q-max: 1809.96, Q-min: -56.97
Q_loss1: 1823.49, Q_loss2: 1832.96, min_Q_loss1: -169.83, min_Q_loss2: -161.78

Train epoch 299/3000 -- step 300000

[F                                                                                                    
[F[ Model Length ] Epoch: 299 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 299000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 299 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 299299
[ Model Rollout ] Added: 49020 | Model pool: 500000 (max 500000) | Length: 4.902 | Train rep: 1

Diagnostics -- iteration 300000
real_batch_obs: 1770.87, model_batch_obs: 1855.00
real_batch_act: 200.74, model_batch_act: 189.36
real_batch_rewards: 1335.14, model_batch_rewards: 1332.20
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 257.23
total_steps: 300000.00
Q-avg: 1118.49, Q-max: 1835.49, Q-min: -854.12
Q_loss1: 378.43, Q_loss2: 517.04, min_Q_loss1: -101.67, min_Q_loss2: -100.23

Train epoch 300/3000 -- step 301000

[F                                                                                                    
[F[ Model Length ] Epoch: 300 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 300000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 300 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 300300
[ Model Rollout ] Added: 49086 | Model pool: 500000 (max 500000) | Length: 4.9086 | Train rep: 1

Diagnostics -- iteration 301000
real_batch_obs: 1840.40, model_batch_obs: 1764.92
real_batch_act: 203.22, model_batch_act: 188.94
real_batch_rewards: 1409.98, model_batch_rewards: 1345.30
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 327.36
total_steps: 301000.00
Q-avg: 1089.85, Q-max: 1767.50, Q-min: -60.45
Q_loss1: 1771.10, Q_loss2: 2211.51, min_Q_loss1: 61.67, min_Q_loss2: 66.83

Train epoch 301/3000 -- step 302000

[F                                                                                                    
[F[ Model Length ] Epoch: 301 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 301000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 301 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 301301
[ Model Rollout ] Added: 49043 | Model pool: 500000 (max 500000) | Length: 4.9043 | Train rep: 1

Diagnostics -- iteration 302000
real_batch_obs: 1822.24, model_batch_obs: 1851.63
real_batch_act: 196.53, model_batch_act: 187.07
real_batch_rewards: 1333.59, model_batch_rewards: 1355.28
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 345.97
total_steps: 302000.00
Q-avg: 1189.53, Q-max: 1849.70, Q-min: -558.43
Q_loss1: 554.02, Q_loss2: 608.92, min_Q_loss1: 0.39, min_Q_loss2: 0.77

Train epoch 302/3000 -- step 303000

[F                                                                                                    
[F[ Model Length ] Epoch: 302 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 302000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 302 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 302302
[ Model Rollout ] Added: 49038 | Model pool: 500000 (max 500000) | Length: 4.9038 | Train rep: 1

Diagnostics -- iteration 303000
real_batch_obs: 1812.38, model_batch_obs: 1854.43
real_batch_act: 201.77, model_batch_act: 191.80
real_batch_rewards: 1342.29, model_batch_rewards: 1305.95
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 311.14
total_steps: 303000.00
Q-avg: 1080.31, Q-max: 1767.00, Q-min: -86.83
Q_loss1: 275.93, Q_loss2: 334.68, min_Q_loss1: -62.46, min_Q_loss2: -50.34

Train epoch 303/3000 -- step 304000

[F                                                                                                    
[F[ Model Length ] Epoch: 303 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 303000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 303 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 303303
[ Model Rollout ] Added: 49067 | Model pool: 500000 (max 500000) | Length: 4.9067 | Train rep: 1

Diagnostics -- iteration 304000
real_batch_obs: 1796.35, model_batch_obs: 2016.56
real_batch_act: 202.66, model_batch_act: 196.42
real_batch_rewards: 1256.85, model_batch_rewards: 1368.90
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 292.06
total_steps: 304000.00
Q-avg: 1153.10, Q-max: 1771.09, Q-min: -33.82
Q_loss1: 365.78, Q_loss2: 336.08, min_Q_loss1: -130.45, min_Q_loss2: -138.39

Train epoch 304/3000 -- step 305000

[F                                                                                                    
[F[ Model Length ] Epoch: 304 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 304000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 304 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 304304
[ Model Rollout ] Added: 49021 | Model pool: 500000 (max 500000) | Length: 4.9021 | Train rep: 1

Diagnostics -- iteration 305000
real_batch_obs: 1793.30, model_batch_obs: 1893.04
real_batch_act: 201.55, model_batch_act: 184.75
real_batch_rewards: 1346.56, model_batch_rewards: 1406.41
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 260.95
total_steps: 305000.00
Q-avg: 1101.94, Q-max: 1787.63, Q-min: -616.83
Q_loss1: 1980.99, Q_loss2: 2025.40, min_Q_loss1: -189.11, min_Q_loss2: -187.41

Train epoch 305/3000 -- step 306000

[F                                                                                                    
[F[ Model Length ] Epoch: 305 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 305000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 305 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 305305
[ Model Rollout ] Added: 49023 | Model pool: 500000 (max 500000) | Length: 4.9023 | Train rep: 1

Diagnostics -- iteration 306000
real_batch_obs: 1804.83, model_batch_obs: 1966.17
real_batch_act: 205.04, model_batch_act: 191.06
real_batch_rewards: 1328.79, model_batch_rewards: 1363.63
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 280.18
total_steps: 306000.00
Q-avg: 1169.70, Q-max: 1828.37, Q-min: -32.91
Q_loss1: 155.87, Q_loss2: 183.87, min_Q_loss1: -184.76, min_Q_loss2: -191.30

Train epoch 306/3000 -- step 307000

[F                                                                                                    
[F[ Model Length ] Epoch: 306 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 306000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 306 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 306306
[ Model Rollout ] Added: 48999 | Model pool: 500000 (max 500000) | Length: 4.8999 | Train rep: 1

Diagnostics -- iteration 307000
real_batch_obs: 1839.49, model_batch_obs: 1952.52
real_batch_act: 203.78, model_batch_act: 201.05
real_batch_rewards: 1323.83, model_batch_rewards: 1423.22
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 254.66
total_steps: 307000.00
Q-avg: 1103.47, Q-max: 1728.93, Q-min: -622.17
Q_loss1: 595.53, Q_loss2: 894.83, min_Q_loss1: -580.35, min_Q_loss2: -571.93

Train epoch 307/3000 -- step 308000

[F                                                                                                    
[F[ Model Length ] Epoch: 307 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 307000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 307 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 307307
[ Model Rollout ] Added: 49070 | Model pool: 500000 (max 500000) | Length: 4.907 | Train rep: 1

Diagnostics -- iteration 308000
real_batch_obs: 1994.18, model_batch_obs: 2019.23
real_batch_act: 205.64, model_batch_act: 198.79
real_batch_rewards: 1337.08, model_batch_rewards: 1357.47
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 257.08
total_steps: 308000.00
Q-avg: 1164.51, Q-max: 1685.08, Q-min: -258.12
Q_loss1: 524.52, Q_loss2: 552.26, min_Q_loss1: -271.57, min_Q_loss2: -280.40

Train epoch 308/3000 -- step 309000

[F                                                                                                    
[F[ Model Length ] Epoch: 308 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 308000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 308 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 308308
[ Model Rollout ] Added: 49020 | Model pool: 500000 (max 500000) | Length: 4.902 | Train rep: 1

Diagnostics -- iteration 309000
real_batch_obs: 1854.01, model_batch_obs: 1836.00
real_batch_act: 207.33, model_batch_act: 188.88
real_batch_rewards: 1327.39, model_batch_rewards: 1369.41
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 265.24
total_steps: 309000.00
Q-avg: 1107.45, Q-max: 1701.90, Q-min: -269.98
Q_loss1: 722.12, Q_loss2: 635.79, min_Q_loss1: -278.23, min_Q_loss2: -292.01

Train epoch 309/3000 -- step 310000

[F                                                                                                    
[F[ Model Length ] Epoch: 309 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 309000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 309 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 309309
[ Model Rollout ] Added: 49055 | Model pool: 500000 (max 500000) | Length: 4.9055 | Train rep: 1

Diagnostics -- iteration 310000
real_batch_obs: 1861.69, model_batch_obs: 2035.32
real_batch_act: 202.02, model_batch_act: 192.79
real_batch_rewards: 1370.81, model_batch_rewards: 1315.24
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 265.81
total_steps: 310000.00
Q-avg: 1159.50, Q-max: 1665.46, Q-min: -356.67
Q_loss1: 2479.47, Q_loss2: 2261.76, min_Q_loss1: -153.77, min_Q_loss2: -151.18

Train epoch 310/3000 -- step 311000

[F                                                                                                    
[F[ Model Length ] Epoch: 310 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 310000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 310 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 310310
[ Model Rollout ] Added: 49001 | Model pool: 500000 (max 500000) | Length: 4.9001 | Train rep: 1

Diagnostics -- iteration 311000
real_batch_obs: 1831.37, model_batch_obs: 1853.13
real_batch_act: 185.45, model_batch_act: 185.60
real_batch_rewards: 1333.53, model_batch_rewards: 1339.89
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 258.84
total_steps: 311000.00
Q-avg: 1072.15, Q-max: 1673.13, Q-min: -707.16
Q_loss1: 647.09, Q_loss2: 646.04, min_Q_loss1: -523.79, min_Q_loss2: -541.00

Train epoch 311/3000 -- step 312000

[F                                                                                                    
[F[ Model Length ] Epoch: 311 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 311000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 311 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 311311
[ Model Rollout ] Added: 49001 | Model pool: 500000 (max 500000) | Length: 4.9001 | Train rep: 1

Diagnostics -- iteration 312000
real_batch_obs: 1783.97, model_batch_obs: 1860.83
real_batch_act: 191.27, model_batch_act: 200.16
real_batch_rewards: 1326.84, model_batch_rewards: 1330.49
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 268.37
total_steps: 312000.00
Q-avg: 1125.28, Q-max: 1680.28, Q-min: -616.48
Q_loss1: 1013.70, Q_loss2: 862.25, min_Q_loss1: -236.28, min_Q_loss2: -248.14

Train epoch 312/3000 -- step 313000

[F                                                                                                    
[F[ Model Length ] Epoch: 312 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 312000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 312 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 312312
[ Model Rollout ] Added: 49109 | Model pool: 500000 (max 500000) | Length: 4.9109 | Train rep: 1

Diagnostics -- iteration 313000
real_batch_obs: 1822.52, model_batch_obs: 1922.65
real_batch_act: 216.63, model_batch_act: 194.05
real_batch_rewards: 1354.34, model_batch_rewards: 1360.51
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 281.34
total_steps: 313000.00
Q-avg: 1091.82, Q-max: 1666.67, Q-min: -1159.05
Q_loss1: 859.56, Q_loss2: 869.96, min_Q_loss1: -474.12, min_Q_loss2: -481.55

Train epoch 313/3000 -- step 314000

[F                                                                                                    
[F[ Model Length ] Epoch: 313 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 313000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 313 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 313313
[ Model Rollout ] Added: 48951 | Model pool: 500000 (max 500000) | Length: 4.8951 | Train rep: 1

Diagnostics -- iteration 314000
real_batch_obs: 1767.76, model_batch_obs: 1910.44
real_batch_act: 189.12, model_batch_act: 195.24
real_batch_rewards: 1331.79, model_batch_rewards: 1312.84
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 274.31
total_steps: 314000.00
Q-avg: 1128.00, Q-max: 1654.64, Q-min: -26.90
Q_loss1: 147.83, Q_loss2: 118.83, min_Q_loss1: -207.09, min_Q_loss2: -215.80

Train epoch 314/3000 -- step 315000

[F                                                                                                    
[F[ Model Length ] Epoch: 314 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 314000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 314 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 314314
[ Model Rollout ] Added: 49077 | Model pool: 500000 (max 500000) | Length: 4.9077 | Train rep: 1

Diagnostics -- iteration 315000
real_batch_obs: 2016.85, model_batch_obs: 1802.29
real_batch_act: 213.64, model_batch_act: 180.88
real_batch_rewards: 1420.81, model_batch_rewards: 1269.12
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 271.40
total_steps: 315000.00
Q-avg: 1119.94, Q-max: 1678.49, Q-min: -78.09
Q_loss1: 2606.90, Q_loss2: 2481.50, min_Q_loss1: -36.51, min_Q_loss2: -39.10

Train epoch 315/3000 -- step 316000

[F                                                                                                    
[F[ Model Length ] Epoch: 315 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 315000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 315 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 315315
[ Model Rollout ] Added: 49051 | Model pool: 500000 (max 500000) | Length: 4.9051 | Train rep: 1

Diagnostics -- iteration 316000
real_batch_obs: 1877.89, model_batch_obs: 1870.14
real_batch_act: 197.51, model_batch_act: 192.63
real_batch_rewards: 1395.64, model_batch_rewards: 1300.34
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 256.95
total_steps: 316000.00
Q-avg: 1095.40, Q-max: 1670.57, Q-min: -413.46
Q_loss1: 1172.70, Q_loss2: 441.72, min_Q_loss1: -23.97, min_Q_loss2: -38.99

Train epoch 316/3000 -- step 317000

[F                                                                                                    
[F[ Model Length ] Epoch: 316 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 316000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 316 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 316316
[ Model Rollout ] Added: 48975 | Model pool: 500000 (max 500000) | Length: 4.8975 | Train rep: 1

Diagnostics -- iteration 317000
real_batch_obs: 1768.49, model_batch_obs: 1959.22
real_batch_act: 203.86, model_batch_act: 193.42
real_batch_rewards: 1360.67, model_batch_rewards: 1405.00
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 249.09
total_steps: 317000.00
Q-avg: 1091.39, Q-max: 1625.69, Q-min: -953.50
Q_loss1: 499.99, Q_loss2: 459.54, min_Q_loss1: -242.82, min_Q_loss2: -240.25

Train epoch 317/3000 -- step 318000

[F                                                                                                    
[F[ Model Length ] Epoch: 317 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 317000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 317 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 317317
[ Model Rollout ] Added: 49043 | Model pool: 500000 (max 500000) | Length: 4.9043 | Train rep: 1

Diagnostics -- iteration 318000
real_batch_obs: 1932.69, model_batch_obs: 1899.09
real_batch_act: 208.97, model_batch_act: 195.10
real_batch_rewards: 1358.27, model_batch_rewards: 1352.56
real_batch_dones: 2.00, model_batch_dones: 1.00
evaluation/return-average: 243.79
total_steps: 318000.00
Q-avg: 1091.58, Q-max: 1650.80, Q-min: -421.31
Q_loss1: 2817.72, Q_loss2: 2727.16, min_Q_loss1: -324.09, min_Q_loss2: -320.75

Train epoch 318/3000 -- step 319000

[F                                                                                                    
[F[ Model Length ] Epoch: 318 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 318000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 318 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 318318
[ Model Rollout ] Added: 49055 | Model pool: 500000 (max 500000) | Length: 4.9055 | Train rep: 1

Diagnostics -- iteration 319000
real_batch_obs: 1861.22, model_batch_obs: 1954.61
real_batch_act: 202.44, model_batch_act: 200.34
real_batch_rewards: 1298.27, model_batch_rewards: 1338.31
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 245.40
total_steps: 319000.00
Q-avg: 1159.12, Q-max: 1630.51, Q-min: -121.07
Q_loss1: 158.69, Q_loss2: 243.20, min_Q_loss1: -257.92, min_Q_loss2: -257.26

Train epoch 319/3000 -- step 320000

[F                                                                                                    
[F[ Model Length ] Epoch: 319 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 319000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 319 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 319319
[ Model Rollout ] Added: 49046 | Model pool: 500000 (max 500000) | Length: 4.9046 | Train rep: 1

Diagnostics -- iteration 320000
real_batch_obs: 1736.71, model_batch_obs: 1991.34
real_batch_act: 196.50, model_batch_act: 193.58
real_batch_rewards: 1322.32, model_batch_rewards: 1393.46
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 261.09
total_steps: 320000.00
Q-avg: 1091.30, Q-max: 1654.88, Q-min: -493.95
Q_loss1: 280.62, Q_loss2: 260.54, min_Q_loss1: -472.90, min_Q_loss2: -472.95

Train epoch 320/3000 -- step 321000

[F                                                                                                    
[F[ Model Length ] Epoch: 320 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 320000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 320 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 320320
[ Model Rollout ] Added: 49062 | Model pool: 500000 (max 500000) | Length: 4.9062 | Train rep: 1

Diagnostics -- iteration 321000
real_batch_obs: 1823.28, model_batch_obs: 1870.46
real_batch_act: 203.55, model_batch_act: 186.26
real_batch_rewards: 1333.41, model_batch_rewards: 1285.01
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 257.95
total_steps: 321000.00
Q-avg: 1115.40, Q-max: 1607.19, Q-min: -159.89
Q_loss1: 414.04, Q_loss2: 375.54, min_Q_loss1: 2.64, min_Q_loss2: 2.71

Train epoch 321/3000 -- step 322000

[F                                                                                                    
[F[ Model Length ] Epoch: 321 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 321000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 321 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 321321
[ Model Rollout ] Added: 49011 | Model pool: 500000 (max 500000) | Length: 4.9011 | Train rep: 1

Diagnostics -- iteration 322000
real_batch_obs: 1807.13, model_batch_obs: 1976.07
real_batch_act: 189.86, model_batch_act: 183.36
real_batch_rewards: 1324.07, model_batch_rewards: 1345.38
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 273.53
total_steps: 322000.00
Q-avg: 1136.59, Q-max: 1619.23, Q-min: -205.32
Q_loss1: 947.70, Q_loss2: 901.13, min_Q_loss1: -336.07, min_Q_loss2: -337.44

Train epoch 322/3000 -- step 323000

[F                                                                                                    
[F[ Model Length ] Epoch: 322 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 322000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 322 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 322322
[ Model Rollout ] Added: 49048 | Model pool: 500000 (max 500000) | Length: 4.9048 | Train rep: 1

Diagnostics -- iteration 323000
real_batch_obs: 1846.84, model_batch_obs: 1933.18
real_batch_act: 202.01, model_batch_act: 198.98
real_batch_rewards: 1351.21, model_batch_rewards: 1363.92
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 334.33
total_steps: 323000.00
Q-avg: 1049.85, Q-max: 1589.14, Q-min: -492.76
Q_loss1: 653.66, Q_loss2: 727.16, min_Q_loss1: -351.69, min_Q_loss2: -356.45

Train epoch 323/3000 -- step 324000

[F                                                                                                    
[F[ Model Length ] Epoch: 323 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 323000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 323 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 323323
[ Model Rollout ] Added: 49074 | Model pool: 500000 (max 500000) | Length: 4.9074 | Train rep: 1

Diagnostics -- iteration 324000
real_batch_obs: 1924.11, model_batch_obs: 1908.84
real_batch_act: 196.68, model_batch_act: 182.54
real_batch_rewards: 1342.49, model_batch_rewards: 1377.15
real_batch_dones: 2.00, model_batch_dones: 4.00
evaluation/return-average: 288.29
total_steps: 324000.00
Q-avg: 1032.95, Q-max: 1597.02, Q-min: -588.96
Q_loss1: 7370.57, Q_loss2: 7496.56, min_Q_loss1: -556.56, min_Q_loss2: -548.70

Train epoch 324/3000 -- step 325000

[F                                                                                                    
[F[ Model Length ] Epoch: 324 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 324000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 324 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 324324
[ Model Rollout ] Added: 48999 | Model pool: 500000 (max 500000) | Length: 4.8999 | Train rep: 1

Diagnostics -- iteration 325000
real_batch_obs: 1832.47, model_batch_obs: 1870.11
real_batch_act: 204.20, model_batch_act: 196.99
real_batch_rewards: 1347.37, model_batch_rewards: 1355.50
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 284.31
total_steps: 325000.00
Q-avg: 1100.36, Q-max: 1597.44, Q-min: -450.21
Q_loss1: 1381.53, Q_loss2: 920.07, min_Q_loss1: -242.09, min_Q_loss2: -237.18

Train epoch 325/3000 -- step 326000

[F                                                                                                    
[F[ Model Length ] Epoch: 325 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 325000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 325 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 325325
[ Model Rollout ] Added: 49027 | Model pool: 500000 (max 500000) | Length: 4.9027 | Train rep: 1

Diagnostics -- iteration 326000
real_batch_obs: 1890.41, model_batch_obs: 1781.24
real_batch_act: 194.66, model_batch_act: 202.59
real_batch_rewards: 1391.60, model_batch_rewards: 1333.33
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 269.42
total_steps: 326000.00
Q-avg: 1096.43, Q-max: 1571.84, Q-min: -394.65
Q_loss1: 290.32, Q_loss2: 315.53, min_Q_loss1: -175.89, min_Q_loss2: -177.17

Train epoch 326/3000 -- step 327000

[F                                                                                                    
[F[ Model Length ] Epoch: 326 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 326000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 326 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 326326
[ Model Rollout ] Added: 49007 | Model pool: 500000 (max 500000) | Length: 4.9007 | Train rep: 1

Diagnostics -- iteration 327000
real_batch_obs: 1869.48, model_batch_obs: 1906.76
real_batch_act: 209.12, model_batch_act: 196.83
real_batch_rewards: 1305.11, model_batch_rewards: 1322.49
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 268.68
total_steps: 327000.00
Q-avg: 1109.51, Q-max: 1595.03, Q-min: -738.69
Q_loss1: 1618.18, Q_loss2: 1804.59, min_Q_loss1: -382.24, min_Q_loss2: -395.40

Train epoch 327/3000 -- step 328000

[F                                                                                                    
[F[ Model Length ] Epoch: 327 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 327000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 327 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 327327
[ Model Rollout ] Added: 49039 | Model pool: 500000 (max 500000) | Length: 4.9039 | Train rep: 1

Diagnostics -- iteration 328000
real_batch_obs: 1894.75, model_batch_obs: 1938.06
real_batch_act: 204.71, model_batch_act: 188.33
real_batch_rewards: 1394.22, model_batch_rewards: 1326.29
real_batch_dones: 0.00, model_batch_dones: 5.00
evaluation/return-average: 269.90
total_steps: 328000.00
Q-avg: 1076.14, Q-max: 1593.58, Q-min: -107.99
Q_loss1: 1409.09, Q_loss2: 1345.33, min_Q_loss1: -177.85, min_Q_loss2: -175.81

Train epoch 328/3000 -- step 329000

[F                                                                                                    
[F[ Model Length ] Epoch: 328 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 328000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 328 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 328328
[ Model Rollout ] Added: 48997 | Model pool: 500000 (max 500000) | Length: 4.8997 | Train rep: 1

Diagnostics -- iteration 329000
real_batch_obs: 1887.25, model_batch_obs: 1795.82
real_batch_act: 199.92, model_batch_act: 186.97
real_batch_rewards: 1288.04, model_batch_rewards: 1275.71
real_batch_dones: 2.00, model_batch_dones: 0.00
evaluation/return-average: 274.85
total_steps: 329000.00
Q-avg: 1078.78, Q-max: 1509.79, Q-min: -608.46
Q_loss1: 7193.28, Q_loss2: 6831.66, min_Q_loss1: -391.48, min_Q_loss2: -391.30

Train epoch 329/3000 -- step 330000

[F                                                                                                    
[F[ Model Length ] Epoch: 329 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 329000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 329 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 329329
[ Model Rollout ] Added: 49054 | Model pool: 500000 (max 500000) | Length: 4.9054 | Train rep: 1

Diagnostics -- iteration 330000
real_batch_obs: 1807.40, model_batch_obs: 1884.29
real_batch_act: 197.99, model_batch_act: 190.29
real_batch_rewards: 1342.47, model_batch_rewards: 1325.31
real_batch_dones: 3.00, model_batch_dones: 2.00
evaluation/return-average: 272.00
total_steps: 330000.00
Q-avg: 1037.31, Q-max: 1518.13, Q-min: -147.09
Q_loss1: 440.31, Q_loss2: 222.33, min_Q_loss1: -232.46, min_Q_loss2: -232.37

Train epoch 330/3000 -- step 331000

[F                                                                                                    
[F[ Model Length ] Epoch: 330 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 330000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 330 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 330330
[ Model Rollout ] Added: 49020 | Model pool: 500000 (max 500000) | Length: 4.902 | Train rep: 1

Diagnostics -- iteration 331000
real_batch_obs: 1791.61, model_batch_obs: 1890.62
real_batch_act: 199.44, model_batch_act: 183.38
real_batch_rewards: 1330.22, model_batch_rewards: 1320.85
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 274.94
total_steps: 331000.00
Q-avg: 1116.60, Q-max: 1587.44, Q-min: -127.15
Q_loss1: 635.10, Q_loss2: 695.51, min_Q_loss1: -339.43, min_Q_loss2: -348.09

Train epoch 331/3000 -- step 332000

[F                                                                                                    
[F[ Model Length ] Epoch: 331 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 331000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 331 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 331331
[ Model Rollout ] Added: 49054 | Model pool: 500000 (max 500000) | Length: 4.9054 | Train rep: 1

Diagnostics -- iteration 332000
real_batch_obs: 1878.24, model_batch_obs: 1856.69
real_batch_act: 199.39, model_batch_act: 197.64
real_batch_rewards: 1311.51, model_batch_rewards: 1299.01
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 268.22
total_steps: 332000.00
Q-avg: 1068.65, Q-max: 1522.91, Q-min: -172.37
Q_loss1: 315.36, Q_loss2: 297.27, min_Q_loss1: -67.49, min_Q_loss2: -69.41

Train epoch 332/3000 -- step 333000

[F                                                                                                    
[F[ Model Length ] Epoch: 332 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 332000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 332 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 332332
[ Model Rollout ] Added: 49094 | Model pool: 500000 (max 500000) | Length: 4.9094 | Train rep: 1

Diagnostics -- iteration 333000
real_batch_obs: 1983.17, model_batch_obs: 1854.39
real_batch_act: 199.61, model_batch_act: 198.32
real_batch_rewards: 1288.26, model_batch_rewards: 1273.76
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 283.95
total_steps: 333000.00
Q-avg: 1101.22, Q-max: 1510.90, Q-min: -274.24
Q_loss1: 799.91, Q_loss2: 816.30, min_Q_loss1: -275.12, min_Q_loss2: -279.48

Train epoch 333/3000 -- step 334000

[F                                                                                                    
[F[ Model Length ] Epoch: 333 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 333000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 333 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 333333
[ Model Rollout ] Added: 48910 | Model pool: 500000 (max 500000) | Length: 4.891 | Train rep: 1

Diagnostics -- iteration 334000
real_batch_obs: 1909.36, model_batch_obs: 1934.21
real_batch_act: 194.02, model_batch_act: 191.13
real_batch_rewards: 1329.80, model_batch_rewards: 1387.25
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 279.29
total_steps: 334000.00
Q-avg: 1078.69, Q-max: 1541.20, Q-min: -216.49
Q_loss1: 215.25, Q_loss2: 182.79, min_Q_loss1: -388.91, min_Q_loss2: -394.08

Train epoch 334/3000 -- step 335000

[F                                                                                                    
[F[ Model Length ] Epoch: 334 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 334000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 334 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 334334
[ Model Rollout ] Added: 49059 | Model pool: 500000 (max 500000) | Length: 4.9059 | Train rep: 1

Diagnostics -- iteration 335000
real_batch_obs: 1876.20, model_batch_obs: 1834.86
real_batch_act: 195.74, model_batch_act: 192.29
real_batch_rewards: 1368.95, model_batch_rewards: 1333.48
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 281.44
total_steps: 335000.00
Q-avg: 1036.51, Q-max: 1598.58, Q-min: -326.77
Q_loss1: 376.74, Q_loss2: 401.24, min_Q_loss1: -148.22, min_Q_loss2: -147.02

Train epoch 335/3000 -- step 336000

[F                                                                                                    
[F[ Model Length ] Epoch: 335 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 335000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 335 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 335335
[ Model Rollout ] Added: 49040 | Model pool: 500000 (max 500000) | Length: 4.904 | Train rep: 1

Diagnostics -- iteration 336000
real_batch_obs: 1828.82, model_batch_obs: 1923.76
real_batch_act: 197.66, model_batch_act: 193.33
real_batch_rewards: 1375.38, model_batch_rewards: 1336.04
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 267.48
total_steps: 336000.00
Q-avg: 1120.05, Q-max: 1597.07, Q-min: -27.95
Q_loss1: 136.29, Q_loss2: 183.13, min_Q_loss1: -59.36, min_Q_loss2: -65.50

Train epoch 336/3000 -- step 337000

[F                                                                                                    
[F[ Model Length ] Epoch: 336 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 336000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 336 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 336336
[ Model Rollout ] Added: 49004 | Model pool: 500000 (max 500000) | Length: 4.9004 | Train rep: 1

Diagnostics -- iteration 337000
real_batch_obs: 1910.70, model_batch_obs: 1911.95
real_batch_act: 193.24, model_batch_act: 198.97
real_batch_rewards: 1462.75, model_batch_rewards: 1335.53
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 271.02
total_steps: 337000.00
Q-avg: 1025.76, Q-max: 1548.16, Q-min: -295.02
Q_loss1: 470.93, Q_loss2: 466.84, min_Q_loss1: 32.01, min_Q_loss2: 35.37

Train epoch 337/3000 -- step 338000

[F                                                                                                    
[F[ Model Length ] Epoch: 337 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 337000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 337 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 337337
[ Model Rollout ] Added: 49108 | Model pool: 500000 (max 500000) | Length: 4.9108 | Train rep: 1

Diagnostics -- iteration 338000
real_batch_obs: 1848.72, model_batch_obs: 1882.34
real_batch_act: 198.84, model_batch_act: 190.08
real_batch_rewards: 1366.29, model_batch_rewards: 1278.42
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 291.38
total_steps: 338000.00
Q-avg: 1128.94, Q-max: 1674.37, Q-min: -102.44
Q_loss1: 291.37, Q_loss2: 349.60, min_Q_loss1: -14.45, min_Q_loss2: -11.31

Train epoch 338/3000 -- step 339000

[F                                                                                                    
[F[ Model Length ] Epoch: 338 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 338000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 338 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 338338
[ Model Rollout ] Added: 48998 | Model pool: 500000 (max 500000) | Length: 4.8998 | Train rep: 1

Diagnostics -- iteration 339000
real_batch_obs: 1801.01, model_batch_obs: 1968.83
real_batch_act: 198.65, model_batch_act: 188.57
real_batch_rewards: 1367.16, model_batch_rewards: 1347.26
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 299.15
total_steps: 339000.00
Q-avg: 1070.50, Q-max: 1614.70, Q-min: -1004.98
Q_loss1: 1154.84, Q_loss2: 605.57, min_Q_loss1: -160.01, min_Q_loss2: -167.46

Train epoch 339/3000 -- step 340000

[F                                                                                                    
[F[ Model Length ] Epoch: 339 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 339000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 339 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 339339
[ Model Rollout ] Added: 49032 | Model pool: 500000 (max 500000) | Length: 4.9032 | Train rep: 1

Diagnostics -- iteration 340000
real_batch_obs: 1751.72, model_batch_obs: 1900.55
real_batch_act: 177.96, model_batch_act: 194.58
real_batch_rewards: 1351.73, model_batch_rewards: 1677.41
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 283.80
total_steps: 340000.00
Q-avg: 1031.89, Q-max: 1611.03, Q-min: -1212.34
Q_loss1: 1321.01, Q_loss2: 1033.58, min_Q_loss1: -30.81, min_Q_loss2: -34.05

Train epoch 340/3000 -- step 341000

[F                                                                                                    
[F[ Model Length ] Epoch: 340 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 340000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 340 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 340340
[ Model Rollout ] Added: 49045 | Model pool: 500000 (max 500000) | Length: 4.9045 | Train rep: 1

Diagnostics -- iteration 341000
real_batch_obs: 1881.12, model_batch_obs: 1939.68
real_batch_act: 186.18, model_batch_act: 199.86
real_batch_rewards: 1362.99, model_batch_rewards: 1326.14
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 295.83
total_steps: 341000.00
Q-avg: 1099.52, Q-max: 1598.97, Q-min: -54.44
Q_loss1: 328.03, Q_loss2: 342.27, min_Q_loss1: -136.02, min_Q_loss2: -123.41

Train epoch 341/3000 -- step 342000

[F                                                                                                    
[F[ Model Length ] Epoch: 341 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 341000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 341 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 341341
[ Model Rollout ] Added: 48998 | Model pool: 500000 (max 500000) | Length: 4.8998 | Train rep: 1

Diagnostics -- iteration 342000
real_batch_obs: 1861.53, model_batch_obs: 1826.30
real_batch_act: 192.31, model_batch_act: 193.73
real_batch_rewards: 1311.55, model_batch_rewards: 1412.79
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 286.80
total_steps: 342000.00
Q-avg: 1053.02, Q-max: 1589.59, Q-min: -828.25
Q_loss1: 1112.32, Q_loss2: 1373.77, min_Q_loss1: -248.33, min_Q_loss2: -239.98

Train epoch 342/3000 -- step 343000

[F                                                                                                    
[F[ Model Length ] Epoch: 342 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 342000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 342 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 342342
[ Model Rollout ] Added: 49012 | Model pool: 500000 (max 500000) | Length: 4.9012 | Train rep: 1

Diagnostics -- iteration 343000
real_batch_obs: 2002.68, model_batch_obs: 1843.79
real_batch_act: 192.38, model_batch_act: 194.47
real_batch_rewards: 1384.03, model_batch_rewards: 1312.30
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 305.29
total_steps: 343000.00
Q-avg: 1069.33, Q-max: 1620.23, Q-min: -31.54
Q_loss1: 2866.32, Q_loss2: 2749.63, min_Q_loss1: -232.09, min_Q_loss2: -240.35

Train epoch 343/3000 -- step 344000

[F                                                                                                    
[F[ Model Length ] Epoch: 343 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 343000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 343 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 343343
[ Model Rollout ] Added: 48941 | Model pool: 500000 (max 500000) | Length: 4.8941 | Train rep: 1

Diagnostics -- iteration 344000
real_batch_obs: 1872.49, model_batch_obs: 1943.71
real_batch_act: 201.30, model_batch_act: 186.89
real_batch_rewards: 1344.25, model_batch_rewards: 1308.28
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 352.24
total_steps: 344000.00
Q-avg: 1070.40, Q-max: 1603.06, Q-min: -576.64
Q_loss1: 789.26, Q_loss2: 904.36, min_Q_loss1: -133.93, min_Q_loss2: -134.95

Train epoch 344/3000 -- step 345000

[F                                                                                                    
[F[ Model Length ] Epoch: 344 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 344000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 344 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 344344
[ Model Rollout ] Added: 49050 | Model pool: 500000 (max 500000) | Length: 4.905 | Train rep: 1

Diagnostics -- iteration 345000
real_batch_obs: 1731.04, model_batch_obs: 1841.43
real_batch_act: 200.47, model_batch_act: 188.77
real_batch_rewards: 1235.24, model_batch_rewards: 1409.86
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 293.73
total_steps: 345000.00
Q-avg: 1099.23, Q-max: 1625.01, Q-min: -232.87
Q_loss1: 263.33, Q_loss2: 202.24, min_Q_loss1: -433.75, min_Q_loss2: -441.69

Train epoch 345/3000 -- step 346000

[F                                                                                                    
[F[ Model Length ] Epoch: 345 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 345000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 345 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 345345
[ Model Rollout ] Added: 49104 | Model pool: 500000 (max 500000) | Length: 4.9104 | Train rep: 1

Diagnostics -- iteration 346000
real_batch_obs: 1843.83, model_batch_obs: 1898.89
real_batch_act: 194.91, model_batch_act: 190.76
real_batch_rewards: 1396.05, model_batch_rewards: 1378.24
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 317.88
total_steps: 346000.00
Q-avg: 1078.41, Q-max: 1605.96, Q-min: -214.33
Q_loss1: 373.61, Q_loss2: 451.94, min_Q_loss1: 95.85, min_Q_loss2: 91.78

Train epoch 346/3000 -- step 347000

[F                                                                                                    
[F[ Model Length ] Epoch: 346 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 346000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 346 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 346346
[ Model Rollout ] Added: 49008 | Model pool: 500000 (max 500000) | Length: 4.9008 | Train rep: 1

Diagnostics -- iteration 347000
real_batch_obs: 1805.35, model_batch_obs: 1859.94
real_batch_act: 198.62, model_batch_act: 189.34
real_batch_rewards: 1365.21, model_batch_rewards: 1320.99
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 298.46
total_steps: 347000.00
Q-avg: 1073.75, Q-max: 1693.01, Q-min: -266.93
Q_loss1: 734.32, Q_loss2: 744.24, min_Q_loss1: -130.47, min_Q_loss2: -135.36

Train epoch 347/3000 -- step 348000

[F                                                                                                    
[F[ Model Length ] Epoch: 347 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 347000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 347 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 347347
[ Model Rollout ] Added: 49100 | Model pool: 500000 (max 500000) | Length: 4.91 | Train rep: 1

Diagnostics -- iteration 348000
real_batch_obs: 1901.33, model_batch_obs: 1897.86
real_batch_act: 198.33, model_batch_act: 183.49
real_batch_rewards: 1297.91, model_batch_rewards: 1355.65
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 277.51
total_steps: 348000.00
Q-avg: 1102.08, Q-max: 1611.49, Q-min: -311.14
Q_loss1: 737.10, Q_loss2: 890.61, min_Q_loss1: -389.93, min_Q_loss2: -392.32

Train epoch 348/3000 -- step 349000

[F                                                                                                    
[F[ Model Length ] Epoch: 348 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 348000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 348 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 348348
[ Model Rollout ] Added: 48961 | Model pool: 500000 (max 500000) | Length: 4.8961 | Train rep: 1

Diagnostics -- iteration 349000
real_batch_obs: 1924.25, model_batch_obs: 1982.71
real_batch_act: 213.18, model_batch_act: 197.67
real_batch_rewards: 1434.69, model_batch_rewards: 1316.53
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 336.47
total_steps: 349000.00
Q-avg: 1091.27, Q-max: 1600.75, Q-min: -34.29
Q_loss1: 705.61, Q_loss2: 562.84, min_Q_loss1: 217.78, min_Q_loss2: 214.38

Train epoch 349/3000 -- step 350000

[F                                                                                                    
[F[ Model Length ] Epoch: 349 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 349000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 349 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 349349
[ Model Rollout ] Added: 49015 | Model pool: 500000 (max 500000) | Length: 4.9015 | Train rep: 1

Diagnostics -- iteration 350000
real_batch_obs: 1841.31, model_batch_obs: 1867.07
real_batch_act: 195.87, model_batch_act: 198.13
real_batch_rewards: 1410.77, model_batch_rewards: 1311.25
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 316.10
total_steps: 350000.00
Q-avg: 1069.81, Q-max: 1614.86, Q-min: -446.64
Q_loss1: 233.33, Q_loss2: 265.74, min_Q_loss1: -314.53, min_Q_loss2: -312.35

Train epoch 350/3000 -- step 351000

[F                                                                                                    
[F[ Model Length ] Epoch: 350 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 350000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 350 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 350350
[ Model Rollout ] Added: 49021 | Model pool: 500000 (max 500000) | Length: 4.9021 | Train rep: 1

Diagnostics -- iteration 351000
real_batch_obs: 1830.52, model_batch_obs: 1990.97
real_batch_act: 200.11, model_batch_act: 192.41
real_batch_rewards: 1315.42, model_batch_rewards: 1367.11
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 274.07
total_steps: 351000.00
Q-avg: 1099.96, Q-max: 1613.21, Q-min: -518.46
Q_loss1: 1885.13, Q_loss2: 1969.95, min_Q_loss1: -185.75, min_Q_loss2: -179.40

Train epoch 351/3000 -- step 352000

[F                                                                                                    
[F[ Model Length ] Epoch: 351 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 351000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 351 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 351351
[ Model Rollout ] Added: 49029 | Model pool: 500000 (max 500000) | Length: 4.9029 | Train rep: 1

Diagnostics -- iteration 352000
real_batch_obs: 1818.54, model_batch_obs: 1831.52
real_batch_act: 210.93, model_batch_act: 182.23
real_batch_rewards: 1361.83, model_batch_rewards: 1407.79
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 276.02
total_steps: 352000.00
Q-avg: 1046.66, Q-max: 1622.72, Q-min: -558.58
Q_loss1: 1460.23, Q_loss2: 1514.29, min_Q_loss1: -164.51, min_Q_loss2: -162.69

Train epoch 352/3000 -- step 353000

[F                                                                                                    
[F[ Model Length ] Epoch: 352 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 352000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 352 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 352352
[ Model Rollout ] Added: 48958 | Model pool: 500000 (max 500000) | Length: 4.8958 | Train rep: 1

Diagnostics -- iteration 353000
real_batch_obs: 1843.63, model_batch_obs: 1836.35
real_batch_act: 214.65, model_batch_act: 189.88
real_batch_rewards: 1321.28, model_batch_rewards: 1298.70
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 272.71
total_steps: 353000.00
Q-avg: 1072.05, Q-max: 1621.23, Q-min: -1150.45
Q_loss1: 789.95, Q_loss2: 952.18, min_Q_loss1: -131.59, min_Q_loss2: -131.51

Train epoch 353/3000 -- step 354000

[F                                                                                                    
[F[ Model Length ] Epoch: 353 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 353000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 353 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 353353
[ Model Rollout ] Added: 48998 | Model pool: 500000 (max 500000) | Length: 4.8998 | Train rep: 1

Diagnostics -- iteration 354000
real_batch_obs: 1833.29, model_batch_obs: 1862.06
real_batch_act: 199.31, model_batch_act: 180.39
real_batch_rewards: 1398.98, model_batch_rewards: 1327.78
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 267.06
total_steps: 354000.00
Q-avg: 1073.62, Q-max: 1606.78, Q-min: -1241.27
Q_loss1: 801.20, Q_loss2: 768.20, min_Q_loss1: -518.01, min_Q_loss2: -526.35

Train epoch 354/3000 -- step 355000

[F                                                                                                    
[F[ Model Length ] Epoch: 354 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 354000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 354 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 354354
[ Model Rollout ] Added: 49106 | Model pool: 500000 (max 500000) | Length: 4.9106 | Train rep: 1

Diagnostics -- iteration 355000
real_batch_obs: 1932.31, model_batch_obs: 1882.72
real_batch_act: 203.90, model_batch_act: 186.97
real_batch_rewards: 1427.04, model_batch_rewards: 1358.70
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 270.55
total_steps: 355000.00
Q-avg: 1063.75, Q-max: 1630.99, Q-min: -368.57
Q_loss1: 4537.44, Q_loss2: 4314.61, min_Q_loss1: -72.35, min_Q_loss2: -72.22

Train epoch 355/3000 -- step 356000

[F                                                                                                    
[F[ Model Length ] Epoch: 355 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 355000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 355 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 355355
[ Model Rollout ] Added: 49109 | Model pool: 500000 (max 500000) | Length: 4.9109 | Train rep: 1

Diagnostics -- iteration 356000
real_batch_obs: 1831.08, model_batch_obs: 1877.22
real_batch_act: 183.58, model_batch_act: 193.23
real_batch_rewards: 1361.21, model_batch_rewards: 1259.98
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 281.39
total_steps: 356000.00
Q-avg: 1081.94, Q-max: 1677.18, Q-min: -203.70
Q_loss1: 919.12, Q_loss2: 1058.59, min_Q_loss1: -253.07, min_Q_loss2: -248.49

Train epoch 356/3000 -- step 357000

[F                                                                                                    
[F[ Model Length ] Epoch: 356 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 356000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 356 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 356356
[ Model Rollout ] Added: 49000 | Model pool: 500000 (max 500000) | Length: 4.9 | Train rep: 1

Diagnostics -- iteration 357000
real_batch_obs: 1989.33, model_batch_obs: 1938.65
real_batch_act: 210.52, model_batch_act: 198.52
real_batch_rewards: 1417.36, model_batch_rewards: 1369.33
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 289.08
total_steps: 357000.00
Q-avg: 1095.93, Q-max: 1721.39, Q-min: -109.40
Q_loss1: 1869.38, Q_loss2: 1674.09, min_Q_loss1: 55.06, min_Q_loss2: 45.67

Train epoch 357/3000 -- step 358000

[F                                                                                                    
[F[ Model Length ] Epoch: 357 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 357000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 357 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 357357
[ Model Rollout ] Added: 49067 | Model pool: 500000 (max 500000) | Length: 4.9067 | Train rep: 1

Diagnostics -- iteration 358000
real_batch_obs: 1840.83, model_batch_obs: 1830.61
real_batch_act: 197.11, model_batch_act: 193.66
real_batch_rewards: 1406.97, model_batch_rewards: 1396.17
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 351.45
total_steps: 358000.00
Q-avg: 1026.42, Q-max: 1657.11, Q-min: -590.22
Q_loss1: 5644.35, Q_loss2: 4866.57, min_Q_loss1: -175.42, min_Q_loss2: -187.82

Train epoch 358/3000 -- step 359000

[F                                                                                                    
[F[ Model Length ] Epoch: 358 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 358000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 358 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 358358
[ Model Rollout ] Added: 49105 | Model pool: 500000 (max 500000) | Length: 4.9105 | Train rep: 1

Diagnostics -- iteration 359000
real_batch_obs: 1782.38, model_batch_obs: 1842.24
real_batch_act: 198.18, model_batch_act: 190.34
real_batch_rewards: 1285.55, model_batch_rewards: 1366.17
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 269.27
total_steps: 359000.00
Q-avg: 1087.12, Q-max: 1630.43, Q-min: -440.94
Q_loss1: 193.25, Q_loss2: 256.03, min_Q_loss1: -189.12, min_Q_loss2: -180.03

Train epoch 359/3000 -- step 360000

[F                                                                                                    
[F[ Model Length ] Epoch: 359 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 359000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 359 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 359359
[ Model Rollout ] Added: 49050 | Model pool: 500000 (max 500000) | Length: 4.905 | Train rep: 1

Diagnostics -- iteration 360000
real_batch_obs: 1989.74, model_batch_obs: 1817.86
real_batch_act: 193.72, model_batch_act: 191.33
real_batch_rewards: 1374.41, model_batch_rewards: 1307.66
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 287.62
total_steps: 360000.00
Q-avg: 1109.94, Q-max: 1614.63, Q-min: -918.80
Q_loss1: 997.13, Q_loss2: 981.33, min_Q_loss1: -203.26, min_Q_loss2: -200.79

Train epoch 360/3000 -- step 361000

[F                                                                                                    
[F[ Model Length ] Epoch: 360 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 360000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 360 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 360360
[ Model Rollout ] Added: 48975 | Model pool: 500000 (max 500000) | Length: 4.8975 | Train rep: 1

Diagnostics -- iteration 361000
real_batch_obs: 1813.91, model_batch_obs: 1870.80
real_batch_act: 196.88, model_batch_act: 188.75
real_batch_rewards: 1391.62, model_batch_rewards: 1329.27
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 350.96
total_steps: 361000.00
Q-avg: 1061.43, Q-max: 1606.04, Q-min: -813.69
Q_loss1: 1828.87, Q_loss2: 1136.00, min_Q_loss1: -96.43, min_Q_loss2: -93.19

Train epoch 361/3000 -- step 362000

[F                                                                                                    
[F[ Model Length ] Epoch: 361 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 361000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 361 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 361361
[ Model Rollout ] Added: 49039 | Model pool: 500000 (max 500000) | Length: 4.9039 | Train rep: 1

Diagnostics -- iteration 362000
real_batch_obs: 1822.46, model_batch_obs: 2002.22
real_batch_act: 202.06, model_batch_act: 185.67
real_batch_rewards: 1365.74, model_batch_rewards: 1403.44
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 350.60
total_steps: 362000.00
Q-avg: 1098.79, Q-max: 1588.90, Q-min: -208.52
Q_loss1: 199.91, Q_loss2: 202.04, min_Q_loss1: -360.55, min_Q_loss2: -353.58

Train epoch 362/3000 -- step 363000

[F                                                                                                    
[F[ Model Length ] Epoch: 362 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 362000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 362 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 362362
[ Model Rollout ] Added: 48963 | Model pool: 500000 (max 500000) | Length: 4.8963 | Train rep: 1

Diagnostics -- iteration 363000
real_batch_obs: 1870.83, model_batch_obs: 1806.07
real_batch_act: 204.31, model_batch_act: 198.33
real_batch_rewards: 1387.57, model_batch_rewards: 1314.80
real_batch_dones: 2.00, model_batch_dones: 5.00
evaluation/return-average: 274.70
total_steps: 363000.00
Q-avg: 1032.77, Q-max: 1619.84, Q-min: -56.34
Q_loss1: 1421.03, Q_loss2: 1465.54, min_Q_loss1: -113.08, min_Q_loss2: -115.24

Train epoch 363/3000 -- step 364000

[F                                                                                                    
[F[ Model Length ] Epoch: 363 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 363000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 363 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 363363
[ Model Rollout ] Added: 49004 | Model pool: 500000 (max 500000) | Length: 4.9004 | Train rep: 1

Diagnostics -- iteration 364000
real_batch_obs: 1905.20, model_batch_obs: 1903.34
real_batch_act: 202.01, model_batch_act: 185.68
real_batch_rewards: 1379.65, model_batch_rewards: 1343.94
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 270.70
total_steps: 364000.00
Q-avg: 1045.41, Q-max: 1662.40, Q-min: -608.40
Q_loss1: 461.08, Q_loss2: 553.56, min_Q_loss1: -380.11, min_Q_loss2: -391.20

Train epoch 364/3000 -- step 365000

[F                                                                                                    
[F[ Model Length ] Epoch: 364 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 364000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 364 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 364364
[ Model Rollout ] Added: 49046 | Model pool: 500000 (max 500000) | Length: 4.9046 | Train rep: 1

Diagnostics -- iteration 365000
real_batch_obs: 1770.98, model_batch_obs: 1858.86
real_batch_act: 192.01, model_batch_act: 188.85
real_batch_rewards: 1261.87, model_batch_rewards: 1313.67
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 270.89
total_steps: 365000.00
Q-avg: 1149.05, Q-max: 1609.27, Q-min: -75.16
Q_loss1: 988.41, Q_loss2: 861.53, min_Q_loss1: -273.66, min_Q_loss2: -277.01

Train epoch 365/3000 -- step 366000

[F                                                                                                    
[F[ Model Length ] Epoch: 365 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 365000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 365 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 365365
[ Model Rollout ] Added: 49097 | Model pool: 500000 (max 500000) | Length: 4.9097 | Train rep: 1

Diagnostics -- iteration 366000
real_batch_obs: 1855.44, model_batch_obs: 1914.14
real_batch_act: 202.43, model_batch_act: 198.50
real_batch_rewards: 1373.68, model_batch_rewards: 1334.13
real_batch_dones: 2.00, model_batch_dones: 1.00
evaluation/return-average: 281.66
total_steps: 366000.00
Q-avg: 1066.50, Q-max: 1618.48, Q-min: -175.69
Q_loss1: 2042.38, Q_loss2: 1887.43, min_Q_loss1: -159.34, min_Q_loss2: -166.27

Train epoch 366/3000 -- step 367000

[F                                                                                                    
[F[ Model Length ] Epoch: 366 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 366000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 366 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 366366
[ Model Rollout ] Added: 49015 | Model pool: 500000 (max 500000) | Length: 4.9015 | Train rep: 1

Diagnostics -- iteration 367000
real_batch_obs: 1854.97, model_batch_obs: 1819.50
real_batch_act: 198.33, model_batch_act: 193.55
real_batch_rewards: 1373.48, model_batch_rewards: 1367.15
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 289.04
total_steps: 367000.00
Q-avg: 1083.05, Q-max: 1641.00, Q-min: -476.24
Q_loss1: 667.20, Q_loss2: 688.76, min_Q_loss1: -141.22, min_Q_loss2: -133.54

Train epoch 367/3000 -- step 368000

[F                                                                                                    
[F[ Model Length ] Epoch: 367 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 367000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 367 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 367367
[ Model Rollout ] Added: 49001 | Model pool: 500000 (max 500000) | Length: 4.9001 | Train rep: 1

Diagnostics -- iteration 368000
real_batch_obs: 1884.66, model_batch_obs: 1786.27
real_batch_act: 202.42, model_batch_act: 193.35
real_batch_rewards: 1340.04, model_batch_rewards: 1733.04
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 267.64
total_steps: 368000.00
Q-avg: 1090.49, Q-max: 1662.79, Q-min: -1423.78
Q_loss1: 3605.08, Q_loss2: 2684.90, min_Q_loss1: -180.22, min_Q_loss2: -173.33

Train epoch 368/3000 -- step 369000

[F                                                                                                    
[F[ Model Length ] Epoch: 368 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 368000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 368 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 368368
[ Model Rollout ] Added: 49003 | Model pool: 500000 (max 500000) | Length: 4.9003 | Train rep: 1

Diagnostics -- iteration 369000
real_batch_obs: 1808.70, model_batch_obs: 1992.78
real_batch_act: 203.84, model_batch_act: 192.97
real_batch_rewards: 1365.10, model_batch_rewards: 1389.49
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 292.51
total_steps: 369000.00
Q-avg: 1054.45, Q-max: 1706.35, Q-min: -408.05
Q_loss1: 450.98, Q_loss2: 461.12, min_Q_loss1: -416.31, min_Q_loss2: -409.34

Train epoch 369/3000 -- step 370000

[F                                                                                                    
[F[ Model Length ] Epoch: 369 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 369000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 369 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 369369
[ Model Rollout ] Added: 48994 | Model pool: 500000 (max 500000) | Length: 4.8994 | Train rep: 1

Diagnostics -- iteration 370000
real_batch_obs: 1794.98, model_batch_obs: 1858.00
real_batch_act: 198.71, model_batch_act: 187.09
real_batch_rewards: 1318.99, model_batch_rewards: 1286.40
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 278.90
total_steps: 370000.00
Q-avg: 1107.16, Q-max: 1704.44, Q-min: -399.58
Q_loss1: 536.64, Q_loss2: 552.43, min_Q_loss1: -375.30, min_Q_loss2: -378.99

Train epoch 370/3000 -- step 371000

[F                                                                                                    
[F[ Model Length ] Epoch: 370 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 370000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 370 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 370370
[ Model Rollout ] Added: 49025 | Model pool: 500000 (max 500000) | Length: 4.9025 | Train rep: 1

Diagnostics -- iteration 371000
real_batch_obs: 1806.23, model_batch_obs: 1862.11
real_batch_act: 184.67, model_batch_act: 192.66
real_batch_rewards: 1361.17, model_batch_rewards: 1333.51
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 283.14
total_steps: 371000.00
Q-avg: 1071.52, Q-max: 1672.18, Q-min: -246.16
Q_loss1: 376.82, Q_loss2: 404.80, min_Q_loss1: -292.51, min_Q_loss2: -296.46

Train epoch 371/3000 -- step 372000

[F                                                                                                    
[F[ Model Length ] Epoch: 371 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 371000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 371 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 371371
[ Model Rollout ] Added: 49027 | Model pool: 500000 (max 500000) | Length: 4.9027 | Train rep: 1

Diagnostics -- iteration 372000
real_batch_obs: 1874.19, model_batch_obs: 1814.85
real_batch_act: 198.33, model_batch_act: 186.95
real_batch_rewards: 1326.79, model_batch_rewards: 1302.20
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 277.54
total_steps: 372000.00
Q-avg: 1076.05, Q-max: 1712.42, Q-min: -230.08
Q_loss1: 693.40, Q_loss2: 825.49, min_Q_loss1: -359.99, min_Q_loss2: -363.37

Train epoch 372/3000 -- step 373000

[F                                                                                                    
[F[ Model Length ] Epoch: 372 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 372000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 372 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 372372
[ Model Rollout ] Added: 49000 | Model pool: 500000 (max 500000) | Length: 4.9 | Train rep: 1

Diagnostics -- iteration 373000
real_batch_obs: 1748.86, model_batch_obs: 1911.07
real_batch_act: 201.99, model_batch_act: 177.63
real_batch_rewards: 1261.15, model_batch_rewards: 1342.54
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 321.05
total_steps: 373000.00
Q-avg: 1088.16, Q-max: 1691.50, Q-min: -368.66
Q_loss1: 355.68, Q_loss2: 488.47, min_Q_loss1: -298.47, min_Q_loss2: -293.64

Train epoch 373/3000 -- step 374000

[F                                                                                                    
[F[ Model Length ] Epoch: 373 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 373000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 373 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 373373
[ Model Rollout ] Added: 49006 | Model pool: 500000 (max 500000) | Length: 4.9006 | Train rep: 1

Diagnostics -- iteration 374000
real_batch_obs: 1773.35, model_batch_obs: 1884.40
real_batch_act: 206.76, model_batch_act: 182.91
real_batch_rewards: 1286.91, model_batch_rewards: 1432.17
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 324.46
total_steps: 374000.00
Q-avg: 1101.92, Q-max: 1654.00, Q-min: -183.14
Q_loss1: 166.86, Q_loss2: 127.78, min_Q_loss1: -547.17, min_Q_loss2: -543.38

Train epoch 374/3000 -- step 375000

[F                                                                                                    
[F[ Model Length ] Epoch: 374 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 374000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 374 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 374374
[ Model Rollout ] Added: 49010 | Model pool: 500000 (max 500000) | Length: 4.901 | Train rep: 1

Diagnostics -- iteration 375000
real_batch_obs: 1802.38, model_batch_obs: 1867.57
real_batch_act: 196.51, model_batch_act: 192.54
real_batch_rewards: 1345.87, model_batch_rewards: 1279.87
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 334.63
total_steps: 375000.00
Q-avg: 1142.45, Q-max: 1691.60, Q-min: -252.72
Q_loss1: 428.81, Q_loss2: 468.68, min_Q_loss1: -147.99, min_Q_loss2: -154.57

Train epoch 375/3000 -- step 376000

[F                                                                                                    
[F[ Model Length ] Epoch: 375 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 375000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 375 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 375375
[ Model Rollout ] Added: 49014 | Model pool: 500000 (max 500000) | Length: 4.9014 | Train rep: 1

Diagnostics -- iteration 376000
real_batch_obs: 1752.07, model_batch_obs: 1807.59
real_batch_act: 194.89, model_batch_act: 184.63
real_batch_rewards: 1363.15, model_batch_rewards: 1316.00
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 345.28
total_steps: 376000.00
Q-avg: 1074.26, Q-max: 1668.24, Q-min: -640.02
Q_loss1: 792.05, Q_loss2: 579.62, min_Q_loss1: -648.20, min_Q_loss2: -649.52

Train epoch 376/3000 -- step 377000

[F                                                                                                    
[F[ Model Length ] Epoch: 376 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 376000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 376 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 376376
[ Model Rollout ] Added: 49056 | Model pool: 500000 (max 500000) | Length: 4.9056 | Train rep: 1

Diagnostics -- iteration 377000
real_batch_obs: 1657.43, model_batch_obs: 1829.95
real_batch_act: 198.77, model_batch_act: 189.81
real_batch_rewards: 1322.95, model_batch_rewards: 1310.94
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 344.04
total_steps: 377000.00
Q-avg: 1013.35, Q-max: 1663.21, Q-min: -868.63
Q_loss1: 995.70, Q_loss2: 1049.02, min_Q_loss1: -192.11, min_Q_loss2: -190.63

Train epoch 377/3000 -- step 378000

[F                                                                                                    
[F[ Model Length ] Epoch: 377 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 377000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 377 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 377377
[ Model Rollout ] Added: 48996 | Model pool: 500000 (max 500000) | Length: 4.8996 | Train rep: 1

Diagnostics -- iteration 378000
real_batch_obs: 1905.62, model_batch_obs: 1878.49
real_batch_act: 199.36, model_batch_act: 195.61
real_batch_rewards: 1369.52, model_batch_rewards: 1342.53
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 320.43
total_steps: 378000.00
Q-avg: 1049.72, Q-max: 1674.65, Q-min: -1226.29
Q_loss1: 1766.52, Q_loss2: 875.50, min_Q_loss1: -335.43, min_Q_loss2: -340.64

Train epoch 378/3000 -- step 379000

[F                                                                                                    
[F[ Model Length ] Epoch: 378 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 378000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 378 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 378378
[ Model Rollout ] Added: 49088 | Model pool: 500000 (max 500000) | Length: 4.9088 | Train rep: 1

Diagnostics -- iteration 379000
real_batch_obs: 1821.04, model_batch_obs: 1888.79
real_batch_act: 180.80, model_batch_act: 188.74
real_batch_rewards: 1356.98, model_batch_rewards: 1387.17
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 285.92
total_steps: 379000.00
Q-avg: 1074.52, Q-max: 1645.02, Q-min: 15.54
Q_loss1: 182.12, Q_loss2: 179.20, min_Q_loss1: -39.35, min_Q_loss2: -45.38

Train epoch 379/3000 -- step 380000

[F                                                                                                    
[F[ Model Length ] Epoch: 379 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 379000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 379 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 379379
[ Model Rollout ] Added: 49032 | Model pool: 500000 (max 500000) | Length: 4.9032 | Train rep: 1

Diagnostics -- iteration 380000
real_batch_obs: 1796.24, model_batch_obs: 1774.57
real_batch_act: 197.26, model_batch_act: 189.15
real_batch_rewards: 1332.17, model_batch_rewards: 1356.63
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 289.01
total_steps: 380000.00
Q-avg: 1094.35, Q-max: 1660.60, Q-min: -455.00
Q_loss1: 393.68, Q_loss2: 312.17, min_Q_loss1: -164.97, min_Q_loss2: -164.28

Train epoch 380/3000 -- step 381000

[F                                                                                                    
[F[ Model Length ] Epoch: 380 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 380000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 380 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 380380
[ Model Rollout ] Added: 49008 | Model pool: 500000 (max 500000) | Length: 4.9008 | Train rep: 1

Diagnostics -- iteration 381000
real_batch_obs: 1872.33, model_batch_obs: 2021.71
real_batch_act: 212.18, model_batch_act: 180.92
real_batch_rewards: 1321.02, model_batch_rewards: 1367.39
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 294.27
total_steps: 381000.00
Q-avg: 1115.73, Q-max: 1627.25, Q-min: -52.51
Q_loss1: 374.47, Q_loss2: 364.30, min_Q_loss1: -292.82, min_Q_loss2: -278.98

Train epoch 381/3000 -- step 382000

[F                                                                                                    
[F[ Model Length ] Epoch: 381 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 381000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 381 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 381381
[ Model Rollout ] Added: 49115 | Model pool: 500000 (max 500000) | Length: 4.9115 | Train rep: 1

Diagnostics -- iteration 382000
real_batch_obs: 1854.20, model_batch_obs: 1821.93
real_batch_act: 192.57, model_batch_act: 178.72
real_batch_rewards: 1385.66, model_batch_rewards: 1307.49
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 275.49
total_steps: 382000.00
Q-avg: 1069.94, Q-max: 1646.95, Q-min: -306.27
Q_loss1: 1568.65, Q_loss2: 1488.53, min_Q_loss1: -237.06, min_Q_loss2: -235.13

Train epoch 382/3000 -- step 383000

[F                                                                                                    
[F[ Model Length ] Epoch: 382 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 382000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 382 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 382382
[ Model Rollout ] Added: 49052 | Model pool: 500000 (max 500000) | Length: 4.9052 | Train rep: 1

Diagnostics -- iteration 383000
real_batch_obs: 1817.01, model_batch_obs: 1874.90
real_batch_act: 212.38, model_batch_act: 188.74
real_batch_rewards: 1338.35, model_batch_rewards: 1372.67
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 280.65
total_steps: 383000.00
Q-avg: 1066.70, Q-max: 1563.58, Q-min: -937.69
Q_loss1: 603.18, Q_loss2: 1089.89, min_Q_loss1: -205.31, min_Q_loss2: -213.51

Train epoch 383/3000 -- step 384000

[F                                                                                                    
[F[ Model Length ] Epoch: 383 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 383000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 383 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 383383
[ Model Rollout ] Added: 48987 | Model pool: 500000 (max 500000) | Length: 4.8987 | Train rep: 1

Diagnostics -- iteration 384000
real_batch_obs: 1810.41, model_batch_obs: 1800.41
real_batch_act: 194.25, model_batch_act: 199.13
real_batch_rewards: 1270.43, model_batch_rewards: 1351.12
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 271.72
total_steps: 384000.00
Q-avg: 1091.54, Q-max: 1544.04, Q-min: -102.68
Q_loss1: 430.46, Q_loss2: 565.93, min_Q_loss1: -248.46, min_Q_loss2: -254.73

Train epoch 384/3000 -- step 385000

[F                                                                                                    
[F[ Model Length ] Epoch: 384 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 384000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 384 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 384384
[ Model Rollout ] Added: 48954 | Model pool: 500000 (max 500000) | Length: 4.8954 | Train rep: 1

Diagnostics -- iteration 385000
real_batch_obs: 1978.90, model_batch_obs: 1886.62
real_batch_act: 200.66, model_batch_act: 193.72
real_batch_rewards: 1325.30, model_batch_rewards: 1348.39
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 281.68
total_steps: 385000.00
Q-avg: 1062.02, Q-max: 1563.21, Q-min: -358.97
Q_loss1: 1134.35, Q_loss2: 1022.48, min_Q_loss1: -256.94, min_Q_loss2: -263.11

Train epoch 385/3000 -- step 386000

[F                                                                                                    
[F[ Model Length ] Epoch: 385 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 385000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 385 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 385385
[ Model Rollout ] Added: 48981 | Model pool: 500000 (max 500000) | Length: 4.8981 | Train rep: 1

Diagnostics -- iteration 386000
real_batch_obs: 1828.07, model_batch_obs: 1875.13
real_batch_act: 197.15, model_batch_act: 190.95
real_batch_rewards: 1361.63, model_batch_rewards: 1295.08
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 281.61
total_steps: 386000.00
Q-avg: 1063.68, Q-max: 1553.87, Q-min: -123.18
Q_loss1: 530.46, Q_loss2: 575.63, min_Q_loss1: -20.07, min_Q_loss2: -16.98

Train epoch 386/3000 -- step 387000

[F                                                                                                    
[F[ Model Length ] Epoch: 386 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 386000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 386 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 386386
[ Model Rollout ] Added: 48943 | Model pool: 500000 (max 500000) | Length: 4.8943 | Train rep: 1

Diagnostics -- iteration 387000
real_batch_obs: 1794.80, model_batch_obs: 1896.29
real_batch_act: 188.49, model_batch_act: 195.98
real_batch_rewards: 1337.79, model_batch_rewards: 1346.88
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 287.41
total_steps: 387000.00
Q-avg: 1088.78, Q-max: 1548.24, Q-min: -160.67
Q_loss1: 601.11, Q_loss2: 547.08, min_Q_loss1: -146.15, min_Q_loss2: -151.31

Train epoch 387/3000 -- step 388000

[F                                                                                                    
[F[ Model Length ] Epoch: 387 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 387000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 387 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 387387
[ Model Rollout ] Added: 49005 | Model pool: 500000 (max 500000) | Length: 4.9005 | Train rep: 1

Diagnostics -- iteration 388000
real_batch_obs: 1874.64, model_batch_obs: 1907.24
real_batch_act: 202.34, model_batch_act: 195.84
real_batch_rewards: 1385.21, model_batch_rewards: 1644.15
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 279.73
total_steps: 388000.00
Q-avg: 1069.40, Q-max: 1582.06, Q-min: -1157.57
Q_loss1: 2248.25, Q_loss2: 2290.80, min_Q_loss1: -567.77, min_Q_loss2: -562.58

Train epoch 388/3000 -- step 389000

[F                                                                                                    
[F[ Model Length ] Epoch: 388 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 388000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 388 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 388388
[ Model Rollout ] Added: 49008 | Model pool: 500000 (max 500000) | Length: 4.9008 | Train rep: 1

Diagnostics -- iteration 389000
real_batch_obs: 1967.03, model_batch_obs: 1775.60
real_batch_act: 210.50, model_batch_act: 189.87
real_batch_rewards: 1357.93, model_batch_rewards: 1261.46
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 286.31
total_steps: 389000.00
Q-avg: 1086.97, Q-max: 1611.66, Q-min: -234.81
Q_loss1: 1521.99, Q_loss2: 2103.22, min_Q_loss1: -258.51, min_Q_loss2: -237.43

Train epoch 389/3000 -- step 390000

[F                                                                                                    
[F[ Model Length ] Epoch: 389 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 389000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 389 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 389389
[ Model Rollout ] Added: 48975 | Model pool: 500000 (max 500000) | Length: 4.8975 | Train rep: 1

Diagnostics -- iteration 390000
real_batch_obs: 1757.61, model_batch_obs: 1968.05
real_batch_act: 200.70, model_batch_act: 188.82
real_batch_rewards: 1303.76, model_batch_rewards: 1372.54
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 273.82
total_steps: 390000.00
Q-avg: 1118.14, Q-max: 1636.27, Q-min: -174.47
Q_loss1: 518.82, Q_loss2: 434.53, min_Q_loss1: -224.44, min_Q_loss2: -221.80

Train epoch 390/3000 -- step 391000

[F                                                                                                    
[F[ Model Length ] Epoch: 390 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 390000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 390 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 390390
[ Model Rollout ] Added: 48943 | Model pool: 500000 (max 500000) | Length: 4.8943 | Train rep: 1

Diagnostics -- iteration 391000
real_batch_obs: 1821.12, model_batch_obs: 1930.48
real_batch_act: 198.20, model_batch_act: 197.84
real_batch_rewards: 1364.68, model_batch_rewards: 1383.74
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 278.56
total_steps: 391000.00
Q-avg: 1105.04, Q-max: 1625.95, Q-min: -490.87
Q_loss1: 272.95, Q_loss2: 287.85, min_Q_loss1: -197.75, min_Q_loss2: -194.58

Train epoch 391/3000 -- step 392000

[F                                                                                                    
[F[ Model Length ] Epoch: 391 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 391000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 391 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 391391
[ Model Rollout ] Added: 49061 | Model pool: 500000 (max 500000) | Length: 4.9061 | Train rep: 1

Diagnostics -- iteration 392000
real_batch_obs: 1849.84, model_batch_obs: 1931.56
real_batch_act: 199.91, model_batch_act: 183.22
real_batch_rewards: 1373.19, model_batch_rewards: 1291.75
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 283.48
total_steps: 392000.00
Q-avg: 1009.21, Q-max: 1621.33, Q-min: -324.67
Q_loss1: 260.09, Q_loss2: 232.89, min_Q_loss1: 23.29, min_Q_loss2: 27.28

Train epoch 392/3000 -- step 393000

[F                                                                                                    
[F[ Model Length ] Epoch: 392 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 392000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 392 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 392392
[ Model Rollout ] Added: 49013 | Model pool: 500000 (max 500000) | Length: 4.9013 | Train rep: 1

Diagnostics -- iteration 393000
real_batch_obs: 1803.15, model_batch_obs: 1880.70
real_batch_act: 203.01, model_batch_act: 205.26
real_batch_rewards: 1357.75, model_batch_rewards: 1372.14
real_batch_dones: 2.00, model_batch_dones: 1.00
evaluation/return-average: 330.90
total_steps: 393000.00
Q-avg: 1072.93, Q-max: 1611.55, Q-min: -145.79
Q_loss1: 480.24, Q_loss2: 629.53, min_Q_loss1: -157.56, min_Q_loss2: -150.55

Train epoch 393/3000 -- step 394000

[F                                                                                                    
[F[ Model Length ] Epoch: 393 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 393000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 393 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 393393
[ Model Rollout ] Added: 48936 | Model pool: 500000 (max 500000) | Length: 4.8936 | Train rep: 1

Diagnostics -- iteration 394000
real_batch_obs: 1856.69, model_batch_obs: 1917.30
real_batch_act: 191.18, model_batch_act: 189.52
real_batch_rewards: 1347.01, model_batch_rewards: 1312.83
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 282.00
total_steps: 394000.00
Q-avg: 1042.98, Q-max: 1654.34, Q-min: -76.27
Q_loss1: 478.95, Q_loss2: 470.98, min_Q_loss1: -318.25, min_Q_loss2: -314.01

Train epoch 394/3000 -- step 395000

[F                                                                                                    
[F[ Model Length ] Epoch: 394 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 394000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 394 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 394394
[ Model Rollout ] Added: 48922 | Model pool: 500000 (max 500000) | Length: 4.8922 | Train rep: 1

Diagnostics -- iteration 395000
real_batch_obs: 1826.69, model_batch_obs: 1913.72
real_batch_act: 202.20, model_batch_act: 201.60
real_batch_rewards: 1364.69, model_batch_rewards: 1323.76
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 306.09
total_steps: 395000.00
Q-avg: 1051.33, Q-max: 1701.89, Q-min: -657.03
Q_loss1: 741.87, Q_loss2: 622.27, min_Q_loss1: -230.14, min_Q_loss2: -229.36

Train epoch 395/3000 -- step 396000

[F                                                                                                    
[F[ Model Length ] Epoch: 395 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 395000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 395 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 395395
[ Model Rollout ] Added: 49024 | Model pool: 500000 (max 500000) | Length: 4.9024 | Train rep: 1

Diagnostics -- iteration 396000
real_batch_obs: 1910.82, model_batch_obs: 1927.25
real_batch_act: 205.86, model_batch_act: 188.64
real_batch_rewards: 1372.51, model_batch_rewards: 1338.24
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 283.03
total_steps: 396000.00
Q-avg: 1082.34, Q-max: 1608.40, Q-min: -150.02
Q_loss1: 310.68, Q_loss2: 309.02, min_Q_loss1: -400.34, min_Q_loss2: -407.99

Train epoch 396/3000 -- step 397000

[F                                                                                                    
[F[ Model Length ] Epoch: 396 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 396000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 396 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 396396
[ Model Rollout ] Added: 49016 | Model pool: 500000 (max 500000) | Length: 4.9016 | Train rep: 1

Diagnostics -- iteration 397000
real_batch_obs: 1777.08, model_batch_obs: 1783.48
real_batch_act: 196.25, model_batch_act: 207.70
real_batch_rewards: 1371.95, model_batch_rewards: 1324.70
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 325.55
total_steps: 397000.00
Q-avg: 1068.58, Q-max: 1606.43, Q-min: -269.76
Q_loss1: 923.97, Q_loss2: 881.89, min_Q_loss1: -207.37, min_Q_loss2: -206.83

Train epoch 397/3000 -- step 398000

[F                                                                                                    
[F[ Model Length ] Epoch: 397 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 397000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 397 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 397397
[ Model Rollout ] Added: 49011 | Model pool: 500000 (max 500000) | Length: 4.9011 | Train rep: 1

Diagnostics -- iteration 398000
real_batch_obs: 1801.11, model_batch_obs: 1968.63
real_batch_act: 191.96, model_batch_act: 193.88
real_batch_rewards: 1359.16, model_batch_rewards: 1385.03
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 328.84
total_steps: 398000.00
Q-avg: 1055.68, Q-max: 1572.53, Q-min: -102.09
Q_loss1: 1509.02, Q_loss2: 1452.59, min_Q_loss1: -257.06, min_Q_loss2: -256.71

Train epoch 398/3000 -- step 399000

[F                                                                                                    
[F[ Model Length ] Epoch: 398 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 398000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 398 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 398398
[ Model Rollout ] Added: 49026 | Model pool: 500000 (max 500000) | Length: 4.9026 | Train rep: 1

Diagnostics -- iteration 399000
real_batch_obs: 1792.51, model_batch_obs: 1908.49
real_batch_act: 191.87, model_batch_act: 196.75
real_batch_rewards: 1305.92, model_batch_rewards: 1322.09
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 295.03
total_steps: 399000.00
Q-avg: 1090.51, Q-max: 1570.23, Q-min: -1468.91
Q_loss1: 1056.18, Q_loss2: 711.11, min_Q_loss1: -178.80, min_Q_loss2: -182.53

Train epoch 399/3000 -- step 400000

[F                                                                                                    
[F[ Model Length ] Epoch: 399 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 399000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 399 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 399399
[ Model Rollout ] Added: 49063 | Model pool: 500000 (max 500000) | Length: 4.9063 | Train rep: 1

Diagnostics -- iteration 400000
real_batch_obs: 1900.39, model_batch_obs: 1914.89
real_batch_act: 192.30, model_batch_act: 187.02
real_batch_rewards: 1428.19, model_batch_rewards: 1347.58
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 295.08
total_steps: 400000.00
Q-avg: 1075.55, Q-max: 1546.82, Q-min: -428.64
Q_loss1: 985.17, Q_loss2: 1033.21, min_Q_loss1: -110.98, min_Q_loss2: -113.69

Train epoch 400/3000 -- step 401000

[F                                                                                                    
[F[ Model Length ] Epoch: 400 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 400000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 400 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 400400
[ Model Rollout ] Added: 48971 | Model pool: 500000 (max 500000) | Length: 4.8971 | Train rep: 1

Diagnostics -- iteration 401000
real_batch_obs: 1750.71, model_batch_obs: 2037.27
real_batch_act: 203.16, model_batch_act: 196.71
real_batch_rewards: 1299.54, model_batch_rewards: 3644.60
real_batch_dones: 1.00, model_batch_dones: 5.00
evaluation/return-average: 282.99
total_steps: 401000.00
Q-avg: 1036.41, Q-max: 1566.89, Q-min: -2699.04
Q_loss1: 2639.32, Q_loss2: 2639.54, min_Q_loss1: -461.87, min_Q_loss2: -451.27

Train epoch 401/3000 -- step 402000

[F                                                                                                    
[F[ Model Length ] Epoch: 401 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 401000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 401 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 401401
[ Model Rollout ] Added: 49027 | Model pool: 500000 (max 500000) | Length: 4.9027 | Train rep: 1

Diagnostics -- iteration 402000
real_batch_obs: 1878.41, model_batch_obs: 1969.61
real_batch_act: 196.26, model_batch_act: 193.20
real_batch_rewards: 1363.35, model_batch_rewards: 1342.01
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 327.84
total_steps: 402000.00
Q-avg: 1030.79, Q-max: 1585.08, Q-min: -871.78
Q_loss1: 622.46, Q_loss2: 609.71, min_Q_loss1: -243.31, min_Q_loss2: -241.50

Train epoch 402/3000 -- step 403000

[F                                                                                                    
[F[ Model Length ] Epoch: 402 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 402000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 402 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 402402
[ Model Rollout ] Added: 49027 | Model pool: 500000 (max 500000) | Length: 4.9027 | Train rep: 1

Diagnostics -- iteration 403000
real_batch_obs: 1838.47, model_batch_obs: 1907.11
real_batch_act: 202.71, model_batch_act: 196.64
real_batch_rewards: 1332.49, model_batch_rewards: 1369.69
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 327.73
total_steps: 403000.00
Q-avg: 1063.28, Q-max: 1549.70, Q-min: -878.49
Q_loss1: 1808.66, Q_loss2: 1404.06, min_Q_loss1: -91.71, min_Q_loss2: -86.79

Train epoch 403/3000 -- step 404000

[F                                                                                                    
[F[ Model Length ] Epoch: 403 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 403000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 403 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 403403
[ Model Rollout ] Added: 49066 | Model pool: 500000 (max 500000) | Length: 4.9066 | Train rep: 1

Diagnostics -- iteration 404000
real_batch_obs: 1814.90, model_batch_obs: 1861.16
real_batch_act: 198.98, model_batch_act: 192.08
real_batch_rewards: 1320.60, model_batch_rewards: 2402.68
real_batch_dones: 1.00, model_batch_dones: 7.00
evaluation/return-average: 340.70
total_steps: 404000.00
Q-avg: 1071.00, Q-max: 1533.04, Q-min: -4591.51
Q_loss1: 25151.87, Q_loss2: 20713.55, min_Q_loss1: -492.56, min_Q_loss2: -482.95

Train epoch 404/3000 -- step 405000

[F                                                                                                    
[F[ Model Length ] Epoch: 404 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 404000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 404 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 404404
[ Model Rollout ] Added: 49034 | Model pool: 500000 (max 500000) | Length: 4.9034 | Train rep: 1

Diagnostics -- iteration 405000
real_batch_obs: 1862.78, model_batch_obs: 1838.26
real_batch_act: 209.37, model_batch_act: 196.34
real_batch_rewards: 1349.12, model_batch_rewards: 1364.48
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 343.26
total_steps: 405000.00
Q-avg: 1044.50, Q-max: 1591.95, Q-min: -149.22
Q_loss1: 1306.98, Q_loss2: 1241.66, min_Q_loss1: -328.33, min_Q_loss2: -320.41

Train epoch 405/3000 -- step 406000

[F                                                                                                    
[F[ Model Length ] Epoch: 405 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 405000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 405 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 405405
[ Model Rollout ] Added: 49032 | Model pool: 500000 (max 500000) | Length: 4.9032 | Train rep: 1

Diagnostics -- iteration 406000
real_batch_obs: 1809.96, model_batch_obs: 1907.76
real_batch_act: 203.86, model_batch_act: 196.47
real_batch_rewards: 1345.30, model_batch_rewards: 1319.28
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 346.53
total_steps: 406000.00
Q-avg: 1029.57, Q-max: 1537.48, Q-min: -461.50
Q_loss1: 628.49, Q_loss2: 507.30, min_Q_loss1: -434.79, min_Q_loss2: -435.48

Train epoch 406/3000 -- step 407000

[F                                                                                                    
[F[ Model Length ] Epoch: 406 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 406000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 406 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 406406
[ Model Rollout ] Added: 49037 | Model pool: 500000 (max 500000) | Length: 4.9037 | Train rep: 1

Diagnostics -- iteration 407000
real_batch_obs: 1875.47, model_batch_obs: 2004.51
real_batch_act: 201.25, model_batch_act: 185.19
real_batch_rewards: 1424.66, model_batch_rewards: 1379.48
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 354.49
total_steps: 407000.00
Q-avg: 1058.23, Q-max: 1573.40, Q-min: -358.81
Q_loss1: 152.72, Q_loss2: 160.06, min_Q_loss1: -239.53, min_Q_loss2: -246.61

Train epoch 407/3000 -- step 408000

[F                                                                                                    
[F[ Model Length ] Epoch: 407 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 407000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 407 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 407407
[ Model Rollout ] Added: 48968 | Model pool: 500000 (max 500000) | Length: 4.8968 | Train rep: 1

Diagnostics -- iteration 408000
real_batch_obs: 1886.70, model_batch_obs: 1862.24
real_batch_act: 199.44, model_batch_act: 192.28
real_batch_rewards: 1326.01, model_batch_rewards: 1365.38
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 327.19
total_steps: 408000.00
Q-avg: 1056.23, Q-max: 1537.82, Q-min: -781.69
Q_loss1: 706.78, Q_loss2: 589.52, min_Q_loss1: -517.72, min_Q_loss2: -511.00

Train epoch 408/3000 -- step 409000

[F                                                                                                    
[F[ Model Length ] Epoch: 408 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 408000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 408 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 408408
[ Model Rollout ] Added: 48964 | Model pool: 500000 (max 500000) | Length: 4.8964 | Train rep: 1

Diagnostics -- iteration 409000
real_batch_obs: 1870.99, model_batch_obs: 2066.27
real_batch_act: 201.33, model_batch_act: 193.63
real_batch_rewards: 1422.83, model_batch_rewards: 1319.09
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 381.74
total_steps: 409000.00
Q-avg: 1083.98, Q-max: 1599.16, Q-min: -873.57
Q_loss1: 1711.50, Q_loss2: 917.02, min_Q_loss1: -179.70, min_Q_loss2: -160.76

Train epoch 409/3000 -- step 410000

[F                                                                                                    
[F[ Model Length ] Epoch: 409 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 409000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 409 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 409409
[ Model Rollout ] Added: 49024 | Model pool: 500000 (max 500000) | Length: 4.9024 | Train rep: 1

Diagnostics -- iteration 410000
real_batch_obs: 1863.93, model_batch_obs: 1880.94
real_batch_act: 197.70, model_batch_act: 187.58
real_batch_rewards: 1362.41, model_batch_rewards: 1369.48
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 346.10
total_steps: 410000.00
Q-avg: 1062.64, Q-max: 1623.85, Q-min: -685.60
Q_loss1: 1315.89, Q_loss2: 1155.97, min_Q_loss1: -412.86, min_Q_loss2: -403.07

Train epoch 410/3000 -- step 411000

[F                                                                                                    
[F[ Model Length ] Epoch: 410 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 410000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 410 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 410410
[ Model Rollout ] Added: 49068 | Model pool: 500000 (max 500000) | Length: 4.9068 | Train rep: 1

Diagnostics -- iteration 411000
real_batch_obs: 1791.79, model_batch_obs: 1884.14
real_batch_act: 206.31, model_batch_act: 195.35
real_batch_rewards: 1371.93, model_batch_rewards: 1333.19
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 353.90
total_steps: 411000.00
Q-avg: 1033.92, Q-max: 1612.62, Q-min: -193.89
Q_loss1: 617.84, Q_loss2: 486.83, min_Q_loss1: -87.76, min_Q_loss2: -81.94

Train epoch 411/3000 -- step 412000

[F                                                                                                    
[F[ Model Length ] Epoch: 411 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 411000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 411 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 411411
[ Model Rollout ] Added: 48991 | Model pool: 500000 (max 500000) | Length: 4.8991 | Train rep: 1

Diagnostics -- iteration 412000
real_batch_obs: 1836.27, model_batch_obs: 1877.76
real_batch_act: 197.77, model_batch_act: 195.95
real_batch_rewards: 1398.60, model_batch_rewards: 1655.47
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 345.20
total_steps: 412000.00
Q-avg: 1067.43, Q-max: 1601.09, Q-min: -629.68
Q_loss1: 659.14, Q_loss2: 875.08, min_Q_loss1: -199.60, min_Q_loss2: -204.73

Train epoch 412/3000 -- step 413000

[F                                                                                                    
[F[ Model Length ] Epoch: 412 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 412000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 412 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 412412
[ Model Rollout ] Added: 49000 | Model pool: 500000 (max 500000) | Length: 4.9 | Train rep: 1

Diagnostics -- iteration 413000
real_batch_obs: 1801.07, model_batch_obs: 1806.43
real_batch_act: 188.40, model_batch_act: 191.33
real_batch_rewards: 1342.43, model_batch_rewards: 1437.51
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 326.79
total_steps: 413000.00
Q-avg: 1057.42, Q-max: 1609.50, Q-min: -1530.88
Q_loss1: 478.88, Q_loss2: 525.71, min_Q_loss1: -248.64, min_Q_loss2: -254.68

Train epoch 413/3000 -- step 414000

[F                                                                                                    
[F[ Model Length ] Epoch: 413 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 413000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 413 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 413413
[ Model Rollout ] Added: 49069 | Model pool: 500000 (max 500000) | Length: 4.9069 | Train rep: 1

Diagnostics -- iteration 414000
real_batch_obs: 1775.27, model_batch_obs: 1883.35
real_batch_act: 195.79, model_batch_act: 193.31
real_batch_rewards: 1339.27, model_batch_rewards: 1321.87
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 345.28
total_steps: 414000.00
Q-avg: 1099.78, Q-max: 1634.10, Q-min: -1096.77
Q_loss1: 599.84, Q_loss2: 558.89, min_Q_loss1: -149.64, min_Q_loss2: -146.98

Train epoch 414/3000 -- step 415000

[F                                                                                                    
[F[ Model Length ] Epoch: 414 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 414000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 414 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 414414
[ Model Rollout ] Added: 49031 | Model pool: 500000 (max 500000) | Length: 4.9031 | Train rep: 1

Diagnostics -- iteration 415000
real_batch_obs: 1832.42, model_batch_obs: 1837.77
real_batch_act: 204.37, model_batch_act: 188.52
real_batch_rewards: 1347.34, model_batch_rewards: 1446.36
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 286.23
total_steps: 415000.00
Q-avg: 1043.95, Q-max: 1583.41, Q-min: -1156.47
Q_loss1: 235.52, Q_loss2: 467.01, min_Q_loss1: -511.57, min_Q_loss2: -519.81

Train epoch 415/3000 -- step 416000

[F                                                                                                    
[F[ Model Length ] Epoch: 415 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 415000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 415 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 415415
[ Model Rollout ] Added: 48922 | Model pool: 500000 (max 500000) | Length: 4.8922 | Train rep: 1

Diagnostics -- iteration 416000
real_batch_obs: 1770.99, model_batch_obs: 1903.13
real_batch_act: 186.59, model_batch_act: 190.63
real_batch_rewards: 1390.46, model_batch_rewards: 1322.04
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 319.49
total_steps: 416000.00
Q-avg: 1073.61, Q-max: 1670.01, Q-min: -257.69
Q_loss1: 804.27, Q_loss2: 735.13, min_Q_loss1: -91.92, min_Q_loss2: -87.96

Train epoch 416/3000 -- step 417000

[F                                                                                                    
[F[ Model Length ] Epoch: 416 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 416000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 416 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 416416
[ Model Rollout ] Added: 49094 | Model pool: 500000 (max 500000) | Length: 4.9094 | Train rep: 1

Diagnostics -- iteration 417000
real_batch_obs: 1805.34, model_batch_obs: 1806.74
real_batch_act: 207.72, model_batch_act: 186.62
real_batch_rewards: 1307.86, model_batch_rewards: 1252.86
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 285.27
total_steps: 417000.00
Q-avg: 1112.92, Q-max: 1610.93, Q-min: -100.93
Q_loss1: 262.76, Q_loss2: 309.00, min_Q_loss1: 43.13, min_Q_loss2: 44.37

Train epoch 417/3000 -- step 418000

[F                                                                                                    
[F[ Model Length ] Epoch: 417 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 417000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 417 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 417417
[ Model Rollout ] Added: 49027 | Model pool: 500000 (max 500000) | Length: 4.9027 | Train rep: 1

Diagnostics -- iteration 418000
real_batch_obs: 1791.43, model_batch_obs: 1988.27
real_batch_act: 191.24, model_batch_act: 188.53
real_batch_rewards: 1312.32, model_batch_rewards: 1335.51
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 326.63
total_steps: 418000.00
Q-avg: 1079.33, Q-max: 1577.74, Q-min: -749.97
Q_loss1: 959.08, Q_loss2: 845.05, min_Q_loss1: -315.57, min_Q_loss2: -309.16

Train epoch 418/3000 -- step 419000

[F                                                                                                    
[F[ Model Length ] Epoch: 418 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 418000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 418 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 418418
[ Model Rollout ] Added: 49094 | Model pool: 500000 (max 500000) | Length: 4.9094 | Train rep: 1

Diagnostics -- iteration 419000
real_batch_obs: 1794.70, model_batch_obs: 2025.18
real_batch_act: 199.62, model_batch_act: 191.62
real_batch_rewards: 1312.52, model_batch_rewards: 1367.83
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 314.83
total_steps: 419000.00
Q-avg: 1063.47, Q-max: 1596.53, Q-min: -432.08
Q_loss1: 281.01, Q_loss2: 220.97, min_Q_loss1: -515.15, min_Q_loss2: -525.89

Train epoch 419/3000 -- step 420000

[F                                                                                                    
[F[ Model Length ] Epoch: 419 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 419000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 419 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 419419
[ Model Rollout ] Added: 49001 | Model pool: 500000 (max 500000) | Length: 4.9001 | Train rep: 1

Diagnostics -- iteration 420000
real_batch_obs: 1817.31, model_batch_obs: 1830.16
real_batch_act: 197.52, model_batch_act: 199.81
real_batch_rewards: 1310.96, model_batch_rewards: 1340.39
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 357.14
total_steps: 420000.00
Q-avg: 1059.63, Q-max: 1584.76, Q-min: -702.52
Q_loss1: 2578.20, Q_loss2: 2424.71, min_Q_loss1: -240.76, min_Q_loss2: -239.48

Train epoch 420/3000 -- step 421000

[F                                                                                                    
[F[ Model Length ] Epoch: 420 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 420000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 420 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 420420
[ Model Rollout ] Added: 49066 | Model pool: 500000 (max 500000) | Length: 4.9066 | Train rep: 1

Diagnostics -- iteration 421000
real_batch_obs: 1880.41, model_batch_obs: 1844.22
real_batch_act: 197.40, model_batch_act: 187.04
real_batch_rewards: 1368.90, model_batch_rewards: 1274.30
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 339.21
total_steps: 421000.00
Q-avg: 1064.43, Q-max: 1568.09, Q-min: -1120.99
Q_loss1: 689.89, Q_loss2: 807.68, min_Q_loss1: -307.17, min_Q_loss2: -312.30

Train epoch 421/3000 -- step 422000

[F                                                                                                    
[F[ Model Length ] Epoch: 421 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 421000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 421 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 421421
[ Model Rollout ] Added: 49083 | Model pool: 500000 (max 500000) | Length: 4.9083 | Train rep: 1

Diagnostics -- iteration 422000
real_batch_obs: 1694.67, model_batch_obs: 1910.90
real_batch_act: 200.80, model_batch_act: 189.39
real_batch_rewards: 1285.76, model_batch_rewards: 1288.42
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 354.81
total_steps: 422000.00
Q-avg: 1094.46, Q-max: 1566.32, Q-min: -238.32
Q_loss1: 458.26, Q_loss2: 597.97, min_Q_loss1: -196.06, min_Q_loss2: -191.83

Train epoch 422/3000 -- step 423000

[F                                                                                                    
[F[ Model Length ] Epoch: 422 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 422000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 422 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 422422
[ Model Rollout ] Added: 49051 | Model pool: 500000 (max 500000) | Length: 4.9051 | Train rep: 1

Diagnostics -- iteration 423000
real_batch_obs: 1865.71, model_batch_obs: 1937.27
real_batch_act: 193.03, model_batch_act: 183.73
real_batch_rewards: 1326.21, model_batch_rewards: 1338.60
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 294.22
total_steps: 423000.00
Q-avg: 1075.92, Q-max: 1574.85, Q-min: -89.67
Q_loss1: 270.72, Q_loss2: 438.53, min_Q_loss1: -297.38, min_Q_loss2: -306.56

Train epoch 423/3000 -- step 424000

[F                                                                                                    
[F[ Model Length ] Epoch: 423 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 423000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 423 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 423423
[ Model Rollout ] Added: 48970 | Model pool: 500000 (max 500000) | Length: 4.897 | Train rep: 1

Diagnostics -- iteration 424000
real_batch_obs: 1869.20, model_batch_obs: 1840.99
real_batch_act: 198.79, model_batch_act: 181.51
real_batch_rewards: 1339.66, model_batch_rewards: 1319.32
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 359.46
total_steps: 424000.00
Q-avg: 1031.10, Q-max: 1505.93, Q-min: -333.62
Q_loss1: 550.50, Q_loss2: 469.32, min_Q_loss1: -159.79, min_Q_loss2: -155.06

Train epoch 424/3000 -- step 425000

[F                                                                                                    
[F[ Model Length ] Epoch: 424 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 424000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 424 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 424424
[ Model Rollout ] Added: 48940 | Model pool: 500000 (max 500000) | Length: 4.894 | Train rep: 1

Diagnostics -- iteration 425000
real_batch_obs: 1778.57, model_batch_obs: 1836.52
real_batch_act: 196.66, model_batch_act: 189.74
real_batch_rewards: 1393.34, model_batch_rewards: 1242.72
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 353.04
total_steps: 425000.00
Q-avg: 1074.89, Q-max: 1555.18, Q-min: -84.38
Q_loss1: 260.69, Q_loss2: 269.43, min_Q_loss1: -3.68, min_Q_loss2: -10.22

Train epoch 425/3000 -- step 426000

[F                                                                                                    
[F[ Model Length ] Epoch: 425 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 425000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 425 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 425425
[ Model Rollout ] Added: 49004 | Model pool: 500000 (max 500000) | Length: 4.9004 | Train rep: 1

Diagnostics -- iteration 426000
real_batch_obs: 1863.26, model_batch_obs: 1954.90
real_batch_act: 208.81, model_batch_act: 193.49
real_batch_rewards: 1317.40, model_batch_rewards: 1361.22
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 329.83
total_steps: 426000.00
Q-avg: 1047.56, Q-max: 1549.87, Q-min: -325.77
Q_loss1: 1371.10, Q_loss2: 1434.01, min_Q_loss1: -430.13, min_Q_loss2: -435.73

Train epoch 426/3000 -- step 427000

[F                                                                                                    
[F[ Model Length ] Epoch: 426 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 426000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 426 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 426426
[ Model Rollout ] Added: 49067 | Model pool: 500000 (max 500000) | Length: 4.9067 | Train rep: 1

Diagnostics -- iteration 427000
real_batch_obs: 1837.58, model_batch_obs: 1859.80
real_batch_act: 197.73, model_batch_act: 192.02
real_batch_rewards: 1311.68, model_batch_rewards: 1345.00
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 334.13
total_steps: 427000.00
Q-avg: 1063.75, Q-max: 1515.54, Q-min: -89.01
Q_loss1: 121.20, Q_loss2: 153.56, min_Q_loss1: -485.16, min_Q_loss2: -484.71

Train epoch 427/3000 -- step 428000

[F                                                                                                    
[F[ Model Length ] Epoch: 427 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 427000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 427 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 427427
[ Model Rollout ] Added: 49048 | Model pool: 500000 (max 500000) | Length: 4.9048 | Train rep: 1

Diagnostics -- iteration 428000
real_batch_obs: 1746.59, model_batch_obs: 1896.99
real_batch_act: 205.13, model_batch_act: 196.30
real_batch_rewards: 1316.45, model_batch_rewards: 1401.90
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 360.84
total_steps: 428000.00
Q-avg: 1073.79, Q-max: 1532.82, Q-min: -11.84
Q_loss1: 512.97, Q_loss2: 416.46, min_Q_loss1: -168.11, min_Q_loss2: -165.19

Train epoch 428/3000 -- step 429000

[F                                                                                                    
[F[ Model Length ] Epoch: 428 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 428000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 428 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 428428
[ Model Rollout ] Added: 48979 | Model pool: 500000 (max 500000) | Length: 4.8979 | Train rep: 1

Diagnostics -- iteration 429000
real_batch_obs: 1767.52, model_batch_obs: 1975.66
real_batch_act: 197.62, model_batch_act: 193.40
real_batch_rewards: 1367.74, model_batch_rewards: 1328.85
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 364.88
total_steps: 429000.00
Q-avg: 1044.63, Q-max: 1495.49, Q-min: -550.33
Q_loss1: 659.38, Q_loss2: 859.75, min_Q_loss1: -27.58, min_Q_loss2: -16.19

Train epoch 429/3000 -- step 430000

[F                                                                                                    
[F[ Model Length ] Epoch: 429 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 429000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 429 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 429429
[ Model Rollout ] Added: 49073 | Model pool: 500000 (max 500000) | Length: 4.9073 | Train rep: 1

Diagnostics -- iteration 430000
real_batch_obs: 1794.90, model_batch_obs: 1778.13
real_batch_act: 207.89, model_batch_act: 190.23
real_batch_rewards: 1299.89, model_batch_rewards: 1295.23
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 366.85
total_steps: 430000.00
Q-avg: 998.20, Q-max: 1482.65, Q-min: -877.05
Q_loss1: 220.14, Q_loss2: 278.79, min_Q_loss1: -261.24, min_Q_loss2: -264.41

Train epoch 430/3000 -- step 431000

[F                                                                                                    
[F[ Model Length ] Epoch: 430 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 430000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 430 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 430430
[ Model Rollout ] Added: 49031 | Model pool: 500000 (max 500000) | Length: 4.9031 | Train rep: 1

Diagnostics -- iteration 431000
real_batch_obs: 1795.18, model_batch_obs: 1875.99
real_batch_act: 191.36, model_batch_act: 195.02
real_batch_rewards: 1311.15, model_batch_rewards: 1313.57
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 362.13
total_steps: 431000.00
Q-avg: 1053.79, Q-max: 1471.62, Q-min: -397.55
Q_loss1: 1246.09, Q_loss2: 1465.78, min_Q_loss1: -387.15, min_Q_loss2: -396.33

Train epoch 431/3000 -- step 432000

[F                                                                                                    
[F[ Model Length ] Epoch: 431 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 431000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 431 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 431431
[ Model Rollout ] Added: 48980 | Model pool: 500000 (max 500000) | Length: 4.898 | Train rep: 1

Diagnostics -- iteration 432000
real_batch_obs: 1869.59, model_batch_obs: 1939.14
real_batch_act: 205.15, model_batch_act: 197.17
real_batch_rewards: 1310.39, model_batch_rewards: 1336.45
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 326.48
total_steps: 432000.00
Q-avg: 1077.46, Q-max: 1480.41, Q-min: -349.85
Q_loss1: 1076.54, Q_loss2: 1581.49, min_Q_loss1: -405.79, min_Q_loss2: -410.56

Train epoch 432/3000 -- step 433000

[F                                                                                                    
[F[ Model Length ] Epoch: 432 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 432000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 432 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 432432
[ Model Rollout ] Added: 48979 | Model pool: 500000 (max 500000) | Length: 4.8979 | Train rep: 1

Diagnostics -- iteration 433000
real_batch_obs: 1844.94, model_batch_obs: 1833.48
real_batch_act: 207.92, model_batch_act: 195.88
real_batch_rewards: 1426.10, model_batch_rewards: 1346.64
real_batch_dones: 1.00, model_batch_dones: 4.00
evaluation/return-average: 413.91
total_steps: 433000.00
Q-avg: 997.88, Q-max: 1466.91, Q-min: -246.26
Q_loss1: 727.50, Q_loss2: 788.39, min_Q_loss1: 95.60, min_Q_loss2: 98.81

Train epoch 433/3000 -- step 434000

[F                                                                                                    
[F[ Model Length ] Epoch: 433 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 433000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 433 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 433433
[ Model Rollout ] Added: 49058 | Model pool: 500000 (max 500000) | Length: 4.9058 | Train rep: 1

Diagnostics -- iteration 434000
real_batch_obs: 1865.69, model_batch_obs: 1926.58
real_batch_act: 209.33, model_batch_act: 194.35
real_batch_rewards: 1327.59, model_batch_rewards: 1382.32
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 303.34
total_steps: 434000.00
Q-avg: 979.86, Q-max: 1457.25, Q-min: -528.85
Q_loss1: 791.11, Q_loss2: 808.65, min_Q_loss1: -545.25, min_Q_loss2: -544.04

Train epoch 434/3000 -- step 435000

[F                                                                                                    
[F[ Model Length ] Epoch: 434 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 434000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 434 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 434434
[ Model Rollout ] Added: 48994 | Model pool: 500000 (max 500000) | Length: 4.8994 | Train rep: 1

Diagnostics -- iteration 435000
real_batch_obs: 1803.73, model_batch_obs: 1841.49
real_batch_act: 197.11, model_batch_act: 188.41
real_batch_rewards: 1303.70, model_batch_rewards: 1319.64
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 291.01
total_steps: 435000.00
Q-avg: 1071.05, Q-max: 1483.00, Q-min: -304.24
Q_loss1: 189.08, Q_loss2: 202.71, min_Q_loss1: 8.65, min_Q_loss2: 15.14

Train epoch 435/3000 -- step 436000

[F                                                                                                    
[F[ Model Length ] Epoch: 435 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 435000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 435 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 435435
[ Model Rollout ] Added: 49047 | Model pool: 500000 (max 500000) | Length: 4.9047 | Train rep: 1

Diagnostics -- iteration 436000
real_batch_obs: 1897.41, model_batch_obs: 1915.40
real_batch_act: 210.80, model_batch_act: 191.68
real_batch_rewards: 1342.88, model_batch_rewards: 1340.55
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 386.45
total_steps: 436000.00
Q-avg: 1019.17, Q-max: 1473.25, Q-min: -763.65
Q_loss1: 1743.90, Q_loss2: 1732.02, min_Q_loss1: -474.11, min_Q_loss2: -466.42

Train epoch 436/3000 -- step 437000

[F                                                                                                    
[F[ Model Length ] Epoch: 436 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 436000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 436 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 436436
[ Model Rollout ] Added: 49074 | Model pool: 500000 (max 500000) | Length: 4.9074 | Train rep: 1

Diagnostics -- iteration 437000
real_batch_obs: 1958.15, model_batch_obs: 1779.57
real_batch_act: 212.48, model_batch_act: 188.88
real_batch_rewards: 1333.30, model_batch_rewards: 1260.92
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 392.66
total_steps: 437000.00
Q-avg: 1036.67, Q-max: 1466.29, Q-min: -38.62
Q_loss1: 409.90, Q_loss2: 544.08, min_Q_loss1: -60.17, min_Q_loss2: -64.46

Train epoch 437/3000 -- step 438000

[F                                                                                                    
[F[ Model Length ] Epoch: 437 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 437000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 437 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 437437
[ Model Rollout ] Added: 48997 | Model pool: 500000 (max 500000) | Length: 4.8997 | Train rep: 1

Diagnostics -- iteration 438000
real_batch_obs: 1732.30, model_batch_obs: 1819.56
real_batch_act: 199.32, model_batch_act: 187.79
real_batch_rewards: 1357.64, model_batch_rewards: 1324.48
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 1255.87
total_steps: 438000.00
Q-avg: 996.31, Q-max: 1479.61, Q-min: -796.80
Q_loss1: 1053.42, Q_loss2: 1236.14, min_Q_loss1: -435.15, min_Q_loss2: -429.21

Train epoch 438/3000 -- step 439000

[F                                                                                                    
[F[ Model Length ] Epoch: 438 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 438000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 438 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 438438
[ Model Rollout ] Added: 49040 | Model pool: 500000 (max 500000) | Length: 4.904 | Train rep: 1

Diagnostics -- iteration 439000
real_batch_obs: 1884.63, model_batch_obs: 1893.68
real_batch_act: 201.04, model_batch_act: 195.68
real_batch_rewards: 1355.80, model_batch_rewards: 1336.03
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 1320.07
total_steps: 439000.00
Q-avg: 968.42, Q-max: 1458.51, Q-min: -218.39
Q_loss1: 650.47, Q_loss2: 777.13, min_Q_loss1: -242.83, min_Q_loss2: -245.75

Train epoch 439/3000 -- step 440000

[F                                                                                                    
[F[ Model Length ] Epoch: 439 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 439000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 439 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 439439
[ Model Rollout ] Added: 48980 | Model pool: 500000 (max 500000) | Length: 4.898 | Train rep: 1

Diagnostics -- iteration 440000
real_batch_obs: 1766.08, model_batch_obs: 1871.24
real_batch_act: 199.89, model_batch_act: 186.83
real_batch_rewards: 1422.38, model_batch_rewards: 1313.41
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 387.48
total_steps: 440000.00
Q-avg: 989.80, Q-max: 1435.60, Q-min: -834.09
Q_loss1: 1841.38, Q_loss2: 2043.66, min_Q_loss1: -391.98, min_Q_loss2: -388.48

Train epoch 440/3000 -- step 441000

[F                                                                                                    
[F[ Model Length ] Epoch: 440 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 440000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 440 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 440440
[ Model Rollout ] Added: 49118 | Model pool: 500000 (max 500000) | Length: 4.9118 | Train rep: 1

Diagnostics -- iteration 441000
real_batch_obs: 1799.78, model_batch_obs: 1885.75
real_batch_act: 200.90, model_batch_act: 196.94
real_batch_rewards: 1269.08, model_batch_rewards: 1361.97
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 403.14
total_steps: 441000.00
Q-avg: 1055.36, Q-max: 1436.18, Q-min: -217.64
Q_loss1: 1820.07, Q_loss2: 2032.70, min_Q_loss1: -409.53, min_Q_loss2: -403.12

Train epoch 441/3000 -- step 442000

[F                                                                                                    
[F[ Model Length ] Epoch: 441 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 441000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 441 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 441441
[ Model Rollout ] Added: 49027 | Model pool: 500000 (max 500000) | Length: 4.9027 | Train rep: 1

Diagnostics -- iteration 442000
real_batch_obs: 1839.39, model_batch_obs: 1863.57
real_batch_act: 203.23, model_batch_act: 193.37
real_batch_rewards: 1324.02, model_batch_rewards: 1311.62
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 434.81
total_steps: 442000.00
Q-avg: 1047.40, Q-max: 1453.81, Q-min: -80.69
Q_loss1: 1412.11, Q_loss2: 1212.95, min_Q_loss1: -307.84, min_Q_loss2: -287.02

Train epoch 442/3000 -- step 443000

[F                                                                                                    
[F[ Model Length ] Epoch: 442 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 442000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 442 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 442442
[ Model Rollout ] Added: 48983 | Model pool: 500000 (max 500000) | Length: 4.8983 | Train rep: 1

Diagnostics -- iteration 443000
real_batch_obs: 1963.57, model_batch_obs: 1854.32
real_batch_act: 208.70, model_batch_act: 185.58
real_batch_rewards: 1421.84, model_batch_rewards: 1364.64
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 1675.07
total_steps: 443000.00
Q-avg: 1040.72, Q-max: 1433.54, Q-min: -62.58
Q_loss1: 271.24, Q_loss2: 347.36, min_Q_loss1: -100.84, min_Q_loss2: -103.17

Train epoch 443/3000 -- step 444000

[F                                                                                                    
[F[ Model Length ] Epoch: 443 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 443000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 443 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 443443
[ Model Rollout ] Added: 49047 | Model pool: 500000 (max 500000) | Length: 4.9047 | Train rep: 1

Diagnostics -- iteration 444000
real_batch_obs: 1889.56, model_batch_obs: 1874.01
real_batch_act: 194.68, model_batch_act: 188.64
real_batch_rewards: 1333.72, model_batch_rewards: 1315.82
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 2247.37
total_steps: 444000.00
Q-avg: 1063.60, Q-max: 1430.97, Q-min: -297.04
Q_loss1: 197.99, Q_loss2: 241.92, min_Q_loss1: -329.07, min_Q_loss2: -328.65

Train epoch 444/3000 -- step 445000

[F                                                                                                    
[F[ Model Length ] Epoch: 444 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 444000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 444 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 444444
[ Model Rollout ] Added: 49057 | Model pool: 500000 (max 500000) | Length: 4.9057 | Train rep: 1

Diagnostics -- iteration 445000
real_batch_obs: 1777.92, model_batch_obs: 1901.41
real_batch_act: 191.10, model_batch_act: 199.82
real_batch_rewards: 1307.46, model_batch_rewards: 1350.28
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 1369.29
total_steps: 445000.00
Q-avg: 1005.37, Q-max: 1410.23, Q-min: -970.77
Q_loss1: 4992.04, Q_loss2: 5980.44, min_Q_loss1: -528.79, min_Q_loss2: -524.98

Train epoch 445/3000 -- step 446000

[F                                                                                                    
[F[ Model Length ] Epoch: 445 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 445000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 445 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 445445
[ Model Rollout ] Added: 49126 | Model pool: 500000 (max 500000) | Length: 4.9126 | Train rep: 1

Diagnostics -- iteration 446000
real_batch_obs: 1790.37, model_batch_obs: 1908.50
real_batch_act: 197.53, model_batch_act: 189.38
real_batch_rewards: 1330.75, model_batch_rewards: 1334.14
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 1290.55
total_steps: 446000.00
Q-avg: 1023.65, Q-max: 1403.97, Q-min: -685.97
Q_loss1: 388.05, Q_loss2: 396.22, min_Q_loss1: -324.33, min_Q_loss2: -315.34

Train epoch 446/3000 -- step 447000

[F                                                                                                    
[F[ Model Length ] Epoch: 446 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 446000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 446 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 446446
[ Model Rollout ] Added: 49057 | Model pool: 500000 (max 500000) | Length: 4.9057 | Train rep: 1

Diagnostics -- iteration 447000
real_batch_obs: 1938.66, model_batch_obs: 1887.53
real_batch_act: 193.97, model_batch_act: 181.97
real_batch_rewards: 1378.16, model_batch_rewards: 1331.93
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 1410.05
total_steps: 447000.00
Q-avg: 1040.89, Q-max: 1398.11, Q-min: -316.59
Q_loss1: 1064.71, Q_loss2: 1441.35, min_Q_loss1: -359.75, min_Q_loss2: -360.49

Train epoch 447/3000 -- step 448000

[F                                                                                                    
[F[ Model Length ] Epoch: 447 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 447000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 447 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 447447
[ Model Rollout ] Added: 48995 | Model pool: 500000 (max 500000) | Length: 4.8995 | Train rep: 1

Diagnostics -- iteration 448000
real_batch_obs: 1858.06, model_batch_obs: 1878.00
real_batch_act: 201.93, model_batch_act: 188.14
real_batch_rewards: 1386.99, model_batch_rewards: 1365.90
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 2533.43
total_steps: 448000.00
Q-avg: 998.74, Q-max: 1389.07, Q-min: -146.02
Q_loss1: 2647.16, Q_loss2: 2358.85, min_Q_loss1: -273.28, min_Q_loss2: -279.49

Train epoch 448/3000 -- step 449000

[F                                                                                                    
[F[ Model Length ] Epoch: 448 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 448000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 448 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 448448
[ Model Rollout ] Added: 49025 | Model pool: 500000 (max 500000) | Length: 4.9025 | Train rep: 1

Diagnostics -- iteration 449000
real_batch_obs: 1785.69, model_batch_obs: 1792.96
real_batch_act: 201.59, model_batch_act: 191.09
real_batch_rewards: 1351.15, model_batch_rewards: 1353.74
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 2427.47
total_steps: 449000.00
Q-avg: 995.11, Q-max: 1386.30, Q-min: -347.22
Q_loss1: 945.55, Q_loss2: 1103.23, min_Q_loss1: -280.46, min_Q_loss2: -278.48

Train epoch 449/3000 -- step 450000

[F                                                                                                    
[F[ Model Length ] Epoch: 449 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 449000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 449 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 449449
[ Model Rollout ] Added: 48981 | Model pool: 500000 (max 500000) | Length: 4.8981 | Train rep: 1

Diagnostics -- iteration 450000
real_batch_obs: 1900.76, model_batch_obs: 1845.52
real_batch_act: 201.95, model_batch_act: 192.70
real_batch_rewards: 1380.59, model_batch_rewards: 1300.23
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 1222.79
total_steps: 450000.00
Q-avg: 1002.32, Q-max: 1399.80, Q-min: -1243.25
Q_loss1: 2481.96, Q_loss2: 2358.77, min_Q_loss1: -468.23, min_Q_loss2: -460.57

Train epoch 450/3000 -- step 451000

[F                                                                                                    
[F[ Model Length ] Epoch: 450 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 450000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 450 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 450450
[ Model Rollout ] Added: 49065 | Model pool: 500000 (max 500000) | Length: 4.9065 | Train rep: 1

Diagnostics -- iteration 451000
real_batch_obs: 1663.55, model_batch_obs: 1801.29
real_batch_act: 207.40, model_batch_act: 190.87
real_batch_rewards: 1352.94, model_batch_rewards: 1279.96
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 1530.66
total_steps: 451000.00
Q-avg: 992.36, Q-max: 1386.34, Q-min: -530.38
Q_loss1: 726.98, Q_loss2: 736.46, min_Q_loss1: -96.64, min_Q_loss2: -103.21

Train epoch 451/3000 -- step 452000

[F                                                                                                    
[F[ Model Length ] Epoch: 451 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 451000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 451 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 451451
[ Model Rollout ] Added: 49043 | Model pool: 500000 (max 500000) | Length: 4.9043 | Train rep: 1

Diagnostics -- iteration 452000
real_batch_obs: 1831.14, model_batch_obs: 1861.60
real_batch_act: 207.80, model_batch_act: 198.87
real_batch_rewards: 1301.49, model_batch_rewards: 1330.63
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 1297.14
total_steps: 452000.00
Q-avg: 1036.98, Q-max: 1396.33, Q-min: -160.67
Q_loss1: 651.87, Q_loss2: 917.73, min_Q_loss1: -381.53, min_Q_loss2: -385.67

Train epoch 452/3000 -- step 453000

[F                                                                                                    
[F[ Model Length ] Epoch: 452 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 452000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 452 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 452452
[ Model Rollout ] Added: 49087 | Model pool: 500000 (max 500000) | Length: 4.9087 | Train rep: 1

Diagnostics -- iteration 453000
real_batch_obs: 1928.38, model_batch_obs: 2002.87
real_batch_act: 188.34, model_batch_act: 199.87
real_batch_rewards: 1406.56, model_batch_rewards: 1404.17
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 2442.90
total_steps: 453000.00
Q-avg: 1041.99, Q-max: 1392.02, Q-min: -650.56
Q_loss1: 2298.37, Q_loss2: 2374.24, min_Q_loss1: -270.14, min_Q_loss2: -281.10

Train epoch 453/3000 -- step 454000

[F                                                                                                    
[F[ Model Length ] Epoch: 453 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 453000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 453 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 453453
[ Model Rollout ] Added: 48997 | Model pool: 500000 (max 500000) | Length: 4.8997 | Train rep: 1

Diagnostics -- iteration 454000
real_batch_obs: 1811.27, model_batch_obs: 1822.37
real_batch_act: 208.68, model_batch_act: 194.29
real_batch_rewards: 1326.68, model_batch_rewards: 1405.39
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 2978.23
total_steps: 454000.00
Q-avg: 995.90, Q-max: 1378.07, Q-min: -1296.54
Q_loss1: 813.02, Q_loss2: 645.40, min_Q_loss1: -221.67, min_Q_loss2: -221.07

Train epoch 454/3000 -- step 455000

[F                                                                                                    
[F[ Model Length ] Epoch: 454 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 454000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 454 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 454454
[ Model Rollout ] Added: 49105 | Model pool: 500000 (max 500000) | Length: 4.9105 | Train rep: 1

Diagnostics -- iteration 455000
real_batch_obs: 1824.32, model_batch_obs: 1894.73
real_batch_act: 206.76, model_batch_act: 202.62
real_batch_rewards: 1396.41, model_batch_rewards: 1352.03
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 3040.25
total_steps: 455000.00
Q-avg: 1019.92, Q-max: 1368.09, Q-min: -155.14
Q_loss1: 2804.98, Q_loss2: 2813.88, min_Q_loss1: -97.22, min_Q_loss2: -89.93

Train epoch 455/3000 -- step 456000

[F                                                                                                    
[F[ Model Length ] Epoch: 455 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 455000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 455 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 455455
[ Model Rollout ] Added: 49059 | Model pool: 500000 (max 500000) | Length: 4.9059 | Train rep: 1

Diagnostics -- iteration 456000
real_batch_obs: 1964.13, model_batch_obs: 1843.16
real_batch_act: 204.40, model_batch_act: 201.12
real_batch_rewards: 1375.92, model_batch_rewards: 1306.54
real_batch_dones: 2.00, model_batch_dones: 3.00
evaluation/return-average: 2945.49
total_steps: 456000.00
Q-avg: 1061.02, Q-max: 1368.51, Q-min: -125.69
Q_loss1: 189.63, Q_loss2: 306.89, min_Q_loss1: -52.52, min_Q_loss2: -68.82

Train epoch 456/3000 -- step 457000

[F                                                                                                    
[F[ Model Length ] Epoch: 456 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 456000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 456 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 456456
[ Model Rollout ] Added: 49034 | Model pool: 500000 (max 500000) | Length: 4.9034 | Train rep: 1

Diagnostics -- iteration 457000
real_batch_obs: 1786.79, model_batch_obs: 1900.50
real_batch_act: 192.09, model_batch_act: 193.20
real_batch_rewards: 1297.12, model_batch_rewards: 1243.14
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 3016.97
total_steps: 457000.00
Q-avg: 1025.42, Q-max: 1384.46, Q-min: -787.08
Q_loss1: 1097.56, Q_loss2: 946.57, min_Q_loss1: -429.84, min_Q_loss2: -429.38

Train epoch 457/3000 -- step 458000

[F                                                                                                    
[F[ Model Length ] Epoch: 457 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 457000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 457 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 457457
[ Model Rollout ] Added: 49069 | Model pool: 500000 (max 500000) | Length: 4.9069 | Train rep: 1

Diagnostics -- iteration 458000
real_batch_obs: 1923.07, model_batch_obs: 1869.54
real_batch_act: 197.93, model_batch_act: 189.69
real_batch_rewards: 1340.41, model_batch_rewards: 1600.44
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 2895.47
total_steps: 458000.00
Q-avg: 1004.13, Q-max: 1382.18, Q-min: -937.76
Q_loss1: 2104.60, Q_loss2: 1377.00, min_Q_loss1: -169.39, min_Q_loss2: -169.15

Train epoch 458/3000 -- step 459000

[F                                                                                                    
[F[ Model Length ] Epoch: 458 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 458000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 458 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 458458
[ Model Rollout ] Added: 48976 | Model pool: 500000 (max 500000) | Length: 4.8976 | Train rep: 1

Diagnostics -- iteration 459000
real_batch_obs: 1903.71, model_batch_obs: 1909.56
real_batch_act: 211.63, model_batch_act: 193.99
real_batch_rewards: 1350.97, model_batch_rewards: 1324.01
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 1299.52
total_steps: 459000.00
Q-avg: 1024.27, Q-max: 1372.27, Q-min: -73.76
Q_loss1: 430.04, Q_loss2: 442.49, min_Q_loss1: -133.19, min_Q_loss2: -134.04

Train epoch 459/3000 -- step 460000

[F                                                                                                    
[F[ Model Length ] Epoch: 459 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 459000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 459 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 459459
[ Model Rollout ] Added: 49028 | Model pool: 500000 (max 500000) | Length: 4.9028 | Train rep: 1

Diagnostics -- iteration 460000
real_batch_obs: 1791.66, model_batch_obs: 1864.72
real_batch_act: 199.70, model_batch_act: 190.51
real_batch_rewards: 1318.52, model_batch_rewards: 1354.63
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 1019.18
total_steps: 460000.00
Q-avg: 1024.58, Q-max: 1378.99, Q-min: -267.25
Q_loss1: 552.20, Q_loss2: 491.38, min_Q_loss1: -200.54, min_Q_loss2: -197.05

Train epoch 460/3000 -- step 461000

[F                                                                                                    
[F[ Model Length ] Epoch: 460 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 460000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 460 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 460460
[ Model Rollout ] Added: 48966 | Model pool: 500000 (max 500000) | Length: 4.8966 | Train rep: 1

Diagnostics -- iteration 461000
real_batch_obs: 1854.25, model_batch_obs: 1920.34
real_batch_act: 196.32, model_batch_act: 186.49
real_batch_rewards: 1345.87, model_batch_rewards: 1317.26
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 2446.71
total_steps: 461000.00
Q-avg: 1055.25, Q-max: 1391.16, Q-min: -78.07
Q_loss1: 572.26, Q_loss2: 591.78, min_Q_loss1: 131.05, min_Q_loss2: 132.17

Train epoch 461/3000 -- step 462000

[F                                                                                                    
[F[ Model Length ] Epoch: 461 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 461000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 461 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 461461
[ Model Rollout ] Added: 48945 | Model pool: 500000 (max 500000) | Length: 4.8945 | Train rep: 1

Diagnostics -- iteration 462000
real_batch_obs: 1744.15, model_batch_obs: 1947.13
real_batch_act: 205.85, model_batch_act: 192.04
real_batch_rewards: 1340.75, model_batch_rewards: 1391.42
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 980.64
total_steps: 462000.00
Q-avg: 962.49, Q-max: 1391.37, Q-min: -627.14
Q_loss1: 1117.06, Q_loss2: 989.21, min_Q_loss1: -25.34, min_Q_loss2: -34.87

Train epoch 462/3000 -- step 463000

[F                                                                                                    
[F[ Model Length ] Epoch: 462 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 462000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 462 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 462462
[ Model Rollout ] Added: 49068 | Model pool: 500000 (max 500000) | Length: 4.9068 | Train rep: 1

Diagnostics -- iteration 463000
real_batch_obs: 1895.52, model_batch_obs: 1872.41
real_batch_act: 207.32, model_batch_act: 202.31
real_batch_rewards: 1331.55, model_batch_rewards: 1358.18
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 1578.86
total_steps: 463000.00
Q-avg: 1028.37, Q-max: 1386.22, Q-min: -524.97
Q_loss1: 1055.83, Q_loss2: 1195.74, min_Q_loss1: -202.39, min_Q_loss2: -208.98

Train epoch 463/3000 -- step 464000

[F                                                                                                    
[F[ Model Length ] Epoch: 463 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 463000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 463 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 463463
[ Model Rollout ] Added: 49013 | Model pool: 500000 (max 500000) | Length: 4.9013 | Train rep: 1

Diagnostics -- iteration 464000
real_batch_obs: 1690.25, model_batch_obs: 1931.06
real_batch_act: 190.98, model_batch_act: 193.83
real_batch_rewards: 1281.78, model_batch_rewards: 1398.91
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 2107.38
total_steps: 464000.00
Q-avg: 1065.83, Q-max: 1405.80, Q-min: -549.82
Q_loss1: 363.30, Q_loss2: 281.56, min_Q_loss1: -323.60, min_Q_loss2: -322.50

Train epoch 464/3000 -- step 465000

[F                                                                                                    
[F[ Model Length ] Epoch: 464 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 464000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 464 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 464464
[ Model Rollout ] Added: 48984 | Model pool: 500000 (max 500000) | Length: 4.8984 | Train rep: 1

Diagnostics -- iteration 465000
real_batch_obs: 1648.90, model_batch_obs: 1876.44
real_batch_act: 199.86, model_batch_act: 196.00
real_batch_rewards: 1297.84, model_batch_rewards: 1346.22
real_batch_dones: 3.00, model_batch_dones: 4.00
evaluation/return-average: 1614.10
total_steps: 465000.00
Q-avg: 987.08, Q-max: 1408.94, Q-min: -492.52
Q_loss1: 452.91, Q_loss2: 252.40, min_Q_loss1: -545.75, min_Q_loss2: -548.19

Train epoch 465/3000 -- step 466000

[F                                                                                                    
[F[ Model Length ] Epoch: 465 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 465000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 465 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 465465
[ Model Rollout ] Added: 49080 | Model pool: 500000 (max 500000) | Length: 4.908 | Train rep: 1

Diagnostics -- iteration 466000
real_batch_obs: 1904.85, model_batch_obs: 1867.60
real_batch_act: 201.69, model_batch_act: 199.28
real_batch_rewards: 1387.63, model_batch_rewards: 1327.21
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 1068.21
total_steps: 466000.00
Q-avg: 1020.54, Q-max: 1420.83, Q-min: -258.37
Q_loss1: 392.91, Q_loss2: 434.45, min_Q_loss1: -271.41, min_Q_loss2: -268.88

Train epoch 466/3000 -- step 467000

[F                                                                                                    
[F[ Model Length ] Epoch: 466 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 466000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 466 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 466466
[ Model Rollout ] Added: 48989 | Model pool: 500000 (max 500000) | Length: 4.8989 | Train rep: 1

Diagnostics -- iteration 467000
real_batch_obs: 1749.40, model_batch_obs: 1854.03
real_batch_act: 205.18, model_batch_act: 186.72
real_batch_rewards: 1295.22, model_batch_rewards: 1335.46
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 930.66
total_steps: 467000.00
Q-avg: 1014.18, Q-max: 1435.89, Q-min: -1339.44
Q_loss1: 1179.23, Q_loss2: 656.29, min_Q_loss1: -151.88, min_Q_loss2: -144.78

Train epoch 467/3000 -- step 468000

[F                                                                                                    
[F[ Model Length ] Epoch: 467 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 467000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 467 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 467467
[ Model Rollout ] Added: 49180 | Model pool: 500000 (max 500000) | Length: 4.918 | Train rep: 1

Diagnostics -- iteration 468000
real_batch_obs: 1885.57, model_batch_obs: 1900.10
real_batch_act: 192.17, model_batch_act: 198.59
real_batch_rewards: 1351.12, model_batch_rewards: 1369.60
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 388.73
total_steps: 468000.00
Q-avg: 1020.10, Q-max: 1506.36, Q-min: -109.34
Q_loss1: 981.90, Q_loss2: 852.76, min_Q_loss1: -351.37, min_Q_loss2: -363.06

Train epoch 468/3000 -- step 469000

[F                                                                                                    
[F[ Model Length ] Epoch: 468 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 468000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 468 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 468468
[ Model Rollout ] Added: 49017 | Model pool: 500000 (max 500000) | Length: 4.9017 | Train rep: 1

Diagnostics -- iteration 469000
real_batch_obs: 1766.97, model_batch_obs: 1882.61
real_batch_act: 200.16, model_batch_act: 188.35
real_batch_rewards: 1312.15, model_batch_rewards: 1364.74
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 377.87
total_steps: 469000.00
Q-avg: 1044.72, Q-max: 1516.97, Q-min: -889.05
Q_loss1: 282.99, Q_loss2: 272.27, min_Q_loss1: -131.64, min_Q_loss2: -130.70

Train epoch 469/3000 -- step 470000

[F                                                                                                    
[F[ Model Length ] Epoch: 469 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 469000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 469 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 469469
[ Model Rollout ] Added: 49025 | Model pool: 500000 (max 500000) | Length: 4.9025 | Train rep: 1

Diagnostics -- iteration 470000
real_batch_obs: 1958.16, model_batch_obs: 1933.56
real_batch_act: 192.30, model_batch_act: 193.39
real_batch_rewards: 1329.59, model_batch_rewards: 3430.57
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 382.88
total_steps: 470000.00
Q-avg: 1033.02, Q-max: 1526.27, Q-min: -2288.49
Q_loss1: 3232.52, Q_loss2: 3281.07, min_Q_loss1: -533.57, min_Q_loss2: -537.31

Train epoch 470/3000 -- step 471000

[F                                                                                                    
[F[ Model Length ] Epoch: 470 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 470000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 470 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 470470
[ Model Rollout ] Added: 48950 | Model pool: 500000 (max 500000) | Length: 4.895 | Train rep: 1

Diagnostics -- iteration 471000
real_batch_obs: 1804.22, model_batch_obs: 1841.22
real_batch_act: 201.15, model_batch_act: 197.50
real_batch_rewards: 1391.79, model_batch_rewards: 1338.55
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 360.33
total_steps: 471000.00
Q-avg: 1016.07, Q-max: 1638.02, Q-min: -1499.21
Q_loss1: 763.33, Q_loss2: 543.33, min_Q_loss1: -482.89, min_Q_loss2: -476.43

Train epoch 471/3000 -- step 472000

[F                                                                                                    
[F[ Model Length ] Epoch: 471 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 471000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 471 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 471471
[ Model Rollout ] Added: 49042 | Model pool: 500000 (max 500000) | Length: 4.9042 | Train rep: 1

Diagnostics -- iteration 472000
real_batch_obs: 1788.92, model_batch_obs: 1830.23
real_batch_act: 206.18, model_batch_act: 192.75
real_batch_rewards: 1333.59, model_batch_rewards: 1312.93
real_batch_dones: 2.00, model_batch_dones: 1.00
evaluation/return-average: 348.18
total_steps: 472000.00
Q-avg: 999.38, Q-max: 1569.97, Q-min: -249.94
Q_loss1: 414.54, Q_loss2: 426.02, min_Q_loss1: 50.73, min_Q_loss2: 58.15

Train epoch 472/3000 -- step 473000

[F                                                                                                    
[F[ Model Length ] Epoch: 472 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 472000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 472 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 472472
[ Model Rollout ] Added: 48994 | Model pool: 500000 (max 500000) | Length: 4.8994 | Train rep: 1

Diagnostics -- iteration 473000
real_batch_obs: 1776.66, model_batch_obs: 1891.68
real_batch_act: 202.28, model_batch_act: 200.56
real_batch_rewards: 1362.87, model_batch_rewards: 1373.10
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 377.24
total_steps: 473000.00
Q-avg: 1020.32, Q-max: 1694.83, Q-min: -179.12
Q_loss1: 1403.91, Q_loss2: 1227.91, min_Q_loss1: -443.07, min_Q_loss2: -442.43

Train epoch 473/3000 -- step 474000

[F                                                                                                    
[F[ Model Length ] Epoch: 473 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 473000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 473 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 473473
[ Model Rollout ] Added: 49075 | Model pool: 500000 (max 500000) | Length: 4.9075 | Train rep: 1

Diagnostics -- iteration 474000
real_batch_obs: 1916.74, model_batch_obs: 1822.90
real_batch_act: 202.13, model_batch_act: 181.94
real_batch_rewards: 1361.90, model_batch_rewards: 1355.61
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 361.57
total_steps: 474000.00
Q-avg: 1043.72, Q-max: 1641.64, Q-min: -234.10
Q_loss1: 162.70, Q_loss2: 150.40, min_Q_loss1: -254.42, min_Q_loss2: -246.28

Train epoch 474/3000 -- step 475000

[F                                                                                                    
[F[ Model Length ] Epoch: 474 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 474000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 474 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 474474
[ Model Rollout ] Added: 48920 | Model pool: 500000 (max 500000) | Length: 4.892 | Train rep: 1

Diagnostics -- iteration 475000
real_batch_obs: 1817.76, model_batch_obs: 1908.61
real_batch_act: 198.03, model_batch_act: 196.49
real_batch_rewards: 1378.78, model_batch_rewards: 1238.28
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 357.10
total_steps: 475000.00
Q-avg: 1028.42, Q-max: 1656.22, Q-min: -907.62
Q_loss1: 718.56, Q_loss2: 575.80, min_Q_loss1: -139.43, min_Q_loss2: -130.68

Train epoch 475/3000 -- step 476000

[F                                                                                                    
[F[ Model Length ] Epoch: 475 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 475000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 475 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 475475
[ Model Rollout ] Added: 49038 | Model pool: 500000 (max 500000) | Length: 4.9038 | Train rep: 1

Diagnostics -- iteration 476000
real_batch_obs: 1731.36, model_batch_obs: 1819.60
real_batch_act: 202.77, model_batch_act: 189.34
real_batch_rewards: 1286.45, model_batch_rewards: 1315.60
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 376.55
total_steps: 476000.00
Q-avg: 1064.48, Q-max: 1659.84, Q-min: -457.46
Q_loss1: 1087.05, Q_loss2: 1226.49, min_Q_loss1: -236.82, min_Q_loss2: -239.95

Train epoch 476/3000 -- step 477000

[F                                                                                                    
[F[ Model Length ] Epoch: 476 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 476000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 476 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 476476
[ Model Rollout ] Added: 49056 | Model pool: 500000 (max 500000) | Length: 4.9056 | Train rep: 1

Diagnostics -- iteration 477000
real_batch_obs: 1786.20, model_batch_obs: 1848.58
real_batch_act: 208.11, model_batch_act: 191.32
real_batch_rewards: 1347.63, model_batch_rewards: 1345.36
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 367.18
total_steps: 477000.00
Q-avg: 1038.95, Q-max: 1672.95, Q-min: -10.17
Q_loss1: 219.74, Q_loss2: 204.11, min_Q_loss1: -21.04, min_Q_loss2: -18.98

Train epoch 477/3000 -- step 478000

[F                                                                                                    
[F[ Model Length ] Epoch: 477 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 477000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 477 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 477477
[ Model Rollout ] Added: 49002 | Model pool: 500000 (max 500000) | Length: 4.9002 | Train rep: 1

Diagnostics -- iteration 478000
real_batch_obs: 1807.64, model_batch_obs: 1867.73
real_batch_act: 185.17, model_batch_act: 198.91
real_batch_rewards: 1362.43, model_batch_rewards: 2738.95
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 383.57
total_steps: 478000.00
Q-avg: 1016.77, Q-max: 1631.01, Q-min: -4526.15
Q_loss1: 18006.84, Q_loss2: 18912.24, min_Q_loss1: -478.75, min_Q_loss2: -476.15

Train epoch 478/3000 -- step 479000

[F                                                                                                    
[F[ Model Length ] Epoch: 478 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 478000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 478 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 478478
[ Model Rollout ] Added: 49060 | Model pool: 500000 (max 500000) | Length: 4.906 | Train rep: 1

Diagnostics -- iteration 479000
real_batch_obs: 1927.19, model_batch_obs: 2037.30
real_batch_act: 200.50, model_batch_act: 188.42
real_batch_rewards: 1343.76, model_batch_rewards: 1594.68
real_batch_dones: 0.00, model_batch_dones: 5.00
evaluation/return-average: 362.47
total_steps: 479000.00
Q-avg: 1035.98, Q-max: 1633.31, Q-min: -786.70
Q_loss1: 1010.26, Q_loss2: 1025.34, min_Q_loss1: -293.37, min_Q_loss2: -295.18

Train epoch 479/3000 -- step 480000

[F                                                                                                    
[F[ Model Length ] Epoch: 479 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 479000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 479 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 479479
[ Model Rollout ] Added: 49074 | Model pool: 500000 (max 500000) | Length: 4.9074 | Train rep: 1

Diagnostics -- iteration 480000
real_batch_obs: 1962.72, model_batch_obs: 1828.44
real_batch_act: 188.89, model_batch_act: 197.02
real_batch_rewards: 1455.05, model_batch_rewards: 1287.27
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 382.78
total_steps: 480000.00
Q-avg: 1039.50, Q-max: 1621.80, Q-min: -212.40
Q_loss1: 335.35, Q_loss2: 330.10, min_Q_loss1: 289.25, min_Q_loss2: 290.58

Train epoch 480/3000 -- step 481000

[F                                                                                                    
[F[ Model Length ] Epoch: 480 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 480000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 480 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 480480
[ Model Rollout ] Added: 49051 | Model pool: 500000 (max 500000) | Length: 4.9051 | Train rep: 1

Diagnostics -- iteration 481000
real_batch_obs: 1991.95, model_batch_obs: 1851.14
real_batch_act: 210.80, model_batch_act: 184.73
real_batch_rewards: 1375.48, model_batch_rewards: 1314.52
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 378.08
total_steps: 481000.00
Q-avg: 1083.74, Q-max: 1610.84, Q-min: -87.50
Q_loss1: 395.29, Q_loss2: 353.49, min_Q_loss1: -5.14, min_Q_loss2: -8.85

Train epoch 481/3000 -- step 482000

[F                                                                                                    
[F[ Model Length ] Epoch: 481 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 481000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 481 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 481481
[ Model Rollout ] Added: 48910 | Model pool: 500000 (max 500000) | Length: 4.891 | Train rep: 1

Diagnostics -- iteration 482000
real_batch_obs: 1812.59, model_batch_obs: 1847.96
real_batch_act: 196.96, model_batch_act: 189.65
real_batch_rewards: 1336.96, model_batch_rewards: 1300.19
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 387.94
total_steps: 482000.00
Q-avg: 1097.87, Q-max: 1591.28, Q-min: -37.04
Q_loss1: 1325.05, Q_loss2: 1285.19, min_Q_loss1: -75.59, min_Q_loss2: -75.17

Train epoch 482/3000 -- step 483000

[F                                                                                                    
[F[ Model Length ] Epoch: 482 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 482000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 482 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 482482
[ Model Rollout ] Added: 48960 | Model pool: 500000 (max 500000) | Length: 4.896 | Train rep: 1

Diagnostics -- iteration 483000
real_batch_obs: 1882.59, model_batch_obs: 1921.85
real_batch_act: 203.01, model_batch_act: 186.43
real_batch_rewards: 1341.22, model_batch_rewards: 1377.42
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 382.87
total_steps: 483000.00
Q-avg: 1077.68, Q-max: 1599.84, Q-min: -410.31
Q_loss1: 672.14, Q_loss2: 537.24, min_Q_loss1: -254.83, min_Q_loss2: -245.69

Train epoch 483/3000 -- step 484000

[F                                                                                                    
[F[ Model Length ] Epoch: 483 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 483000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 483 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 483483
[ Model Rollout ] Added: 48899 | Model pool: 500000 (max 500000) | Length: 4.8899 | Train rep: 1

Diagnostics -- iteration 484000
real_batch_obs: 1803.58, model_batch_obs: 1884.26
real_batch_act: 203.46, model_batch_act: 197.11
real_batch_rewards: 1373.37, model_batch_rewards: 1331.82
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 380.17
total_steps: 484000.00
Q-avg: 1112.17, Q-max: 1598.79, Q-min: -61.84
Q_loss1: 2813.72, Q_loss2: 2522.06, min_Q_loss1: -251.45, min_Q_loss2: -254.04

Train epoch 484/3000 -- step 485000

[F                                                                                                    
[F[ Model Length ] Epoch: 484 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 484000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 484 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 484484
[ Model Rollout ] Added: 49021 | Model pool: 500000 (max 500000) | Length: 4.9021 | Train rep: 1

Diagnostics -- iteration 485000
real_batch_obs: 1885.58, model_batch_obs: 1910.76
real_batch_act: 192.47, model_batch_act: 191.40
real_batch_rewards: 1357.14, model_batch_rewards: 1371.02
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 389.68
total_steps: 485000.00
Q-avg: 1084.99, Q-max: 1595.15, Q-min: -395.76
Q_loss1: 474.36, Q_loss2: 612.66, min_Q_loss1: -474.85, min_Q_loss2: -486.55

Train epoch 485/3000 -- step 486000

[F                                                                                                    
[F[ Model Length ] Epoch: 485 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 485000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 485 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 485485
[ Model Rollout ] Added: 49013 | Model pool: 500000 (max 500000) | Length: 4.9013 | Train rep: 1

Diagnostics -- iteration 486000
real_batch_obs: 1825.20, model_batch_obs: 2000.75
real_batch_act: 196.19, model_batch_act: 191.09
real_batch_rewards: 1325.42, model_batch_rewards: 1372.24
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 325.63
total_steps: 486000.00
Q-avg: 1070.52, Q-max: 1581.26, Q-min: -398.36
Q_loss1: 245.74, Q_loss2: 231.61, min_Q_loss1: -433.40, min_Q_loss2: -431.70

Train epoch 486/3000 -- step 487000

[F                                                                                                    
[F[ Model Length ] Epoch: 486 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 486000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 486 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 486486
[ Model Rollout ] Added: 49060 | Model pool: 500000 (max 500000) | Length: 4.906 | Train rep: 1

Diagnostics -- iteration 487000
real_batch_obs: 1715.08, model_batch_obs: 1947.52
real_batch_act: 195.28, model_batch_act: 197.83
real_batch_rewards: 1253.32, model_batch_rewards: 1443.44
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 299.01
total_steps: 487000.00
Q-avg: 1100.83, Q-max: 1567.62, Q-min: -795.09
Q_loss1: 2110.28, Q_loss2: 2155.26, min_Q_loss1: -506.10, min_Q_loss2: -511.49

Train epoch 487/3000 -- step 488000

[F                                                                                                    
[F[ Model Length ] Epoch: 487 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 487000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 487 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 487487
[ Model Rollout ] Added: 49055 | Model pool: 500000 (max 500000) | Length: 4.9055 | Train rep: 1

Diagnostics -- iteration 488000
real_batch_obs: 1752.96, model_batch_obs: 1861.12
real_batch_act: 203.96, model_batch_act: 190.92
real_batch_rewards: 1272.20, model_batch_rewards: 1344.64
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 418.61
total_steps: 488000.00
Q-avg: 1035.58, Q-max: 1563.21, Q-min: -687.85
Q_loss1: 4263.24, Q_loss2: 4967.56, min_Q_loss1: -227.59, min_Q_loss2: -224.10

Train epoch 488/3000 -- step 489000

[F                                                                                                    
[F[ Model Length ] Epoch: 488 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 488000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 488 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 488488
[ Model Rollout ] Added: 49035 | Model pool: 500000 (max 500000) | Length: 4.9035 | Train rep: 1

Diagnostics -- iteration 489000
real_batch_obs: 1805.13, model_batch_obs: 1782.56
real_batch_act: 198.38, model_batch_act: 191.63
real_batch_rewards: 1344.98, model_batch_rewards: 1345.37
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 1057.29
total_steps: 489000.00
Q-avg: 1013.31, Q-max: 1537.57, Q-min: -467.34
Q_loss1: 1349.67, Q_loss2: 1435.63, min_Q_loss1: -347.33, min_Q_loss2: -343.77

Train epoch 489/3000 -- step 490000

[F                                                                                                    
[F[ Model Length ] Epoch: 489 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 489000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 489 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 489489
[ Model Rollout ] Added: 49035 | Model pool: 500000 (max 500000) | Length: 4.9035 | Train rep: 1

Diagnostics -- iteration 490000
real_batch_obs: 1785.45, model_batch_obs: 1819.55
real_batch_act: 204.59, model_batch_act: 186.56
real_batch_rewards: 1345.32, model_batch_rewards: 1332.14
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 575.35
total_steps: 490000.00
Q-avg: 1052.02, Q-max: 1521.42, Q-min: -884.43
Q_loss1: 1428.03, Q_loss2: 1423.40, min_Q_loss1: -281.16, min_Q_loss2: -266.36

Train epoch 490/3000 -- step 491000

[F                                                                                                    
[F[ Model Length ] Epoch: 490 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 490000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 490 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 490490
[ Model Rollout ] Added: 49050 | Model pool: 500000 (max 500000) | Length: 4.905 | Train rep: 1

Diagnostics -- iteration 491000
real_batch_obs: 1766.56, model_batch_obs: 1804.95
real_batch_act: 200.40, model_batch_act: 195.55
real_batch_rewards: 1373.95, model_batch_rewards: 1288.85
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 1391.12
total_steps: 491000.00
Q-avg: 1028.60, Q-max: 1500.06, Q-min: -185.61
Q_loss1: 425.24, Q_loss2: 401.79, min_Q_loss1: 56.60, min_Q_loss2: 57.38

Train epoch 491/3000 -- step 492000

[F                                                                                                    
[F[ Model Length ] Epoch: 491 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 491000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 491 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 491491
[ Model Rollout ] Added: 49049 | Model pool: 500000 (max 500000) | Length: 4.9049 | Train rep: 1

Diagnostics -- iteration 492000
real_batch_obs: 1767.22, model_batch_obs: 1851.76
real_batch_act: 197.59, model_batch_act: 184.11
real_batch_rewards: 1315.46, model_batch_rewards: 1393.57
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 1271.89
total_steps: 492000.00
Q-avg: 1088.43, Q-max: 1547.51, Q-min: -751.16
Q_loss1: 593.25, Q_loss2: 543.13, min_Q_loss1: -540.29, min_Q_loss2: -542.07

Train epoch 492/3000 -- step 493000

[F                                                                                                    
[F[ Model Length ] Epoch: 492 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 492000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 492 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 492492
[ Model Rollout ] Added: 48967 | Model pool: 500000 (max 500000) | Length: 4.8967 | Train rep: 1

Diagnostics -- iteration 493000
real_batch_obs: 1925.71, model_batch_obs: 1876.76
real_batch_act: 210.22, model_batch_act: 181.56
real_batch_rewards: 1307.52, model_batch_rewards: 1372.58
real_batch_dones: 2.00, model_batch_dones: 0.00
evaluation/return-average: 962.79
total_steps: 493000.00
Q-avg: 1076.59, Q-max: 1539.36, Q-min: -336.94
Q_loss1: 802.52, Q_loss2: 815.88, min_Q_loss1: -202.58, min_Q_loss2: -208.21

Train epoch 493/3000 -- step 494000

[F                                                                                                    
[F[ Model Length ] Epoch: 493 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 493000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 493 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 493493
[ Model Rollout ] Added: 48985 | Model pool: 500000 (max 500000) | Length: 4.8985 | Train rep: 1

Diagnostics -- iteration 494000
real_batch_obs: 1761.27, model_batch_obs: 1805.04
real_batch_act: 190.55, model_batch_act: 184.01
real_batch_rewards: 1378.59, model_batch_rewards: 1348.13
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 1001.12
total_steps: 494000.00
Q-avg: 1052.34, Q-max: 1540.96, Q-min: -61.86
Q_loss1: 1528.69, Q_loss2: 1288.30, min_Q_loss1: -79.59, min_Q_loss2: -87.11

Train epoch 494/3000 -- step 495000

[F                                                                                                    
[F[ Model Length ] Epoch: 494 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 494000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 494 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 494494
[ Model Rollout ] Added: 49064 | Model pool: 500000 (max 500000) | Length: 4.9064 | Train rep: 1

Diagnostics -- iteration 495000
real_batch_obs: 1809.94, model_batch_obs: 1886.93
real_batch_act: 201.37, model_batch_act: 180.40
real_batch_rewards: 1257.32, model_batch_rewards: 1394.07
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 1289.31
total_steps: 495000.00
Q-avg: 1076.57, Q-max: 1535.15, Q-min: -97.43
Q_loss1: 164.68, Q_loss2: 163.94, min_Q_loss1: -186.51, min_Q_loss2: -188.12

Train epoch 495/3000 -- step 496000

[F                                                                                                    
[F[ Model Length ] Epoch: 495 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 495000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 495 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 495495
[ Model Rollout ] Added: 49057 | Model pool: 500000 (max 500000) | Length: 4.9057 | Train rep: 1

Diagnostics -- iteration 496000
real_batch_obs: 1840.54, model_batch_obs: 1826.98
real_batch_act: 202.19, model_batch_act: 189.92
real_batch_rewards: 1413.98, model_batch_rewards: 1349.97
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 1275.82
total_steps: 496000.00
Q-avg: 1035.07, Q-max: 1529.93, Q-min: -103.63
Q_loss1: 1525.95, Q_loss2: 1752.85, min_Q_loss1: -105.13, min_Q_loss2: -99.54

Train epoch 496/3000 -- step 497000

[F                                                                                                    
[F[ Model Length ] Epoch: 496 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 496000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 496 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 496496
[ Model Rollout ] Added: 48999 | Model pool: 500000 (max 500000) | Length: 4.8999 | Train rep: 1

Diagnostics -- iteration 497000
real_batch_obs: 1924.95, model_batch_obs: 1840.17
real_batch_act: 197.22, model_batch_act: 188.31
real_batch_rewards: 1432.17, model_batch_rewards: 1330.94
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 1027.69
total_steps: 497000.00
Q-avg: 1043.03, Q-max: 1523.73, Q-min: -240.66
Q_loss1: 524.92, Q_loss2: 471.18, min_Q_loss1: -114.35, min_Q_loss2: -119.26

Train epoch 497/3000 -- step 498000

[F                                                                                                    
[F[ Model Length ] Epoch: 497 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 497000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 497 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 497497
[ Model Rollout ] Added: 48976 | Model pool: 500000 (max 500000) | Length: 4.8976 | Train rep: 1

Diagnostics -- iteration 498000
real_batch_obs: 1898.71, model_batch_obs: 1736.27
real_batch_act: 197.17, model_batch_act: 199.73
real_batch_rewards: 1377.66, model_batch_rewards: 1344.49
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 1060.87
total_steps: 498000.00
Q-avg: 1032.13, Q-max: 1503.62, Q-min: -980.44
Q_loss1: 933.55, Q_loss2: 872.63, min_Q_loss1: -341.76, min_Q_loss2: -339.46

Train epoch 498/3000 -- step 499000

[F                                                                                                    
[F[ Model Length ] Epoch: 498 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 498000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 498 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 498498
[ Model Rollout ] Added: 48920 | Model pool: 500000 (max 500000) | Length: 4.892 | Train rep: 1

Diagnostics -- iteration 499000
real_batch_obs: 1762.61, model_batch_obs: 1833.10
real_batch_act: 194.79, model_batch_act: 201.46
real_batch_rewards: 1280.67, model_batch_rewards: 1291.12
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 1451.59
total_steps: 499000.00
Q-avg: 1024.02, Q-max: 1470.72, Q-min: -262.17
Q_loss1: 328.98, Q_loss2: 393.32, min_Q_loss1: -99.24, min_Q_loss2: -97.79

Train epoch 499/3000 -- step 500000

[F                                                                                                    
[F[ Model Length ] Epoch: 499 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 499000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 499 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 499499
[ Model Rollout ] Added: 49021 | Model pool: 500000 (max 500000) | Length: 4.9021 | Train rep: 1

Diagnostics -- iteration 500000
real_batch_obs: 1769.29, model_batch_obs: 1914.38
real_batch_act: 198.25, model_batch_act: 188.60
real_batch_rewards: 1327.01, model_batch_rewards: 1401.09
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 1505.83
total_steps: 500000.00
Q-avg: 1026.07, Q-max: 1467.30, Q-min: -692.93
Q_loss1: 666.24, Q_loss2: 548.85, min_Q_loss1: -271.58, min_Q_loss2: -271.88

Train epoch 500/3000 -- step 501000

[F                                                                                                    
[F[ Model Length ] Epoch: 500 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 500000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 500 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 500500
[ Model Rollout ] Added: 49026 | Model pool: 500000 (max 500000) | Length: 4.9026 | Train rep: 1

Diagnostics -- iteration 501000
real_batch_obs: 1842.21, model_batch_obs: 1903.37
real_batch_act: 185.42, model_batch_act: 199.73
real_batch_rewards: 1335.95, model_batch_rewards: 1330.02
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 1094.78
total_steps: 501000.00
Q-avg: 1078.54, Q-max: 1480.76, Q-min: -222.46
Q_loss1: 636.96, Q_loss2: 377.20, min_Q_loss1: -159.25, min_Q_loss2: -161.15

Train epoch 501/3000 -- step 502000

[F                                                                                                    
[F[ Model Length ] Epoch: 501 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 501000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 501 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 501501
[ Model Rollout ] Added: 48989 | Model pool: 500000 (max 500000) | Length: 4.8989 | Train rep: 1

Diagnostics -- iteration 502000
real_batch_obs: 1690.57, model_batch_obs: 2054.26
real_batch_act: 178.31, model_batch_act: 185.50
real_batch_rewards: 1261.03, model_batch_rewards: 1406.69
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 976.01
total_steps: 502000.00
Q-avg: 1019.72, Q-max: 1449.51, Q-min: -29.55
Q_loss1: 355.67, Q_loss2: 437.04, min_Q_loss1: -649.53, min_Q_loss2: -655.52

Train epoch 502/3000 -- step 503000

[F                                                                                                    
[F[ Model Length ] Epoch: 502 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 502000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 502 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 502502
[ Model Rollout ] Added: 49067 | Model pool: 500000 (max 500000) | Length: 4.9067 | Train rep: 1

Diagnostics -- iteration 503000
real_batch_obs: 1786.62, model_batch_obs: 1921.10
real_batch_act: 193.67, model_batch_act: 182.82
real_batch_rewards: 1352.41, model_batch_rewards: 1368.92
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 1493.08
total_steps: 503000.00
Q-avg: 1025.64, Q-max: 1457.42, Q-min: -131.33
Q_loss1: 930.07, Q_loss2: 787.01, min_Q_loss1: -330.74, min_Q_loss2: -329.35

Train epoch 503/3000 -- step 504000

[F                                                                                                    
[F[ Model Length ] Epoch: 503 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 503000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 503 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 503503
[ Model Rollout ] Added: 49009 | Model pool: 500000 (max 500000) | Length: 4.9009 | Train rep: 1

Diagnostics -- iteration 504000
real_batch_obs: 1826.55, model_batch_obs: 1874.59
real_batch_act: 185.16, model_batch_act: 194.96
real_batch_rewards: 1382.64, model_batch_rewards: 1399.72
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 1022.20
total_steps: 504000.00
Q-avg: 1016.05, Q-max: 1454.98, Q-min: -201.99
Q_loss1: 487.09, Q_loss2: 632.10, min_Q_loss1: -402.87, min_Q_loss2: -413.28

Train epoch 504/3000 -- step 505000

[F                                                                                                    
[F[ Model Length ] Epoch: 504 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 504000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 504 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 504504
[ Model Rollout ] Added: 49036 | Model pool: 500000 (max 500000) | Length: 4.9036 | Train rep: 1

Diagnostics -- iteration 505000
real_batch_obs: 1800.71, model_batch_obs: 1904.37
real_batch_act: 197.42, model_batch_act: 198.22
real_batch_rewards: 1408.14, model_batch_rewards: 1353.85
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 1195.51
total_steps: 505000.00
Q-avg: 1004.89, Q-max: 1451.62, Q-min: -722.13
Q_loss1: 245.99, Q_loss2: 181.47, min_Q_loss1: -340.89, min_Q_loss2: -331.73

Train epoch 505/3000 -- step 506000

[F                                                                                                    
[F[ Model Length ] Epoch: 505 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 505000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 505 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 505505
[ Model Rollout ] Added: 49112 | Model pool: 500000 (max 500000) | Length: 4.9112 | Train rep: 1

Diagnostics -- iteration 506000
real_batch_obs: 1797.87, model_batch_obs: 1907.79
real_batch_act: 203.10, model_batch_act: 188.66
real_batch_rewards: 1326.19, model_batch_rewards: 1314.78
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 1001.62
total_steps: 506000.00
Q-avg: 1022.93, Q-max: 1427.88, Q-min: -340.68
Q_loss1: 268.69, Q_loss2: 263.84, min_Q_loss1: -542.60, min_Q_loss2: -539.64

Train epoch 506/3000 -- step 507000

[F                                                                                                    
[F[ Model Length ] Epoch: 506 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 506000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 506 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 506506
[ Model Rollout ] Added: 48996 | Model pool: 500000 (max 500000) | Length: 4.8996 | Train rep: 1

Diagnostics -- iteration 507000
real_batch_obs: 1892.82, model_batch_obs: 2034.04
real_batch_act: 207.82, model_batch_act: 188.45
real_batch_rewards: 1350.56, model_batch_rewards: 1363.47
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 1653.32
total_steps: 507000.00
Q-avg: 996.95, Q-max: 1419.21, Q-min: -195.56
Q_loss1: 409.53, Q_loss2: 474.82, min_Q_loss1: -378.70, min_Q_loss2: -373.36

Train epoch 507/3000 -- step 508000

[F                                                                                                    
[F[ Model Length ] Epoch: 507 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 507000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 507 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 507507
[ Model Rollout ] Added: 49025 | Model pool: 500000 (max 500000) | Length: 4.9025 | Train rep: 1

Diagnostics -- iteration 508000
real_batch_obs: 1869.33, model_batch_obs: 1849.67
real_batch_act: 188.75, model_batch_act: 190.50
real_batch_rewards: 1356.41, model_batch_rewards: 1401.18
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 3049.74
total_steps: 508000.00
Q-avg: 1004.94, Q-max: 1457.67, Q-min: -1904.60
Q_loss1: 6916.20, Q_loss2: 7474.32, min_Q_loss1: -511.17, min_Q_loss2: -507.47

Train epoch 508/3000 -- step 509000

[F                                                                                                    
[F[ Model Length ] Epoch: 508 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 508000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 508 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 508508
[ Model Rollout ] Added: 49004 | Model pool: 500000 (max 500000) | Length: 4.9004 | Train rep: 1

Diagnostics -- iteration 509000
real_batch_obs: 1805.47, model_batch_obs: 1944.13
real_batch_act: 195.28, model_batch_act: 196.96
real_batch_rewards: 1340.78, model_batch_rewards: 1363.30
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 1275.70
total_steps: 509000.00
Q-avg: 1026.19, Q-max: 1422.88, Q-min: -854.24
Q_loss1: 487.19, Q_loss2: 429.43, min_Q_loss1: -312.79, min_Q_loss2: -312.02

Train epoch 509/3000 -- step 510000

[F                                                                                                    
[F[ Model Length ] Epoch: 509 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 509000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 509 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 509509
[ Model Rollout ] Added: 49040 | Model pool: 500000 (max 500000) | Length: 4.904 | Train rep: 1

Diagnostics -- iteration 510000
real_batch_obs: 1801.00, model_batch_obs: 1808.72
real_batch_act: 189.03, model_batch_act: 193.81
real_batch_rewards: 1307.54, model_batch_rewards: 1303.63
real_batch_dones: 2.00, model_batch_dones: 3.00
evaluation/return-average: 2574.78
total_steps: 510000.00
Q-avg: 1041.14, Q-max: 1434.63, Q-min: -149.94
Q_loss1: 245.31, Q_loss2: 330.38, min_Q_loss1: -139.42, min_Q_loss2: -138.03

Train epoch 510/3000 -- step 511000

[F                                                                                                    
[F[ Model Length ] Epoch: 510 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 510000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 510 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 510510
[ Model Rollout ] Added: 49022 | Model pool: 500000 (max 500000) | Length: 4.9022 | Train rep: 1

Diagnostics -- iteration 511000
real_batch_obs: 1768.50, model_batch_obs: 2017.17
real_batch_act: 191.41, model_batch_act: 190.93
real_batch_rewards: 1286.22, model_batch_rewards: 1355.70
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 1264.32
total_steps: 511000.00
Q-avg: 1078.66, Q-max: 1448.95, Q-min: -303.86
Q_loss1: 508.50, Q_loss2: 473.13, min_Q_loss1: -393.04, min_Q_loss2: -388.84

Train epoch 511/3000 -- step 512000

[F                                                                                                    
[F[ Model Length ] Epoch: 511 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 511000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 511 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 511511
[ Model Rollout ] Added: 49041 | Model pool: 500000 (max 500000) | Length: 4.9041 | Train rep: 1

Diagnostics -- iteration 512000
real_batch_obs: 1688.72, model_batch_obs: 1937.71
real_batch_act: 182.06, model_batch_act: 192.82
real_batch_rewards: 1283.70, model_batch_rewards: 1349.41
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 1385.21
total_steps: 512000.00
Q-avg: 1044.37, Q-max: 1442.90, Q-min: -1033.36
Q_loss1: 441.77, Q_loss2: 547.66, min_Q_loss1: -123.55, min_Q_loss2: -126.69

Train epoch 512/3000 -- step 513000

[F                                                                                                    
[F[ Model Length ] Epoch: 512 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 512000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 512 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 512512
[ Model Rollout ] Added: 49071 | Model pool: 500000 (max 500000) | Length: 4.9071 | Train rep: 1

Diagnostics -- iteration 513000
real_batch_obs: 1829.27, model_batch_obs: 1841.45
real_batch_act: 199.52, model_batch_act: 197.52
real_batch_rewards: 1419.41, model_batch_rewards: 1381.75
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 1926.00
total_steps: 513000.00
Q-avg: 1016.87, Q-max: 1417.14, Q-min: -373.25
Q_loss1: 701.62, Q_loss2: 699.93, min_Q_loss1: -110.59, min_Q_loss2: -112.47

Train epoch 513/3000 -- step 514000

[F                                                                                                    
[F[ Model Length ] Epoch: 513 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 513000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 513 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 513513
[ Model Rollout ] Added: 49045 | Model pool: 500000 (max 500000) | Length: 4.9045 | Train rep: 1

Diagnostics -- iteration 514000
real_batch_obs: 1878.92, model_batch_obs: 1887.36
real_batch_act: 199.19, model_batch_act: 189.58
real_batch_rewards: 1388.48, model_batch_rewards: 1387.54
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 2370.06
total_steps: 514000.00
Q-avg: 1000.31, Q-max: 1437.18, Q-min: -334.54
Q_loss1: 1022.29, Q_loss2: 1286.98, min_Q_loss1: -179.05, min_Q_loss2: -175.05

Train epoch 514/3000 -- step 515000

[F                                                                                                    
[F[ Model Length ] Epoch: 514 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 514000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 514 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 514514
[ Model Rollout ] Added: 49049 | Model pool: 500000 (max 500000) | Length: 4.9049 | Train rep: 1

Diagnostics -- iteration 515000
real_batch_obs: 1931.46, model_batch_obs: 1858.14
real_batch_act: 211.39, model_batch_act: 188.82
real_batch_rewards: 1274.43, model_batch_rewards: 1334.93
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 1207.47
total_steps: 515000.00
Q-avg: 1037.14, Q-max: 1425.57, Q-min: -198.23
Q_loss1: 1525.44, Q_loss2: 1417.60, min_Q_loss1: -524.31, min_Q_loss2: -519.43

Train epoch 515/3000 -- step 516000

[F                                                                                                    
[F[ Model Length ] Epoch: 515 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 515000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 515 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 515515
[ Model Rollout ] Added: 49050 | Model pool: 500000 (max 500000) | Length: 4.905 | Train rep: 1

Diagnostics -- iteration 516000
real_batch_obs: 1903.91, model_batch_obs: 1917.46
real_batch_act: 205.08, model_batch_act: 189.21
real_batch_rewards: 1416.20, model_batch_rewards: 1363.61
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 1091.92
total_steps: 516000.00
Q-avg: 1021.74, Q-max: 1427.22, Q-min: -634.41
Q_loss1: 1830.25, Q_loss2: 1660.59, min_Q_loss1: -310.99, min_Q_loss2: -306.02

Train epoch 516/3000 -- step 517000

[F                                                                                                    
[F[ Model Length ] Epoch: 516 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 516000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 516 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 516516
[ Model Rollout ] Added: 49087 | Model pool: 500000 (max 500000) | Length: 4.9087 | Train rep: 1

Diagnostics -- iteration 517000
real_batch_obs: 1794.88, model_batch_obs: 2029.40
real_batch_act: 194.03, model_batch_act: 203.99
real_batch_rewards: 1308.02, model_batch_rewards: 1370.20
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 1250.66
total_steps: 517000.00
Q-avg: 1038.18, Q-max: 1423.84, Q-min: -78.97
Q_loss1: 995.32, Q_loss2: 917.86, min_Q_loss1: 34.39, min_Q_loss2: 32.37

Train epoch 517/3000 -- step 518000

[F                                                                                                    
[F[ Model Length ] Epoch: 517 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 517000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 517 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 517517
[ Model Rollout ] Added: 48924 | Model pool: 500000 (max 500000) | Length: 4.8924 | Train rep: 1

Diagnostics -- iteration 518000
real_batch_obs: 1798.00, model_batch_obs: 1923.76
real_batch_act: 204.24, model_batch_act: 190.50
real_batch_rewards: 1345.53, model_batch_rewards: 1329.55
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 438.02
total_steps: 518000.00
Q-avg: 1016.63, Q-max: 1447.18, Q-min: -149.34
Q_loss1: 215.09, Q_loss2: 325.85, min_Q_loss1: -96.92, min_Q_loss2: -118.42

Train epoch 518/3000 -- step 519000

[F                                                                                                    
[F[ Model Length ] Epoch: 518 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 518000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 518 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 518518
[ Model Rollout ] Added: 49054 | Model pool: 500000 (max 500000) | Length: 4.9054 | Train rep: 1

Diagnostics -- iteration 519000
real_batch_obs: 1844.40, model_batch_obs: 1855.75
real_batch_act: 195.32, model_batch_act: 193.31
real_batch_rewards: 1324.55, model_batch_rewards: 1327.42
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 352.56
total_steps: 519000.00
Q-avg: 1055.98, Q-max: 1464.75, Q-min: -77.72
Q_loss1: 505.05, Q_loss2: 615.10, min_Q_loss1: -237.04, min_Q_loss2: -238.45

Train epoch 519/3000 -- step 520000

[F                                                                                                    
[F[ Model Length ] Epoch: 519 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 519000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 519 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 519519
[ Model Rollout ] Added: 48944 | Model pool: 500000 (max 500000) | Length: 4.8944 | Train rep: 1

Diagnostics -- iteration 520000
real_batch_obs: 1732.42, model_batch_obs: 2354.62
real_batch_act: 194.06, model_batch_act: 192.18
real_batch_rewards: 1349.88, model_batch_rewards: 3592.89
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 361.31
total_steps: 520000.00
Q-avg: 1020.57, Q-max: 1466.29, Q-min: -1655.62
Q_loss1: 3755.78, Q_loss2: 5852.91, min_Q_loss1: -174.87, min_Q_loss2: -163.12

Train epoch 520/3000 -- step 521000

[F                                                                                                    
[F[ Model Length ] Epoch: 520 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 520000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 520 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 520520
[ Model Rollout ] Added: 49040 | Model pool: 500000 (max 500000) | Length: 4.904 | Train rep: 1

Diagnostics -- iteration 521000
real_batch_obs: 1926.17, model_batch_obs: 1893.58
real_batch_act: 202.36, model_batch_act: 204.02
real_batch_rewards: 1373.84, model_batch_rewards: 1494.34
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 339.11
total_steps: 521000.00
Q-avg: 1028.57, Q-max: 1502.34, Q-min: -966.02
Q_loss1: 923.26, Q_loss2: 1544.00, min_Q_loss1: -507.81, min_Q_loss2: -508.15

Train epoch 521/3000 -- step 522000

[F                                                                                                    
[F[ Model Length ] Epoch: 521 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 521000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 521 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 521521
[ Model Rollout ] Added: 49052 | Model pool: 500000 (max 500000) | Length: 4.9052 | Train rep: 1

Diagnostics -- iteration 522000
real_batch_obs: 1749.64, model_batch_obs: 1955.93
real_batch_act: 198.34, model_batch_act: 188.91
real_batch_rewards: 1309.39, model_batch_rewards: 1286.40
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 336.40
total_steps: 522000.00
Q-avg: 973.19, Q-max: 1488.49, Q-min: -1435.44
Q_loss1: 677.48, Q_loss2: 589.47, min_Q_loss1: -311.96, min_Q_loss2: -306.13

Train epoch 522/3000 -- step 523000

[F                                                                                                    
[F[ Model Length ] Epoch: 522 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 522000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 522 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 522522
[ Model Rollout ] Added: 49041 | Model pool: 500000 (max 500000) | Length: 4.9041 | Train rep: 1

Diagnostics -- iteration 523000
real_batch_obs: 1874.88, model_batch_obs: 1844.27
real_batch_act: 184.50, model_batch_act: 186.76
real_batch_rewards: 1331.65, model_batch_rewards: 1336.21
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 321.45
total_steps: 523000.00
Q-avg: 1048.70, Q-max: 1529.42, Q-min: -737.94
Q_loss1: 926.30, Q_loss2: 1032.20, min_Q_loss1: -213.70, min_Q_loss2: -222.64

Train epoch 523/3000 -- step 524000

[F                                                                                                    
[F[ Model Length ] Epoch: 523 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 523000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 523 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 523523
[ Model Rollout ] Added: 48960 | Model pool: 500000 (max 500000) | Length: 4.896 | Train rep: 1

Diagnostics -- iteration 524000
real_batch_obs: 1841.32, model_batch_obs: 1933.48
real_batch_act: 210.81, model_batch_act: 189.84
real_batch_rewards: 1408.60, model_batch_rewards: 1343.04
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 359.72
total_steps: 524000.00
Q-avg: 1057.26, Q-max: 1583.62, Q-min: -303.01
Q_loss1: 360.34, Q_loss2: 289.99, min_Q_loss1: -235.22, min_Q_loss2: -244.40

Train epoch 524/3000 -- step 525000

[F                                                                                                    
[F[ Model Length ] Epoch: 524 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 524000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 524 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 524524
[ Model Rollout ] Added: 48952 | Model pool: 500000 (max 500000) | Length: 4.8952 | Train rep: 1

Diagnostics -- iteration 525000
real_batch_obs: 1932.86, model_batch_obs: 1815.96
real_batch_act: 205.95, model_batch_act: 181.64
real_batch_rewards: 1392.07, model_batch_rewards: 1295.88
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 356.75
total_steps: 525000.00
Q-avg: 1021.72, Q-max: 1593.56, Q-min: -583.48
Q_loss1: 1792.48, Q_loss2: 1949.58, min_Q_loss1: -288.75, min_Q_loss2: -295.17

Train epoch 525/3000 -- step 526000

[F                                                                                                    
[F[ Model Length ] Epoch: 525 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 525000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 525 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 525525
[ Model Rollout ] Added: 49084 | Model pool: 500000 (max 500000) | Length: 4.9084 | Train rep: 1

Diagnostics -- iteration 526000
real_batch_obs: 1794.99, model_batch_obs: 1929.70
real_batch_act: 187.64, model_batch_act: 196.66
real_batch_rewards: 1311.89, model_batch_rewards: 1352.20
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 273.30
total_steps: 526000.00
Q-avg: 1058.38, Q-max: 1626.32, Q-min: -201.16
Q_loss1: 247.79, Q_loss2: 250.22, min_Q_loss1: -174.48, min_Q_loss2: -165.65

Train epoch 526/3000 -- step 527000

[F                                                                                                    
[F[ Model Length ] Epoch: 526 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 526000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 526 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 526526
[ Model Rollout ] Added: 49108 | Model pool: 500000 (max 500000) | Length: 4.9108 | Train rep: 1

Diagnostics -- iteration 527000
real_batch_obs: 1843.22, model_batch_obs: 1987.84
real_batch_act: 196.65, model_batch_act: 188.28
real_batch_rewards: 1345.23, model_batch_rewards: 1350.51
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 349.83
total_steps: 527000.00
Q-avg: 1038.30, Q-max: 1620.29, Q-min: -1308.10
Q_loss1: 4628.23, Q_loss2: 4718.98, min_Q_loss1: -309.79, min_Q_loss2: -313.65

Train epoch 527/3000 -- step 528000

[F                                                                                                    
[F[ Model Length ] Epoch: 527 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 527000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 527 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 527527
[ Model Rollout ] Added: 49042 | Model pool: 500000 (max 500000) | Length: 4.9042 | Train rep: 1

Diagnostics -- iteration 528000
real_batch_obs: 1881.28, model_batch_obs: 1878.39
real_batch_act: 193.60, model_batch_act: 191.21
real_batch_rewards: 1357.21, model_batch_rewards: 1400.02
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 349.14
total_steps: 528000.00
Q-avg: 1050.09, Q-max: 1680.34, Q-min: -72.91
Q_loss1: 1040.74, Q_loss2: 1080.25, min_Q_loss1: -243.19, min_Q_loss2: -255.76

Train epoch 528/3000 -- step 529000

[F                                                                                                    
[F[ Model Length ] Epoch: 528 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 528000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 528 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 528528
[ Model Rollout ] Added: 49009 | Model pool: 500000 (max 500000) | Length: 4.9009 | Train rep: 1

Diagnostics -- iteration 529000
real_batch_obs: 1733.33, model_batch_obs: 1957.71
real_batch_act: 206.35, model_batch_act: 191.04
real_batch_rewards: 1307.35, model_batch_rewards: 1357.15
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 356.47
total_steps: 529000.00
Q-avg: 1060.04, Q-max: 1632.24, Q-min: -1284.56
Q_loss1: 1045.22, Q_loss2: 797.33, min_Q_loss1: -238.15, min_Q_loss2: -232.81

Train epoch 529/3000 -- step 530000

[F                                                                                                    
[F[ Model Length ] Epoch: 529 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 529000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 529 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 529529
[ Model Rollout ] Added: 49024 | Model pool: 500000 (max 500000) | Length: 4.9024 | Train rep: 1

Diagnostics -- iteration 530000
real_batch_obs: 1771.36, model_batch_obs: 1952.54
real_batch_act: 199.03, model_batch_act: 188.81
real_batch_rewards: 1371.53, model_batch_rewards: 1375.05
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 297.03
total_steps: 530000.00
Q-avg: 1021.86, Q-max: 1620.68, Q-min: -428.91
Q_loss1: 422.94, Q_loss2: 833.42, min_Q_loss1: -265.16, min_Q_loss2: -276.36

Train epoch 530/3000 -- step 531000

[F                                                                                                    
[F[ Model Length ] Epoch: 530 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 530000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 530 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 530530
[ Model Rollout ] Added: 48991 | Model pool: 500000 (max 500000) | Length: 4.8991 | Train rep: 1

Diagnostics -- iteration 531000
real_batch_obs: 1758.09, model_batch_obs: 1844.14
real_batch_act: 190.96, model_batch_act: 190.87
real_batch_rewards: 1386.73, model_batch_rewards: 1377.17
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 262.46
total_steps: 531000.00
Q-avg: 1025.11, Q-max: 1608.81, Q-min: -452.53
Q_loss1: 448.63, Q_loss2: 470.07, min_Q_loss1: -221.61, min_Q_loss2: -224.30

Train epoch 531/3000 -- step 532000

[F                                                                                                    
[F[ Model Length ] Epoch: 531 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 531000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 531 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 531531
[ Model Rollout ] Added: 49037 | Model pool: 500000 (max 500000) | Length: 4.9037 | Train rep: 1

Diagnostics -- iteration 532000
real_batch_obs: 1761.02, model_batch_obs: 1953.57
real_batch_act: 202.07, model_batch_act: 189.81
real_batch_rewards: 1332.80, model_batch_rewards: 1600.94
real_batch_dones: 0.00, model_batch_dones: 5.00
evaluation/return-average: 276.44
total_steps: 532000.00
Q-avg: 1058.22, Q-max: 1614.81, Q-min: -1585.84
Q_loss1: 3899.78, Q_loss2: 2806.75, min_Q_loss1: -277.51, min_Q_loss2: -269.78

Train epoch 532/3000 -- step 533000

[F                                                                                                    
[F[ Model Length ] Epoch: 532 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 532000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 532 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 532532
[ Model Rollout ] Added: 49075 | Model pool: 500000 (max 500000) | Length: 4.9075 | Train rep: 1

Diagnostics -- iteration 533000
real_batch_obs: 1839.87, model_batch_obs: 1999.35
real_batch_act: 201.59, model_batch_act: 186.81
real_batch_rewards: 1376.93, model_batch_rewards: 1399.51
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 304.74
total_steps: 533000.00
Q-avg: 1007.36, Q-max: 1634.08, Q-min: -292.60
Q_loss1: 572.07, Q_loss2: 558.48, min_Q_loss1: -197.77, min_Q_loss2: -199.21

Train epoch 533/3000 -- step 534000

[F                                                                                                    
[F[ Model Length ] Epoch: 533 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 533000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 533 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 533533
[ Model Rollout ] Added: 49026 | Model pool: 500000 (max 500000) | Length: 4.9026 | Train rep: 1

Diagnostics -- iteration 534000
real_batch_obs: 1796.99, model_batch_obs: 1835.82
real_batch_act: 197.31, model_batch_act: 193.66
real_batch_rewards: 1385.34, model_batch_rewards: 1320.96
real_batch_dones: 1.00, model_batch_dones: 5.00
evaluation/return-average: 295.04
total_steps: 534000.00
Q-avg: 1029.96, Q-max: 1576.32, Q-min: -231.07
Q_loss1: 532.23, Q_loss2: 600.55, min_Q_loss1: -415.76, min_Q_loss2: -409.56

Train epoch 534/3000 -- step 535000

[F                                                                                                    
[F[ Model Length ] Epoch: 534 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 534000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 534 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 534534
[ Model Rollout ] Added: 49065 | Model pool: 500000 (max 500000) | Length: 4.9065 | Train rep: 1

Diagnostics -- iteration 535000
real_batch_obs: 1875.58, model_batch_obs: 1905.36
real_batch_act: 193.13, model_batch_act: 200.68
real_batch_rewards: 1349.81, model_batch_rewards: 1341.65
real_batch_dones: 2.00, model_batch_dones: 0.00
evaluation/return-average: 451.75
total_steps: 535000.00
Q-avg: 1011.01, Q-max: 1581.73, Q-min: -694.77
Q_loss1: 863.07, Q_loss2: 915.62, min_Q_loss1: -173.29, min_Q_loss2: -174.56

Train epoch 535/3000 -- step 536000

[F                                                                                                    
[F[ Model Length ] Epoch: 535 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 535000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 535 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 535535
[ Model Rollout ] Added: 49019 | Model pool: 500000 (max 500000) | Length: 4.9019 | Train rep: 1

Diagnostics -- iteration 536000
real_batch_obs: 1858.20, model_batch_obs: 1928.56
real_batch_act: 205.43, model_batch_act: 188.00
real_batch_rewards: 1362.69, model_batch_rewards: 1359.56
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 325.65
total_steps: 536000.00
Q-avg: 1074.06, Q-max: 1560.63, Q-min: 0.30
Q_loss1: 344.30, Q_loss2: 328.16, min_Q_loss1: -230.13, min_Q_loss2: -229.87

Train epoch 536/3000 -- step 537000

[F                                                                                                    
[F[ Model Length ] Epoch: 536 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 536000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 536 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 536536
[ Model Rollout ] Added: 49047 | Model pool: 500000 (max 500000) | Length: 4.9047 | Train rep: 1

Diagnostics -- iteration 537000
real_batch_obs: 1784.06, model_batch_obs: 1877.31
real_batch_act: 188.15, model_batch_act: 189.57
real_batch_rewards: 1361.47, model_batch_rewards: 1335.40
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 317.91
total_steps: 537000.00
Q-avg: 1094.66, Q-max: 1591.52, Q-min: -236.57
Q_loss1: 219.41, Q_loss2: 211.19, min_Q_loss1: -164.40, min_Q_loss2: -163.96

Train epoch 537/3000 -- step 538000

[F                                                                                                    
[F[ Model Length ] Epoch: 537 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 537000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 537 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 537537
[ Model Rollout ] Added: 49061 | Model pool: 500000 (max 500000) | Length: 4.9061 | Train rep: 1

Diagnostics -- iteration 538000
real_batch_obs: 1848.86, model_batch_obs: 1938.89
real_batch_act: 201.90, model_batch_act: 189.94
real_batch_rewards: 1299.12, model_batch_rewards: 1354.76
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 325.20
total_steps: 538000.00
Q-avg: 1061.37, Q-max: 1520.27, Q-min: -323.62
Q_loss1: 780.80, Q_loss2: 807.33, min_Q_loss1: -409.57, min_Q_loss2: -408.23

Train epoch 538/3000 -- step 539000

[F                                                                                                    
[F[ Model Length ] Epoch: 538 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 538000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 538 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 538538
[ Model Rollout ] Added: 49056 | Model pool: 500000 (max 500000) | Length: 4.9056 | Train rep: 1

Diagnostics -- iteration 539000
real_batch_obs: 1816.95, model_batch_obs: 1915.30
real_batch_act: 210.33, model_batch_act: 189.77
real_batch_rewards: 1346.80, model_batch_rewards: 1328.99
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 337.06
total_steps: 539000.00
Q-avg: 1073.92, Q-max: 1520.07, Q-min: -215.40
Q_loss1: 1366.22, Q_loss2: 1341.58, min_Q_loss1: -406.78, min_Q_loss2: -413.63

Train epoch 539/3000 -- step 540000

[F                                                                                                    
[F[ Model Length ] Epoch: 539 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 539000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 539 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 539539
[ Model Rollout ] Added: 48980 | Model pool: 500000 (max 500000) | Length: 4.898 | Train rep: 1

Diagnostics -- iteration 540000
real_batch_obs: 1802.39, model_batch_obs: 1968.65
real_batch_act: 195.55, model_batch_act: 194.35
real_batch_rewards: 1305.41, model_batch_rewards: 1374.40
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 312.37
total_steps: 540000.00
Q-avg: 1020.26, Q-max: 1493.16, Q-min: -1083.87
Q_loss1: 2728.69, Q_loss2: 2375.31, min_Q_loss1: -530.77, min_Q_loss2: -537.69

Train epoch 540/3000 -- step 541000

[F                                                                                                    
[F[ Model Length ] Epoch: 540 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 540000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 540 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 540540
[ Model Rollout ] Added: 49048 | Model pool: 500000 (max 500000) | Length: 4.9048 | Train rep: 1

Diagnostics -- iteration 541000
real_batch_obs: 1787.20, model_batch_obs: 1878.29
real_batch_act: 197.62, model_batch_act: 191.42
real_batch_rewards: 1345.68, model_batch_rewards: 1351.93
real_batch_dones: 0.00, model_batch_dones: 5.00
evaluation/return-average: 436.72
total_steps: 541000.00
Q-avg: 1069.30, Q-max: 1540.34, Q-min: -87.54
Q_loss1: 183.79, Q_loss2: 197.23, min_Q_loss1: -383.46, min_Q_loss2: -378.77

Train epoch 541/3000 -- step 542000

[F                                                                                                    
[F[ Model Length ] Epoch: 541 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 541000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 541 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 541541
[ Model Rollout ] Added: 49081 | Model pool: 500000 (max 500000) | Length: 4.9081 | Train rep: 1

Diagnostics -- iteration 542000
real_batch_obs: 1778.21, model_batch_obs: 1852.88
real_batch_act: 197.81, model_batch_act: 190.25
real_batch_rewards: 1347.52, model_batch_rewards: 1455.04
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 1700.78
total_steps: 542000.00
Q-avg: 1047.89, Q-max: 1516.62, Q-min: -1878.83
Q_loss1: 838.34, Q_loss2: 807.86, min_Q_loss1: -450.88, min_Q_loss2: -460.52

Train epoch 542/3000 -- step 543000

[F                                                                                                    
[F[ Model Length ] Epoch: 542 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 542000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 542 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 542542
[ Model Rollout ] Added: 48991 | Model pool: 500000 (max 500000) | Length: 4.8991 | Train rep: 1

Diagnostics -- iteration 543000
real_batch_obs: 1848.90, model_batch_obs: 1928.56
real_batch_act: 205.12, model_batch_act: 194.02
real_batch_rewards: 1408.12, model_batch_rewards: 1712.18
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 940.76
total_steps: 543000.00
Q-avg: 998.72, Q-max: 1501.22, Q-min: -982.06
Q_loss1: 2195.72, Q_loss2: 2198.49, min_Q_loss1: -154.21, min_Q_loss2: -151.08

Train epoch 543/3000 -- step 544000

[F                                                                                                    
[F[ Model Length ] Epoch: 543 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 543000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 543 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 543543
[ Model Rollout ] Added: 49047 | Model pool: 500000 (max 500000) | Length: 4.9047 | Train rep: 1

Diagnostics -- iteration 544000
real_batch_obs: 1949.62, model_batch_obs: 1861.78
real_batch_act: 207.85, model_batch_act: 194.47
real_batch_rewards: 1368.67, model_batch_rewards: 1340.25
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 1148.78
total_steps: 544000.00
Q-avg: 1033.92, Q-max: 1515.29, Q-min: -482.92
Q_loss1: 943.30, Q_loss2: 962.79, min_Q_loss1: -402.76, min_Q_loss2: -410.88

Train epoch 544/3000 -- step 545000

[F                                                                                                    
[F[ Model Length ] Epoch: 544 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 544000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 544 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 544544
[ Model Rollout ] Added: 48983 | Model pool: 500000 (max 500000) | Length: 4.8983 | Train rep: 1

Diagnostics -- iteration 545000
real_batch_obs: 1774.35, model_batch_obs: 1849.95
real_batch_act: 185.60, model_batch_act: 200.06
real_batch_rewards: 1362.01, model_batch_rewards: 1321.07
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 1031.64
total_steps: 545000.00
Q-avg: 1043.40, Q-max: 1532.92, Q-min: -284.81
Q_loss1: 415.59, Q_loss2: 346.88, min_Q_loss1: -292.74, min_Q_loss2: -301.78

Train epoch 545/3000 -- step 546000

[F                                                                                                    
[F[ Model Length ] Epoch: 545 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 545000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 545 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 545545
[ Model Rollout ] Added: 49025 | Model pool: 500000 (max 500000) | Length: 4.9025 | Train rep: 1

Diagnostics -- iteration 546000
real_batch_obs: 1836.01, model_batch_obs: 1908.61
real_batch_act: 191.05, model_batch_act: 191.34
real_batch_rewards: 1272.34, model_batch_rewards: 1372.81
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 2674.49
total_steps: 546000.00
Q-avg: 1076.07, Q-max: 1540.12, Q-min: -182.38
Q_loss1: 277.95, Q_loss2: 320.34, min_Q_loss1: -378.12, min_Q_loss2: -379.68

Train epoch 546/3000 -- step 547000

[F                                                                                                    
[F[ Model Length ] Epoch: 546 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 546000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 546 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 546546
[ Model Rollout ] Added: 49067 | Model pool: 500000 (max 500000) | Length: 4.9067 | Train rep: 1

Diagnostics -- iteration 547000
real_batch_obs: 1852.50, model_batch_obs: 1893.19
real_batch_act: 201.07, model_batch_act: 177.91
real_batch_rewards: 1400.14, model_batch_rewards: 1380.19
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 1533.24
total_steps: 547000.00
Q-avg: 1049.86, Q-max: 1496.28, Q-min: -1234.69
Q_loss1: 591.82, Q_loss2: 494.71, min_Q_loss1: -106.77, min_Q_loss2: -112.40

Train epoch 547/3000 -- step 548000

[F                                                                                                    
[F[ Model Length ] Epoch: 547 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 547000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 547 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 547547
[ Model Rollout ] Added: 48992 | Model pool: 500000 (max 500000) | Length: 4.8992 | Train rep: 1

Diagnostics -- iteration 548000
real_batch_obs: 1731.50, model_batch_obs: 1867.88
real_batch_act: 192.10, model_batch_act: 185.27
real_batch_rewards: 1323.73, model_batch_rewards: 1301.92
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 1515.62
total_steps: 548000.00
Q-avg: 1063.10, Q-max: 1507.27, Q-min: -784.03
Q_loss1: 428.53, Q_loss2: 375.09, min_Q_loss1: -303.63, min_Q_loss2: -313.03

Train epoch 548/3000 -- step 549000

[F                                                                                                    
[F[ Model Length ] Epoch: 548 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 548000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 548 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 548548
[ Model Rollout ] Added: 49036 | Model pool: 500000 (max 500000) | Length: 4.9036 | Train rep: 1

Diagnostics -- iteration 549000
real_batch_obs: 1933.66, model_batch_obs: 1884.79
real_batch_act: 203.58, model_batch_act: 196.64
real_batch_rewards: 1371.49, model_batch_rewards: 1392.81
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 2301.85
total_steps: 549000.00
Q-avg: 1085.11, Q-max: 1483.18, Q-min: -413.54
Q_loss1: 417.25, Q_loss2: 443.03, min_Q_loss1: -301.76, min_Q_loss2: -301.80

Train epoch 549/3000 -- step 550000

[F                                                                                                    
[F[ Model Length ] Epoch: 549 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 549000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 549 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 549549
[ Model Rollout ] Added: 49118 | Model pool: 500000 (max 500000) | Length: 4.9118 | Train rep: 1

Diagnostics -- iteration 550000
real_batch_obs: 1712.25, model_batch_obs: 2005.84
real_batch_act: 195.66, model_batch_act: 193.89
real_batch_rewards: 1359.59, model_batch_rewards: 1419.02
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 357.23
total_steps: 550000.00
Q-avg: 1036.60, Q-max: 1468.41, Q-min: -1207.62
Q_loss1: 3125.00, Q_loss2: 2521.16, min_Q_loss1: -344.87, min_Q_loss2: -339.75

Train epoch 550/3000 -- step 551000

[F                                                                                                    
[F[ Model Length ] Epoch: 550 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 550000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 550 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 550550
[ Model Rollout ] Added: 48996 | Model pool: 500000 (max 500000) | Length: 4.8996 | Train rep: 1

Diagnostics -- iteration 551000
real_batch_obs: 1773.00, model_batch_obs: 1844.25
real_batch_act: 194.73, model_batch_act: 191.75
real_batch_rewards: 1389.98, model_batch_rewards: 1322.11
real_batch_dones: 1.00, model_batch_dones: 4.00
evaluation/return-average: 1324.56
total_steps: 551000.00
Q-avg: 1027.01, Q-max: 1454.54, Q-min: -715.30
Q_loss1: 956.13, Q_loss2: 1182.23, min_Q_loss1: -123.96, min_Q_loss2: -130.56

Train epoch 551/3000 -- step 552000

[F                                                                                                    
[F[ Model Length ] Epoch: 551 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 551000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 551 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 551551
[ Model Rollout ] Added: 49011 | Model pool: 500000 (max 500000) | Length: 4.9011 | Train rep: 1

Diagnostics -- iteration 552000
real_batch_obs: 1806.24, model_batch_obs: 1913.43
real_batch_act: 189.78, model_batch_act: 190.56
real_batch_rewards: 1285.66, model_batch_rewards: 1327.07
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 2167.39
total_steps: 552000.00
Q-avg: 1046.58, Q-max: 1436.68, Q-min: -640.07
Q_loss1: 35011.87, Q_loss2: 33586.93, min_Q_loss1: -399.07, min_Q_loss2: -401.37

Train epoch 552/3000 -- step 553000

[F                                                                                                    
[F[ Model Length ] Epoch: 552 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 552000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 552 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 552552
[ Model Rollout ] Added: 48966 | Model pool: 500000 (max 500000) | Length: 4.8966 | Train rep: 1

Diagnostics -- iteration 553000
real_batch_obs: 1843.39, model_batch_obs: 1928.32
real_batch_act: 196.03, model_batch_act: 189.25
real_batch_rewards: 1360.82, model_batch_rewards: 1300.42
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 2046.65
total_steps: 553000.00
Q-avg: 1056.84, Q-max: 1441.03, Q-min: -611.94
Q_loss1: 421.90, Q_loss2: 330.90, min_Q_loss1: -304.08, min_Q_loss2: -305.53

Train epoch 553/3000 -- step 554000

[F                                                                                                    
[F[ Model Length ] Epoch: 553 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 553000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 553 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 553553
[ Model Rollout ] Added: 48983 | Model pool: 500000 (max 500000) | Length: 4.8983 | Train rep: 1

Diagnostics -- iteration 554000
real_batch_obs: 1773.82, model_batch_obs: 1884.65
real_batch_act: 193.52, model_batch_act: 186.46
real_batch_rewards: 1363.26, model_batch_rewards: 1320.80
real_batch_dones: 3.00, model_batch_dones: 0.00
evaluation/return-average: 308.96
total_steps: 554000.00
Q-avg: 1036.11, Q-max: 1440.56, Q-min: -157.33
Q_loss1: 644.53, Q_loss2: 693.80, min_Q_loss1: -10.04, min_Q_loss2: 2.97

Train epoch 554/3000 -- step 555000

[F                                                                                                    
[F[ Model Length ] Epoch: 554 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 554000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 554 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 554554
[ Model Rollout ] Added: 49094 | Model pool: 500000 (max 500000) | Length: 4.9094 | Train rep: 1

Diagnostics -- iteration 555000
real_batch_obs: 1900.77, model_batch_obs: 1853.19
real_batch_act: 197.57, model_batch_act: 195.10
real_batch_rewards: 1348.35, model_batch_rewards: 1335.71
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 306.52
total_steps: 555000.00
Q-avg: 1021.94, Q-max: 1543.99, Q-min: -158.11
Q_loss1: 214.78, Q_loss2: 255.70, min_Q_loss1: -268.20, min_Q_loss2: -269.39

Train epoch 555/3000 -- step 556000

[F                                                                                                    
[F[ Model Length ] Epoch: 555 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 555000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 555 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 555555
[ Model Rollout ] Added: 49079 | Model pool: 500000 (max 500000) | Length: 4.9079 | Train rep: 1

Diagnostics -- iteration 556000
real_batch_obs: 1806.82, model_batch_obs: 1788.80
real_batch_act: 202.98, model_batch_act: 189.23
real_batch_rewards: 1281.77, model_batch_rewards: 1360.90
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 324.33
total_steps: 556000.00
Q-avg: 1067.47, Q-max: 1434.60, Q-min: -716.22
Q_loss1: 2814.74, Q_loss2: 3509.59, min_Q_loss1: -188.58, min_Q_loss2: -190.79

Train epoch 556/3000 -- step 557000

[F                                                                                                    
[F[ Model Length ] Epoch: 556 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 556000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 556 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 556556
[ Model Rollout ] Added: 48990 | Model pool: 500000 (max 500000) | Length: 4.899 | Train rep: 1

Diagnostics -- iteration 557000
real_batch_obs: 1881.35, model_batch_obs: 1978.82
real_batch_act: 194.36, model_batch_act: 192.87
real_batch_rewards: 1342.80, model_batch_rewards: 1382.00
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 333.62
total_steps: 557000.00
Q-avg: 1066.41, Q-max: 1483.85, Q-min: -396.21
Q_loss1: 661.27, Q_loss2: 492.49, min_Q_loss1: -244.06, min_Q_loss2: -244.99

Train epoch 557/3000 -- step 558000

[F                                                                                                    
[F[ Model Length ] Epoch: 557 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 557000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 557 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 557557
[ Model Rollout ] Added: 49099 | Model pool: 500000 (max 500000) | Length: 4.9099 | Train rep: 1

Diagnostics -- iteration 558000
real_batch_obs: 1783.96, model_batch_obs: 1902.89
real_batch_act: 196.71, model_batch_act: 191.51
real_batch_rewards: 1224.88, model_batch_rewards: 1291.10
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 334.97
total_steps: 558000.00
Q-avg: 1047.23, Q-max: 1457.95, Q-min: -110.80
Q_loss1: 237.47, Q_loss2: 226.98, min_Q_loss1: -437.98, min_Q_loss2: -432.44

Train epoch 558/3000 -- step 559000

[F                                                                                                    
[F[ Model Length ] Epoch: 558 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 558000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 558 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 558558
[ Model Rollout ] Added: 49050 | Model pool: 500000 (max 500000) | Length: 4.905 | Train rep: 1

Diagnostics -- iteration 559000
real_batch_obs: 1879.46, model_batch_obs: 1963.31
real_batch_act: 208.79, model_batch_act: 198.27
real_batch_rewards: 1348.84, model_batch_rewards: 1421.82
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 316.67
total_steps: 559000.00
Q-avg: 1033.64, Q-max: 1504.75, Q-min: -158.25
Q_loss1: 231.77, Q_loss2: 367.26, min_Q_loss1: -353.83, min_Q_loss2: -354.73

Train epoch 559/3000 -- step 560000

[F                                                                                                    
[F[ Model Length ] Epoch: 559 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 559000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 559 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 559559
[ Model Rollout ] Added: 49022 | Model pool: 500000 (max 500000) | Length: 4.9022 | Train rep: 1

Diagnostics -- iteration 560000
real_batch_obs: 1753.15, model_batch_obs: 1934.66
real_batch_act: 195.33, model_batch_act: 193.39
real_batch_rewards: 1336.50, model_batch_rewards: 1379.10
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 347.47
total_steps: 560000.00
Q-avg: 1011.51, Q-max: 1473.90, Q-min: -233.08
Q_loss1: 737.09, Q_loss2: 1152.52, min_Q_loss1: -140.41, min_Q_loss2: -129.76

Train epoch 560/3000 -- step 561000

[F                                                                                                    
[F[ Model Length ] Epoch: 560 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 560000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 560 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 560560
[ Model Rollout ] Added: 49067 | Model pool: 500000 (max 500000) | Length: 4.9067 | Train rep: 1

Diagnostics -- iteration 561000
real_batch_obs: 1900.52, model_batch_obs: 1829.73
real_batch_act: 204.14, model_batch_act: 195.83
real_batch_rewards: 1392.33, model_batch_rewards: 1594.88
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 378.22
total_steps: 561000.00
Q-avg: 1045.71, Q-max: 1480.58, Q-min: -1291.25
Q_loss1: 22246.09, Q_loss2: 24053.84, min_Q_loss1: -238.98, min_Q_loss2: -227.98

Train epoch 561/3000 -- step 562000

[F                                                                                                    
[F[ Model Length ] Epoch: 561 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 561000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 561 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 561561
[ Model Rollout ] Added: 49023 | Model pool: 500000 (max 500000) | Length: 4.9023 | Train rep: 1

Diagnostics -- iteration 562000
real_batch_obs: 1826.43, model_batch_obs: 1802.63
real_batch_act: 191.97, model_batch_act: 192.72
real_batch_rewards: 1382.60, model_batch_rewards: 1285.11
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 351.84
total_steps: 562000.00
Q-avg: 1028.81, Q-max: 1497.77, Q-min: -409.52
Q_loss1: 191.62, Q_loss2: 159.95, min_Q_loss1: -211.99, min_Q_loss2: -204.84

Train epoch 562/3000 -- step 563000

[F                                                                                                    
[F[ Model Length ] Epoch: 562 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 562000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 562 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 562562
[ Model Rollout ] Added: 49010 | Model pool: 500000 (max 500000) | Length: 4.901 | Train rep: 1

Diagnostics -- iteration 563000
real_batch_obs: 1744.41, model_batch_obs: 1940.04
real_batch_act: 185.09, model_batch_act: 187.63
real_batch_rewards: 1300.38, model_batch_rewards: 1342.14
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 344.23
total_steps: 563000.00
Q-avg: 1058.71, Q-max: 1489.88, Q-min: -347.66
Q_loss1: 257.57, Q_loss2: 338.53, min_Q_loss1: -257.09, min_Q_loss2: -261.84

Train epoch 563/3000 -- step 564000

[F                                                                                                    
[F[ Model Length ] Epoch: 563 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 563000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 563 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 563563
[ Model Rollout ] Added: 49008 | Model pool: 500000 (max 500000) | Length: 4.9008 | Train rep: 1

Diagnostics -- iteration 564000
real_batch_obs: 1778.95, model_batch_obs: 1906.13
real_batch_act: 204.74, model_batch_act: 192.97
real_batch_rewards: 1285.16, model_batch_rewards: 1288.97
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 365.21
total_steps: 564000.00
Q-avg: 1032.31, Q-max: 1524.67, Q-min: -761.95
Q_loss1: 1620.99, Q_loss2: 1407.81, min_Q_loss1: -410.78, min_Q_loss2: -398.12

Train epoch 564/3000 -- step 565000

[F                                                                                                    
[F[ Model Length ] Epoch: 564 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 564000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 564 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 564564
[ Model Rollout ] Added: 49072 | Model pool: 500000 (max 500000) | Length: 4.9072 | Train rep: 1

Diagnostics -- iteration 565000
real_batch_obs: 1751.84, model_batch_obs: 1945.25
real_batch_act: 203.95, model_batch_act: 193.90
real_batch_rewards: 1318.03, model_batch_rewards: 1401.59
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 344.22
total_steps: 565000.00
Q-avg: 1018.19, Q-max: 1540.49, Q-min: -307.89
Q_loss1: 129.21, Q_loss2: 120.07, min_Q_loss1: -372.50, min_Q_loss2: -375.14

Train epoch 565/3000 -- step 566000

[F                                                                                                    
[F[ Model Length ] Epoch: 565 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 565000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 565 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 565565
[ Model Rollout ] Added: 48986 | Model pool: 500000 (max 500000) | Length: 4.8986 | Train rep: 1

Diagnostics -- iteration 566000
real_batch_obs: 1814.36, model_batch_obs: 1927.06
real_batch_act: 195.68, model_batch_act: 182.78
real_batch_rewards: 1342.69, model_batch_rewards: 1419.60
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 340.88
total_steps: 566000.00
Q-avg: 1030.14, Q-max: 1563.74, Q-min: -540.26
Q_loss1: 865.97, Q_loss2: 886.67, min_Q_loss1: -308.26, min_Q_loss2: -302.05

Train epoch 566/3000 -- step 567000

[F                                                                                                    
[F[ Model Length ] Epoch: 566 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 566000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 566 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 566566
[ Model Rollout ] Added: 49055 | Model pool: 500000 (max 500000) | Length: 4.9055 | Train rep: 1

Diagnostics -- iteration 567000
real_batch_obs: 1930.60, model_batch_obs: 1841.39
real_batch_act: 208.35, model_batch_act: 193.51
real_batch_rewards: 1467.94, model_batch_rewards: 1333.34
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 355.75
total_steps: 567000.00
Q-avg: 1038.31, Q-max: 1561.04, Q-min: -178.27
Q_loss1: 282.05, Q_loss2: 253.98, min_Q_loss1: -67.45, min_Q_loss2: -72.31

Train epoch 567/3000 -- step 568000

[F                                                                                                    
[F[ Model Length ] Epoch: 567 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 567000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 567 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 567567
[ Model Rollout ] Added: 49097 | Model pool: 500000 (max 500000) | Length: 4.9097 | Train rep: 1

Diagnostics -- iteration 568000
real_batch_obs: 1783.64, model_batch_obs: 1903.83
real_batch_act: 195.50, model_batch_act: 187.56
real_batch_rewards: 1326.72, model_batch_rewards: 1341.36
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 355.14
total_steps: 568000.00
Q-avg: 1038.32, Q-max: 1640.86, Q-min: -754.83
Q_loss1: 378.44, Q_loss2: 322.24, min_Q_loss1: -497.29, min_Q_loss2: -490.40

Train epoch 568/3000 -- step 569000

[F                                                                                                    
[F[ Model Length ] Epoch: 568 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 568000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 568 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 568568
[ Model Rollout ] Added: 49069 | Model pool: 500000 (max 500000) | Length: 4.9069 | Train rep: 1

Diagnostics -- iteration 569000
real_batch_obs: 1824.46, model_batch_obs: 1952.22
real_batch_act: 205.93, model_batch_act: 194.40
real_batch_rewards: 1315.42, model_batch_rewards: 1362.32
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 357.54
total_steps: 569000.00
Q-avg: 1006.86, Q-max: 1630.78, Q-min: -1770.41
Q_loss1: 5329.41, Q_loss2: 5176.65, min_Q_loss1: -439.54, min_Q_loss2: -439.91

Train epoch 569/3000 -- step 570000

[F                                                                                                    
[F[ Model Length ] Epoch: 569 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 569000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 569 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 569569
[ Model Rollout ] Added: 48990 | Model pool: 500000 (max 500000) | Length: 4.899 | Train rep: 1

Diagnostics -- iteration 570000
real_batch_obs: 1829.17, model_batch_obs: 1863.80
real_batch_act: 189.40, model_batch_act: 196.88
real_batch_rewards: 1311.52, model_batch_rewards: 2033.71
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 352.40
total_steps: 570000.00
Q-avg: 1065.24, Q-max: 1610.60, Q-min: -811.26
Q_loss1: 948.34, Q_loss2: 953.90, min_Q_loss1: -404.29, min_Q_loss2: -397.59

Train epoch 570/3000 -- step 571000

[F                                                                                                    
[F[ Model Length ] Epoch: 570 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 570000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 570 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 570570
[ Model Rollout ] Added: 49074 | Model pool: 500000 (max 500000) | Length: 4.9074 | Train rep: 1

Diagnostics -- iteration 571000
real_batch_obs: 1849.47, model_batch_obs: 1890.13
real_batch_act: 201.63, model_batch_act: 182.66
real_batch_rewards: 1390.83, model_batch_rewards: 1263.85
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 325.45
total_steps: 571000.00
Q-avg: 1053.65, Q-max: 1569.31, Q-min: -236.73
Q_loss1: 694.22, Q_loss2: 712.18, min_Q_loss1: -166.12, min_Q_loss2: -164.07

Train epoch 571/3000 -- step 572000

[F                                                                                                    
[F[ Model Length ] Epoch: 571 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 571000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 571 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 571571
[ Model Rollout ] Added: 49037 | Model pool: 500000 (max 500000) | Length: 4.9037 | Train rep: 1

Diagnostics -- iteration 572000
real_batch_obs: 1899.55, model_batch_obs: 1931.42
real_batch_act: 192.46, model_batch_act: 207.08
real_batch_rewards: 1349.90, model_batch_rewards: 1329.45
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 356.34
total_steps: 572000.00
Q-avg: 1120.66, Q-max: 1586.05, Q-min: -100.32
Q_loss1: 615.03, Q_loss2: 543.68, min_Q_loss1: -230.35, min_Q_loss2: -228.39

Train epoch 572/3000 -- step 573000

[F                                                                                                    
[F[ Model Length ] Epoch: 572 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 572000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 572 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 572572
[ Model Rollout ] Added: 49056 | Model pool: 500000 (max 500000) | Length: 4.9056 | Train rep: 1

Diagnostics -- iteration 573000
real_batch_obs: 1855.95, model_batch_obs: 1861.92
real_batch_act: 196.58, model_batch_act: 185.45
real_batch_rewards: 1294.81, model_batch_rewards: 1383.32
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 333.00
total_steps: 573000.00
Q-avg: 1063.16, Q-max: 1552.01, Q-min: -859.23
Q_loss1: 2380.52, Q_loss2: 3725.47, min_Q_loss1: -622.43, min_Q_loss2: -611.40

Train epoch 573/3000 -- step 574000

[F                                                                                                    
[F[ Model Length ] Epoch: 573 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 573000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 573 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 573573
[ Model Rollout ] Added: 48998 | Model pool: 500000 (max 500000) | Length: 4.8998 | Train rep: 1

Diagnostics -- iteration 574000
real_batch_obs: 1822.64, model_batch_obs: 1904.71
real_batch_act: 199.15, model_batch_act: 188.13
real_batch_rewards: 1290.78, model_batch_rewards: 1317.00
real_batch_dones: 0.00, model_batch_dones: 5.00
evaluation/return-average: 333.14
total_steps: 574000.00
Q-avg: 1094.19, Q-max: 1552.27, Q-min: -379.26
Q_loss1: 1078.03, Q_loss2: 1169.85, min_Q_loss1: -356.10, min_Q_loss2: -361.08

Train epoch 574/3000 -- step 575000

[F                                                                                                    
[F[ Model Length ] Epoch: 574 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 574000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 574 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 574574
[ Model Rollout ] Added: 48936 | Model pool: 500000 (max 500000) | Length: 4.8936 | Train rep: 1

Diagnostics -- iteration 575000
real_batch_obs: 1775.99, model_batch_obs: 1875.17
real_batch_act: 198.69, model_batch_act: 184.68
real_batch_rewards: 1324.80, model_batch_rewards: 1317.81
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 362.63
total_steps: 575000.00
Q-avg: 1008.31, Q-max: 1527.19, Q-min: -674.64
Q_loss1: 1840.65, Q_loss2: 1726.60, min_Q_loss1: -391.79, min_Q_loss2: -391.63

Train epoch 575/3000 -- step 576000

[F                                                                                                    
[F[ Model Length ] Epoch: 575 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 575000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 575 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 575575
[ Model Rollout ] Added: 48949 | Model pool: 500000 (max 500000) | Length: 4.8949 | Train rep: 1

Diagnostics -- iteration 576000
real_batch_obs: 1758.99, model_batch_obs: 1899.27
real_batch_act: 192.01, model_batch_act: 197.62
real_batch_rewards: 1303.34, model_batch_rewards: 1399.49
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 338.53
total_steps: 576000.00
Q-avg: 1088.64, Q-max: 1499.54, Q-min: -21.12
Q_loss1: 192.72, Q_loss2: 221.11, min_Q_loss1: -97.57, min_Q_loss2: -94.33

Train epoch 576/3000 -- step 577000

[F                                                                                                    
[F[ Model Length ] Epoch: 576 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 576000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 576 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 576576
[ Model Rollout ] Added: 48966 | Model pool: 500000 (max 500000) | Length: 4.8966 | Train rep: 1

Diagnostics -- iteration 577000
real_batch_obs: 1840.67, model_batch_obs: 1799.87
real_batch_act: 204.58, model_batch_act: 196.55
real_batch_rewards: 1335.37, model_batch_rewards: 1298.14
real_batch_dones: 2.00, model_batch_dones: 0.00
evaluation/return-average: 354.06
total_steps: 577000.00
Q-avg: 1114.79, Q-max: 1498.86, Q-min: -283.52
Q_loss1: 433.26, Q_loss2: 381.63, min_Q_loss1: 99.93, min_Q_loss2: 101.12

Train epoch 577/3000 -- step 578000

[F                                                                                                    
[F[ Model Length ] Epoch: 577 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 577000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 577 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 577577
[ Model Rollout ] Added: 49120 | Model pool: 500000 (max 500000) | Length: 4.912 | Train rep: 1

Diagnostics -- iteration 578000
real_batch_obs: 1938.67, model_batch_obs: 1927.61
real_batch_act: 196.09, model_batch_act: 191.59
real_batch_rewards: 1357.98, model_batch_rewards: 1354.52
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 563.30
total_steps: 578000.00
Q-avg: 1062.51, Q-max: 1470.78, Q-min: -755.09
Q_loss1: 565.54, Q_loss2: 458.86, min_Q_loss1: -419.97, min_Q_loss2: -428.77

Train epoch 578/3000 -- step 579000

[F                                                                                                    
[F[ Model Length ] Epoch: 578 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 578000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 578 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 578578
[ Model Rollout ] Added: 49042 | Model pool: 500000 (max 500000) | Length: 4.9042 | Train rep: 1

Diagnostics -- iteration 579000
real_batch_obs: 1893.36, model_batch_obs: 1932.27
real_batch_act: 199.77, model_batch_act: 191.61
real_batch_rewards: 1371.95, model_batch_rewards: 1370.67
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 298.57
total_steps: 579000.00
Q-avg: 1049.82, Q-max: 1454.61, Q-min: -814.42
Q_loss1: 3129.65, Q_loss2: 3025.56, min_Q_loss1: -229.70, min_Q_loss2: -230.16

Train epoch 579/3000 -- step 580000

[F                                                                                                    
[F[ Model Length ] Epoch: 579 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 579000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 579 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 579579
[ Model Rollout ] Added: 49111 | Model pool: 500000 (max 500000) | Length: 4.9111 | Train rep: 1

Diagnostics -- iteration 580000
real_batch_obs: 1913.90, model_batch_obs: 1886.99
real_batch_act: 194.48, model_batch_act: 192.20
real_batch_rewards: 1429.23, model_batch_rewards: 1423.77
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 304.03
total_steps: 580000.00
Q-avg: 1067.01, Q-max: 1477.10, Q-min: -737.20
Q_loss1: 857.06, Q_loss2: 657.76, min_Q_loss1: -161.21, min_Q_loss2: -156.70

Train epoch 580/3000 -- step 581000

[F                                                                                                    
[F[ Model Length ] Epoch: 580 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 580000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 580 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 580580
[ Model Rollout ] Added: 49036 | Model pool: 500000 (max 500000) | Length: 4.9036 | Train rep: 1

Diagnostics -- iteration 581000
real_batch_obs: 1872.45, model_batch_obs: 1946.35
real_batch_act: 193.50, model_batch_act: 182.92
real_batch_rewards: 1325.42, model_batch_rewards: 1340.85
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 775.87
total_steps: 581000.00
Q-avg: 1071.22, Q-max: 1495.09, Q-min: -971.51
Q_loss1: 2423.07, Q_loss2: 2430.00, min_Q_loss1: -276.16, min_Q_loss2: -274.89

Train epoch 581/3000 -- step 582000

[F                                                                                                    
[F[ Model Length ] Epoch: 581 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 581000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 581 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 581581
[ Model Rollout ] Added: 49005 | Model pool: 500000 (max 500000) | Length: 4.9005 | Train rep: 1

Diagnostics -- iteration 582000
real_batch_obs: 1890.95, model_batch_obs: 1802.44
real_batch_act: 186.41, model_batch_act: 195.92
real_batch_rewards: 1357.14, model_batch_rewards: 1254.76
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 1330.58
total_steps: 582000.00
Q-avg: 1048.51, Q-max: 1469.50, Q-min: -674.43
Q_loss1: 1845.18, Q_loss2: 2075.58, min_Q_loss1: -39.18, min_Q_loss2: -38.83

Train epoch 582/3000 -- step 583000

[F                                                                                                    
[F[ Model Length ] Epoch: 582 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 582000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 582 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 582582
[ Model Rollout ] Added: 49049 | Model pool: 500000 (max 500000) | Length: 4.9049 | Train rep: 1

Diagnostics -- iteration 583000
real_batch_obs: 1854.12, model_batch_obs: 1939.69
real_batch_act: 192.77, model_batch_act: 198.05
real_batch_rewards: 1427.95, model_batch_rewards: 1366.54
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 1034.37
total_steps: 583000.00
Q-avg: 1033.60, Q-max: 1481.35, Q-min: -522.04
Q_loss1: 739.72, Q_loss2: 806.79, min_Q_loss1: -154.63, min_Q_loss2: -165.76

Train epoch 583/3000 -- step 584000

[F                                                                                                    
[F[ Model Length ] Epoch: 583 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 583000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 583 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 583583
[ Model Rollout ] Added: 48975 | Model pool: 500000 (max 500000) | Length: 4.8975 | Train rep: 1

Diagnostics -- iteration 584000
real_batch_obs: 1832.50, model_batch_obs: 1938.42
real_batch_act: 192.59, model_batch_act: 194.64
real_batch_rewards: 1276.67, model_batch_rewards: 1310.62
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 992.35
total_steps: 584000.00
Q-avg: 1069.93, Q-max: 1492.39, Q-min: -174.44
Q_loss1: 441.30, Q_loss2: 432.12, min_Q_loss1: -352.81, min_Q_loss2: -349.81

Train epoch 584/3000 -- step 585000

[F                                                                                                    
[F[ Model Length ] Epoch: 584 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 584000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 584 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 584584
[ Model Rollout ] Added: 49053 | Model pool: 500000 (max 500000) | Length: 4.9053 | Train rep: 1

Diagnostics -- iteration 585000
real_batch_obs: 1845.74, model_batch_obs: 1896.35
real_batch_act: 196.94, model_batch_act: 197.38
real_batch_rewards: 1327.83, model_batch_rewards: 1343.71
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 1153.35
total_steps: 585000.00
Q-avg: 1044.44, Q-max: 1484.51, Q-min: -419.20
Q_loss1: 2744.54, Q_loss2: 2539.16, min_Q_loss1: -190.02, min_Q_loss2: -194.51

Train epoch 585/3000 -- step 586000

[F                                                                                                    
[F[ Model Length ] Epoch: 585 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 585000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 585 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 585585
[ Model Rollout ] Added: 49003 | Model pool: 500000 (max 500000) | Length: 4.9003 | Train rep: 1

Diagnostics -- iteration 586000
real_batch_obs: 1787.78, model_batch_obs: 1925.15
real_batch_act: 193.18, model_batch_act: 191.54
real_batch_rewards: 1322.36, model_batch_rewards: 1389.18
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 1622.62
total_steps: 586000.00
Q-avg: 1035.85, Q-max: 1470.94, Q-min: -1283.84
Q_loss1: 1091.00, Q_loss2: 1072.98, min_Q_loss1: -583.93, min_Q_loss2: -584.80

Train epoch 586/3000 -- step 587000

[F                                                                                                    
[F[ Model Length ] Epoch: 586 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 586000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 586 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 586586
[ Model Rollout ] Added: 48934 | Model pool: 500000 (max 500000) | Length: 4.8934 | Train rep: 1

Diagnostics -- iteration 587000
real_batch_obs: 1910.18, model_batch_obs: 1896.83
real_batch_act: 193.67, model_batch_act: 177.38
real_batch_rewards: 1356.48, model_batch_rewards: 1340.75
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 1569.42
total_steps: 587000.00
Q-avg: 1067.07, Q-max: 1473.49, Q-min: -721.82
Q_loss1: 1593.45, Q_loss2: 1707.56, min_Q_loss1: -128.15, min_Q_loss2: -122.96

Train epoch 587/3000 -- step 588000

[F                                                                                                    
[F[ Model Length ] Epoch: 587 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 587000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 587 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 587587
[ Model Rollout ] Added: 49081 | Model pool: 500000 (max 500000) | Length: 4.9081 | Train rep: 1

Diagnostics -- iteration 588000
real_batch_obs: 1799.06, model_batch_obs: 1899.81
real_batch_act: 197.66, model_batch_act: 193.67
real_batch_rewards: 1330.57, model_batch_rewards: 1338.81
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 430.62
total_steps: 588000.00
Q-avg: 1058.81, Q-max: 1465.75, Q-min: -488.63
Q_loss1: 596.28, Q_loss2: 583.39, min_Q_loss1: -255.64, min_Q_loss2: -253.00

Train epoch 588/3000 -- step 589000

[F                                                                                                    
[F[ Model Length ] Epoch: 588 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 588000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 588 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 588588
[ Model Rollout ] Added: 48959 | Model pool: 500000 (max 500000) | Length: 4.8959 | Train rep: 1

Diagnostics -- iteration 589000
real_batch_obs: 1882.84, model_batch_obs: 1936.83
real_batch_act: 202.76, model_batch_act: 188.89
real_batch_rewards: 1403.92, model_batch_rewards: 1349.61
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 1269.88
total_steps: 589000.00
Q-avg: 1075.85, Q-max: 1480.83, Q-min: -50.34
Q_loss1: 464.47, Q_loss2: 357.96, min_Q_loss1: -397.48, min_Q_loss2: -394.43

Train epoch 589/3000 -- step 590000

[F                                                                                                    
[F[ Model Length ] Epoch: 589 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 589000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 589 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 589589
[ Model Rollout ] Added: 49108 | Model pool: 500000 (max 500000) | Length: 4.9108 | Train rep: 1

Diagnostics -- iteration 590000
real_batch_obs: 1857.80, model_batch_obs: 1853.98
real_batch_act: 207.26, model_batch_act: 182.97
real_batch_rewards: 1375.62, model_batch_rewards: 1350.54
real_batch_dones: 2.00, model_batch_dones: 1.00
evaluation/return-average: 1052.13
total_steps: 590000.00
Q-avg: 1032.61, Q-max: 1490.94, Q-min: -184.07
Q_loss1: 5564.48, Q_loss2: 5308.55, min_Q_loss1: -265.21, min_Q_loss2: -263.75

Train epoch 590/3000 -- step 591000

[F                                                                                                    
[F[ Model Length ] Epoch: 590 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 590000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 590 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 590590
[ Model Rollout ] Added: 49032 | Model pool: 500000 (max 500000) | Length: 4.9032 | Train rep: 1

Diagnostics -- iteration 591000
real_batch_obs: 1815.82, model_batch_obs: 1920.18
real_batch_act: 201.37, model_batch_act: 186.21
real_batch_rewards: 1302.96, model_batch_rewards: 1381.19
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 731.13
total_steps: 591000.00
Q-avg: 1070.16, Q-max: 1520.05, Q-min: -1803.29
Q_loss1: 584.55, Q_loss2: 514.60, min_Q_loss1: -243.75, min_Q_loss2: -241.65

Train epoch 591/3000 -- step 592000

[F                                                                                                    
[F[ Model Length ] Epoch: 591 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 591000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 591 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 591591
[ Model Rollout ] Added: 49052 | Model pool: 500000 (max 500000) | Length: 4.9052 | Train rep: 1

Diagnostics -- iteration 592000
real_batch_obs: 1871.56, model_batch_obs: 1910.42
real_batch_act: 199.94, model_batch_act: 194.31
real_batch_rewards: 1287.04, model_batch_rewards: 1375.34
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 865.64
total_steps: 592000.00
Q-avg: 1038.11, Q-max: 1514.81, Q-min: -799.36
Q_loss1: 1143.64, Q_loss2: 1324.70, min_Q_loss1: -423.18, min_Q_loss2: -421.55

Train epoch 592/3000 -- step 593000

[F                                                                                                    
[F[ Model Length ] Epoch: 592 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 592000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 592 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 592592
[ Model Rollout ] Added: 49079 | Model pool: 500000 (max 500000) | Length: 4.9079 | Train rep: 1

Diagnostics -- iteration 593000
real_batch_obs: 1855.54, model_batch_obs: 1885.64
real_batch_act: 191.22, model_batch_act: 198.52
real_batch_rewards: 1309.15, model_batch_rewards: 1342.25
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 423.72
total_steps: 593000.00
Q-avg: 1045.54, Q-max: 1493.15, Q-min: -431.73
Q_loss1: 278.16, Q_loss2: 196.63, min_Q_loss1: -325.99, min_Q_loss2: -336.52

Train epoch 593/3000 -- step 594000

[F                                                                                                    
[F[ Model Length ] Epoch: 593 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 593000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 593 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 593593
[ Model Rollout ] Added: 49066 | Model pool: 500000 (max 500000) | Length: 4.9066 | Train rep: 1

Diagnostics -- iteration 594000
real_batch_obs: 1733.85, model_batch_obs: 1859.73
real_batch_act: 192.12, model_batch_act: 190.73
real_batch_rewards: 1316.14, model_batch_rewards: 1287.82
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 346.80
total_steps: 594000.00
Q-avg: 1056.39, Q-max: 1547.38, Q-min: -136.35
Q_loss1: 2854.18, Q_loss2: 2409.58, min_Q_loss1: -468.60, min_Q_loss2: -462.07

Train epoch 594/3000 -- step 595000

[F                                                                                                    
[F[ Model Length ] Epoch: 594 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 594000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 594 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 594594
[ Model Rollout ] Added: 49124 | Model pool: 500000 (max 500000) | Length: 4.9124 | Train rep: 1

Diagnostics -- iteration 595000
real_batch_obs: 1768.88, model_batch_obs: 1941.90
real_batch_act: 193.71, model_batch_act: 191.16
real_batch_rewards: 1309.11, model_batch_rewards: 1333.77
real_batch_dones: 2.00, model_batch_dones: 2.00
evaluation/return-average: 360.95
total_steps: 595000.00
Q-avg: 1045.00, Q-max: 1508.55, Q-min: -835.24
Q_loss1: 936.77, Q_loss2: 1129.85, min_Q_loss1: -373.22, min_Q_loss2: -384.82

Train epoch 595/3000 -- step 596000

[F                                                                                                    
[F[ Model Length ] Epoch: 595 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 595000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 595 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 595595
[ Model Rollout ] Added: 49008 | Model pool: 500000 (max 500000) | Length: 4.9008 | Train rep: 1

Diagnostics -- iteration 596000
real_batch_obs: 1755.54, model_batch_obs: 1870.58
real_batch_act: 205.47, model_batch_act: 193.55
real_batch_rewards: 1297.78, model_batch_rewards: 1378.14
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 334.68
total_steps: 596000.00
Q-avg: 1067.12, Q-max: 1536.92, Q-min: -178.58
Q_loss1: 285.21, Q_loss2: 476.18, min_Q_loss1: -428.46, min_Q_loss2: -424.62

Train epoch 596/3000 -- step 597000

[F                                                                                                    
[F[ Model Length ] Epoch: 596 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 596000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 596 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 596596
[ Model Rollout ] Added: 48920 | Model pool: 500000 (max 500000) | Length: 4.892 | Train rep: 1

Diagnostics -- iteration 597000
real_batch_obs: 1847.62, model_batch_obs: 1909.35
real_batch_act: 203.62, model_batch_act: 187.96
real_batch_rewards: 1344.35, model_batch_rewards: 1329.49
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 375.34
total_steps: 597000.00
Q-avg: 1067.94, Q-max: 1505.68, Q-min: -32.68
Q_loss1: 508.03, Q_loss2: 604.00, min_Q_loss1: -244.12, min_Q_loss2: -239.91

Train epoch 597/3000 -- step 598000

[F                                                                                                    
[F[ Model Length ] Epoch: 597 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 597000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 597 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 597597
[ Model Rollout ] Added: 49056 | Model pool: 500000 (max 500000) | Length: 4.9056 | Train rep: 1

Diagnostics -- iteration 598000
real_batch_obs: 1863.12, model_batch_obs: 1905.00
real_batch_act: 194.29, model_batch_act: 186.48
real_batch_rewards: 1316.85, model_batch_rewards: 1322.93
real_batch_dones: 2.00, model_batch_dones: 2.00
evaluation/return-average: 378.58
total_steps: 598000.00
Q-avg: 1066.69, Q-max: 1506.19, Q-min: -224.76
Q_loss1: 539.86, Q_loss2: 540.54, min_Q_loss1: -101.73, min_Q_loss2: -98.24

Train epoch 598/3000 -- step 599000

[F                                                                                                    
[F[ Model Length ] Epoch: 598 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 598000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 598 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 598598
[ Model Rollout ] Added: 48966 | Model pool: 500000 (max 500000) | Length: 4.8966 | Train rep: 1

Diagnostics -- iteration 599000
real_batch_obs: 1941.11, model_batch_obs: 1866.82
real_batch_act: 210.49, model_batch_act: 189.77
real_batch_rewards: 1344.51, model_batch_rewards: 1388.07
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 384.05
total_steps: 599000.00
Q-avg: 1050.55, Q-max: 1496.00, Q-min: -299.84
Q_loss1: 609.01, Q_loss2: 521.33, min_Q_loss1: -34.39, min_Q_loss2: -30.37

Train epoch 599/3000 -- step 600000

[F                                                                                                    
[F[ Model Length ] Epoch: 599 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 599000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 599 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 599599
[ Model Rollout ] Added: 49040 | Model pool: 500000 (max 500000) | Length: 4.904 | Train rep: 1

Diagnostics -- iteration 600000
real_batch_obs: 1815.19, model_batch_obs: 1893.94
real_batch_act: 199.61, model_batch_act: 193.71
real_batch_rewards: 1303.29, model_batch_rewards: 1395.73
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 364.89
total_steps: 600000.00
Q-avg: 1074.33, Q-max: 1494.99, Q-min: -1259.24
Q_loss1: 2131.08, Q_loss2: 3363.16, min_Q_loss1: -424.84, min_Q_loss2: -424.00

Train epoch 600/3000 -- step 601000

[F                                                                                                    
[F[ Model Length ] Epoch: 600 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 600000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 600 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 600600
[ Model Rollout ] Added: 49181 | Model pool: 500000 (max 500000) | Length: 4.9181 | Train rep: 1

Diagnostics -- iteration 601000
real_batch_obs: 1732.65, model_batch_obs: 1878.61
real_batch_act: 192.05, model_batch_act: 199.71
real_batch_rewards: 1308.85, model_batch_rewards: 1321.47
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 351.58
total_steps: 601000.00
Q-avg: 1054.24, Q-max: 1501.97, Q-min: -178.15
Q_loss1: 1620.91, Q_loss2: 1484.34, min_Q_loss1: -334.42, min_Q_loss2: -343.00

Train epoch 601/3000 -- step 602000

[F                                                                                                    
[F[ Model Length ] Epoch: 601 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 601000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 601 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 601601
[ Model Rollout ] Added: 48965 | Model pool: 500000 (max 500000) | Length: 4.8965 | Train rep: 1

Diagnostics -- iteration 602000
real_batch_obs: 1825.86, model_batch_obs: 1908.50
real_batch_act: 201.52, model_batch_act: 186.75
real_batch_rewards: 1352.36, model_batch_rewards: 1353.21
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 372.49
total_steps: 602000.00
Q-avg: 1054.76, Q-max: 1525.76, Q-min: -168.40
Q_loss1: 951.30, Q_loss2: 1086.71, min_Q_loss1: -206.63, min_Q_loss2: -209.02

Train epoch 602/3000 -- step 603000

[F                                                                                                    
[F[ Model Length ] Epoch: 602 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 602000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 602 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 602602
[ Model Rollout ] Added: 49008 | Model pool: 500000 (max 500000) | Length: 4.9008 | Train rep: 1

Diagnostics -- iteration 603000
real_batch_obs: 1830.32, model_batch_obs: 1962.54
real_batch_act: 203.94, model_batch_act: 187.84
real_batch_rewards: 1390.19, model_batch_rewards: 1365.66
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 409.81
total_steps: 603000.00
Q-avg: 1066.89, Q-max: 1520.85, Q-min: -16.53
Q_loss1: 884.56, Q_loss2: 916.01, min_Q_loss1: -221.09, min_Q_loss2: -216.82

Train epoch 603/3000 -- step 604000

[F                                                                                                    
[F[ Model Length ] Epoch: 603 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 603000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 603 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 603603
[ Model Rollout ] Added: 49006 | Model pool: 500000 (max 500000) | Length: 4.9006 | Train rep: 1

Diagnostics -- iteration 604000
real_batch_obs: 1753.26, model_batch_obs: 1945.84
real_batch_act: 196.58, model_batch_act: 195.00
real_batch_rewards: 1322.81, model_batch_rewards: 1379.01
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 397.84
total_steps: 604000.00
Q-avg: 1034.04, Q-max: 1511.65, Q-min: -315.20
Q_loss1: 2685.59, Q_loss2: 2697.88, min_Q_loss1: -415.63, min_Q_loss2: -423.64

Train epoch 604/3000 -- step 605000

[F                                                                                                    
[F[ Model Length ] Epoch: 604 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 604000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 604 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 604604
[ Model Rollout ] Added: 49075 | Model pool: 500000 (max 500000) | Length: 4.9075 | Train rep: 1

Diagnostics -- iteration 605000
real_batch_obs: 1891.74, model_batch_obs: 1806.05
real_batch_act: 199.47, model_batch_act: 189.89
real_batch_rewards: 1412.38, model_batch_rewards: 1338.82
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 392.98
total_steps: 605000.00
Q-avg: 1071.19, Q-max: 1554.88, Q-min: -360.16
Q_loss1: 666.61, Q_loss2: 790.00, min_Q_loss1: -41.06, min_Q_loss2: -43.56

Train epoch 605/3000 -- step 606000

[F                                                                                                    
[F[ Model Length ] Epoch: 605 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 605000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 605 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 605605
[ Model Rollout ] Added: 49000 | Model pool: 500000 (max 500000) | Length: 4.9 | Train rep: 1

Diagnostics -- iteration 606000
real_batch_obs: 1867.68, model_batch_obs: 1874.21
real_batch_act: 191.88, model_batch_act: 194.37
real_batch_rewards: 1345.93, model_batch_rewards: 1357.19
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 395.47
total_steps: 606000.00
Q-avg: 1050.10, Q-max: 1526.50, Q-min: -412.97
Q_loss1: 3684.80, Q_loss2: 3603.44, min_Q_loss1: -411.82, min_Q_loss2: -416.70

Train epoch 606/3000 -- step 607000

[F                                                                                                    
[F[ Model Length ] Epoch: 606 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 606000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 606 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 606606
[ Model Rollout ] Added: 49048 | Model pool: 500000 (max 500000) | Length: 4.9048 | Train rep: 1

Diagnostics -- iteration 607000
real_batch_obs: 1949.18, model_batch_obs: 1871.70
real_batch_act: 193.25, model_batch_act: 192.52
real_batch_rewards: 1375.57, model_batch_rewards: 1342.01
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 514.17
total_steps: 607000.00
Q-avg: 1033.22, Q-max: 1485.27, Q-min: -381.72
Q_loss1: 1860.65, Q_loss2: 2035.57, min_Q_loss1: -203.79, min_Q_loss2: -204.15

Train epoch 607/3000 -- step 608000

[F                                                                                                    
[F[ Model Length ] Epoch: 607 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 607000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 607 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 607607
[ Model Rollout ] Added: 48987 | Model pool: 500000 (max 500000) | Length: 4.8987 | Train rep: 1

Diagnostics -- iteration 608000
real_batch_obs: 1773.15, model_batch_obs: 1910.93
real_batch_act: 195.94, model_batch_act: 195.29
real_batch_rewards: 1276.91, model_batch_rewards: 1296.99
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 634.93
total_steps: 608000.00
Q-avg: 1029.44, Q-max: 1490.85, Q-min: -312.47
Q_loss1: 525.68, Q_loss2: 572.52, min_Q_loss1: -479.83, min_Q_loss2: -481.01

Train epoch 608/3000 -- step 609000

[F                                                                                                    
[F[ Model Length ] Epoch: 608 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 608000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 608 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 608608
[ Model Rollout ] Added: 48994 | Model pool: 500000 (max 500000) | Length: 4.8994 | Train rep: 1

Diagnostics -- iteration 609000
real_batch_obs: 1844.68, model_batch_obs: 1883.03
real_batch_act: 204.13, model_batch_act: 193.60
real_batch_rewards: 1338.26, model_batch_rewards: 1316.30
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 434.18
total_steps: 609000.00
Q-avg: 1040.00, Q-max: 1467.94, Q-min: -320.92
Q_loss1: 789.17, Q_loss2: 829.93, min_Q_loss1: -320.51, min_Q_loss2: -321.63

Train epoch 609/3000 -- step 610000

[F                                                                                                    
[F[ Model Length ] Epoch: 609 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 609000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 609 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 609609
[ Model Rollout ] Added: 48960 | Model pool: 500000 (max 500000) | Length: 4.896 | Train rep: 1

Diagnostics -- iteration 610000
real_batch_obs: 1857.75, model_batch_obs: 1964.98
real_batch_act: 194.33, model_batch_act: 188.45
real_batch_rewards: 1423.82, model_batch_rewards: 1356.04
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 425.50
total_steps: 610000.00
Q-avg: 1045.53, Q-max: 1501.51, Q-min: -58.74
Q_loss1: 358.70, Q_loss2: 315.04, min_Q_loss1: 69.59, min_Q_loss2: 58.11

Train epoch 610/3000 -- step 611000

[F                                                                                                    
[F[ Model Length ] Epoch: 610 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 610000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 610 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 610610
[ Model Rollout ] Added: 48975 | Model pool: 500000 (max 500000) | Length: 4.8975 | Train rep: 1

Diagnostics -- iteration 611000
real_batch_obs: 1807.38, model_batch_obs: 1773.00
real_batch_act: 196.42, model_batch_act: 195.80
real_batch_rewards: 1372.43, model_batch_rewards: 1275.27
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 402.36
total_steps: 611000.00
Q-avg: 1096.45, Q-max: 1496.58, Q-min: -341.78
Q_loss1: 3673.80, Q_loss2: 3146.20, min_Q_loss1: -235.35, min_Q_loss2: -247.50

Train epoch 611/3000 -- step 612000

[F                                                                                                    
[F[ Model Length ] Epoch: 611 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 611000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 611 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 611611
[ Model Rollout ] Added: 48938 | Model pool: 500000 (max 500000) | Length: 4.8938 | Train rep: 1

Diagnostics -- iteration 612000
real_batch_obs: 1765.42, model_batch_obs: 1885.29
real_batch_act: 208.41, model_batch_act: 186.41
real_batch_rewards: 1376.68, model_batch_rewards: 1368.62
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 380.76
total_steps: 612000.00
Q-avg: 1019.34, Q-max: 1480.57, Q-min: -25.31
Q_loss1: 289.87, Q_loss2: 297.95, min_Q_loss1: -95.63, min_Q_loss2: -100.55

Train epoch 612/3000 -- step 613000

[F                                                                                                    
[F[ Model Length ] Epoch: 612 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 612000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 612 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 612612
[ Model Rollout ] Added: 49019 | Model pool: 500000 (max 500000) | Length: 4.9019 | Train rep: 1

Diagnostics -- iteration 613000
real_batch_obs: 1747.20, model_batch_obs: 1916.08
real_batch_act: 202.22, model_batch_act: 190.48
real_batch_rewards: 1344.51, model_batch_rewards: 1429.52
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 379.04
total_steps: 613000.00
Q-avg: 1014.06, Q-max: 1482.50, Q-min: -432.58
Q_loss1: 1049.84, Q_loss2: 990.12, min_Q_loss1: -343.11, min_Q_loss2: -350.04

Train epoch 613/3000 -- step 614000

[F                                                                                                    
[F[ Model Length ] Epoch: 613 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 613000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 613 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 613613
[ Model Rollout ] Added: 49066 | Model pool: 500000 (max 500000) | Length: 4.9066 | Train rep: 1

Diagnostics -- iteration 614000
real_batch_obs: 1754.24, model_batch_obs: 1880.42
real_batch_act: 188.95, model_batch_act: 189.57
real_batch_rewards: 1333.38, model_batch_rewards: 1368.30
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 386.48
total_steps: 614000.00
Q-avg: 1068.55, Q-max: 1500.05, Q-min: -41.14
Q_loss1: 131.14, Q_loss2: 155.18, min_Q_loss1: -593.02, min_Q_loss2: -586.85

Train epoch 614/3000 -- step 615000

[F                                                                                                    
[F[ Model Length ] Epoch: 614 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 614000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 614 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 614614
[ Model Rollout ] Added: 49017 | Model pool: 500000 (max 500000) | Length: 4.9017 | Train rep: 1

Diagnostics -- iteration 615000
real_batch_obs: 1809.30, model_batch_obs: 1910.08
real_batch_act: 203.20, model_batch_act: 195.38
real_batch_rewards: 1398.07, model_batch_rewards: 1364.36
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 367.02
total_steps: 615000.00
Q-avg: 984.59, Q-max: 1485.79, Q-min: -1080.29
Q_loss1: 16635.40, Q_loss2: 17070.90, min_Q_loss1: 19.26, min_Q_loss2: 27.17

Train epoch 615/3000 -- step 616000

[F                                                                                                    
[F[ Model Length ] Epoch: 615 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 615000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 615 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 615615
[ Model Rollout ] Added: 49011 | Model pool: 500000 (max 500000) | Length: 4.9011 | Train rep: 1

Diagnostics -- iteration 616000
real_batch_obs: 1795.84, model_batch_obs: 1808.00
real_batch_act: 204.63, model_batch_act: 184.97
real_batch_rewards: 1302.18, model_batch_rewards: 1260.63
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 370.20
total_steps: 616000.00
Q-avg: 1109.75, Q-max: 1483.98, Q-min: -638.63
Q_loss1: 1391.33, Q_loss2: 1266.63, min_Q_loss1: -396.38, min_Q_loss2: -392.06

Train epoch 616/3000 -- step 617000

[F                                                                                                    
[F[ Model Length ] Epoch: 616 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 616000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 616 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 616616
[ Model Rollout ] Added: 49013 | Model pool: 500000 (max 500000) | Length: 4.9013 | Train rep: 1

Diagnostics -- iteration 617000
real_batch_obs: 1874.38, model_batch_obs: 1822.82
real_batch_act: 191.62, model_batch_act: 196.96
real_batch_rewards: 1431.48, model_batch_rewards: 1296.08
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 371.18
total_steps: 617000.00
Q-avg: 1044.67, Q-max: 1509.29, Q-min: -928.44
Q_loss1: 401.98, Q_loss2: 461.70, min_Q_loss1: -25.09, min_Q_loss2: -21.18

Train epoch 617/3000 -- step 618000

[F                                                                                                    
[F[ Model Length ] Epoch: 617 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 617000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 617 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 617617
[ Model Rollout ] Added: 49020 | Model pool: 500000 (max 500000) | Length: 4.902 | Train rep: 1

Diagnostics -- iteration 618000
real_batch_obs: 1844.56, model_batch_obs: 1866.40
real_batch_act: 192.67, model_batch_act: 199.58
real_batch_rewards: 1317.32, model_batch_rewards: 1358.30
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 401.64
total_steps: 618000.00
Q-avg: 1037.75, Q-max: 1537.33, Q-min: -189.52
Q_loss1: 1664.83, Q_loss2: 1657.25, min_Q_loss1: -435.52, min_Q_loss2: -444.08

Train epoch 618/3000 -- step 619000

[F                                                                                                    
[F[ Model Length ] Epoch: 618 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 618000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 618 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 618618
[ Model Rollout ] Added: 49084 | Model pool: 500000 (max 500000) | Length: 4.9084 | Train rep: 1

Diagnostics -- iteration 619000
real_batch_obs: 1879.01, model_batch_obs: 1706.27
real_batch_act: 195.48, model_batch_act: 192.79
real_batch_rewards: 1366.14, model_batch_rewards: 1261.91
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 411.46
total_steps: 619000.00
Q-avg: 1088.86, Q-max: 1522.38, Q-min: -495.88
Q_loss1: 376.33, Q_loss2: 380.63, min_Q_loss1: -97.72, min_Q_loss2: -107.56

Train epoch 619/3000 -- step 620000

[F                                                                                                    
[F[ Model Length ] Epoch: 619 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 619000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 619 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 619619
[ Model Rollout ] Added: 49058 | Model pool: 500000 (max 500000) | Length: 4.9058 | Train rep: 1

Diagnostics -- iteration 620000
real_batch_obs: 1868.15, model_batch_obs: 1866.07
real_batch_act: 203.50, model_batch_act: 193.69
real_batch_rewards: 1364.63, model_batch_rewards: 1387.99
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 394.25
total_steps: 620000.00
Q-avg: 1013.14, Q-max: 1506.99, Q-min: -607.78
Q_loss1: 906.70, Q_loss2: 981.41, min_Q_loss1: -245.18, min_Q_loss2: -245.91

Train epoch 620/3000 -- step 621000

[F                                                                                                    
[F[ Model Length ] Epoch: 620 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 620000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 620 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 620620
[ Model Rollout ] Added: 48971 | Model pool: 500000 (max 500000) | Length: 4.8971 | Train rep: 1

Diagnostics -- iteration 621000
real_batch_obs: 1924.06, model_batch_obs: 1888.48
real_batch_act: 199.52, model_batch_act: 187.25
real_batch_rewards: 1317.75, model_batch_rewards: 1376.22
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 396.12
total_steps: 621000.00
Q-avg: 1067.21, Q-max: 1505.49, Q-min: -607.42
Q_loss1: 2131.66, Q_loss2: 2435.35, min_Q_loss1: -373.61, min_Q_loss2: -371.96

Train epoch 621/3000 -- step 622000

[F                                                                                                    
[F[ Model Length ] Epoch: 621 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 621000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 621 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 621621
[ Model Rollout ] Added: 48987 | Model pool: 500000 (max 500000) | Length: 4.8987 | Train rep: 1

Diagnostics -- iteration 622000
real_batch_obs: 1853.04, model_batch_obs: 1931.29
real_batch_act: 211.15, model_batch_act: 196.99
real_batch_rewards: 1376.18, model_batch_rewards: 1335.72
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 379.45
total_steps: 622000.00
Q-avg: 1016.16, Q-max: 1492.65, Q-min: -1029.83
Q_loss1: 1768.49, Q_loss2: 1669.52, min_Q_loss1: -362.78, min_Q_loss2: -365.16

Train epoch 622/3000 -- step 623000

[F                                                                                                    
[F[ Model Length ] Epoch: 622 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 622000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 622 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 622622
[ Model Rollout ] Added: 49032 | Model pool: 500000 (max 500000) | Length: 4.9032 | Train rep: 1

Diagnostics -- iteration 623000
real_batch_obs: 1929.07, model_batch_obs: 1909.61
real_batch_act: 201.87, model_batch_act: 193.53
real_batch_rewards: 1324.53, model_batch_rewards: 1433.97
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 379.10
total_steps: 623000.00
Q-avg: 1020.52, Q-max: 1497.67, Q-min: -1753.29
Q_loss1: 5965.29, Q_loss2: 4132.23, min_Q_loss1: -376.81, min_Q_loss2: -369.94

Train epoch 623/3000 -- step 624000

[F                                                                                                    
[F[ Model Length ] Epoch: 623 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 623000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 623 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 623623
[ Model Rollout ] Added: 49052 | Model pool: 500000 (max 500000) | Length: 4.9052 | Train rep: 1

Diagnostics -- iteration 624000
real_batch_obs: 1871.20, model_batch_obs: 1945.47
real_batch_act: 199.35, model_batch_act: 185.74
real_batch_rewards: 1384.80, model_batch_rewards: 1287.65
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 338.47
total_steps: 624000.00
Q-avg: 1022.79, Q-max: 1514.49, Q-min: -50.21
Q_loss1: 369.07, Q_loss2: 442.50, min_Q_loss1: -107.46, min_Q_loss2: -118.15

Train epoch 624/3000 -- step 625000

[F                                                                                                    
[F[ Model Length ] Epoch: 624 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 624000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 624 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 624624
[ Model Rollout ] Added: 49040 | Model pool: 500000 (max 500000) | Length: 4.904 | Train rep: 1

Diagnostics -- iteration 625000
real_batch_obs: 1901.84, model_batch_obs: 1927.80
real_batch_act: 193.13, model_batch_act: 194.09
real_batch_rewards: 1393.38, model_batch_rewards: 1274.44
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 402.98
total_steps: 625000.00
Q-avg: 1045.71, Q-max: 1477.40, Q-min: -24.49
Q_loss1: 140.81, Q_loss2: 150.33, min_Q_loss1: -91.73, min_Q_loss2: -99.95

Train epoch 625/3000 -- step 626000

[F                                                                                                    
[F[ Model Length ] Epoch: 625 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 625000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 625 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 625625
[ Model Rollout ] Added: 49032 | Model pool: 500000 (max 500000) | Length: 4.9032 | Train rep: 1

Diagnostics -- iteration 626000
real_batch_obs: 1769.01, model_batch_obs: 1803.05
real_batch_act: 204.59, model_batch_act: 193.60
real_batch_rewards: 1255.89, model_batch_rewards: 1376.64
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 319.44
total_steps: 626000.00
Q-avg: 1023.12, Q-max: 1463.26, Q-min: -141.14
Q_loss1: 234.12, Q_loss2: 193.35, min_Q_loss1: -523.14, min_Q_loss2: -522.47

Train epoch 626/3000 -- step 627000

[F                                                                                                    
[F[ Model Length ] Epoch: 626 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 626000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 626 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 626626
[ Model Rollout ] Added: 48993 | Model pool: 500000 (max 500000) | Length: 4.8993 | Train rep: 1

Diagnostics -- iteration 627000
real_batch_obs: 1863.02, model_batch_obs: 1906.12
real_batch_act: 200.24, model_batch_act: 190.10
real_batch_rewards: 1386.32, model_batch_rewards: 1362.37
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 364.65
total_steps: 627000.00
Q-avg: 991.73, Q-max: 1448.16, Q-min: -795.76
Q_loss1: 3299.50, Q_loss2: 2875.40, min_Q_loss1: -254.52, min_Q_loss2: -256.42

Train epoch 627/3000 -- step 628000

[F                                                                                                    
[F[ Model Length ] Epoch: 627 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 627000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 627 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 627627
[ Model Rollout ] Added: 49048 | Model pool: 500000 (max 500000) | Length: 4.9048 | Train rep: 1

Diagnostics -- iteration 628000
real_batch_obs: 1880.10, model_batch_obs: 1900.37
real_batch_act: 198.61, model_batch_act: 196.77
real_batch_rewards: 1403.98, model_batch_rewards: 1371.53
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 1288.27
total_steps: 628000.00
Q-avg: 1072.72, Q-max: 1455.29, Q-min: -196.97
Q_loss1: 684.70, Q_loss2: 634.58, min_Q_loss1: -163.96, min_Q_loss2: -167.73

Train epoch 628/3000 -- step 629000

[F                                                                                                    
[F[ Model Length ] Epoch: 628 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 628000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 628 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 628628
[ Model Rollout ] Added: 49038 | Model pool: 500000 (max 500000) | Length: 4.9038 | Train rep: 1

Diagnostics -- iteration 629000
real_batch_obs: 1846.01, model_batch_obs: 1818.07
real_batch_act: 192.97, model_batch_act: 198.06
real_batch_rewards: 1394.68, model_batch_rewards: 1308.44
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 970.01
total_steps: 629000.00
Q-avg: 1059.45, Q-max: 1446.86, Q-min: -67.56
Q_loss1: 170.45, Q_loss2: 166.62, min_Q_loss1: -219.00, min_Q_loss2: -217.99

Train epoch 629/3000 -- step 630000

[F                                                                                                    
[F[ Model Length ] Epoch: 629 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 629000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 629 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 629629
[ Model Rollout ] Added: 49105 | Model pool: 500000 (max 500000) | Length: 4.9105 | Train rep: 1

Diagnostics -- iteration 630000
real_batch_obs: 1766.67, model_batch_obs: 1886.65
real_batch_act: 197.61, model_batch_act: 193.75
real_batch_rewards: 1358.26, model_batch_rewards: 1357.58
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 919.50
total_steps: 630000.00
Q-avg: 1042.52, Q-max: 1429.60, Q-min: -664.56
Q_loss1: 1143.66, Q_loss2: 1069.72, min_Q_loss1: -364.03, min_Q_loss2: -358.07

Train epoch 630/3000 -- step 631000

[F                                                                                                    
[F[ Model Length ] Epoch: 630 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 630000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 630 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 630630
[ Model Rollout ] Added: 49039 | Model pool: 500000 (max 500000) | Length: 4.9039 | Train rep: 1

Diagnostics -- iteration 631000
real_batch_obs: 1923.66, model_batch_obs: 1880.23
real_batch_act: 198.47, model_batch_act: 196.86
real_batch_rewards: 1383.24, model_batch_rewards: 1297.79
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 1008.84
total_steps: 631000.00
Q-avg: 1037.90, Q-max: 1416.28, Q-min: -738.36
Q_loss1: 3623.09, Q_loss2: 3776.32, min_Q_loss1: -381.42, min_Q_loss2: -378.52

Train epoch 631/3000 -- step 632000

[F                                                                                                    
[F[ Model Length ] Epoch: 631 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 631000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 631 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 631631
[ Model Rollout ] Added: 49048 | Model pool: 500000 (max 500000) | Length: 4.9048 | Train rep: 1

Diagnostics -- iteration 632000
real_batch_obs: 1819.50, model_batch_obs: 1824.35
real_batch_act: 194.50, model_batch_act: 189.11
real_batch_rewards: 1307.94, model_batch_rewards: 1357.28
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 765.13
total_steps: 632000.00
Q-avg: 1046.38, Q-max: 1412.54, Q-min: -179.99
Q_loss1: 984.49, Q_loss2: 984.30, min_Q_loss1: -291.53, min_Q_loss2: -291.52

Train epoch 632/3000 -- step 633000

[F                                                                                                    
[F[ Model Length ] Epoch: 632 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 632000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 632 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 632632
[ Model Rollout ] Added: 48963 | Model pool: 500000 (max 500000) | Length: 4.8963 | Train rep: 1

Diagnostics -- iteration 633000
real_batch_obs: 1770.23, model_batch_obs: 1919.55
real_batch_act: 188.75, model_batch_act: 192.48
real_batch_rewards: 1330.75, model_batch_rewards: 1301.05
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 790.31
total_steps: 633000.00
Q-avg: 1063.19, Q-max: 1416.15, Q-min: -184.41
Q_loss1: 301.24, Q_loss2: 328.49, min_Q_loss1: -91.41, min_Q_loss2: -88.68

Train epoch 633/3000 -- step 634000

[F                                                                                                    
[F[ Model Length ] Epoch: 633 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 633000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 633 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 633633
[ Model Rollout ] Added: 48986 | Model pool: 500000 (max 500000) | Length: 4.8986 | Train rep: 1

Diagnostics -- iteration 634000
real_batch_obs: 1796.14, model_batch_obs: 1962.50
real_batch_act: 204.67, model_batch_act: 200.77
real_batch_rewards: 1347.27, model_batch_rewards: 1343.98
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 1625.55
total_steps: 634000.00
Q-avg: 1012.10, Q-max: 1433.89, Q-min: -770.62
Q_loss1: 598.94, Q_loss2: 794.30, min_Q_loss1: -181.46, min_Q_loss2: -191.98

Train epoch 634/3000 -- step 635000

[F                                                                                                    
[F[ Model Length ] Epoch: 634 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 634000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 634 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 634634
[ Model Rollout ] Added: 49003 | Model pool: 500000 (max 500000) | Length: 4.9003 | Train rep: 1

Diagnostics -- iteration 635000
real_batch_obs: 1909.41, model_batch_obs: 1887.58
real_batch_act: 201.93, model_batch_act: 189.29
real_batch_rewards: 1333.70, model_batch_rewards: 1347.41
real_batch_dones: 2.00, model_batch_dones: 1.00
evaluation/return-average: 791.18
total_steps: 635000.00
Q-avg: 1043.39, Q-max: 1452.98, Q-min: -96.54
Q_loss1: 236.40, Q_loss2: 292.07, min_Q_loss1: -64.06, min_Q_loss2: -67.67

Train epoch 635/3000 -- step 636000

[F                                                                                                    
[F[ Model Length ] Epoch: 635 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 635000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 635 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 635635
[ Model Rollout ] Added: 49003 | Model pool: 500000 (max 500000) | Length: 4.9003 | Train rep: 1

Diagnostics -- iteration 636000
real_batch_obs: 1807.25, model_batch_obs: 1854.39
real_batch_act: 193.59, model_batch_act: 186.66
real_batch_rewards: 1300.15, model_batch_rewards: 1349.54
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 870.66
total_steps: 636000.00
Q-avg: 1089.36, Q-max: 1434.59, Q-min: -126.40
Q_loss1: 1185.08, Q_loss2: 1185.85, min_Q_loss1: -300.21, min_Q_loss2: -294.82

Train epoch 636/3000 -- step 637000

[F                                                                                                    
[F[ Model Length ] Epoch: 636 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 636000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 636 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 636636
[ Model Rollout ] Added: 49114 | Model pool: 500000 (max 500000) | Length: 4.9114 | Train rep: 1

Diagnostics -- iteration 637000
real_batch_obs: 1805.83, model_batch_obs: 1789.39
real_batch_act: 208.40, model_batch_act: 187.62
real_batch_rewards: 1336.44, model_batch_rewards: 1322.22
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 1375.42
total_steps: 637000.00
Q-avg: 1006.29, Q-max: 1475.02, Q-min: -480.23
Q_loss1: 611.57, Q_loss2: 767.51, min_Q_loss1: -12.23, min_Q_loss2: -2.92

Train epoch 637/3000 -- step 638000

[F                                                                                                    
[F[ Model Length ] Epoch: 637 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 637000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 637 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 637637
[ Model Rollout ] Added: 49062 | Model pool: 500000 (max 500000) | Length: 4.9062 | Train rep: 1

Diagnostics -- iteration 638000
real_batch_obs: 1832.04, model_batch_obs: 1891.94
real_batch_act: 203.91, model_batch_act: 194.54
real_batch_rewards: 1387.85, model_batch_rewards: 1313.03
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 2431.34
total_steps: 638000.00
Q-avg: 1016.11, Q-max: 1466.91, Q-min: -726.49
Q_loss1: 1221.56, Q_loss2: 1166.65, min_Q_loss1: -228.90, min_Q_loss2: -215.69

Train epoch 638/3000 -- step 639000

[F                                                                                                    
[F[ Model Length ] Epoch: 638 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 638000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 638 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 638638
[ Model Rollout ] Added: 49070 | Model pool: 500000 (max 500000) | Length: 4.907 | Train rep: 1

Diagnostics -- iteration 639000
real_batch_obs: 1900.08, model_batch_obs: 1718.98
real_batch_act: 195.07, model_batch_act: 188.52
real_batch_rewards: 1382.72, model_batch_rewards: 1276.80
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 1950.47
total_steps: 639000.00
Q-avg: 1036.01, Q-max: 1472.70, Q-min: -128.86
Q_loss1: 853.75, Q_loss2: 897.81, min_Q_loss1: -71.56, min_Q_loss2: -63.72

Train epoch 639/3000 -- step 640000

[F                                                                                                    
[F[ Model Length ] Epoch: 639 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 639000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 639 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 639639
[ Model Rollout ] Added: 48956 | Model pool: 500000 (max 500000) | Length: 4.8956 | Train rep: 1

Diagnostics -- iteration 640000
real_batch_obs: 1913.49, model_batch_obs: 1757.79
real_batch_act: 197.11, model_batch_act: 195.18
real_batch_rewards: 1338.16, model_batch_rewards: 1333.33
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 2304.45
total_steps: 640000.00
Q-avg: 1046.91, Q-max: 1501.15, Q-min: -112.02
Q_loss1: 283.95, Q_loss2: 266.08, min_Q_loss1: -109.39, min_Q_loss2: -111.56

Train epoch 640/3000 -- step 641000

[F                                                                                                    
[F[ Model Length ] Epoch: 640 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 640000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 640 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 640640
[ Model Rollout ] Added: 48936 | Model pool: 500000 (max 500000) | Length: 4.8936 | Train rep: 1

Diagnostics -- iteration 641000
real_batch_obs: 1871.67, model_batch_obs: 1848.20
real_batch_act: 195.79, model_batch_act: 191.81
real_batch_rewards: 1352.31, model_batch_rewards: 1294.72
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 1486.95
total_steps: 641000.00
Q-avg: 1035.52, Q-max: 1473.86, Q-min: -634.08
Q_loss1: 445.15, Q_loss2: 297.82, min_Q_loss1: -24.13, min_Q_loss2: -25.92

Train epoch 641/3000 -- step 642000

[F                                                                                                    
[F[ Model Length ] Epoch: 641 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 641000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 641 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 641641
[ Model Rollout ] Added: 48935 | Model pool: 500000 (max 500000) | Length: 4.8935 | Train rep: 1

Diagnostics -- iteration 642000
real_batch_obs: 1837.90, model_batch_obs: 1873.50
real_batch_act: 198.78, model_batch_act: 180.32
real_batch_rewards: 1404.02, model_batch_rewards: 1299.24
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 1061.38
total_steps: 642000.00
Q-avg: 1041.45, Q-max: 1473.28, Q-min: -357.55
Q_loss1: 380.11, Q_loss2: 410.77, min_Q_loss1: -152.49, min_Q_loss2: -161.58

Train epoch 642/3000 -- step 643000

[F                                                                                                    
[F[ Model Length ] Epoch: 642 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 642000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 642 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 642642
[ Model Rollout ] Added: 49025 | Model pool: 500000 (max 500000) | Length: 4.9025 | Train rep: 1

Diagnostics -- iteration 643000
real_batch_obs: 1899.02, model_batch_obs: 1789.84
real_batch_act: 194.55, model_batch_act: 198.35
real_batch_rewards: 1364.16, model_batch_rewards: 1339.22
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 2231.22
total_steps: 643000.00
Q-avg: 1000.97, Q-max: 1441.46, Q-min: -939.67
Q_loss1: 1293.99, Q_loss2: 1977.62, min_Q_loss1: -399.48, min_Q_loss2: -407.40

Train epoch 643/3000 -- step 644000

[F                                                                                                    
[F[ Model Length ] Epoch: 643 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 643000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 643 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 643643
[ Model Rollout ] Added: 49070 | Model pool: 500000 (max 500000) | Length: 4.907 | Train rep: 1

Diagnostics -- iteration 644000
real_batch_obs: 1802.35, model_batch_obs: 1935.38
real_batch_act: 206.46, model_batch_act: 186.73
real_batch_rewards: 1375.74, model_batch_rewards: 1277.94
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 2760.80
total_steps: 644000.00
Q-avg: 998.88, Q-max: 1464.21, Q-min: -560.38
Q_loss1: 1318.80, Q_loss2: 1259.92, min_Q_loss1: 12.23, min_Q_loss2: 6.56

Train epoch 644/3000 -- step 645000

[F                                                                                                    
[F[ Model Length ] Epoch: 644 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 644000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 644 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 644644
[ Model Rollout ] Added: 49038 | Model pool: 500000 (max 500000) | Length: 4.9038 | Train rep: 1

Diagnostics -- iteration 645000
real_batch_obs: 1728.54, model_batch_obs: 1856.58
real_batch_act: 190.39, model_batch_act: 189.12
real_batch_rewards: 1344.54, model_batch_rewards: 1311.27
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 1686.88
total_steps: 645000.00
Q-avg: 1038.59, Q-max: 1505.64, Q-min: -238.63
Q_loss1: 2763.43, Q_loss2: 2763.30, min_Q_loss1: -221.50, min_Q_loss2: -220.51

Train epoch 645/3000 -- step 646000

[F                                                                                                    
[F[ Model Length ] Epoch: 645 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 645000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 645 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 645645
[ Model Rollout ] Added: 49056 | Model pool: 500000 (max 500000) | Length: 4.9056 | Train rep: 1

Diagnostics -- iteration 646000
real_batch_obs: 1932.98, model_batch_obs: 1974.49
real_batch_act: 206.22, model_batch_act: 193.57
real_batch_rewards: 1314.19, model_batch_rewards: 1315.60
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 2108.82
total_steps: 646000.00
Q-avg: 1061.77, Q-max: 1437.31, Q-min: -51.49
Q_loss1: 1069.87, Q_loss2: 1351.61, min_Q_loss1: -196.04, min_Q_loss2: -206.11

Train epoch 646/3000 -- step 647000

[F                                                                                                    
[F[ Model Length ] Epoch: 646 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 646000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 646 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 646646
[ Model Rollout ] Added: 48993 | Model pool: 500000 (max 500000) | Length: 4.8993 | Train rep: 1

Diagnostics -- iteration 647000
real_batch_obs: 1877.24, model_batch_obs: 1902.43
real_batch_act: 198.90, model_batch_act: 200.64
real_batch_rewards: 1396.91, model_batch_rewards: 1353.68
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 1259.55
total_steps: 647000.00
Q-avg: 1053.54, Q-max: 1425.77, Q-min: -105.04
Q_loss1: 390.04, Q_loss2: 366.61, min_Q_loss1: -156.47, min_Q_loss2: -157.37

Train epoch 647/3000 -- step 648000

[F                                                                                                    
[F[ Model Length ] Epoch: 647 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 647000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 647 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 647647
[ Model Rollout ] Added: 49017 | Model pool: 500000 (max 500000) | Length: 4.9017 | Train rep: 1

Diagnostics -- iteration 648000
real_batch_obs: 1819.51, model_batch_obs: 1890.61
real_batch_act: 191.11, model_batch_act: 195.83
real_batch_rewards: 1311.53, model_batch_rewards: 1505.80
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 931.30
total_steps: 648000.00
Q-avg: 979.89, Q-max: 1426.81, Q-min: -756.03
Q_loss1: 1537.11, Q_loss2: 1530.46, min_Q_loss1: -403.79, min_Q_loss2: -404.84

Train epoch 648/3000 -- step 649000

[F                                                                                                    
[F[ Model Length ] Epoch: 648 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 648000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 648 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 648648
[ Model Rollout ] Added: 49027 | Model pool: 500000 (max 500000) | Length: 4.9027 | Train rep: 1

Diagnostics -- iteration 649000
real_batch_obs: 1825.61, model_batch_obs: 1813.64
real_batch_act: 194.62, model_batch_act: 196.76
real_batch_rewards: 1283.74, model_batch_rewards: 1296.76
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 469.71
total_steps: 649000.00
Q-avg: 1067.17, Q-max: 1410.26, Q-min: -9.60
Q_loss1: 680.23, Q_loss2: 554.84, min_Q_loss1: -231.16, min_Q_loss2: -225.58

Train epoch 649/3000 -- step 650000

[F                                                                                                    
[F[ Model Length ] Epoch: 649 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 649000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 649 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 649649
[ Model Rollout ] Added: 49063 | Model pool: 500000 (max 500000) | Length: 4.9063 | Train rep: 1

Diagnostics -- iteration 650000
real_batch_obs: 1881.60, model_batch_obs: 1966.03
real_batch_act: 201.66, model_batch_act: 189.88
real_batch_rewards: 1419.05, model_batch_rewards: 1641.52
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 688.47
total_steps: 650000.00
Q-avg: 1043.47, Q-max: 1421.70, Q-min: -530.84
Q_loss1: 2299.03, Q_loss2: 2147.28, min_Q_loss1: -402.51, min_Q_loss2: -402.49

Train epoch 650/3000 -- step 651000

[F                                                                                                    
[F[ Model Length ] Epoch: 650 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 650000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 650 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 650650
[ Model Rollout ] Added: 49014 | Model pool: 500000 (max 500000) | Length: 4.9014 | Train rep: 1

Diagnostics -- iteration 651000
real_batch_obs: 1778.98, model_batch_obs: 1809.16
real_batch_act: 199.29, model_batch_act: 181.60
real_batch_rewards: 1426.47, model_batch_rewards: 1324.10
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 360.18
total_steps: 651000.00
Q-avg: 1001.80, Q-max: 1424.42, Q-min: -873.48
Q_loss1: 358.54, Q_loss2: 621.29, min_Q_loss1: -88.61, min_Q_loss2: -94.59

Train epoch 651/3000 -- step 652000

[F                                                                                                    
[F[ Model Length ] Epoch: 651 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 651000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 651 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 651651
[ Model Rollout ] Added: 49003 | Model pool: 500000 (max 500000) | Length: 4.9003 | Train rep: 1

Diagnostics -- iteration 652000
real_batch_obs: 1781.39, model_batch_obs: 1890.86
real_batch_act: 201.94, model_batch_act: 198.46
real_batch_rewards: 1345.88, model_batch_rewards: 1429.52
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 870.22
total_steps: 652000.00
Q-avg: 1001.05, Q-max: 1454.78, Q-min: -137.59
Q_loss1: 2319.45, Q_loss2: 2391.42, min_Q_loss1: -331.26, min_Q_loss2: -329.34

Train epoch 652/3000 -- step 653000

[F                                                                                                    
[F[ Model Length ] Epoch: 652 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 652000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 652 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 652652
[ Model Rollout ] Added: 49090 | Model pool: 500000 (max 500000) | Length: 4.909 | Train rep: 1

Diagnostics -- iteration 653000
real_batch_obs: 1870.31, model_batch_obs: 1965.54
real_batch_act: 212.76, model_batch_act: 194.63
real_batch_rewards: 1352.81, model_batch_rewards: 1344.99
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 620.64
total_steps: 653000.00
Q-avg: 1031.73, Q-max: 1414.11, Q-min: -562.97
Q_loss1: 770.31, Q_loss2: 714.98, min_Q_loss1: -6.89, min_Q_loss2: -8.22

Train epoch 653/3000 -- step 654000

[F                                                                                                    
[F[ Model Length ] Epoch: 653 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 653000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 653 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 653653
[ Model Rollout ] Added: 49040 | Model pool: 500000 (max 500000) | Length: 4.904 | Train rep: 1

Diagnostics -- iteration 654000
real_batch_obs: 1727.18, model_batch_obs: 1954.39
real_batch_act: 193.15, model_batch_act: 193.25
real_batch_rewards: 1338.27, model_batch_rewards: 1407.88
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 1157.34
total_steps: 654000.00
Q-avg: 1016.04, Q-max: 1444.71, Q-min: -258.85
Q_loss1: 234.20, Q_loss2: 229.91, min_Q_loss1: -322.72, min_Q_loss2: -320.75

Train epoch 654/3000 -- step 655000

[F                                                                                                    
[F[ Model Length ] Epoch: 654 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 654000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 654 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 654654
[ Model Rollout ] Added: 49111 | Model pool: 500000 (max 500000) | Length: 4.9111 | Train rep: 1

Diagnostics -- iteration 655000
real_batch_obs: 1988.19, model_batch_obs: 1981.81
real_batch_act: 197.40, model_batch_act: 186.37
real_batch_rewards: 1376.65, model_batch_rewards: 1368.50
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 887.80
total_steps: 655000.00
Q-avg: 1021.16, Q-max: 1424.37, Q-min: -1055.64
Q_loss1: 4805.33, Q_loss2: 4216.86, min_Q_loss1: -223.88, min_Q_loss2: -227.59

Train epoch 655/3000 -- step 656000

[F                                                                                                    
[F[ Model Length ] Epoch: 655 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 655000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 655 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 655655
[ Model Rollout ] Added: 48980 | Model pool: 500000 (max 500000) | Length: 4.898 | Train rep: 1

Diagnostics -- iteration 656000
real_batch_obs: 1909.31, model_batch_obs: 1893.01
real_batch_act: 189.51, model_batch_act: 186.93
real_batch_rewards: 1401.28, model_batch_rewards: 1384.72
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 850.97
total_steps: 656000.00
Q-avg: 969.01, Q-max: 1461.69, Q-min: -459.14
Q_loss1: 768.20, Q_loss2: 601.54, min_Q_loss1: -222.25, min_Q_loss2: -227.42

Train epoch 656/3000 -- step 657000

[F                                                                                                    
[F[ Model Length ] Epoch: 656 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 656000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 656 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 656656
[ Model Rollout ] Added: 49092 | Model pool: 500000 (max 500000) | Length: 4.9092 | Train rep: 1

Diagnostics -- iteration 657000
real_batch_obs: 1942.99, model_batch_obs: 1828.98
real_batch_act: 215.67, model_batch_act: 186.71
real_batch_rewards: 1380.79, model_batch_rewards: 1362.81
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 919.44
total_steps: 657000.00
Q-avg: 1015.46, Q-max: 1429.09, Q-min: -642.38
Q_loss1: 1000.55, Q_loss2: 1221.30, min_Q_loss1: -280.29, min_Q_loss2: -281.60

Train epoch 657/3000 -- step 658000

[F                                                                                                    
[F[ Model Length ] Epoch: 657 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 657000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 657 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 657657
[ Model Rollout ] Added: 49062 | Model pool: 500000 (max 500000) | Length: 4.9062 | Train rep: 1

Diagnostics -- iteration 658000
real_batch_obs: 1736.46, model_batch_obs: 1892.14
real_batch_act: 192.64, model_batch_act: 185.31
real_batch_rewards: 1349.27, model_batch_rewards: 1325.14
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 865.19
total_steps: 658000.00
Q-avg: 1013.32, Q-max: 1436.90, Q-min: -367.84
Q_loss1: 636.91, Q_loss2: 512.18, min_Q_loss1: -311.52, min_Q_loss2: -308.12

Train epoch 658/3000 -- step 659000

[F                                                                                                    
[F[ Model Length ] Epoch: 658 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 658000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 658 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 658658
[ Model Rollout ] Added: 48995 | Model pool: 500000 (max 500000) | Length: 4.8995 | Train rep: 1

Diagnostics -- iteration 659000
real_batch_obs: 1683.18, model_batch_obs: 1893.55
real_batch_act: 193.12, model_batch_act: 194.91
real_batch_rewards: 1327.68, model_batch_rewards: 1382.86
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 836.07
total_steps: 659000.00
Q-avg: 1023.28, Q-max: 1447.68, Q-min: -405.77
Q_loss1: 952.08, Q_loss2: 276.38, min_Q_loss1: -58.36, min_Q_loss2: -76.77

Train epoch 659/3000 -- step 660000

[F                                                                                                    
[F[ Model Length ] Epoch: 659 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 659000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 659 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 659659
[ Model Rollout ] Added: 49099 | Model pool: 500000 (max 500000) | Length: 4.9099 | Train rep: 1

Diagnostics -- iteration 660000
real_batch_obs: 1930.95, model_batch_obs: 1984.91
real_batch_act: 203.94, model_batch_act: 195.56
real_batch_rewards: 1339.50, model_batch_rewards: 1362.23
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 1039.46
total_steps: 660000.00
Q-avg: 1006.22, Q-max: 1440.93, Q-min: -766.30
Q_loss1: 3141.72, Q_loss2: 3256.23, min_Q_loss1: -220.78, min_Q_loss2: -221.03

Train epoch 660/3000 -- step 661000

[F                                                                                                    
[F[ Model Length ] Epoch: 660 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 660000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 660 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 660660
[ Model Rollout ] Added: 49064 | Model pool: 500000 (max 500000) | Length: 4.9064 | Train rep: 1

Diagnostics -- iteration 661000
real_batch_obs: 1771.49, model_batch_obs: 1807.97
real_batch_act: 195.17, model_batch_act: 182.07
real_batch_rewards: 1275.92, model_batch_rewards: 1332.24
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 839.18
total_steps: 661000.00
Q-avg: 1008.26, Q-max: 1439.27, Q-min: -387.78
Q_loss1: 778.60, Q_loss2: 593.63, min_Q_loss1: -89.58, min_Q_loss2: -77.58

Train epoch 661/3000 -- step 662000

[F                                                                                                    
[F[ Model Length ] Epoch: 661 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 661000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 661 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 661661
[ Model Rollout ] Added: 49053 | Model pool: 500000 (max 500000) | Length: 4.9053 | Train rep: 1

Diagnostics -- iteration 662000
real_batch_obs: 1674.97, model_batch_obs: 1943.75
real_batch_act: 208.31, model_batch_act: 189.54
real_batch_rewards: 1273.03, model_batch_rewards: 1390.91
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 1773.31
total_steps: 662000.00
Q-avg: 1032.97, Q-max: 1446.66, Q-min: -614.51
Q_loss1: 293.42, Q_loss2: 280.99, min_Q_loss1: -407.20, min_Q_loss2: -401.14

Train epoch 662/3000 -- step 663000

[F                                                                                                    
[F[ Model Length ] Epoch: 662 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 662000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 662 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 662662
[ Model Rollout ] Added: 49074 | Model pool: 500000 (max 500000) | Length: 4.9074 | Train rep: 1

Diagnostics -- iteration 663000
real_batch_obs: 1903.86, model_batch_obs: 1848.72
real_batch_act: 198.35, model_batch_act: 194.72
real_batch_rewards: 1352.82, model_batch_rewards: 1348.59
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 1929.01
total_steps: 663000.00
Q-avg: 1004.72, Q-max: 1451.10, Q-min: -279.88
Q_loss1: 1185.56, Q_loss2: 1112.60, min_Q_loss1: -212.83, min_Q_loss2: -208.96

Train epoch 663/3000 -- step 664000

[F                                                                                                    
[F[ Model Length ] Epoch: 663 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 663000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 663 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 663663
[ Model Rollout ] Added: 49029 | Model pool: 500000 (max 500000) | Length: 4.9029 | Train rep: 1

Diagnostics -- iteration 664000
real_batch_obs: 1845.00, model_batch_obs: 1871.93
real_batch_act: 197.99, model_batch_act: 193.78
real_batch_rewards: 1337.65, model_batch_rewards: 1410.20
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 863.02
total_steps: 664000.00
Q-avg: 1044.13, Q-max: 1461.18, Q-min: -177.86
Q_loss1: 3435.39, Q_loss2: 3282.05, min_Q_loss1: -402.82, min_Q_loss2: -400.99

Train epoch 664/3000 -- step 665000

[F                                                                                                    
[F[ Model Length ] Epoch: 664 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 664000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 664 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 664664
[ Model Rollout ] Added: 49054 | Model pool: 500000 (max 500000) | Length: 4.9054 | Train rep: 1

Diagnostics -- iteration 665000
real_batch_obs: 1814.14, model_batch_obs: 1884.99
real_batch_act: 195.00, model_batch_act: 189.48
real_batch_rewards: 1332.98, model_batch_rewards: 1291.56
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 927.03
total_steps: 665000.00
Q-avg: 1016.79, Q-max: 1439.64, Q-min: -728.79
Q_loss1: 319.86, Q_loss2: 279.13, min_Q_loss1: -112.65, min_Q_loss2: -107.27

Train epoch 665/3000 -- step 666000

[F                                                                                                    
[F[ Model Length ] Epoch: 665 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 665000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 665 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 665665
[ Model Rollout ] Added: 49118 | Model pool: 500000 (max 500000) | Length: 4.9118 | Train rep: 1

Diagnostics -- iteration 666000
real_batch_obs: 1849.22, model_batch_obs: 1867.97
real_batch_act: 197.11, model_batch_act: 189.09
real_batch_rewards: 1365.39, model_batch_rewards: 1430.76
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 482.36
total_steps: 666000.00
Q-avg: 1052.91, Q-max: 1455.71, Q-min: -751.14
Q_loss1: 484.37, Q_loss2: 768.16, min_Q_loss1: -288.17, min_Q_loss2: -286.49

Train epoch 666/3000 -- step 667000

[F                                                                                                    
[F[ Model Length ] Epoch: 666 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 666000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 666 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 666666
[ Model Rollout ] Added: 48997 | Model pool: 500000 (max 500000) | Length: 4.8997 | Train rep: 1

Diagnostics -- iteration 667000
real_batch_obs: 1830.00, model_batch_obs: 1855.20
real_batch_act: 191.10, model_batch_act: 193.79
real_batch_rewards: 1350.99, model_batch_rewards: 1532.22
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 1531.17
total_steps: 667000.00
Q-avg: 1017.02, Q-max: 1456.56, Q-min: -1119.05
Q_loss1: 13889.04, Q_loss2: 17365.66, min_Q_loss1: -396.49, min_Q_loss2: -387.44

Train epoch 667/3000 -- step 668000

[F                                                                                                    
[F[ Model Length ] Epoch: 667 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 667000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 667 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 667667
[ Model Rollout ] Added: 48981 | Model pool: 500000 (max 500000) | Length: 4.8981 | Train rep: 1

Diagnostics -- iteration 668000
real_batch_obs: 1836.12, model_batch_obs: 1908.74
real_batch_act: 193.06, model_batch_act: 192.61
real_batch_rewards: 1384.15, model_batch_rewards: 1373.94
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 1797.79
total_steps: 668000.00
Q-avg: 1021.59, Q-max: 1457.73, Q-min: -378.36
Q_loss1: 3768.22, Q_loss2: 3435.63, min_Q_loss1: -175.54, min_Q_loss2: -178.54

Train epoch 668/3000 -- step 669000

[F                                                                                                    
[F[ Model Length ] Epoch: 668 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 668000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 668 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 668668
[ Model Rollout ] Added: 48998 | Model pool: 500000 (max 500000) | Length: 4.8998 | Train rep: 1

Diagnostics -- iteration 669000
real_batch_obs: 1850.05, model_batch_obs: 1935.02
real_batch_act: 209.83, model_batch_act: 190.18
real_batch_rewards: 1368.25, model_batch_rewards: 1298.53
real_batch_dones: 2.00, model_batch_dones: 1.00
evaluation/return-average: 2087.81
total_steps: 669000.00
Q-avg: 990.13, Q-max: 1458.35, Q-min: -389.96
Q_loss1: 262.65, Q_loss2: 296.65, min_Q_loss1: 1.05, min_Q_loss2: 3.53

Train epoch 669/3000 -- step 670000

[F                                                                                                    
[F[ Model Length ] Epoch: 669 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 669000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 669 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 669669
[ Model Rollout ] Added: 49044 | Model pool: 500000 (max 500000) | Length: 4.9044 | Train rep: 1

Diagnostics -- iteration 670000
real_batch_obs: 1874.37, model_batch_obs: 1866.31
real_batch_act: 214.39, model_batch_act: 187.80
real_batch_rewards: 1329.15, model_batch_rewards: 1405.69
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 936.54
total_steps: 670000.00
Q-avg: 1025.68, Q-max: 1437.70, Q-min: -200.60
Q_loss1: 544.58, Q_loss2: 524.02, min_Q_loss1: -499.19, min_Q_loss2: -499.16

Train epoch 670/3000 -- step 671000

[F                                                                                                    
[F[ Model Length ] Epoch: 670 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 670000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 670 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 670670
[ Model Rollout ] Added: 48996 | Model pool: 500000 (max 500000) | Length: 4.8996 | Train rep: 1

Diagnostics -- iteration 671000
real_batch_obs: 1823.22, model_batch_obs: 1986.64
real_batch_act: 205.72, model_batch_act: 191.31
real_batch_rewards: 1324.33, model_batch_rewards: 1525.78
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 1196.49
total_steps: 671000.00
Q-avg: 1055.07, Q-max: 1443.43, Q-min: -733.46
Q_loss1: 3059.20, Q_loss2: 3828.64, min_Q_loss1: -368.60, min_Q_loss2: -363.87

Train epoch 671/3000 -- step 672000

[F                                                                                                    
[F[ Model Length ] Epoch: 671 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 671000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 671 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 671671
[ Model Rollout ] Added: 48982 | Model pool: 500000 (max 500000) | Length: 4.8982 | Train rep: 1

Diagnostics -- iteration 672000
real_batch_obs: 1774.72, model_batch_obs: 1936.62
real_batch_act: 193.32, model_batch_act: 180.27
real_batch_rewards: 1315.46, model_batch_rewards: 1357.34
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 2529.22
total_steps: 672000.00
Q-avg: 1043.81, Q-max: 1430.82, Q-min: -172.63
Q_loss1: 1558.46, Q_loss2: 1625.14, min_Q_loss1: -314.94, min_Q_loss2: -317.95

Train epoch 672/3000 -- step 673000

[F                                                                                                    
[F[ Model Length ] Epoch: 672 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 672000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 672 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 672672
[ Model Rollout ] Added: 49032 | Model pool: 500000 (max 500000) | Length: 4.9032 | Train rep: 1

Diagnostics -- iteration 673000
real_batch_obs: 1921.20, model_batch_obs: 1896.10
real_batch_act: 204.74, model_batch_act: 196.59
real_batch_rewards: 1387.04, model_batch_rewards: 1347.83
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 841.24
total_steps: 673000.00
Q-avg: 1019.76, Q-max: 1458.97, Q-min: -930.86
Q_loss1: 692.21, Q_loss2: 652.21, min_Q_loss1: -300.14, min_Q_loss2: -299.19

Train epoch 673/3000 -- step 674000

[F                                                                                                    
[F[ Model Length ] Epoch: 673 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 673000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 673 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 673673
[ Model Rollout ] Added: 49070 | Model pool: 500000 (max 500000) | Length: 4.907 | Train rep: 1

Diagnostics -- iteration 674000
real_batch_obs: 1842.04, model_batch_obs: 1880.35
real_batch_act: 205.56, model_batch_act: 196.19
real_batch_rewards: 1347.80, model_batch_rewards: 1315.61
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 1109.67
total_steps: 674000.00
Q-avg: 1026.67, Q-max: 1423.60, Q-min: -1155.52
Q_loss1: 2145.41, Q_loss2: 2866.69, min_Q_loss1: -96.00, min_Q_loss2: -93.65

Train epoch 674/3000 -- step 675000

[F                                                                                                    
[F[ Model Length ] Epoch: 674 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 674000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 674 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 674674
[ Model Rollout ] Added: 48959 | Model pool: 500000 (max 500000) | Length: 4.8959 | Train rep: 1

Diagnostics -- iteration 675000
real_batch_obs: 1887.13, model_batch_obs: 1923.80
real_batch_act: 208.07, model_batch_act: 187.36
real_batch_rewards: 1419.76, model_batch_rewards: 1274.56
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 984.83
total_steps: 675000.00
Q-avg: 1007.11, Q-max: 1411.74, Q-min: -478.70
Q_loss1: 631.05, Q_loss2: 619.25, min_Q_loss1: -61.32, min_Q_loss2: -56.01

Train epoch 675/3000 -- step 676000

[F                                                                                                    
[F[ Model Length ] Epoch: 675 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 675000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 675 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 675675
[ Model Rollout ] Added: 49035 | Model pool: 500000 (max 500000) | Length: 4.9035 | Train rep: 1

Diagnostics -- iteration 676000
real_batch_obs: 1815.05, model_batch_obs: 1951.84
real_batch_act: 191.85, model_batch_act: 186.21
real_batch_rewards: 1358.84, model_batch_rewards: 1422.54
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 926.70
total_steps: 676000.00
Q-avg: 995.87, Q-max: 1415.22, Q-min: -942.89
Q_loss1: 494.39, Q_loss2: 316.80, min_Q_loss1: -407.89, min_Q_loss2: -419.46

Train epoch 676/3000 -- step 677000

[F                                                                                                    
[F[ Model Length ] Epoch: 676 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 676000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 676 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 676676
[ Model Rollout ] Added: 49029 | Model pool: 500000 (max 500000) | Length: 4.9029 | Train rep: 1

Diagnostics -- iteration 677000
real_batch_obs: 1796.45, model_batch_obs: 1891.81
real_batch_act: 205.81, model_batch_act: 190.51
real_batch_rewards: 1353.81, model_batch_rewards: 1330.42
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 975.99
total_steps: 677000.00
Q-avg: 999.51, Q-max: 1416.93, Q-min: -164.04
Q_loss1: 276.65, Q_loss2: 300.08, min_Q_loss1: -246.05, min_Q_loss2: -242.43

Train epoch 677/3000 -- step 678000

[F                                                                                                    
[F[ Model Length ] Epoch: 677 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 677000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 677 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 677677
[ Model Rollout ] Added: 49006 | Model pool: 500000 (max 500000) | Length: 4.9006 | Train rep: 1

Diagnostics -- iteration 678000
real_batch_obs: 1798.34, model_batch_obs: 1914.63
real_batch_act: 200.20, model_batch_act: 195.78
real_batch_rewards: 1311.98, model_batch_rewards: 1334.55
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 932.16
total_steps: 678000.00
Q-avg: 997.77, Q-max: 1440.65, Q-min: -442.26
Q_loss1: 631.32, Q_loss2: 588.63, min_Q_loss1: -312.10, min_Q_loss2: -310.47

Train epoch 678/3000 -- step 679000

[F                                                                                                    
[F[ Model Length ] Epoch: 678 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 678000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 678 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 678678
[ Model Rollout ] Added: 49041 | Model pool: 500000 (max 500000) | Length: 4.9041 | Train rep: 1

Diagnostics -- iteration 679000
real_batch_obs: 1799.01, model_batch_obs: 1833.70
real_batch_act: 199.85, model_batch_act: 196.68
real_batch_rewards: 1332.53, model_batch_rewards: 1349.18
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 941.94
total_steps: 679000.00
Q-avg: 1002.64, Q-max: 1422.58, Q-min: -388.62
Q_loss1: 561.21, Q_loss2: 461.87, min_Q_loss1: -375.72, min_Q_loss2: -379.97

Train epoch 679/3000 -- step 680000

[F                                                                                                    
[F[ Model Length ] Epoch: 679 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 679000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 679 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 679679
[ Model Rollout ] Added: 49045 | Model pool: 500000 (max 500000) | Length: 4.9045 | Train rep: 1

Diagnostics -- iteration 680000
real_batch_obs: 1848.57, model_batch_obs: 1784.39
real_batch_act: 204.59, model_batch_act: 191.63
real_batch_rewards: 1367.41, model_batch_rewards: 1288.42
real_batch_dones: 0.00, model_batch_dones: 5.00
evaluation/return-average: 1979.27
total_steps: 680000.00
Q-avg: 1009.57, Q-max: 1435.92, Q-min: -593.65
Q_loss1: 1141.99, Q_loss2: 1067.34, min_Q_loss1: -295.05, min_Q_loss2: -302.54

Train epoch 680/3000 -- step 681000

[F                                                                                                    
[F[ Model Length ] Epoch: 680 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 680000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 680 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 680680
[ Model Rollout ] Added: 49051 | Model pool: 500000 (max 500000) | Length: 4.9051 | Train rep: 1

Diagnostics -- iteration 681000
real_batch_obs: 1798.97, model_batch_obs: 1954.55
real_batch_act: 184.95, model_batch_act: 206.14
real_batch_rewards: 1401.61, model_batch_rewards: 1394.91
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 996.39
total_steps: 681000.00
Q-avg: 1008.19, Q-max: 1434.96, Q-min: -147.41
Q_loss1: 1921.24, Q_loss2: 1991.15, min_Q_loss1: -261.45, min_Q_loss2: -258.68

Train epoch 681/3000 -- step 682000

[F                                                                                                    
[F[ Model Length ] Epoch: 681 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 681000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 681 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 681681
[ Model Rollout ] Added: 49072 | Model pool: 500000 (max 500000) | Length: 4.9072 | Train rep: 1

Diagnostics -- iteration 682000
real_batch_obs: 1763.67, model_batch_obs: 1854.75
real_batch_act: 198.49, model_batch_act: 194.31
real_batch_rewards: 1337.17, model_batch_rewards: 1284.93
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 2398.14
total_steps: 682000.00
Q-avg: 1025.36, Q-max: 1451.71, Q-min: -739.48
Q_loss1: 1245.48, Q_loss2: 922.56, min_Q_loss1: -46.70, min_Q_loss2: -39.32

Train epoch 682/3000 -- step 683000

[F                                                                                                    
[F[ Model Length ] Epoch: 682 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 682000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 682 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 682682
[ Model Rollout ] Added: 49019 | Model pool: 500000 (max 500000) | Length: 4.9019 | Train rep: 1

Diagnostics -- iteration 683000
real_batch_obs: 1834.97, model_batch_obs: 1899.20
real_batch_act: 194.41, model_batch_act: 181.86
real_batch_rewards: 1332.71, model_batch_rewards: 1326.43
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 2318.71
total_steps: 683000.00
Q-avg: 979.87, Q-max: 1439.36, Q-min: -408.44
Q_loss1: 534.64, Q_loss2: 506.22, min_Q_loss1: -126.52, min_Q_loss2: -118.10

Train epoch 683/3000 -- step 684000

[F                                                                                                    
[F[ Model Length ] Epoch: 683 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 683000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 683 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 683683
[ Model Rollout ] Added: 49083 | Model pool: 500000 (max 500000) | Length: 4.9083 | Train rep: 1

Diagnostics -- iteration 684000
real_batch_obs: 1851.60, model_batch_obs: 1945.41
real_batch_act: 195.58, model_batch_act: 194.78
real_batch_rewards: 1355.02, model_batch_rewards: 1411.34
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 2640.06
total_steps: 684000.00
Q-avg: 998.19, Q-max: 1448.13, Q-min: -2417.10
Q_loss1: 1716.63, Q_loss2: 2951.63, min_Q_loss1: -509.33, min_Q_loss2: -506.01

Train epoch 684/3000 -- step 685000

[F                                                                                                    
[F[ Model Length ] Epoch: 684 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 684000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 684 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 684684
[ Model Rollout ] Added: 49025 | Model pool: 500000 (max 500000) | Length: 4.9025 | Train rep: 1

Diagnostics -- iteration 685000
real_batch_obs: 1938.84, model_batch_obs: 1973.52
real_batch_act: 203.30, model_batch_act: 182.77
real_batch_rewards: 1361.98, model_batch_rewards: 1291.98
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 1310.07
total_steps: 685000.00
Q-avg: 996.23, Q-max: 1430.58, Q-min: -135.61
Q_loss1: 851.98, Q_loss2: 845.21, min_Q_loss1: -192.30, min_Q_loss2: -198.33

Train epoch 685/3000 -- step 686000

[F                                                                                                    
[F[ Model Length ] Epoch: 685 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 685000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 685 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 685685
[ Model Rollout ] Added: 48991 | Model pool: 500000 (max 500000) | Length: 4.8991 | Train rep: 1

Diagnostics -- iteration 686000
real_batch_obs: 1846.78, model_batch_obs: 1821.62
real_batch_act: 205.62, model_batch_act: 189.41
real_batch_rewards: 1356.87, model_batch_rewards: 1342.00
real_batch_dones: 2.00, model_batch_dones: 0.00
evaluation/return-average: 2841.09
total_steps: 686000.00
Q-avg: 995.24, Q-max: 1451.83, Q-min: -906.74
Q_loss1: 1163.17, Q_loss2: 1844.82, min_Q_loss1: -139.54, min_Q_loss2: -151.54

Train epoch 686/3000 -- step 687000

[F                                                                                                    
[F[ Model Length ] Epoch: 686 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 686000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 686 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 686686
[ Model Rollout ] Added: 49171 | Model pool: 500000 (max 500000) | Length: 4.9171 | Train rep: 1

Diagnostics -- iteration 687000
real_batch_obs: 1770.57, model_batch_obs: 1914.93
real_batch_act: 191.17, model_batch_act: 190.05
real_batch_rewards: 1241.51, model_batch_rewards: 1364.94
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 1091.84
total_steps: 687000.00
Q-avg: 1044.14, Q-max: 1460.87, Q-min: -150.88
Q_loss1: 575.90, Q_loss2: 382.55, min_Q_loss1: -483.04, min_Q_loss2: -482.75

Train epoch 687/3000 -- step 688000

[F                                                                                                    
[F[ Model Length ] Epoch: 687 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 687000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 687 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 687687
[ Model Rollout ] Added: 49018 | Model pool: 500000 (max 500000) | Length: 4.9018 | Train rep: 1

Diagnostics -- iteration 688000
real_batch_obs: 1741.88, model_batch_obs: 1838.93
real_batch_act: 193.36, model_batch_act: 183.79
real_batch_rewards: 1295.46, model_batch_rewards: 1391.48
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 1553.15
total_steps: 688000.00
Q-avg: 1026.42, Q-max: 1440.74, Q-min: -162.87
Q_loss1: 3603.83, Q_loss2: 3583.94, min_Q_loss1: -321.05, min_Q_loss2: -327.02

Train epoch 688/3000 -- step 689000

[F                                                                                                    
[F[ Model Length ] Epoch: 688 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 688000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 688 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 688688
[ Model Rollout ] Added: 49036 | Model pool: 500000 (max 500000) | Length: 4.9036 | Train rep: 1

Diagnostics -- iteration 689000
real_batch_obs: 1741.25, model_batch_obs: 1937.79
real_batch_act: 192.50, model_batch_act: 182.48
real_batch_rewards: 1419.73, model_batch_rewards: 1328.82
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 904.27
total_steps: 689000.00
Q-avg: 996.98, Q-max: 1456.72, Q-min: -205.94
Q_loss1: 262.05, Q_loss2: 215.18, min_Q_loss1: -123.48, min_Q_loss2: -124.34

Train epoch 689/3000 -- step 690000

[F                                                                                                    
[F[ Model Length ] Epoch: 689 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 689000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 689 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 689689
[ Model Rollout ] Added: 49003 | Model pool: 500000 (max 500000) | Length: 4.9003 | Train rep: 1

Diagnostics -- iteration 690000
real_batch_obs: 1786.91, model_batch_obs: 1911.18
real_batch_act: 191.75, model_batch_act: 183.76
real_batch_rewards: 1367.77, model_batch_rewards: 4500.70
real_batch_dones: 1.00, model_batch_dones: 6.00
evaluation/return-average: 1997.13
total_steps: 690000.00
Q-avg: 1030.94, Q-max: 1439.30, Q-min: -5780.03
Q_loss1: 11011.10, Q_loss2: 15536.52, min_Q_loss1: -237.37, min_Q_loss2: -255.99

Train epoch 690/3000 -- step 691000

[F                                                                                                    
[F[ Model Length ] Epoch: 690 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 690000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 690 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 690690
[ Model Rollout ] Added: 48964 | Model pool: 500000 (max 500000) | Length: 4.8964 | Train rep: 1

Diagnostics -- iteration 691000
real_batch_obs: 1902.41, model_batch_obs: 1993.81
real_batch_act: 197.12, model_batch_act: 195.44
real_batch_rewards: 1409.53, model_batch_rewards: 1369.95
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 933.60
total_steps: 691000.00
Q-avg: 963.66, Q-max: 1468.75, Q-min: -213.76
Q_loss1: 327.94, Q_loss2: 307.45, min_Q_loss1: -174.33, min_Q_loss2: -181.46

Train epoch 691/3000 -- step 692000

[F                                                                                                    
[F[ Model Length ] Epoch: 691 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 691000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 691 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 691691
[ Model Rollout ] Added: 49022 | Model pool: 500000 (max 500000) | Length: 4.9022 | Train rep: 1

Diagnostics -- iteration 692000
real_batch_obs: 1768.84, model_batch_obs: 1876.33
real_batch_act: 199.89, model_batch_act: 190.36
real_batch_rewards: 1318.15, model_batch_rewards: 1398.83
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 1099.19
total_steps: 692000.00
Q-avg: 1011.61, Q-max: 1492.35, Q-min: -147.46
Q_loss1: 145.90, Q_loss2: 173.65, min_Q_loss1: -337.65, min_Q_loss2: -332.44

Train epoch 692/3000 -- step 693000

[F                                                                                                    
[F[ Model Length ] Epoch: 692 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 692000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 692 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 692692
[ Model Rollout ] Added: 49082 | Model pool: 500000 (max 500000) | Length: 4.9082 | Train rep: 1

Diagnostics -- iteration 693000
real_batch_obs: 1734.28, model_batch_obs: 1885.33
real_batch_act: 195.51, model_batch_act: 193.70
real_batch_rewards: 1333.92, model_batch_rewards: 1327.83
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 369.67
total_steps: 693000.00
Q-avg: 991.30, Q-max: 1500.75, Q-min: -578.61
Q_loss1: 548.22, Q_loss2: 598.71, min_Q_loss1: -125.55, min_Q_loss2: -131.92

Train epoch 693/3000 -- step 694000

[F                                                                                                    
[F[ Model Length ] Epoch: 693 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 693000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 693 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 693693
[ Model Rollout ] Added: 49021 | Model pool: 500000 (max 500000) | Length: 4.9021 | Train rep: 1

Diagnostics -- iteration 694000
real_batch_obs: 1777.49, model_batch_obs: 1756.43
real_batch_act: 194.03, model_batch_act: 189.10
real_batch_rewards: 1284.12, model_batch_rewards: 1350.32
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 373.15
total_steps: 694000.00
Q-avg: 991.40, Q-max: 1556.92, Q-min: -562.50
Q_loss1: 1315.91, Q_loss2: 1701.36, min_Q_loss1: -420.08, min_Q_loss2: -427.12

Train epoch 694/3000 -- step 695000

[F                                                                                                    
[F[ Model Length ] Epoch: 694 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 694000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 694 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 694694
[ Model Rollout ] Added: 49014 | Model pool: 500000 (max 500000) | Length: 4.9014 | Train rep: 1

Diagnostics -- iteration 695000
real_batch_obs: 1817.66, model_batch_obs: 1893.34
real_batch_act: 193.26, model_batch_act: 188.24
real_batch_rewards: 1297.01, model_batch_rewards: 1292.94
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 356.37
total_steps: 695000.00
Q-avg: 1046.19, Q-max: 1588.69, Q-min: -554.92
Q_loss1: 335.59, Q_loss2: 245.41, min_Q_loss1: -11.42, min_Q_loss2: -6.89

Train epoch 695/3000 -- step 696000

[F                                                                                                    
[F[ Model Length ] Epoch: 695 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 695000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 695 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 695695
[ Model Rollout ] Added: 49019 | Model pool: 500000 (max 500000) | Length: 4.9019 | Train rep: 1

Diagnostics -- iteration 696000
real_batch_obs: 1879.08, model_batch_obs: 2042.26
real_batch_act: 192.87, model_batch_act: 196.30
real_batch_rewards: 1350.19, model_batch_rewards: 1623.50
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 358.55
total_steps: 696000.00
Q-avg: 1024.95, Q-max: 1584.97, Q-min: -512.47
Q_loss1: 2264.83, Q_loss2: 2199.95, min_Q_loss1: -473.35, min_Q_loss2: -469.83

Train epoch 696/3000 -- step 697000

[F                                                                                                    
[F[ Model Length ] Epoch: 696 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 696000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 696 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 696696
[ Model Rollout ] Added: 49023 | Model pool: 500000 (max 500000) | Length: 4.9023 | Train rep: 1

Diagnostics -- iteration 697000
real_batch_obs: 1871.82, model_batch_obs: 1781.45
real_batch_act: 205.13, model_batch_act: 188.22
real_batch_rewards: 1370.81, model_batch_rewards: 1274.97
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 364.04
total_steps: 697000.00
Q-avg: 1015.29, Q-max: 1598.34, Q-min: -279.78
Q_loss1: 740.07, Q_loss2: 651.07, min_Q_loss1: -218.69, min_Q_loss2: -222.07

Train epoch 697/3000 -- step 698000

[F                                                                                                    
[F[ Model Length ] Epoch: 697 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 697000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 697 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 697697
[ Model Rollout ] Added: 49099 | Model pool: 500000 (max 500000) | Length: 4.9099 | Train rep: 1

Diagnostics -- iteration 698000
real_batch_obs: 1923.39, model_batch_obs: 1858.15
real_batch_act: 203.61, model_batch_act: 197.47
real_batch_rewards: 1412.32, model_batch_rewards: 1350.82
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 365.83
total_steps: 698000.00
Q-avg: 1003.87, Q-max: 1578.85, Q-min: -443.52
Q_loss1: 726.89, Q_loss2: 877.64, min_Q_loss1: -58.27, min_Q_loss2: -57.24

Train epoch 698/3000 -- step 699000

[F                                                                                                    
[F[ Model Length ] Epoch: 698 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 698000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 698 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 698698
[ Model Rollout ] Added: 48994 | Model pool: 500000 (max 500000) | Length: 4.8994 | Train rep: 1

Diagnostics -- iteration 699000
real_batch_obs: 1855.19, model_batch_obs: 1819.81
real_batch_act: 207.75, model_batch_act: 194.65
real_batch_rewards: 1441.36, model_batch_rewards: 1374.28
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 376.38
total_steps: 699000.00
Q-avg: 1010.17, Q-max: 1551.87, Q-min: -474.43
Q_loss1: 276.46, Q_loss2: 303.43, min_Q_loss1: -241.57, min_Q_loss2: -232.11

Train epoch 699/3000 -- step 700000

[F                                                                                                    
[F[ Model Length ] Epoch: 699 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 699000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 699 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 699699
[ Model Rollout ] Added: 49032 | Model pool: 500000 (max 500000) | Length: 4.9032 | Train rep: 1

Diagnostics -- iteration 700000
real_batch_obs: 1852.68, model_batch_obs: 1966.87
real_batch_act: 197.72, model_batch_act: 191.69
real_batch_rewards: 1333.46, model_batch_rewards: 1366.77
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 1702.35
total_steps: 700000.00
Q-avg: 1046.89, Q-max: 1541.73, Q-min: -248.72
Q_loss1: 226.35, Q_loss2: 214.65, min_Q_loss1: -469.41, min_Q_loss2: -469.56

Train epoch 700/3000 -- step 701000

[F                                                                                                    
[F[ Model Length ] Epoch: 700 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 700000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 700 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 700700
[ Model Rollout ] Added: 49124 | Model pool: 500000 (max 500000) | Length: 4.9124 | Train rep: 1

Diagnostics -- iteration 701000
real_batch_obs: 1774.78, model_batch_obs: 1877.57
real_batch_act: 209.94, model_batch_act: 202.70
real_batch_rewards: 1263.70, model_batch_rewards: 1307.34
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 1427.00
total_steps: 701000.00
Q-avg: 1069.66, Q-max: 1530.12, Q-min: -988.41
Q_loss1: 529.04, Q_loss2: 1065.00, min_Q_loss1: -170.45, min_Q_loss2: -164.59

Train epoch 701/3000 -- step 702000

[F                                                                                                    
[F[ Model Length ] Epoch: 701 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 701000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 701 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 701701
[ Model Rollout ] Added: 49105 | Model pool: 500000 (max 500000) | Length: 4.9105 | Train rep: 1

Diagnostics -- iteration 702000
real_batch_obs: 1775.92, model_batch_obs: 1929.61
real_batch_act: 201.80, model_batch_act: 191.62
real_batch_rewards: 1318.22, model_batch_rewards: 1333.65
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 2719.77
total_steps: 702000.00
Q-avg: 1027.64, Q-max: 1487.40, Q-min: -210.73
Q_loss1: 1899.59, Q_loss2: 1827.52, min_Q_loss1: -511.07, min_Q_loss2: -512.62

Train epoch 702/3000 -- step 703000

[F                                                                                                    
[F[ Model Length ] Epoch: 702 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 702000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 702 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 702702
[ Model Rollout ] Added: 49032 | Model pool: 500000 (max 500000) | Length: 4.9032 | Train rep: 1

Diagnostics -- iteration 703000
real_batch_obs: 1814.41, model_batch_obs: 1843.87
real_batch_act: 197.18, model_batch_act: 180.45
real_batch_rewards: 1368.88, model_batch_rewards: 1333.26
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 2710.56
total_steps: 703000.00
Q-avg: 1025.27, Q-max: 1476.44, Q-min: -469.45
Q_loss1: 2735.53, Q_loss2: 2722.21, min_Q_loss1: -33.44, min_Q_loss2: -37.27

Train epoch 703/3000 -- step 704000

[F                                                                                                    
[F[ Model Length ] Epoch: 703 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 703000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 703 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 703703
[ Model Rollout ] Added: 49036 | Model pool: 500000 (max 500000) | Length: 4.9036 | Train rep: 1

Diagnostics -- iteration 704000
real_batch_obs: 1885.50, model_batch_obs: 1921.10
real_batch_act: 197.27, model_batch_act: 193.13
real_batch_rewards: 1336.65, model_batch_rewards: 1265.27
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 2680.74
total_steps: 704000.00
Q-avg: 1066.36, Q-max: 1474.46, Q-min: -444.32
Q_loss1: 375.54, Q_loss2: 419.26, min_Q_loss1: -385.68, min_Q_loss2: -386.32

Train epoch 704/3000 -- step 705000

[F                                                                                                    
[F[ Model Length ] Epoch: 704 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 704000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 704 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 704704
[ Model Rollout ] Added: 48972 | Model pool: 500000 (max 500000) | Length: 4.8972 | Train rep: 1

Diagnostics -- iteration 705000
real_batch_obs: 1826.40, model_batch_obs: 1902.84
real_batch_act: 202.70, model_batch_act: 187.83
real_batch_rewards: 1353.82, model_batch_rewards: 1310.62
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 2689.45
total_steps: 705000.00
Q-avg: 1025.90, Q-max: 1434.78, Q-min: -383.72
Q_loss1: 450.86, Q_loss2: 378.81, min_Q_loss1: -235.12, min_Q_loss2: -229.93

Train epoch 705/3000 -- step 706000

[F                                                                                                    
[F[ Model Length ] Epoch: 705 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 705000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 705 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 705705
[ Model Rollout ] Added: 48997 | Model pool: 500000 (max 500000) | Length: 4.8997 | Train rep: 1

Diagnostics -- iteration 706000
real_batch_obs: 1879.97, model_batch_obs: 1942.72
real_batch_act: 203.69, model_batch_act: 184.71
real_batch_rewards: 1316.60, model_batch_rewards: 1376.66
real_batch_dones: 2.00, model_batch_dones: 1.00
evaluation/return-average: 1081.79
total_steps: 706000.00
Q-avg: 1019.60, Q-max: 1451.66, Q-min: -996.00
Q_loss1: 9152.16, Q_loss2: 9873.37, min_Q_loss1: -495.52, min_Q_loss2: -490.14

Train epoch 706/3000 -- step 707000

[F                                                                                                    
[F[ Model Length ] Epoch: 706 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 706000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 706 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 706706
[ Model Rollout ] Added: 48987 | Model pool: 500000 (max 500000) | Length: 4.8987 | Train rep: 1

Diagnostics -- iteration 707000
real_batch_obs: 1830.23, model_batch_obs: 1791.93
real_batch_act: 201.29, model_batch_act: 187.02
real_batch_rewards: 1406.99, model_batch_rewards: 1329.91
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 974.54
total_steps: 707000.00
Q-avg: 1045.31, Q-max: 1445.28, Q-min: -418.09
Q_loss1: 237.53, Q_loss2: 184.83, min_Q_loss1: -107.59, min_Q_loss2: -111.68

Train epoch 707/3000 -- step 708000

[F                                                                                                    
[F[ Model Length ] Epoch: 707 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 707000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 707 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 707707
[ Model Rollout ] Added: 49106 | Model pool: 500000 (max 500000) | Length: 4.9106 | Train rep: 1

Diagnostics -- iteration 708000
real_batch_obs: 1888.33, model_batch_obs: 1877.70
real_batch_act: 195.89, model_batch_act: 192.08
real_batch_rewards: 1326.57, model_batch_rewards: 1375.88
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 1166.02
total_steps: 708000.00
Q-avg: 1052.70, Q-max: 1454.43, Q-min: -369.04
Q_loss1: 2891.63, Q_loss2: 2712.04, min_Q_loss1: -321.99, min_Q_loss2: -319.80

Train epoch 708/3000 -- step 709000

[F                                                                                                    
[F[ Model Length ] Epoch: 708 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 708000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 708 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 708708
[ Model Rollout ] Added: 49028 | Model pool: 500000 (max 500000) | Length: 4.9028 | Train rep: 1

Diagnostics -- iteration 709000
real_batch_obs: 1874.16, model_batch_obs: 1968.76
real_batch_act: 206.07, model_batch_act: 188.25
real_batch_rewards: 1370.49, model_batch_rewards: 1312.16
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 2669.99
total_steps: 709000.00
Q-avg: 1045.85, Q-max: 1470.02, Q-min: -136.75
Q_loss1: 509.16, Q_loss2: 488.21, min_Q_loss1: -243.82, min_Q_loss2: -242.56

Train epoch 709/3000 -- step 710000

[F                                                                                                    
[F[ Model Length ] Epoch: 709 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 709000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 709 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 709709
[ Model Rollout ] Added: 48920 | Model pool: 500000 (max 500000) | Length: 4.892 | Train rep: 1

Diagnostics -- iteration 710000
real_batch_obs: 1827.26, model_batch_obs: 1843.77
real_batch_act: 201.24, model_batch_act: 195.64
real_batch_rewards: 1258.17, model_batch_rewards: 1355.32
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 1022.04
total_steps: 710000.00
Q-avg: 1024.93, Q-max: 1502.09, Q-min: -37.65
Q_loss1: 762.65, Q_loss2: 748.24, min_Q_loss1: -409.29, min_Q_loss2: -422.03

Train epoch 710/3000 -- step 711000

[F                                                                                                    
[F[ Model Length ] Epoch: 710 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 710000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 710 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 710710
[ Model Rollout ] Added: 49075 | Model pool: 500000 (max 500000) | Length: 4.9075 | Train rep: 1

Diagnostics -- iteration 711000
real_batch_obs: 1948.31, model_batch_obs: 1886.81
real_batch_act: 213.81, model_batch_act: 189.24
real_batch_rewards: 1349.17, model_batch_rewards: 1577.34
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 2873.28
total_steps: 711000.00
Q-avg: 1054.85, Q-max: 1469.65, Q-min: -1087.04
Q_loss1: 1193.23, Q_loss2: 1819.00, min_Q_loss1: -138.39, min_Q_loss2: -153.33

Train epoch 711/3000 -- step 712000

[F                                                                                                    
[F[ Model Length ] Epoch: 711 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 711000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 711 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 711711
[ Model Rollout ] Added: 48976 | Model pool: 500000 (max 500000) | Length: 4.8976 | Train rep: 1

Diagnostics -- iteration 712000
real_batch_obs: 1806.29, model_batch_obs: 1910.26
real_batch_act: 182.00, model_batch_act: 197.63
real_batch_rewards: 1338.66, model_batch_rewards: 1337.93
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 2927.38
total_steps: 712000.00
Q-avg: 1062.31, Q-max: 1462.06, Q-min: -274.18
Q_loss1: 275.87, Q_loss2: 256.18, min_Q_loss1: -364.35, min_Q_loss2: -372.06

Train epoch 712/3000 -- step 713000

[F                                                                                                    
[F[ Model Length ] Epoch: 712 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 712000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 712 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 712712
[ Model Rollout ] Added: 48983 | Model pool: 500000 (max 500000) | Length: 4.8983 | Train rep: 1

Diagnostics -- iteration 713000
real_batch_obs: 1781.06, model_batch_obs: 1943.01
real_batch_act: 197.23, model_batch_act: 194.65
real_batch_rewards: 1304.06, model_batch_rewards: 1340.35
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 2874.58
total_steps: 713000.00
Q-avg: 1028.32, Q-max: 1487.62, Q-min: -525.84
Q_loss1: 732.93, Q_loss2: 795.73, min_Q_loss1: -307.72, min_Q_loss2: -312.67

Train epoch 713/3000 -- step 714000

[F                                                                                                    
[F[ Model Length ] Epoch: 713 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 713000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 713 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 713713
[ Model Rollout ] Added: 49047 | Model pool: 500000 (max 500000) | Length: 4.9047 | Train rep: 1

Diagnostics -- iteration 714000
real_batch_obs: 1751.10, model_batch_obs: 1861.74
real_batch_act: 199.69, model_batch_act: 186.68
real_batch_rewards: 1359.66, model_batch_rewards: 1367.88
real_batch_dones: 2.00, model_batch_dones: 3.00
evaluation/return-average: 2716.07
total_steps: 714000.00
Q-avg: 1011.57, Q-max: 1482.10, Q-min: -58.02
Q_loss1: 206.30, Q_loss2: 175.76, min_Q_loss1: -114.98, min_Q_loss2: -118.94

Train epoch 714/3000 -- step 715000

[F                                                                                                    
[F[ Model Length ] Epoch: 714 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 714000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 714 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 714714
[ Model Rollout ] Added: 49025 | Model pool: 500000 (max 500000) | Length: 4.9025 | Train rep: 1

Diagnostics -- iteration 715000
real_batch_obs: 1796.09, model_batch_obs: 1859.11
real_batch_act: 190.62, model_batch_act: 193.99
real_batch_rewards: 1306.70, model_batch_rewards: 1356.74
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 2782.63
total_steps: 715000.00
Q-avg: 1074.86, Q-max: 1503.31, Q-min: -121.51
Q_loss1: 240.90, Q_loss2: 206.07, min_Q_loss1: -175.87, min_Q_loss2: -177.01

Train epoch 715/3000 -- step 716000

[F                                                                                                    
[F[ Model Length ] Epoch: 715 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 715000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 715 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 715715
[ Model Rollout ] Added: 49040 | Model pool: 500000 (max 500000) | Length: 4.904 | Train rep: 1

Diagnostics -- iteration 716000
real_batch_obs: 1857.19, model_batch_obs: 1946.38
real_batch_act: 194.69, model_batch_act: 198.79
real_batch_rewards: 1337.44, model_batch_rewards: 1350.93
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 2767.36
total_steps: 716000.00
Q-avg: 1053.64, Q-max: 1488.30, Q-min: -341.31
Q_loss1: 1594.60, Q_loss2: 1744.71, min_Q_loss1: -223.71, min_Q_loss2: -224.25

Train epoch 716/3000 -- step 717000

[F                                                                                                    
[F[ Model Length ] Epoch: 716 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 716000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 716 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 716716
[ Model Rollout ] Added: 49011 | Model pool: 500000 (max 500000) | Length: 4.9011 | Train rep: 1

Diagnostics -- iteration 717000
real_batch_obs: 1869.33, model_batch_obs: 1838.99
real_batch_act: 200.37, model_batch_act: 190.71
real_batch_rewards: 1367.70, model_batch_rewards: 1298.27
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 2796.38
total_steps: 717000.00
Q-avg: 1034.44, Q-max: 1471.75, Q-min: -496.03
Q_loss1: 439.21, Q_loss2: 471.25, min_Q_loss1: -149.82, min_Q_loss2: -159.73

Train epoch 717/3000 -- step 718000

[F                                                                                                    
[F[ Model Length ] Epoch: 717 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 717000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 717 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 717717
[ Model Rollout ] Added: 49039 | Model pool: 500000 (max 500000) | Length: 4.9039 | Train rep: 1

Diagnostics -- iteration 718000
real_batch_obs: 1746.03, model_batch_obs: 1918.01
real_batch_act: 193.85, model_batch_act: 195.71
real_batch_rewards: 1290.23, model_batch_rewards: 1340.45
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 2749.71
total_steps: 718000.00
Q-avg: 1038.76, Q-max: 1478.86, Q-min: -287.88
Q_loss1: 441.83, Q_loss2: 446.68, min_Q_loss1: -290.97, min_Q_loss2: -288.78

Train epoch 718/3000 -- step 719000

[F                                                                                                    
[F[ Model Length ] Epoch: 718 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 718000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 718 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 718718
[ Model Rollout ] Added: 49028 | Model pool: 500000 (max 500000) | Length: 4.9028 | Train rep: 1

Diagnostics -- iteration 719000
real_batch_obs: 1815.92, model_batch_obs: 1948.12
real_batch_act: 202.88, model_batch_act: 182.33
real_batch_rewards: 1321.28, model_batch_rewards: 1421.80
real_batch_dones: 2.00, model_batch_dones: 3.00
evaluation/return-average: 2726.28
total_steps: 719000.00
Q-avg: 1014.57, Q-max: 1460.67, Q-min: -399.52
Q_loss1: 178.53, Q_loss2: 165.78, min_Q_loss1: -393.97, min_Q_loss2: -394.09

Train epoch 719/3000 -- step 720000

[F                                                                                                    
[F[ Model Length ] Epoch: 719 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 719000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 719 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 719719
[ Model Rollout ] Added: 49018 | Model pool: 500000 (max 500000) | Length: 4.9018 | Train rep: 1

Diagnostics -- iteration 720000
real_batch_obs: 1813.70, model_batch_obs: 1805.51
real_batch_act: 183.54, model_batch_act: 195.85
real_batch_rewards: 1268.71, model_batch_rewards: 1390.43
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 2781.28
total_steps: 720000.00
Q-avg: 1087.03, Q-max: 1451.49, Q-min: -561.85
Q_loss1: 436.31, Q_loss2: 380.31, min_Q_loss1: -631.49, min_Q_loss2: -631.97

Train epoch 720/3000 -- step 721000

[F                                                                                                    
[F[ Model Length ] Epoch: 720 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 720000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 720 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 720720
[ Model Rollout ] Added: 48994 | Model pool: 500000 (max 500000) | Length: 4.8994 | Train rep: 1

Diagnostics -- iteration 721000
real_batch_obs: 1837.06, model_batch_obs: 1881.91
real_batch_act: 196.66, model_batch_act: 190.05
real_batch_rewards: 1434.28, model_batch_rewards: 1273.82
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 2696.81
total_steps: 721000.00
Q-avg: 1034.31, Q-max: 1480.35, Q-min: -350.14
Q_loss1: 2579.34, Q_loss2: 2522.05, min_Q_loss1: -53.92, min_Q_loss2: -44.45

Train epoch 721/3000 -- step 722000

[F                                                                                                    
[F[ Model Length ] Epoch: 721 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 721000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 721 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 721721
[ Model Rollout ] Added: 48938 | Model pool: 500000 (max 500000) | Length: 4.8938 | Train rep: 1

Diagnostics -- iteration 722000
real_batch_obs: 1973.56, model_batch_obs: 1860.91
real_batch_act: 202.55, model_batch_act: 192.39
real_batch_rewards: 1333.80, model_batch_rewards: 1382.21
real_batch_dones: 2.00, model_batch_dones: 0.00
evaluation/return-average: 2921.62
total_steps: 722000.00
Q-avg: 1030.98, Q-max: 1458.81, Q-min: -795.21
Q_loss1: 456.29, Q_loss2: 456.49, min_Q_loss1: -166.68, min_Q_loss2: -170.39

Train epoch 722/3000 -- step 723000

[F                                                                                                    
[F[ Model Length ] Epoch: 722 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 722000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 722 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 722722
[ Model Rollout ] Added: 49088 | Model pool: 500000 (max 500000) | Length: 4.9088 | Train rep: 1

Diagnostics -- iteration 723000
real_batch_obs: 1850.91, model_batch_obs: 2001.49
real_batch_act: 206.86, model_batch_act: 190.81
real_batch_rewards: 1266.80, model_batch_rewards: 1418.39
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 2882.06
total_steps: 723000.00
Q-avg: 1035.87, Q-max: 1472.27, Q-min: -420.05
Q_loss1: 1131.87, Q_loss2: 1339.99, min_Q_loss1: -388.16, min_Q_loss2: -390.70

Train epoch 723/3000 -- step 724000

[F                                                                                                    
[F[ Model Length ] Epoch: 723 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 723000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 723 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 723723
[ Model Rollout ] Added: 49050 | Model pool: 500000 (max 500000) | Length: 4.905 | Train rep: 1

Diagnostics -- iteration 724000
real_batch_obs: 1866.95, model_batch_obs: 1828.92
real_batch_act: 209.10, model_batch_act: 188.18
real_batch_rewards: 1404.19, model_batch_rewards: 1284.59
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 2721.50
total_steps: 724000.00
Q-avg: 1072.40, Q-max: 1489.44, Q-min: -61.85
Q_loss1: 3014.12, Q_loss2: 2954.81, min_Q_loss1: -341.66, min_Q_loss2: -344.72

Train epoch 724/3000 -- step 725000

[F                                                                                                    
[F[ Model Length ] Epoch: 724 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 724000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 724 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 724724
[ Model Rollout ] Added: 48986 | Model pool: 500000 (max 500000) | Length: 4.8986 | Train rep: 1

Diagnostics -- iteration 725000
real_batch_obs: 1815.82, model_batch_obs: 1898.47
real_batch_act: 198.40, model_batch_act: 181.84
real_batch_rewards: 1309.75, model_batch_rewards: 1329.26
real_batch_dones: 2.00, model_batch_dones: 1.00
evaluation/return-average: 3015.89
total_steps: 725000.00
Q-avg: 1041.17, Q-max: 1470.04, Q-min: -177.07
Q_loss1: 798.70, Q_loss2: 898.55, min_Q_loss1: -292.40, min_Q_loss2: -295.56

Train epoch 725/3000 -- step 726000

[F                                                                                                    
[F[ Model Length ] Epoch: 725 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 725000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 725 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 725725
[ Model Rollout ] Added: 49078 | Model pool: 500000 (max 500000) | Length: 4.9078 | Train rep: 1

Diagnostics -- iteration 726000
real_batch_obs: 1743.21, model_batch_obs: 1916.95
real_batch_act: 191.08, model_batch_act: 192.17
real_batch_rewards: 1310.50, model_batch_rewards: 1296.43
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 2793.90
total_steps: 726000.00
Q-avg: 1052.10, Q-max: 1481.25, Q-min: -124.15
Q_loss1: 280.50, Q_loss2: 371.61, min_Q_loss1: -221.07, min_Q_loss2: -224.41

Train epoch 726/3000 -- step 727000

[F                                                                                                    
[F[ Model Length ] Epoch: 726 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 726000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 726 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 726726
[ Model Rollout ] Added: 49003 | Model pool: 500000 (max 500000) | Length: 4.9003 | Train rep: 1

Diagnostics -- iteration 727000
real_batch_obs: 1875.31, model_batch_obs: 1855.07
real_batch_act: 210.04, model_batch_act: 196.61
real_batch_rewards: 1347.58, model_batch_rewards: 1354.39
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 2801.36
total_steps: 727000.00
Q-avg: 1028.64, Q-max: 1473.42, Q-min: -446.86
Q_loss1: 425.54, Q_loss2: 494.56, min_Q_loss1: -518.58, min_Q_loss2: -520.68

Train epoch 727/3000 -- step 728000

[F                                                                                                    
[F[ Model Length ] Epoch: 727 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 727000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 727 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 727727
[ Model Rollout ] Added: 49108 | Model pool: 500000 (max 500000) | Length: 4.9108 | Train rep: 1

Diagnostics -- iteration 728000
real_batch_obs: 1931.12, model_batch_obs: 1853.09
real_batch_act: 193.16, model_batch_act: 191.96
real_batch_rewards: 1337.03, model_batch_rewards: 1343.49
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 2809.64
total_steps: 728000.00
Q-avg: 1050.61, Q-max: 1458.37, Q-min: -261.91
Q_loss1: 665.58, Q_loss2: 384.40, min_Q_loss1: -472.96, min_Q_loss2: -491.50

Train epoch 728/3000 -- step 729000

[F                                                                                                    
[F[ Model Length ] Epoch: 728 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 728000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 728 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 728728
[ Model Rollout ] Added: 49006 | Model pool: 500000 (max 500000) | Length: 4.9006 | Train rep: 1

Diagnostics -- iteration 729000
real_batch_obs: 1903.46, model_batch_obs: 1936.75
real_batch_act: 191.00, model_batch_act: 191.26
real_batch_rewards: 1411.29, model_batch_rewards: 1336.15
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 2701.97
total_steps: 729000.00
Q-avg: 1063.82, Q-max: 1468.24, Q-min: -294.64
Q_loss1: 392.24, Q_loss2: 336.18, min_Q_loss1: -296.66, min_Q_loss2: -298.24

Train epoch 729/3000 -- step 730000

[F                                                                                                    
[F[ Model Length ] Epoch: 729 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 729000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 729 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 729729
[ Model Rollout ] Added: 48989 | Model pool: 500000 (max 500000) | Length: 4.8989 | Train rep: 1

Diagnostics -- iteration 730000
real_batch_obs: 1801.42, model_batch_obs: 1770.20
real_batch_act: 198.20, model_batch_act: 181.26
real_batch_rewards: 1354.65, model_batch_rewards: 1369.29
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 2900.13
total_steps: 730000.00
Q-avg: 1043.79, Q-max: 1463.76, Q-min: -476.80
Q_loss1: 732.86, Q_loss2: 589.49, min_Q_loss1: -403.01, min_Q_loss2: -399.31

Train epoch 730/3000 -- step 731000

[F                                                                                                    
[F[ Model Length ] Epoch: 730 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 730000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 730 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 730730
[ Model Rollout ] Added: 49012 | Model pool: 500000 (max 500000) | Length: 4.9012 | Train rep: 1

Diagnostics -- iteration 731000
real_batch_obs: 1828.06, model_batch_obs: 1929.12
real_batch_act: 187.33, model_batch_act: 195.80
real_batch_rewards: 1296.06, model_batch_rewards: 1327.72
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 2817.19
total_steps: 731000.00
Q-avg: 1010.22, Q-max: 1456.26, Q-min: -354.66
Q_loss1: 431.61, Q_loss2: 415.52, min_Q_loss1: -415.82, min_Q_loss2: -415.79

Train epoch 731/3000 -- step 732000

[F                                                                                                    
[F[ Model Length ] Epoch: 731 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 731000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 731 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 731731
[ Model Rollout ] Added: 49002 | Model pool: 500000 (max 500000) | Length: 4.9002 | Train rep: 1

Diagnostics -- iteration 732000
real_batch_obs: 1856.69, model_batch_obs: 1952.28
real_batch_act: 198.41, model_batch_act: 193.08
real_batch_rewards: 1374.34, model_batch_rewards: 1320.62
real_batch_dones: 0.00, model_batch_dones: 6.00
evaluation/return-average: 1460.63
total_steps: 732000.00
Q-avg: 1011.61, Q-max: 1468.98, Q-min: -278.23
Q_loss1: 168.64, Q_loss2: 143.52, min_Q_loss1: -399.27, min_Q_loss2: -403.17

Train epoch 732/3000 -- step 733000

[F                                                                                                    
[F[ Model Length ] Epoch: 732 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 732000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 732 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 732732
[ Model Rollout ] Added: 49047 | Model pool: 500000 (max 500000) | Length: 4.9047 | Train rep: 1

Diagnostics -- iteration 733000
real_batch_obs: 1874.82, model_batch_obs: 1936.77
real_batch_act: 206.63, model_batch_act: 204.51
real_batch_rewards: 1393.58, model_batch_rewards: 1302.20
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 2693.56
total_steps: 733000.00
Q-avg: 1055.28, Q-max: 1460.31, Q-min: -694.70
Q_loss1: 368.98, Q_loss2: 355.85, min_Q_loss1: -412.65, min_Q_loss2: -414.58

Train epoch 733/3000 -- step 734000

[F                                                                                                    
[F[ Model Length ] Epoch: 733 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 733000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 733 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 733733
[ Model Rollout ] Added: 49013 | Model pool: 500000 (max 500000) | Length: 4.9013 | Train rep: 1

Diagnostics -- iteration 734000
real_batch_obs: 1789.11, model_batch_obs: 1893.10
real_batch_act: 201.56, model_batch_act: 185.36
real_batch_rewards: 1380.59, model_batch_rewards: 1330.33
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 2615.92
total_steps: 734000.00
Q-avg: 1030.20, Q-max: 1470.60, Q-min: -193.25
Q_loss1: 814.18, Q_loss2: 913.49, min_Q_loss1: -24.06, min_Q_loss2: -29.07

Train epoch 734/3000 -- step 735000

[F                                                                                                    
[F[ Model Length ] Epoch: 734 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 734000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 734 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 734734
[ Model Rollout ] Added: 48998 | Model pool: 500000 (max 500000) | Length: 4.8998 | Train rep: 1

Diagnostics -- iteration 735000
real_batch_obs: 1939.13, model_batch_obs: 1822.26
real_batch_act: 210.62, model_batch_act: 198.91
real_batch_rewards: 1393.34, model_batch_rewards: 1300.03
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 1211.01
total_steps: 735000.00
Q-avg: 1052.54, Q-max: 1484.58, Q-min: -442.32
Q_loss1: 785.87, Q_loss2: 827.84, min_Q_loss1: -326.46, min_Q_loss2: -322.29

Train epoch 735/3000 -- step 736000

[F                                                                                                    
[F[ Model Length ] Epoch: 735 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 735000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 735 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 735735
[ Model Rollout ] Added: 49024 | Model pool: 500000 (max 500000) | Length: 4.9024 | Train rep: 1

Diagnostics -- iteration 736000
real_batch_obs: 1790.67, model_batch_obs: 1932.22
real_batch_act: 192.23, model_batch_act: 196.38
real_batch_rewards: 1360.40, model_batch_rewards: 1312.30
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 2335.83
total_steps: 736000.00
Q-avg: 1064.94, Q-max: 1543.13, Q-min: -358.09
Q_loss1: 749.98, Q_loss2: 670.15, min_Q_loss1: -239.57, min_Q_loss2: -233.48

Train epoch 736/3000 -- step 737000

[F                                                                                                    
[F[ Model Length ] Epoch: 736 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 736000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 736 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 736736
[ Model Rollout ] Added: 49102 | Model pool: 500000 (max 500000) | Length: 4.9102 | Train rep: 1

Diagnostics -- iteration 737000
real_batch_obs: 1815.11, model_batch_obs: 1823.46
real_batch_act: 208.38, model_batch_act: 199.69
real_batch_rewards: 1331.14, model_batch_rewards: 1266.91
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 2322.45
total_steps: 737000.00
Q-avg: 1046.11, Q-max: 1483.44, Q-min: -916.53
Q_loss1: 431.55, Q_loss2: 414.85, min_Q_loss1: -171.37, min_Q_loss2: -179.99

Train epoch 737/3000 -- step 738000

[F                                                                                                    
[F[ Model Length ] Epoch: 737 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 737000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 737 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 737737
[ Model Rollout ] Added: 48951 | Model pool: 500000 (max 500000) | Length: 4.8951 | Train rep: 1

Diagnostics -- iteration 738000
real_batch_obs: 1771.41, model_batch_obs: 2021.92
real_batch_act: 203.22, model_batch_act: 192.54
real_batch_rewards: 1348.64, model_batch_rewards: 1412.76
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 1082.89
total_steps: 738000.00
Q-avg: 1041.74, Q-max: 1461.90, Q-min: -541.19
Q_loss1: 792.04, Q_loss2: 829.07, min_Q_loss1: -361.63, min_Q_loss2: -359.00

Train epoch 738/3000 -- step 739000

[F                                                                                                    
[F[ Model Length ] Epoch: 738 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 738000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 738 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 738738
[ Model Rollout ] Added: 49096 | Model pool: 500000 (max 500000) | Length: 4.9096 | Train rep: 1

Diagnostics -- iteration 739000
real_batch_obs: 1861.11, model_batch_obs: 1767.49
real_batch_act: 186.45, model_batch_act: 188.48
real_batch_rewards: 1358.70, model_batch_rewards: 1290.22
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 1069.67
total_steps: 739000.00
Q-avg: 1040.35, Q-max: 1456.09, Q-min: -233.03
Q_loss1: 381.75, Q_loss2: 352.25, min_Q_loss1: -422.04, min_Q_loss2: -428.92

Train epoch 739/3000 -- step 740000

[F                                                                                                    
[F[ Model Length ] Epoch: 739 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 739000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 739 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 739739
[ Model Rollout ] Added: 49018 | Model pool: 500000 (max 500000) | Length: 4.9018 | Train rep: 1

Diagnostics -- iteration 740000
real_batch_obs: 1912.13, model_batch_obs: 1887.99
real_batch_act: 197.41, model_batch_act: 191.97
real_batch_rewards: 1319.37, model_batch_rewards: 1337.68
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 2662.30
total_steps: 740000.00
Q-avg: 1056.99, Q-max: 1453.71, Q-min: -216.83
Q_loss1: 130.20, Q_loss2: 91.86, min_Q_loss1: -462.09, min_Q_loss2: -450.55

Train epoch 740/3000 -- step 741000

[F                                                                                                    
[F[ Model Length ] Epoch: 740 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 740000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 740 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 740740
[ Model Rollout ] Added: 49043 | Model pool: 500000 (max 500000) | Length: 4.9043 | Train rep: 1

Diagnostics -- iteration 741000
real_batch_obs: 1911.51, model_batch_obs: 1907.89
real_batch_act: 197.54, model_batch_act: 201.79
real_batch_rewards: 1401.49, model_batch_rewards: 1303.90
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 2695.01
total_steps: 741000.00
Q-avg: 1056.50, Q-max: 1454.02, Q-min: -445.13
Q_loss1: 679.13, Q_loss2: 663.73, min_Q_loss1: -92.01, min_Q_loss2: -90.66

Train epoch 741/3000 -- step 742000

[F                                                                                                    
[F[ Model Length ] Epoch: 741 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 741000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 741 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 741741
[ Model Rollout ] Added: 49114 | Model pool: 500000 (max 500000) | Length: 4.9114 | Train rep: 1

Diagnostics -- iteration 742000
real_batch_obs: 1808.11, model_batch_obs: 1786.39
real_batch_act: 206.31, model_batch_act: 186.14
real_batch_rewards: 1362.32, model_batch_rewards: 1311.41
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 2492.70
total_steps: 742000.00
Q-avg: 1059.73, Q-max: 1504.78, Q-min: -369.32
Q_loss1: 481.45, Q_loss2: 388.48, min_Q_loss1: -313.36, min_Q_loss2: -310.90

Train epoch 742/3000 -- step 743000

[F                                                                                                    
[F[ Model Length ] Epoch: 742 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 742000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 742 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 742742
[ Model Rollout ] Added: 49002 | Model pool: 500000 (max 500000) | Length: 4.9002 | Train rep: 1

Diagnostics -- iteration 743000
real_batch_obs: 1854.67, model_batch_obs: 1951.16
real_batch_act: 201.87, model_batch_act: 191.20
real_batch_rewards: 1282.64, model_batch_rewards: 1425.94
real_batch_dones: 0.00, model_batch_dones: 5.00
evaluation/return-average: 2650.46
total_steps: 743000.00
Q-avg: 1022.29, Q-max: 1469.98, Q-min: -330.16
Q_loss1: 2247.53, Q_loss2: 2325.96, min_Q_loss1: -412.47, min_Q_loss2: -416.42

Train epoch 743/3000 -- step 744000

[F                                                                                                    
[F[ Model Length ] Epoch: 743 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 743000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 743 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 743743
[ Model Rollout ] Added: 48967 | Model pool: 500000 (max 500000) | Length: 4.8967 | Train rep: 1

Diagnostics -- iteration 744000
real_batch_obs: 1906.89, model_batch_obs: 1787.95
real_batch_act: 199.41, model_batch_act: 189.51
real_batch_rewards: 1438.24, model_batch_rewards: 1355.16
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 1684.06
total_steps: 744000.00
Q-avg: 1011.37, Q-max: 1521.13, Q-min: -155.90
Q_loss1: 203.81, Q_loss2: 187.57, min_Q_loss1: -399.65, min_Q_loss2: -402.03

Train epoch 744/3000 -- step 745000

[F                                                                                                    
[F[ Model Length ] Epoch: 744 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 744000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 744 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 744744
[ Model Rollout ] Added: 49072 | Model pool: 500000 (max 500000) | Length: 4.9072 | Train rep: 1

Diagnostics -- iteration 745000
real_batch_obs: 1790.36, model_batch_obs: 1796.68
real_batch_act: 201.60, model_batch_act: 184.64
real_batch_rewards: 1316.52, model_batch_rewards: 1238.23
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 1995.15
total_steps: 745000.00
Q-avg: 1026.42, Q-max: 1460.11, Q-min: -523.05
Q_loss1: 1445.90, Q_loss2: 1317.36, min_Q_loss1: -190.65, min_Q_loss2: -187.08

Train epoch 745/3000 -- step 746000

[F                                                                                                    
[F[ Model Length ] Epoch: 745 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 745000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 745 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 745745
[ Model Rollout ] Added: 48993 | Model pool: 500000 (max 500000) | Length: 4.8993 | Train rep: 1

Diagnostics -- iteration 746000
real_batch_obs: 1877.03, model_batch_obs: 1932.21
real_batch_act: 202.24, model_batch_act: 198.84
real_batch_rewards: 1365.46, model_batch_rewards: 1345.18
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 2741.24
total_steps: 746000.00
Q-avg: 1026.40, Q-max: 1483.22, Q-min: -569.30
Q_loss1: 895.86, Q_loss2: 1091.55, min_Q_loss1: -303.83, min_Q_loss2: -307.12

Train epoch 746/3000 -- step 747000

[F                                                                                                    
[F[ Model Length ] Epoch: 746 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 746000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 746 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 746746
[ Model Rollout ] Added: 49001 | Model pool: 500000 (max 500000) | Length: 4.9001 | Train rep: 1

Diagnostics -- iteration 747000
real_batch_obs: 1905.64, model_batch_obs: 1986.77
real_batch_act: 200.58, model_batch_act: 189.18
real_batch_rewards: 1355.13, model_batch_rewards: 1387.13
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 2688.82
total_steps: 747000.00
Q-avg: 1046.48, Q-max: 1463.97, Q-min: -789.01
Q_loss1: 379.05, Q_loss2: 379.92, min_Q_loss1: -330.42, min_Q_loss2: -338.12

Train epoch 747/3000 -- step 748000

[F                                                                                                    
[F[ Model Length ] Epoch: 747 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 747000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 747 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 747747
[ Model Rollout ] Added: 49078 | Model pool: 500000 (max 500000) | Length: 4.9078 | Train rep: 1

Diagnostics -- iteration 748000
real_batch_obs: 1782.35, model_batch_obs: 1672.75
real_batch_act: 203.20, model_batch_act: 197.13
real_batch_rewards: 1344.68, model_batch_rewards: 1324.42
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 2666.92
total_steps: 748000.00
Q-avg: 1034.02, Q-max: 1444.90, Q-min: -472.94
Q_loss1: 554.35, Q_loss2: 568.89, min_Q_loss1: -83.63, min_Q_loss2: -87.30

Train epoch 748/3000 -- step 749000

[F                                                                                                    
[F[ Model Length ] Epoch: 748 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 748000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 748 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 748748
[ Model Rollout ] Added: 49030 | Model pool: 500000 (max 500000) | Length: 4.903 | Train rep: 1

Diagnostics -- iteration 749000
real_batch_obs: 1757.27, model_batch_obs: 1822.68
real_batch_act: 197.45, model_batch_act: 191.14
real_batch_rewards: 1300.68, model_batch_rewards: 1312.16
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 2757.64
total_steps: 749000.00
Q-avg: 1059.79, Q-max: 1460.56, Q-min: -399.89
Q_loss1: 455.95, Q_loss2: 549.65, min_Q_loss1: -309.17, min_Q_loss2: -312.05

Train epoch 749/3000 -- step 750000

[F                                                                                                    
[F[ Model Length ] Epoch: 749 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 749000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 749 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 749749
[ Model Rollout ] Added: 49049 | Model pool: 500000 (max 500000) | Length: 4.9049 | Train rep: 1

Diagnostics -- iteration 750000
real_batch_obs: 1826.81, model_batch_obs: 1855.90
real_batch_act: 190.61, model_batch_act: 186.71
real_batch_rewards: 1323.03, model_batch_rewards: 1324.79
real_batch_dones: 0.00, model_batch_dones: 5.00
evaluation/return-average: 2774.40
total_steps: 750000.00
Q-avg: 988.57, Q-max: 1428.66, Q-min: -780.53
Q_loss1: 805.18, Q_loss2: 642.52, min_Q_loss1: -189.84, min_Q_loss2: -190.41

Train epoch 750/3000 -- step 751000

[F                                                                                                    
[F[ Model Length ] Epoch: 750 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 750000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 750 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 750750
[ Model Rollout ] Added: 49045 | Model pool: 500000 (max 500000) | Length: 4.9045 | Train rep: 1

Diagnostics -- iteration 751000
real_batch_obs: 1829.40, model_batch_obs: 2031.57
real_batch_act: 208.12, model_batch_act: 192.26
real_batch_rewards: 1345.53, model_batch_rewards: 1421.98
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 2776.12
total_steps: 751000.00
Q-avg: 998.90, Q-max: 1435.83, Q-min: -557.82
Q_loss1: 365.72, Q_loss2: 366.70, min_Q_loss1: -364.27, min_Q_loss2: -360.66

Train epoch 751/3000 -- step 752000

[F                                                                                                    
[F[ Model Length ] Epoch: 751 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 751000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 751 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 751751
[ Model Rollout ] Added: 48991 | Model pool: 500000 (max 500000) | Length: 4.8991 | Train rep: 1

Diagnostics -- iteration 752000
real_batch_obs: 1816.23, model_batch_obs: 1883.46
real_batch_act: 200.89, model_batch_act: 198.14
real_batch_rewards: 1364.93, model_batch_rewards: 1352.04
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 849.35
total_steps: 752000.00
Q-avg: 1008.29, Q-max: 1443.46, Q-min: -697.16
Q_loss1: 562.68, Q_loss2: 581.56, min_Q_loss1: -320.13, min_Q_loss2: -318.71

Train epoch 752/3000 -- step 753000

[F                                                                                                    
[F[ Model Length ] Epoch: 752 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 752000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 752 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 752752
[ Model Rollout ] Added: 49006 | Model pool: 500000 (max 500000) | Length: 4.9006 | Train rep: 1

Diagnostics -- iteration 753000
real_batch_obs: 1927.21, model_batch_obs: 1831.18
real_batch_act: 197.63, model_batch_act: 188.57
real_batch_rewards: 1419.98, model_batch_rewards: 1348.94
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 2924.25
total_steps: 753000.00
Q-avg: 1001.95, Q-max: 1451.31, Q-min: -972.93
Q_loss1: 2463.79, Q_loss2: 2403.42, min_Q_loss1: -458.69, min_Q_loss2: -459.18

Train epoch 753/3000 -- step 754000

[F                                                                                                    
[F[ Model Length ] Epoch: 753 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 753000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 753 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 753753
[ Model Rollout ] Added: 49068 | Model pool: 500000 (max 500000) | Length: 4.9068 | Train rep: 1

Diagnostics -- iteration 754000
real_batch_obs: 1876.05, model_batch_obs: 1916.64
real_batch_act: 194.34, model_batch_act: 200.44
real_batch_rewards: 1399.36, model_batch_rewards: 1313.82
real_batch_dones: 0.00, model_batch_dones: 5.00
evaluation/return-average: 2825.42
total_steps: 754000.00
Q-avg: 999.84, Q-max: 1450.05, Q-min: -331.00
Q_loss1: 1970.27, Q_loss2: 2118.12, min_Q_loss1: -361.96, min_Q_loss2: -358.03

Train epoch 754/3000 -- step 755000

[F                                                                                                    
[F[ Model Length ] Epoch: 754 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 754000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 754 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 754754
[ Model Rollout ] Added: 49040 | Model pool: 500000 (max 500000) | Length: 4.904 | Train rep: 1

Diagnostics -- iteration 755000
real_batch_obs: 1861.29, model_batch_obs: 1863.61
real_batch_act: 191.94, model_batch_act: 194.93
real_batch_rewards: 1343.24, model_batch_rewards: 1340.10
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 2865.27
total_steps: 755000.00
Q-avg: 1034.92, Q-max: 1445.00, Q-min: -987.06
Q_loss1: 809.00, Q_loss2: 792.77, min_Q_loss1: -248.54, min_Q_loss2: -255.87

Train epoch 755/3000 -- step 756000

[F                                                                                                    
[F[ Model Length ] Epoch: 755 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 755000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 755 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 755755
[ Model Rollout ] Added: 49017 | Model pool: 500000 (max 500000) | Length: 4.9017 | Train rep: 1

Diagnostics -- iteration 756000
real_batch_obs: 1864.85, model_batch_obs: 1901.90
real_batch_act: 210.54, model_batch_act: 188.93
real_batch_rewards: 1384.40, model_batch_rewards: 1382.44
real_batch_dones: 1.00, model_batch_dones: 0.00
evaluation/return-average: 3055.99
total_steps: 756000.00
Q-avg: 993.02, Q-max: 1451.78, Q-min: -356.63
Q_loss1: 445.19, Q_loss2: 427.38, min_Q_loss1: -162.38, min_Q_loss2: -161.86

Train epoch 756/3000 -- step 757000

[F                                                                                                    
[F[ Model Length ] Epoch: 756 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 756000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 756 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 756756
[ Model Rollout ] Added: 49033 | Model pool: 500000 (max 500000) | Length: 4.9033 | Train rep: 1

Diagnostics -- iteration 757000
real_batch_obs: 1853.86, model_batch_obs: 1893.02
real_batch_act: 206.81, model_batch_act: 189.44
real_batch_rewards: 1318.21, model_batch_rewards: 1376.69
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 3118.30
total_steps: 757000.00
Q-avg: 1020.53, Q-max: 1463.27, Q-min: -493.92
Q_loss1: 380.92, Q_loss2: 345.28, min_Q_loss1: -216.00, min_Q_loss2: -209.73

Train epoch 757/3000 -- step 758000

[F                                                                                                    
[F[ Model Length ] Epoch: 757 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 757000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 757 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 757757
[ Model Rollout ] Added: 48953 | Model pool: 500000 (max 500000) | Length: 4.8953 | Train rep: 1

Diagnostics -- iteration 758000
real_batch_obs: 1837.22, model_batch_obs: 1918.42
real_batch_act: 192.67, model_batch_act: 189.80
real_batch_rewards: 1340.89, model_batch_rewards: 1597.85
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 2966.70
total_steps: 758000.00
Q-avg: 1005.76, Q-max: 1431.36, Q-min: -1963.35
Q_loss1: 6310.39, Q_loss2: 5238.01, min_Q_loss1: -447.80, min_Q_loss2: -455.35

Train epoch 758/3000 -- step 759000

[F                                                                                                    
[F[ Model Length ] Epoch: 758 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 758000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 758 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 758758
[ Model Rollout ] Added: 48996 | Model pool: 500000 (max 500000) | Length: 4.8996 | Train rep: 1

Diagnostics -- iteration 759000
real_batch_obs: 1719.46, model_batch_obs: 1900.15
real_batch_act: 196.87, model_batch_act: 198.29
real_batch_rewards: 1324.30, model_batch_rewards: 1345.86
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 2917.66
total_steps: 759000.00
Q-avg: 1021.99, Q-max: 1429.57, Q-min: -795.51
Q_loss1: 460.80, Q_loss2: 638.50, min_Q_loss1: -455.93, min_Q_loss2: -456.84

Train epoch 759/3000 -- step 760000

[F                                                                                                    
[F[ Model Length ] Epoch: 759 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 759000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 759 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 759759
[ Model Rollout ] Added: 49019 | Model pool: 500000 (max 500000) | Length: 4.9019 | Train rep: 1

Diagnostics -- iteration 760000
real_batch_obs: 1823.70, model_batch_obs: 1935.70
real_batch_act: 198.84, model_batch_act: 179.80
real_batch_rewards: 1360.60, model_batch_rewards: 1341.17
real_batch_dones: 1.00, model_batch_dones: 4.00
evaluation/return-average: 2941.39
total_steps: 760000.00
Q-avg: 1008.24, Q-max: 1440.85, Q-min: -202.76
Q_loss1: 157.83, Q_loss2: 237.02, min_Q_loss1: -203.09, min_Q_loss2: -199.36

Train epoch 760/3000 -- step 761000

[F                                                                                                    
[F[ Model Length ] Epoch: 760 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 760000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 760 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 760760
[ Model Rollout ] Added: 49108 | Model pool: 500000 (max 500000) | Length: 4.9108 | Train rep: 1

Diagnostics -- iteration 761000
real_batch_obs: 2002.44, model_batch_obs: 1821.21
real_batch_act: 209.54, model_batch_act: 193.33
real_batch_rewards: 1416.56, model_batch_rewards: 1238.91
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 3029.64
total_steps: 761000.00
Q-avg: 971.69, Q-max: 1429.23, Q-min: -256.42
Q_loss1: 377.92, Q_loss2: 241.23, min_Q_loss1: -39.85, min_Q_loss2: -37.99

Train epoch 761/3000 -- step 762000

[F                                                                                                    
[F[ Model Length ] Epoch: 761 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 761000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 761 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 761761
[ Model Rollout ] Added: 48989 | Model pool: 500000 (max 500000) | Length: 4.8989 | Train rep: 1

Diagnostics -- iteration 762000
real_batch_obs: 1905.85, model_batch_obs: 1888.83
real_batch_act: 198.72, model_batch_act: 194.54
real_batch_rewards: 1386.84, model_batch_rewards: 1390.35
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 2809.94
total_steps: 762000.00
Q-avg: 961.39, Q-max: 1438.20, Q-min: -752.48
Q_loss1: 1462.33, Q_loss2: 1522.17, min_Q_loss1: -504.11, min_Q_loss2: -504.15

Train epoch 762/3000 -- step 763000

[F                                                                                                    
[F[ Model Length ] Epoch: 762 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 762000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 762 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 762762
[ Model Rollout ] Added: 48956 | Model pool: 500000 (max 500000) | Length: 4.8956 | Train rep: 1

Diagnostics -- iteration 763000
real_batch_obs: 1822.08, model_batch_obs: 1832.18
real_batch_act: 194.40, model_batch_act: 193.62
real_batch_rewards: 1291.21, model_batch_rewards: 1239.97
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 2828.15
total_steps: 763000.00
Q-avg: 1034.02, Q-max: 1451.91, Q-min: -706.30
Q_loss1: 1248.49, Q_loss2: 1290.82, min_Q_loss1: -817.79, min_Q_loss2: -819.57

Train epoch 763/3000 -- step 764000

[F                                                                                                    
[F[ Model Length ] Epoch: 763 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 763000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 763 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 763763
[ Model Rollout ] Added: 48982 | Model pool: 500000 (max 500000) | Length: 4.8982 | Train rep: 1

Diagnostics -- iteration 764000
real_batch_obs: 1863.70, model_batch_obs: 1948.66
real_batch_act: 199.78, model_batch_act: 187.18
real_batch_rewards: 1407.25, model_batch_rewards: 1410.56
real_batch_dones: 2.00, model_batch_dones: 0.00
evaluation/return-average: 2786.15
total_steps: 764000.00
Q-avg: 997.31, Q-max: 1444.06, Q-min: -748.26
Q_loss1: 170.95, Q_loss2: 201.15, min_Q_loss1: -201.48, min_Q_loss2: -199.51

Train epoch 764/3000 -- step 765000

[F                                                                                                    
[F[ Model Length ] Epoch: 764 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 764000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 764 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 764764
[ Model Rollout ] Added: 49092 | Model pool: 500000 (max 500000) | Length: 4.9092 | Train rep: 1

Diagnostics -- iteration 765000
real_batch_obs: 1811.72, model_batch_obs: 1939.05
real_batch_act: 195.55, model_batch_act: 188.04
real_batch_rewards: 1395.28, model_batch_rewards: 1351.11
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 2848.57
total_steps: 765000.00
Q-avg: 967.45, Q-max: 1430.53, Q-min: -1151.68
Q_loss1: 417.77, Q_loss2: 396.87, min_Q_loss1: -393.46, min_Q_loss2: -395.54

Train epoch 765/3000 -- step 766000

[F                                                                                                    
[F[ Model Length ] Epoch: 765 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 765000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 765 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 765765
[ Model Rollout ] Added: 49024 | Model pool: 500000 (max 500000) | Length: 4.9024 | Train rep: 1

Diagnostics -- iteration 766000
real_batch_obs: 1936.04, model_batch_obs: 1782.18
real_batch_act: 204.73, model_batch_act: 194.68
real_batch_rewards: 1376.97, model_batch_rewards: 1366.99
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 2803.56
total_steps: 766000.00
Q-avg: 943.43, Q-max: 1429.00, Q-min: -488.66
Q_loss1: 1342.38, Q_loss2: 1379.43, min_Q_loss1: -232.62, min_Q_loss2: -229.82

Train epoch 766/3000 -- step 767000

[F                                                                                                    
[F[ Model Length ] Epoch: 766 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 766000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 766 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 766766
[ Model Rollout ] Added: 49036 | Model pool: 500000 (max 500000) | Length: 4.9036 | Train rep: 1

Diagnostics -- iteration 767000
real_batch_obs: 1825.66, model_batch_obs: 1945.81
real_batch_act: 193.83, model_batch_act: 199.42
real_batch_rewards: 1314.83, model_batch_rewards: 1321.44
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 2889.02
total_steps: 767000.00
Q-avg: 1036.74, Q-max: 1445.80, Q-min: -499.46
Q_loss1: 217.88, Q_loss2: 178.51, min_Q_loss1: -246.23, min_Q_loss2: -251.42

Train epoch 767/3000 -- step 768000

[F                                                                                                    
[F[ Model Length ] Epoch: 767 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 767000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 767 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 767767
[ Model Rollout ] Added: 48973 | Model pool: 500000 (max 500000) | Length: 4.8973 | Train rep: 1

Diagnostics -- iteration 768000
real_batch_obs: 1765.72, model_batch_obs: 1837.18
real_batch_act: 196.42, model_batch_act: 189.48
real_batch_rewards: 1320.02, model_batch_rewards: 1314.53
real_batch_dones: 0.00, model_batch_dones: 5.00
evaluation/return-average: 2829.09
total_steps: 768000.00
Q-avg: 976.85, Q-max: 1435.94, Q-min: -912.26
Q_loss1: 2465.38, Q_loss2: 2322.41, min_Q_loss1: -359.71, min_Q_loss2: -360.61

Train epoch 768/3000 -- step 769000

[F                                                                                                    
[F[ Model Length ] Epoch: 768 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 768000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 768 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 768768
[ Model Rollout ] Added: 48975 | Model pool: 500000 (max 500000) | Length: 4.8975 | Train rep: 1

Diagnostics -- iteration 769000
real_batch_obs: 1866.81, model_batch_obs: 1755.46
real_batch_act: 200.74, model_batch_act: 184.67
real_batch_rewards: 1338.09, model_batch_rewards: 1266.14
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 2932.20
total_steps: 769000.00
Q-avg: 1029.75, Q-max: 1423.30, Q-min: -363.81
Q_loss1: 200.72, Q_loss2: 205.95, min_Q_loss1: -230.46, min_Q_loss2: -229.43

Train epoch 769/3000 -- step 770000

[F                                                                                                    
[F[ Model Length ] Epoch: 769 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 769000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 769 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 769769
[ Model Rollout ] Added: 48982 | Model pool: 500000 (max 500000) | Length: 4.8982 | Train rep: 1

Diagnostics -- iteration 770000
real_batch_obs: 1883.93, model_batch_obs: 1886.66
real_batch_act: 196.47, model_batch_act: 191.01
real_batch_rewards: 1299.23, model_batch_rewards: 1357.39
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 2929.57
total_steps: 770000.00
Q-avg: 996.79, Q-max: 1435.20, Q-min: -335.09
Q_loss1: 1194.89, Q_loss2: 1120.55, min_Q_loss1: -243.72, min_Q_loss2: -242.01

Train epoch 770/3000 -- step 771000

[F                                                                                                    
[F[ Model Length ] Epoch: 770 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 770000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 770 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 770770
[ Model Rollout ] Added: 48972 | Model pool: 500000 (max 500000) | Length: 4.8972 | Train rep: 1

Diagnostics -- iteration 771000
real_batch_obs: 1807.52, model_batch_obs: 1939.81
real_batch_act: 195.07, model_batch_act: 183.92
real_batch_rewards: 1406.17, model_batch_rewards: 1350.34
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 2893.64
total_steps: 771000.00
Q-avg: 1018.84, Q-max: 1425.96, Q-min: -71.71
Q_loss1: 1088.26, Q_loss2: 694.39, min_Q_loss1: -181.14, min_Q_loss2: -177.62

Train epoch 771/3000 -- step 772000

[F                                                                                                    
[F[ Model Length ] Epoch: 771 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 771000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 771 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 771771
[ Model Rollout ] Added: 49057 | Model pool: 500000 (max 500000) | Length: 4.9057 | Train rep: 1

Diagnostics -- iteration 772000
real_batch_obs: 1879.43, model_batch_obs: 1864.53
real_batch_act: 204.87, model_batch_act: 185.79
real_batch_rewards: 1334.31, model_batch_rewards: 1365.80
real_batch_dones: 2.00, model_batch_dones: 3.00
evaluation/return-average: 2845.95
total_steps: 772000.00
Q-avg: 1017.10, Q-max: 1428.09, Q-min: -445.65
Q_loss1: 603.35, Q_loss2: 629.10, min_Q_loss1: -426.73, min_Q_loss2: -437.68

Train epoch 772/3000 -- step 773000

[F                                                                                                    
[F[ Model Length ] Epoch: 772 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 772000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 772 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 772772
[ Model Rollout ] Added: 49074 | Model pool: 500000 (max 500000) | Length: 4.9074 | Train rep: 1

Diagnostics -- iteration 773000
real_batch_obs: 2003.27, model_batch_obs: 1702.06
real_batch_act: 209.75, model_batch_act: 192.38
real_batch_rewards: 1335.10, model_batch_rewards: 1286.89
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 2836.24
total_steps: 773000.00
Q-avg: 1014.36, Q-max: 1414.68, Q-min: -328.56
Q_loss1: 594.70, Q_loss2: 521.40, min_Q_loss1: -506.25, min_Q_loss2: -507.90

Train epoch 773/3000 -- step 774000

[F                                                                                                    
[F[ Model Length ] Epoch: 773 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 773000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 773 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 773773
[ Model Rollout ] Added: 49039 | Model pool: 500000 (max 500000) | Length: 4.9039 | Train rep: 1

Diagnostics -- iteration 774000
real_batch_obs: 1821.03, model_batch_obs: 1922.10
real_batch_act: 194.26, model_batch_act: 199.07
real_batch_rewards: 1383.70, model_batch_rewards: 1361.65
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 2914.26
total_steps: 774000.00
Q-avg: 1014.67, Q-max: 1430.94, Q-min: -404.40
Q_loss1: 1139.67, Q_loss2: 1357.56, min_Q_loss1: -264.78, min_Q_loss2: -257.80

Train epoch 774/3000 -- step 775000

[F                                                                                                    
[F[ Model Length ] Epoch: 774 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 774000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 774 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 774774
[ Model Rollout ] Added: 49044 | Model pool: 500000 (max 500000) | Length: 4.9044 | Train rep: 1

Diagnostics -- iteration 775000
real_batch_obs: 1850.90, model_batch_obs: 1809.38
real_batch_act: 195.97, model_batch_act: 184.28
real_batch_rewards: 1383.64, model_batch_rewards: 1356.70
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 2877.27
total_steps: 775000.00
Q-avg: 964.20, Q-max: 1433.71, Q-min: -628.45
Q_loss1: 2306.03, Q_loss2: 2238.67, min_Q_loss1: -363.99, min_Q_loss2: -356.71

Train epoch 775/3000 -- step 776000

[F                                                                                                    
[F[ Model Length ] Epoch: 775 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 775000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 775 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 775775
[ Model Rollout ] Added: 49049 | Model pool: 500000 (max 500000) | Length: 4.9049 | Train rep: 1

Diagnostics -- iteration 776000
real_batch_obs: 1740.38, model_batch_obs: 1916.04
real_batch_act: 210.63, model_batch_act: 193.36
real_batch_rewards: 1330.88, model_batch_rewards: 1382.88
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 2882.81
total_steps: 776000.00
Q-avg: 952.87, Q-max: 1415.04, Q-min: -493.94
Q_loss1: 282.00, Q_loss2: 251.79, min_Q_loss1: -324.75, min_Q_loss2: -337.03

Train epoch 776/3000 -- step 777000

[F                                                                                                    
[F[ Model Length ] Epoch: 776 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 776000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 776 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 776776
[ Model Rollout ] Added: 49054 | Model pool: 500000 (max 500000) | Length: 4.9054 | Train rep: 1

Diagnostics -- iteration 777000
real_batch_obs: 1768.87, model_batch_obs: 1999.23
real_batch_act: 203.57, model_batch_act: 194.41
real_batch_rewards: 1296.93, model_batch_rewards: 1283.13
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 2761.81
total_steps: 777000.00
Q-avg: 1015.71, Q-max: 1424.46, Q-min: -75.89
Q_loss1: 2188.32, Q_loss2: 3095.98, min_Q_loss1: -338.33, min_Q_loss2: -336.99

Train epoch 777/3000 -- step 778000

[F                                                                                                    
[F[ Model Length ] Epoch: 777 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 777000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 777 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 777777
[ Model Rollout ] Added: 49074 | Model pool: 500000 (max 500000) | Length: 4.9074 | Train rep: 1

Diagnostics -- iteration 778000
real_batch_obs: 1938.03, model_batch_obs: 2031.58
real_batch_act: 201.83, model_batch_act: 189.24
real_batch_rewards: 1417.22, model_batch_rewards: 1375.16
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 2825.72
total_steps: 778000.00
Q-avg: 979.23, Q-max: 1413.28, Q-min: -100.14
Q_loss1: 1073.22, Q_loss2: 941.42, min_Q_loss1: -485.50, min_Q_loss2: -491.51

Train epoch 778/3000 -- step 779000

[F                                                                                                    
[F[ Model Length ] Epoch: 778 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 778000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 778 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 778778
[ Model Rollout ] Added: 49024 | Model pool: 500000 (max 500000) | Length: 4.9024 | Train rep: 1

Diagnostics -- iteration 779000
real_batch_obs: 1924.57, model_batch_obs: 1929.04
real_batch_act: 206.70, model_batch_act: 199.95
real_batch_rewards: 1387.70, model_batch_rewards: 1297.53
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 2772.76
total_steps: 779000.00
Q-avg: 1009.49, Q-max: 1433.52, Q-min: -645.75
Q_loss1: 831.69, Q_loss2: 700.01, min_Q_loss1: -332.22, min_Q_loss2: -333.97

Train epoch 779/3000 -- step 780000

[F                                                                                                    
[F[ Model Length ] Epoch: 779 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 779000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 779 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 779779
[ Model Rollout ] Added: 49045 | Model pool: 500000 (max 500000) | Length: 4.9045 | Train rep: 1

Diagnostics -- iteration 780000
real_batch_obs: 1812.38, model_batch_obs: 1961.25
real_batch_act: 191.05, model_batch_act: 188.33
real_batch_rewards: 1367.95, model_batch_rewards: 1715.11
real_batch_dones: 2.00, model_batch_dones: 4.00
evaluation/return-average: 2726.75
total_steps: 780000.00
Q-avg: 997.80, Q-max: 1430.29, Q-min: -770.85
Q_loss1: 1614.37, Q_loss2: 1481.22, min_Q_loss1: -234.11, min_Q_loss2: -238.53

Train epoch 780/3000 -- step 781000

[F                                                                                                    
[F[ Model Length ] Epoch: 780 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 780000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 780 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 780780
[ Model Rollout ] Added: 49046 | Model pool: 500000 (max 500000) | Length: 4.9046 | Train rep: 1

Diagnostics -- iteration 781000
real_batch_obs: 1855.05, model_batch_obs: 1874.62
real_batch_act: 192.61, model_batch_act: 196.09
real_batch_rewards: 1362.13, model_batch_rewards: 1380.64
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 2804.38
total_steps: 781000.00
Q-avg: 981.43, Q-max: 1424.29, Q-min: -340.25
Q_loss1: 618.54, Q_loss2: 601.02, min_Q_loss1: -346.10, min_Q_loss2: -348.03

Train epoch 781/3000 -- step 782000

[F                                                                                                    
[F[ Model Length ] Epoch: 781 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 781000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 781 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 781781
[ Model Rollout ] Added: 48931 | Model pool: 500000 (max 500000) | Length: 4.8931 | Train rep: 1

Diagnostics -- iteration 782000
real_batch_obs: 1858.68, model_batch_obs: 1947.76
real_batch_act: 194.39, model_batch_act: 196.68
real_batch_rewards: 1277.41, model_batch_rewards: 1415.70
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 2846.47
total_steps: 782000.00
Q-avg: 1024.76, Q-max: 1432.53, Q-min: -222.25
Q_loss1: 1575.70, Q_loss2: 1366.18, min_Q_loss1: -547.58, min_Q_loss2: -548.37

Train epoch 782/3000 -- step 783000

[F                                                                                                    
[F[ Model Length ] Epoch: 782 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 782000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 782 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 782782
[ Model Rollout ] Added: 49067 | Model pool: 500000 (max 500000) | Length: 4.9067 | Train rep: 1

Diagnostics -- iteration 783000
real_batch_obs: 1979.75, model_batch_obs: 1936.86
real_batch_act: 195.62, model_batch_act: 199.88
real_batch_rewards: 1401.52, model_batch_rewards: 1377.27
real_batch_dones: 2.00, model_batch_dones: 1.00
evaluation/return-average: 2884.87
total_steps: 783000.00
Q-avg: 990.80, Q-max: 1428.75, Q-min: -208.65
Q_loss1: 265.52, Q_loss2: 314.50, min_Q_loss1: -299.19, min_Q_loss2: -304.20

Train epoch 783/3000 -- step 784000

[F                                                                                                    
[F[ Model Length ] Epoch: 783 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 783000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 783 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 783783
[ Model Rollout ] Added: 49024 | Model pool: 500000 (max 500000) | Length: 4.9024 | Train rep: 1

Diagnostics -- iteration 784000
real_batch_obs: 1846.73, model_batch_obs: 1960.94
real_batch_act: 198.36, model_batch_act: 186.93
real_batch_rewards: 1349.72, model_batch_rewards: 1388.68
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 2903.54
total_steps: 784000.00
Q-avg: 1065.35, Q-max: 1453.70, Q-min: -16.08
Q_loss1: 132.13, Q_loss2: 147.77, min_Q_loss1: 39.80, min_Q_loss2: 34.87

Train epoch 784/3000 -- step 785000

[F                                                                                                    
[F[ Model Length ] Epoch: 784 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 784000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 784 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 784784
[ Model Rollout ] Added: 49005 | Model pool: 500000 (max 500000) | Length: 4.9005 | Train rep: 1

Diagnostics -- iteration 785000
real_batch_obs: 1907.07, model_batch_obs: 1948.65
real_batch_act: 207.41, model_batch_act: 191.48
real_batch_rewards: 1396.75, model_batch_rewards: 1348.30
real_batch_dones: 2.00, model_batch_dones: 1.00
evaluation/return-average: 2859.87
total_steps: 785000.00
Q-avg: 961.40, Q-max: 1434.30, Q-min: -1458.75
Q_loss1: 2083.45, Q_loss2: 1492.35, min_Q_loss1: -86.45, min_Q_loss2: -84.18

Train epoch 785/3000 -- step 786000

[F                                                                                                    
[F[ Model Length ] Epoch: 785 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 785000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 785 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 785785
[ Model Rollout ] Added: 48997 | Model pool: 500000 (max 500000) | Length: 4.8997 | Train rep: 1

Diagnostics -- iteration 786000
real_batch_obs: 1801.65, model_batch_obs: 1944.37
real_batch_act: 198.94, model_batch_act: 194.25
real_batch_rewards: 1371.35, model_batch_rewards: 1390.09
real_batch_dones: 1.00, model_batch_dones: 2.00
evaluation/return-average: 2865.83
total_steps: 786000.00
Q-avg: 985.83, Q-max: 1423.87, Q-min: -210.77
Q_loss1: 693.34, Q_loss2: 583.04, min_Q_loss1: -553.02, min_Q_loss2: -560.29

Train epoch 786/3000 -- step 787000

[F                                                                                                    
[F[ Model Length ] Epoch: 786 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 786000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 786 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 786786
[ Model Rollout ] Added: 49085 | Model pool: 500000 (max 500000) | Length: 4.9085 | Train rep: 1

Diagnostics -- iteration 787000
real_batch_obs: 1805.63, model_batch_obs: 1976.53
real_batch_act: 200.28, model_batch_act: 182.06
real_batch_rewards: 1349.83, model_batch_rewards: 1368.14
real_batch_dones: 0.00, model_batch_dones: 3.00
evaluation/return-average: 2952.23
total_steps: 787000.00
Q-avg: 1022.43, Q-max: 1420.13, Q-min: -439.39
Q_loss1: 478.73, Q_loss2: 456.52, min_Q_loss1: -293.67, min_Q_loss2: -295.56

Train epoch 787/3000 -- step 788000

[F                                                                                                    
[F[ Model Length ] Epoch: 787 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 787000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 787 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 787787
[ Model Rollout ] Added: 49096 | Model pool: 500000 (max 500000) | Length: 4.9096 | Train rep: 1

Diagnostics -- iteration 788000
real_batch_obs: 1887.59, model_batch_obs: 1865.50
real_batch_act: 202.97, model_batch_act: 193.52
real_batch_rewards: 1383.18, model_batch_rewards: 1329.45
real_batch_dones: 1.00, model_batch_dones: 3.00
evaluation/return-average: 2913.86
total_steps: 788000.00
Q-avg: 1014.06, Q-max: 1454.60, Q-min: -1169.78
Q_loss1: 2375.59, Q_loss2: 2400.95, min_Q_loss1: -368.97, min_Q_loss2: -378.22

Train epoch 788/3000 -- step 789000

[F                                                                                                    
[F[ Model Length ] Epoch: 788 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 788000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 788 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 788788
[ Model Rollout ] Added: 49069 | Model pool: 500000 (max 500000) | Length: 4.9069 | Train rep: 1

Diagnostics -- iteration 789000
real_batch_obs: 1900.84, model_batch_obs: 1874.42
real_batch_act: 199.20, model_batch_act: 193.97
real_batch_rewards: 1373.64, model_batch_rewards: 1328.44
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 2972.48
total_steps: 789000.00
Q-avg: 1066.12, Q-max: 1420.52, Q-min: -57.29
Q_loss1: 210.07, Q_loss2: 286.58, min_Q_loss1: -328.55, min_Q_loss2: -325.99

Train epoch 789/3000 -- step 790000

[F                                                                                                    
[F[ Model Length ] Epoch: 789 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 789000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 789 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 789789
[ Model Rollout ] Added: 49083 | Model pool: 500000 (max 500000) | Length: 4.9083 | Train rep: 1

Diagnostics -- iteration 790000
real_batch_obs: 1889.89, model_batch_obs: 1831.88
real_batch_act: 214.49, model_batch_act: 186.61
real_batch_rewards: 1331.18, model_batch_rewards: 1363.87
real_batch_dones: 1.00, model_batch_dones: 1.00
evaluation/return-average: 2884.72
total_steps: 790000.00
Q-avg: 1019.42, Q-max: 1438.46, Q-min: -186.82
Q_loss1: 890.05, Q_loss2: 1056.94, min_Q_loss1: -213.62, min_Q_loss2: -216.08

Train epoch 790/3000 -- step 791000

[F                                                                                                    
[F[ Model Length ] Epoch: 790 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 790000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 790 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 790790
[ Model Rollout ] Added: 49023 | Model pool: 500000 (max 500000) | Length: 4.9023 | Train rep: 1

Diagnostics -- iteration 791000
real_batch_obs: 1933.10, model_batch_obs: 1832.64
real_batch_act: 199.93, model_batch_act: 195.93
real_batch_rewards: 1387.48, model_batch_rewards: 1286.38
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 2961.73
total_steps: 791000.00
Q-avg: 979.71, Q-max: 1424.47, Q-min: -280.03
Q_loss1: 504.28, Q_loss2: 447.81, min_Q_loss1: -388.30, min_Q_loss2: -388.60

Train epoch 791/3000 -- step 792000

[F                                                                                                    
[F[ Model Length ] Epoch: 791 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 791000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 791 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 791791
[ Model Rollout ] Added: 49015 | Model pool: 500000 (max 500000) | Length: 4.9015 | Train rep: 1

Diagnostics -- iteration 792000
real_batch_obs: 1772.59, model_batch_obs: 1949.38
real_batch_act: 203.13, model_batch_act: 189.88
real_batch_rewards: 1297.76, model_batch_rewards: 1362.66
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 2892.54
total_steps: 792000.00
Q-avg: 1028.00, Q-max: 1438.38, Q-min: -185.63
Q_loss1: 259.10, Q_loss2: 320.69, min_Q_loss1: -223.03, min_Q_loss2: -221.34

Train epoch 792/3000 -- step 793000

[F                                                                                                    
[F[ Model Length ] Epoch: 792 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 792000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 792 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 792792
[ Model Rollout ] Added: 49085 | Model pool: 500000 (max 500000) | Length: 4.9085 | Train rep: 1

Diagnostics -- iteration 793000
real_batch_obs: 1853.63, model_batch_obs: 1849.08
real_batch_act: 209.10, model_batch_act: 195.45
real_batch_rewards: 1365.20, model_batch_rewards: 1263.75
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 2901.73
total_steps: 793000.00
Q-avg: 1033.08, Q-max: 1436.64, Q-min: -86.46
Q_loss1: 410.39, Q_loss2: 436.22, min_Q_loss1: 13.72, min_Q_loss2: 19.73

Train epoch 793/3000 -- step 794000

[F                                                                                                    
[F[ Model Length ] Epoch: 793 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 793000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 793 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 793793
[ Model Rollout ] Added: 49059 | Model pool: 500000 (max 500000) | Length: 4.9059 | Train rep: 1

Diagnostics -- iteration 794000
real_batch_obs: 1842.29, model_batch_obs: 1862.87
real_batch_act: 198.09, model_batch_act: 181.91
real_batch_rewards: 1357.49, model_batch_rewards: 1358.67
real_batch_dones: 0.00, model_batch_dones: 0.00
evaluation/return-average: 2894.26
total_steps: 794000.00
Q-avg: 1072.55, Q-max: 1443.43, Q-min: -278.25
Q_loss1: 445.59, Q_loss2: 423.74, min_Q_loss1: -210.59, min_Q_loss2: -210.50

Train epoch 794/3000 -- step 795000

[F                                                                                                    
[F[ Model Length ] Epoch: 794 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 794000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 794 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 794794
[ Model Rollout ] Added: 48918 | Model pool: 500000 (max 500000) | Length: 4.8918 | Train rep: 1

Diagnostics -- iteration 795000
real_batch_obs: 1834.04, model_batch_obs: 1898.77
real_batch_act: 182.58, model_batch_act: 195.79
real_batch_rewards: 1369.21, model_batch_rewards: 1375.06
real_batch_dones: 0.00, model_batch_dones: 4.00
evaluation/return-average: 2891.12
total_steps: 795000.00
Q-avg: 1035.34, Q-max: 1449.78, Q-min: -38.71
Q_loss1: 148.81, Q_loss2: 171.76, min_Q_loss1: -257.21, min_Q_loss2: -258.53

Train epoch 795/3000 -- step 796000

[F                                                                                                    
[F[ Model Length ] Epoch: 795 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 795000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 795 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 795795
[ Model Rollout ] Added: 49038 | Model pool: 500000 (max 500000) | Length: 4.9038 | Train rep: 1

Diagnostics -- iteration 796000
real_batch_obs: 1824.07, model_batch_obs: 1828.46
real_batch_act: 196.65, model_batch_act: 191.17
real_batch_rewards: 1355.23, model_batch_rewards: 1369.81
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 2997.12
total_steps: 796000.00
Q-avg: 996.07, Q-max: 1441.19, Q-min: -178.34
Q_loss1: 213.61, Q_loss2: 241.94, min_Q_loss1: -398.40, min_Q_loss2: -403.95

Train epoch 796/3000 -- step 797000

[F                                                                                                    
[F[ Model Length ] Epoch: 796 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 796000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 796 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 796796
[ Model Rollout ] Added: 49088 | Model pool: 500000 (max 500000) | Length: 4.9088 | Train rep: 1

Diagnostics -- iteration 797000
real_batch_obs: 1752.76, model_batch_obs: 1975.56
real_batch_act: 201.37, model_batch_act: 195.65
real_batch_rewards: 1338.89, model_batch_rewards: 1353.26
real_batch_dones: 0.00, model_batch_dones: 1.00
evaluation/return-average: 2916.39
total_steps: 797000.00
Q-avg: 1083.09, Q-max: 1432.90, Q-min: -224.13
Q_loss1: 283.80, Q_loss2: 240.48, min_Q_loss1: -114.37, min_Q_loss2: -118.53

Train epoch 797/3000 -- step 798000

[F                                                                                                    
[F[ Model Length ] Epoch: 797 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 797000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 797 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 797797
[ Model Rollout ] Added: 48912 | Model pool: 500000 (max 500000) | Length: 4.8912 | Train rep: 1

Diagnostics -- iteration 798000
real_batch_obs: 1836.81, model_batch_obs: 1931.54
real_batch_act: 196.44, model_batch_act: 195.37
real_batch_rewards: 1328.83, model_batch_rewards: 1380.42
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 2914.47
total_steps: 798000.00
Q-avg: 1039.59, Q-max: 1431.95, Q-min: -319.82
Q_loss1: 545.03, Q_loss2: 502.68, min_Q_loss1: -289.24, min_Q_loss2: -287.29

Train epoch 798/3000 -- step 799000

[F                                                                                                    
[F[ Model Length ] Epoch: 798 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 798000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 798 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 798798
[ Model Rollout ] Added: 49048 | Model pool: 500000 (max 500000) | Length: 4.9048 | Train rep: 1

Diagnostics -- iteration 799000
real_batch_obs: 1834.53, model_batch_obs: 1862.96
real_batch_act: 209.36, model_batch_act: 198.00
real_batch_rewards: 1277.00, model_batch_rewards: 1387.33
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 2854.07
total_steps: 799000.00
Q-avg: 991.38, Q-max: 1426.31, Q-min: -527.23
Q_loss1: 617.70, Q_loss2: 644.42, min_Q_loss1: -427.66, min_Q_loss2: -426.62

Train epoch 799/3000 -- step 800000

[F                                                                                                    
[F[ Model Length ] Epoch: 799 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 799000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 799 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 799799
[ Model Rollout ] Added: 48977 | Model pool: 500000 (max 500000) | Length: 4.8977 | Train rep: 1

Diagnostics -- iteration 800000
real_batch_obs: 1937.78, model_batch_obs: 1831.77
real_batch_act: 197.92, model_batch_act: 188.77
real_batch_rewards: 1477.27, model_batch_rewards: 1368.72
real_batch_dones: 0.00, model_batch_dones: 2.00
evaluation/return-average: 2875.24
total_steps: 800000.00
Q-avg: 989.97, Q-max: 1426.15, Q-min: -156.08
Q_loss1: 340.77, Q_loss2: 316.47, min_Q_loss1: -271.83, min_Q_loss2: -275.81

Train epoch 800/3000 -- step 801000

[F                                                                                                    
[F[ Model Length ] Epoch: 800 (min: 20, max: 100) | Length: 5 (min: 5 , max: 5)
[ combo ] Rolling out model at timestep: 0 (ready to train: True) -- total_step 800000 -- model_size 500000
[ Model Rollout ] Starting | Epoch: 800 | Rollout length: 5 | Batch size: 10000 | Type: mlp | Current n_: 800800
[ Model Rollout ] Added: 49036 | Model pool: 500000 (max 500000) | Length: 4.9036 | Train rep: 1

