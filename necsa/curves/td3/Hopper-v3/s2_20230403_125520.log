2023-04-03 12:55:20 - Exp configurations:
batch_size: 256
ckpt_freq: 200000
env_name: Hopper-v3
eval_episodes: 10
eval_freq: 5000
expl_noise: 0.1
gamma: 0.99
hidden_dims: !!python/tuple
- 256
- 256
initializer: glorot_uniform
log_dir: logs
lr: 0.0003
max_timesteps: 1000000
model_dir: saved_models
noise_clip: 0.5
policy_freq: 2
policy_noise: 0.2
seed: 2
start_timesteps: 25000
tau: 0.005

2023-04-03 12:55:25 - 
[#Step 10000] eval_reward: 20.04, eval_step: 29, eval_time: 0

2023-04-03 12:55:26 - 
[#Step 20000] eval_reward: 20.25, eval_step: 29, eval_time: 0

2023-04-03 12:55:33 - 
[#Step 30000] eval_reward: 174.70, eval_step: 87, eval_time: 0, time: 0.21
	critic_loss: 6.33, actor_loss: -19.12
	q1: 16.84, max_q1: 30.89, min_q1: -4.16
	batch_reward: 0.94, batch_reward_max: 2.86, batch_reward_min: -0.66

2023-04-03 12:55:42 - 
[#Step 40000] eval_reward: 323.33, eval_step: 146, eval_time: 0, time: 0.36
	critic_loss: 23.04, actor_loss: -73.87
	q1: 70.34, max_q1: 133.03, min_q1: -3.17
	batch_reward: 1.31, batch_reward_max: 3.32, batch_reward_min: -0.58

2023-04-03 12:55:51 - 
[#Step 50000] eval_reward: 283.10, eval_step: 132, eval_time: 0, time: 0.52
	critic_loss: 89.91, actor_loss: -118.61
	q1: 113.39, max_q1: 177.71, min_q1: -25.71
	batch_reward: 1.56, batch_reward_max: 3.51, batch_reward_min: -0.33

2023-04-03 12:56:00 - 
[#Step 60000] eval_reward: 298.17, eval_step: 128, eval_time: 0, time: 0.67
	critic_loss: 53.94, actor_loss: -149.57
	q1: 143.51, max_q1: 207.71, min_q1: -33.20
	batch_reward: 1.70, batch_reward_max: 3.82, batch_reward_min: -0.31

2023-04-03 12:56:10 - 
[#Step 70000] eval_reward: 246.16, eval_step: 109, eval_time: 0, time: 0.82
	critic_loss: 128.83, actor_loss: -155.88
	q1: 148.40, max_q1: 221.88, min_q1: -6.92
	batch_reward: 1.72, batch_reward_max: 3.60, batch_reward_min: -0.03

2023-04-03 12:56:19 - 
[#Step 80000] eval_reward: 319.16, eval_step: 136, eval_time: 0, time: 0.98
	critic_loss: 31.90, actor_loss: -155.07
	q1: 150.61, max_q1: 216.09, min_q1: -1.45
	batch_reward: 1.78, batch_reward_max: 3.63, batch_reward_min: -0.20

2023-04-03 12:56:28 - 
[#Step 90000] eval_reward: 354.91, eval_step: 183, eval_time: 0, time: 1.13
	critic_loss: 16.55, actor_loss: -143.53
	q1: 139.60, max_q1: 201.34, min_q1: -6.95
	batch_reward: 1.85, batch_reward_max: 3.69, batch_reward_min: 0.02

2023-04-03 12:56:37 - 
[#Step 100000] eval_reward: 336.19, eval_step: 152, eval_time: 0, time: 1.29
	critic_loss: 49.69, actor_loss: -153.63
	q1: 150.06, max_q1: 199.10, min_q1: -1.35
	batch_reward: 1.73, batch_reward_max: 3.62, batch_reward_min: -0.17

2023-04-03 12:56:47 - 
[#Step 110000] eval_reward: 371.45, eval_step: 193, eval_time: 0, time: 1.44
	critic_loss: 11.23, actor_loss: -143.61
	q1: 141.52, max_q1: 189.93, min_q1: 2.30
	batch_reward: 1.86, batch_reward_max: 3.51, batch_reward_min: -0.22

2023-04-03 12:56:56 - 
[#Step 120000] eval_reward: 295.35, eval_step: 131, eval_time: 0, time: 1.60
	critic_loss: 90.75, actor_loss: -141.01
	q1: 137.25, max_q1: 180.95, min_q1: -3.25
	batch_reward: 1.71, batch_reward_max: 3.63, batch_reward_min: -0.19

2023-04-03 12:57:06 - 
[#Step 130000] eval_reward: 429.76, eval_step: 156, eval_time: 0, time: 1.76
	critic_loss: 38.90, actor_loss: -138.81
	q1: 135.53, max_q1: 179.86, min_q1: -0.41
	batch_reward: 1.83, batch_reward_max: 3.71, batch_reward_min: 0.23

2023-04-03 12:57:15 - 
[#Step 140000] eval_reward: 531.64, eval_step: 188, eval_time: 0, time: 1.91
	critic_loss: 13.55, actor_loss: -135.69
	q1: 133.51, max_q1: 176.18, min_q1: -1.77
	batch_reward: 1.89, batch_reward_max: 3.94, batch_reward_min: -0.36

2023-04-03 12:57:24 - 
[#Step 150000] eval_reward: 144.80, eval_step: 62, eval_time: 0, time: 2.06
	critic_loss: 20.43, actor_loss: -136.70
	q1: 133.61, max_q1: 183.21, min_q1: -11.54
	batch_reward: 1.93, batch_reward_max: 4.72, batch_reward_min: -0.07

2023-04-03 12:57:33 - 
[#Step 160000] eval_reward: 571.37, eval_step: 188, eval_time: 0, time: 2.22
	critic_loss: 94.22, actor_loss: -147.21
	q1: 141.93, max_q1: 199.58, min_q1: -35.02
	batch_reward: 1.92, batch_reward_max: 4.32, batch_reward_min: -0.26

2023-04-03 12:57:43 - 
[#Step 170000] eval_reward: 566.06, eval_step: 185, eval_time: 0, time: 2.38
	critic_loss: 27.59, actor_loss: -157.31
	q1: 154.97, max_q1: 212.74, min_q1: 0.71
	batch_reward: 2.10, batch_reward_max: 5.30, batch_reward_min: -0.16

2023-04-03 12:57:52 - 
[#Step 180000] eval_reward: 795.64, eval_step: 248, eval_time: 1, time: 2.54
	critic_loss: 236.67, actor_loss: -168.70
	q1: 165.98, max_q1: 217.30, min_q1: 6.18
	batch_reward: 2.11, batch_reward_max: 4.83, batch_reward_min: 0.06

2023-04-03 12:58:02 - 
[#Step 190000] eval_reward: 1077.76, eval_step: 364, eval_time: 1, time: 2.70
	critic_loss: 25.38, actor_loss: -162.66
	q1: 158.83, max_q1: 252.09, min_q1: -18.72
	batch_reward: 2.17, batch_reward_max: 4.65, batch_reward_min: -0.18

2023-04-03 12:58:12 - 
[#Step 200000] eval_reward: 898.45, eval_step: 272, eval_time: 1, time: 2.86
	critic_loss: 15.57, actor_loss: -172.88
	q1: 169.59, max_q1: 254.98, min_q1: -11.08
	batch_reward: 2.22, batch_reward_max: 4.72, batch_reward_min: -0.70

2023-04-03 12:58:12 - Saving checkpoint at step: 1
2023-04-03 12:58:12 - Saved checkpoint at saved_models/td3/Hopper-v3/s2_20230403_125520/actor_1
2023-04-03 12:58:12 - Saving checkpoint at step: 1
2023-04-03 12:58:12 - Saved checkpoint at saved_models/td3/Hopper-v3/s2_20230403_125520/critic_1
2023-04-03 12:58:21 - 
[#Step 210000] eval_reward: 898.32, eval_step: 283, eval_time: 1, time: 3.02
	critic_loss: 63.35, actor_loss: -180.98
	q1: 176.38, max_q1: 254.45, min_q1: -5.14
	batch_reward: 2.36, batch_reward_max: 5.26, batch_reward_min: -0.67

2023-04-03 12:58:31 - 
[#Step 220000] eval_reward: 776.36, eval_step: 240, eval_time: 1, time: 3.18
	critic_loss: 15.78, actor_loss: -196.31
	q1: 191.95, max_q1: 263.43, min_q1: -7.45
	batch_reward: 2.27, batch_reward_max: 4.74, batch_reward_min: -0.00

2023-04-03 12:58:41 - 
[#Step 230000] eval_reward: 791.95, eval_step: 240, eval_time: 1, time: 3.34
	critic_loss: 16.41, actor_loss: -199.39
	q1: 197.40, max_q1: 259.40, min_q1: -10.55
	batch_reward: 2.44, batch_reward_max: 5.29, batch_reward_min: 0.20

2023-04-03 12:58:51 - 
[#Step 240000] eval_reward: 1852.11, eval_step: 611, eval_time: 1, time: 3.52
	critic_loss: 97.88, actor_loss: -205.83
	q1: 202.21, max_q1: 274.07, min_q1: -10.32
	batch_reward: 2.30, batch_reward_max: 4.83, batch_reward_min: -0.52

2023-04-03 12:59:02 - 
[#Step 250000] eval_reward: 1771.21, eval_step: 568, eval_time: 1, time: 3.69
	critic_loss: 12.39, actor_loss: -201.42
	q1: 198.38, max_q1: 277.25, min_q1: -10.42
	batch_reward: 2.32, batch_reward_max: 5.40, batch_reward_min: 0.11

2023-04-03 12:59:12 - 
[#Step 260000] eval_reward: 1855.60, eval_step: 592, eval_time: 1, time: 3.86
	critic_loss: 26.84, actor_loss: -203.68
	q1: 199.60, max_q1: 281.26, min_q1: -11.81
	batch_reward: 2.48, batch_reward_max: 5.01, batch_reward_min: -0.13

2023-04-03 12:59:22 - 
[#Step 270000] eval_reward: 2101.49, eval_step: 661, eval_time: 2, time: 4.04
	critic_loss: 67.63, actor_loss: -201.44
	q1: 197.03, max_q1: 284.54, min_q1: -7.01
	batch_reward: 2.47, batch_reward_max: 4.76, batch_reward_min: -0.22

2023-04-03 12:59:32 - 
[#Step 280000] eval_reward: 1233.34, eval_step: 410, eval_time: 1, time: 4.20
	critic_loss: 13.17, actor_loss: -205.77
	q1: 202.29, max_q1: 283.55, min_q1: -18.65
	batch_reward: 2.56, batch_reward_max: 5.05, batch_reward_min: 0.26

2023-04-03 12:59:43 - 
[#Step 290000] eval_reward: 1937.19, eval_step: 604, eval_time: 1, time: 4.37
	critic_loss: 24.97, actor_loss: -203.23
	q1: 200.27, max_q1: 286.52, min_q1: -28.51
	batch_reward: 2.59, batch_reward_max: 5.25, batch_reward_min: -0.40

2023-04-03 12:59:53 - 
[#Step 300000] eval_reward: 2201.72, eval_step: 718, eval_time: 2, time: 4.55
	critic_loss: 49.46, actor_loss: -213.11
	q1: 208.39, max_q1: 284.11, min_q1: -18.39
	batch_reward: 2.55, batch_reward_max: 5.31, batch_reward_min: -0.21

2023-04-03 13:00:04 - 
[#Step 310000] eval_reward: 1906.36, eval_step: 623, eval_time: 1, time: 4.72
	critic_loss: 11.82, actor_loss: -213.12
	q1: 210.57, max_q1: 279.62, min_q1: -15.26
	batch_reward: 2.51, batch_reward_max: 4.70, batch_reward_min: -0.43

2023-04-03 13:00:14 - 
[#Step 320000] eval_reward: 1943.49, eval_step: 647, eval_time: 1, time: 4.90
	critic_loss: 17.00, actor_loss: -212.45
	q1: 210.17, max_q1: 285.01, min_q1: -22.75
	batch_reward: 2.64, batch_reward_max: 5.17, batch_reward_min: -0.35

2023-04-03 13:00:25 - 
[#Step 330000] eval_reward: 3164.73, eval_step: 1000, eval_time: 2, time: 5.08
	critic_loss: 21.70, actor_loss: -224.75
	q1: 222.21, max_q1: 287.95, min_q1: 8.69
	batch_reward: 2.59, batch_reward_max: 4.84, batch_reward_min: -0.04

2023-04-03 13:00:36 - 
[#Step 340000] eval_reward: 2734.72, eval_step: 876, eval_time: 2, time: 5.27
	critic_loss: 131.56, actor_loss: -222.91
	q1: 219.91, max_q1: 290.46, min_q1: 1.38
	batch_reward: 2.53, batch_reward_max: 5.18, batch_reward_min: -0.20

2023-04-03 13:00:46 - 
[#Step 350000] eval_reward: 1470.47, eval_step: 469, eval_time: 1, time: 5.44
	critic_loss: 47.32, actor_loss: -212.52
	q1: 209.74, max_q1: 288.77, min_q1: -11.90
	batch_reward: 2.67, batch_reward_max: 5.21, batch_reward_min: -0.15

2023-04-03 13:00:57 - 
[#Step 360000] eval_reward: 1906.04, eval_step: 591, eval_time: 1, time: 5.61
	critic_loss: 16.20, actor_loss: -232.53
	q1: 230.53, max_q1: 290.13, min_q1: 8.03
	batch_reward: 2.62, batch_reward_max: 5.21, batch_reward_min: 0.34

2023-04-03 13:01:08 - 
[#Step 370000] eval_reward: 2508.31, eval_step: 822, eval_time: 2, time: 5.79
	critic_loss: 43.77, actor_loss: -226.58
	q1: 223.75, max_q1: 289.36, min_q1: 7.76
	batch_reward: 2.72, batch_reward_max: 5.26, batch_reward_min: 0.23

2023-04-03 13:01:19 - 
[#Step 380000] eval_reward: 3040.09, eval_step: 1000, eval_time: 2, time: 5.98
	critic_loss: 10.37, actor_loss: -233.42
	q1: 231.78, max_q1: 293.31, min_q1: 15.42
	batch_reward: 2.70, batch_reward_max: 5.03, batch_reward_min: 0.18

2023-04-03 13:01:30 - 
[#Step 390000] eval_reward: 3136.54, eval_step: 1000, eval_time: 2, time: 6.16
	critic_loss: 23.63, actor_loss: -227.83
	q1: 225.09, max_q1: 293.07, min_q1: -21.45
	batch_reward: 2.66, batch_reward_max: 5.31, batch_reward_min: -0.23

2023-04-03 13:01:41 - 
[#Step 400000] eval_reward: 2989.22, eval_step: 960, eval_time: 2, time: 6.35
	critic_loss: 32.03, actor_loss: -236.48
	q1: 232.29, max_q1: 298.87, min_q1: -47.65
	batch_reward: 2.73, batch_reward_max: 5.08, batch_reward_min: 0.14

2023-04-03 13:01:41 - Saving checkpoint at step: 2
2023-04-03 13:01:41 - Saved checkpoint at saved_models/td3/Hopper-v3/s2_20230403_125520/actor_2
2023-04-03 13:01:41 - Saving checkpoint at step: 2
2023-04-03 13:01:41 - Saved checkpoint at saved_models/td3/Hopper-v3/s2_20230403_125520/critic_2
2023-04-03 13:01:52 - 
[#Step 410000] eval_reward: 3134.00, eval_step: 1000, eval_time: 2, time: 6.54
	critic_loss: 9.76, actor_loss: -236.47
	q1: 234.82, max_q1: 298.95, min_q1: 8.80
	batch_reward: 2.61, batch_reward_max: 5.34, batch_reward_min: 0.27

2023-04-03 13:02:04 - 
[#Step 420000] eval_reward: 3075.36, eval_step: 1000, eval_time: 2, time: 6.72
	critic_loss: 66.28, actor_loss: -231.08
	q1: 228.14, max_q1: 299.37, min_q1: -22.80
	batch_reward: 2.83, batch_reward_max: 5.44, batch_reward_min: 0.46

2023-04-03 13:02:15 - 
[#Step 430000] eval_reward: 3253.88, eval_step: 1000, eval_time: 2, time: 6.91
	critic_loss: 10.97, actor_loss: -238.17
	q1: 234.39, max_q1: 298.29, min_q1: -5.24
	batch_reward: 2.65, batch_reward_max: 4.96, batch_reward_min: 0.21

2023-04-03 13:02:26 - 
[#Step 440000] eval_reward: 3006.51, eval_step: 934, eval_time: 2, time: 7.09
	critic_loss: 108.53, actor_loss: -245.02
	q1: 241.57, max_q1: 301.39, min_q1: -14.66
	batch_reward: 2.72, batch_reward_max: 5.81, batch_reward_min: 0.45

2023-04-03 13:02:37 - 
[#Step 450000] eval_reward: 3271.62, eval_step: 1000, eval_time: 2, time: 7.28
	critic_loss: 15.92, actor_loss: -243.66
	q1: 241.67, max_q1: 301.42, min_q1: 10.72
	batch_reward: 2.80, batch_reward_max: 5.84, batch_reward_min: 0.50

2023-04-03 13:02:48 - 
[#Step 460000] eval_reward: 2992.72, eval_step: 936, eval_time: 2, time: 7.47
	critic_loss: 8.86, actor_loss: -249.82
	q1: 248.21, max_q1: 305.26, min_q1: -10.83
	batch_reward: 2.65, batch_reward_max: 5.02, batch_reward_min: -0.12

2023-04-03 13:03:00 - 
[#Step 470000] eval_reward: 3269.00, eval_step: 1000, eval_time: 2, time: 7.66
	critic_loss: 17.86, actor_loss: -239.08
	q1: 236.35, max_q1: 305.64, min_q1: -6.36
	batch_reward: 2.68, batch_reward_max: 5.29, batch_reward_min: 0.12

2023-04-03 13:03:11 - 
[#Step 480000] eval_reward: 3261.08, eval_step: 1000, eval_time: 2, time: 7.84
	critic_loss: 23.82, actor_loss: -251.91
	q1: 249.71, max_q1: 310.26, min_q1: 6.04
	batch_reward: 2.74, batch_reward_max: 5.10, batch_reward_min: -0.08

2023-04-03 13:03:22 - 
[#Step 490000] eval_reward: 3236.05, eval_step: 1000, eval_time: 2, time: 8.03
	critic_loss: 22.69, actor_loss: -247.08
	q1: 243.97, max_q1: 305.12, min_q1: -11.88
	batch_reward: 2.79, batch_reward_max: 5.03, batch_reward_min: -0.35

2023-04-03 13:03:33 - 
[#Step 500000] eval_reward: 3034.12, eval_step: 950, eval_time: 2, time: 8.22
	critic_loss: 10.52, actor_loss: -251.68
	q1: 250.34, max_q1: 307.76, min_q1: 3.84
	batch_reward: 2.74, batch_reward_max: 4.80, batch_reward_min: -0.24

2023-04-03 13:03:45 - 
[#Step 510000] eval_reward: 3156.13, eval_step: 1000, eval_time: 2, time: 8.41
	critic_loss: 15.03, actor_loss: -250.83
	q1: 248.42, max_q1: 311.40, min_q1: -29.31
	batch_reward: 2.84, batch_reward_max: 5.23, batch_reward_min: -0.05

2023-04-03 13:03:56 - 
[#Step 520000] eval_reward: 3331.52, eval_step: 1000, eval_time: 2, time: 8.60
	critic_loss: 14.63, actor_loss: -259.11
	q1: 257.43, max_q1: 309.84, min_q1: -15.69
	batch_reward: 2.69, batch_reward_max: 5.04, batch_reward_min: 0.28

2023-04-03 13:04:07 - 
[#Step 530000] eval_reward: 3165.97, eval_step: 1000, eval_time: 2, time: 8.78
	critic_loss: 44.83, actor_loss: -246.60
	q1: 243.86, max_q1: 310.97, min_q1: -5.67
	batch_reward: 2.82, batch_reward_max: 5.21, batch_reward_min: -0.02

2023-04-03 13:04:19 - 
[#Step 540000] eval_reward: 3257.02, eval_step: 1000, eval_time: 2, time: 8.97
	critic_loss: 17.03, actor_loss: -252.51
	q1: 249.69, max_q1: 310.74, min_q1: -5.39
	batch_reward: 2.79, batch_reward_max: 5.00, batch_reward_min: 0.18

2023-04-03 13:04:30 - 
[#Step 550000] eval_reward: 3227.47, eval_step: 1000, eval_time: 2, time: 9.16
	critic_loss: 8.52, actor_loss: -257.11
	q1: 255.29, max_q1: 310.39, min_q1: -10.95
	batch_reward: 2.80, batch_reward_max: 5.14, batch_reward_min: 0.15

2023-04-03 13:04:41 - 
[#Step 560000] eval_reward: 3200.38, eval_step: 1000, eval_time: 2, time: 9.35
	critic_loss: 8.48, actor_loss: -260.47
	q1: 257.49, max_q1: 313.30, min_q1: -1.40
	batch_reward: 2.83, batch_reward_max: 5.12, batch_reward_min: 0.39

2023-04-03 13:04:52 - 
[#Step 570000] eval_reward: 3232.74, eval_step: 1000, eval_time: 2, time: 9.53
	critic_loss: 37.20, actor_loss: -251.40
	q1: 248.82, max_q1: 310.65, min_q1: -5.57
	batch_reward: 2.72, batch_reward_max: 5.46, batch_reward_min: 0.07

2023-04-03 13:05:03 - 
[#Step 580000] eval_reward: 3236.65, eval_step: 1000, eval_time: 2, time: 9.72
	critic_loss: 11.69, actor_loss: -265.31
	q1: 263.66, max_q1: 314.43, min_q1: 19.13
	batch_reward: 2.85, batch_reward_max: 4.84, batch_reward_min: 0.47

2023-04-03 13:05:15 - 
[#Step 590000] eval_reward: 3269.91, eval_step: 1000, eval_time: 2, time: 9.91
	critic_loss: 10.90, actor_loss: -259.80
	q1: 258.20, max_q1: 314.70, min_q1: -7.45
	batch_reward: 2.72, batch_reward_max: 4.73, batch_reward_min: 0.45

2023-04-03 13:05:26 - 
[#Step 600000] eval_reward: 2907.19, eval_step: 889, eval_time: 2, time: 10.09
	critic_loss: 11.21, actor_loss: -257.87
	q1: 256.72, max_q1: 313.88, min_q1: -28.68
	batch_reward: 2.96, batch_reward_max: 5.24, batch_reward_min: 0.36

2023-04-03 13:05:26 - Saving checkpoint at step: 3
2023-04-03 13:05:26 - Saved checkpoint at saved_models/td3/Hopper-v3/s2_20230403_125520/actor_3
2023-04-03 13:05:26 - Saving checkpoint at step: 3
2023-04-03 13:05:26 - Saved checkpoint at saved_models/td3/Hopper-v3/s2_20230403_125520/critic_3
2023-04-03 13:05:37 - 
[#Step 610000] eval_reward: 3033.10, eval_step: 941, eval_time: 2, time: 10.28
	critic_loss: 25.21, actor_loss: -267.95
	q1: 265.54, max_q1: 316.21, min_q1: -42.12
	batch_reward: 2.79, batch_reward_max: 4.89, batch_reward_min: -0.20

2023-04-03 13:05:48 - 
[#Step 620000] eval_reward: 3171.69, eval_step: 1000, eval_time: 2, time: 10.47
	critic_loss: 26.11, actor_loss: -257.31
	q1: 254.26, max_q1: 317.12, min_q1: -7.40
	batch_reward: 2.91, batch_reward_max: 5.06, batch_reward_min: -0.20

2023-04-03 13:05:59 - 
[#Step 630000] eval_reward: 3298.29, eval_step: 1000, eval_time: 2, time: 10.65
	critic_loss: 6.97, actor_loss: -260.58
	q1: 259.11, max_q1: 316.56, min_q1: 8.07
	batch_reward: 2.90, batch_reward_max: 5.03, batch_reward_min: 0.19

2023-04-03 13:06:11 - 
[#Step 640000] eval_reward: 3296.11, eval_step: 1000, eval_time: 2, time: 10.84
	critic_loss: 14.42, actor_loss: -262.54
	q1: 261.30, max_q1: 314.38, min_q1: 0.78
	batch_reward: 2.91, batch_reward_max: 4.90, batch_reward_min: 0.57

2023-04-03 13:06:22 - 
[#Step 650000] eval_reward: 3264.57, eval_step: 1000, eval_time: 2, time: 11.03
	critic_loss: 19.39, actor_loss: -261.19
	q1: 258.20, max_q1: 318.28, min_q1: -20.38
	batch_reward: 2.80, batch_reward_max: 5.21, batch_reward_min: 0.09

2023-04-03 13:06:33 - 
[#Step 660000] eval_reward: 3320.58, eval_step: 1000, eval_time: 2, time: 11.21
	critic_loss: 12.23, actor_loss: -267.01
	q1: 265.13, max_q1: 317.71, min_q1: -2.26
	batch_reward: 2.80, batch_reward_max: 4.90, batch_reward_min: 0.02

2023-04-03 13:06:44 - 
[#Step 670000] eval_reward: 3097.68, eval_step: 1000, eval_time: 2, time: 11.40
	critic_loss: 221.95, actor_loss: -269.89
	q1: 267.32, max_q1: 316.12, min_q1: 5.45
	batch_reward: 2.86, batch_reward_max: 4.73, batch_reward_min: 0.08

2023-04-03 13:06:56 - 
[#Step 680000] eval_reward: 3324.04, eval_step: 1000, eval_time: 2, time: 11.59
	critic_loss: 11.62, actor_loss: -262.27
	q1: 259.95, max_q1: 318.29, min_q1: 8.05
	batch_reward: 2.90, batch_reward_max: 4.68, batch_reward_min: -0.48

2023-04-03 13:07:07 - 
[#Step 690000] eval_reward: 3256.27, eval_step: 1000, eval_time: 2, time: 11.78
	critic_loss: 6.69, actor_loss: -271.69
	q1: 269.62, max_q1: 318.70, min_q1: -6.37
	batch_reward: 2.97, batch_reward_max: 4.83, batch_reward_min: 0.17

2023-04-03 13:07:18 - 
[#Step 700000] eval_reward: 2955.67, eval_step: 913, eval_time: 2, time: 11.96
	critic_loss: 15.36, actor_loss: -266.05
	q1: 264.26, max_q1: 317.85, min_q1: 2.21
	batch_reward: 2.92, batch_reward_max: 5.49, batch_reward_min: 0.37

2023-04-03 13:07:29 - 
[#Step 710000] eval_reward: 3239.95, eval_step: 1000, eval_time: 2, time: 12.15
	critic_loss: 15.27, actor_loss: -275.74
	q1: 273.77, max_q1: 318.76, min_q1: 2.93
	batch_reward: 2.92, batch_reward_max: 4.82, batch_reward_min: -0.30

2023-04-03 13:07:41 - 
[#Step 720000] eval_reward: 3157.86, eval_step: 1000, eval_time: 2, time: 12.34
	critic_loss: 7.63, actor_loss: -269.23
	q1: 267.85, max_q1: 319.71, min_q1: 11.99
	batch_reward: 3.00, batch_reward_max: 5.25, batch_reward_min: 0.59

2023-04-03 13:07:52 - 
[#Step 730000] eval_reward: 3314.78, eval_step: 1000, eval_time: 2, time: 12.53
	critic_loss: 25.29, actor_loss: -265.06
	q1: 262.14, max_q1: 319.90, min_q1: -20.52
	batch_reward: 2.93, batch_reward_max: 5.07, batch_reward_min: -0.01

2023-04-03 13:08:04 - 
[#Step 740000] eval_reward: 3292.83, eval_step: 1000, eval_time: 2, time: 12.72
	critic_loss: 10.40, actor_loss: -267.08
	q1: 265.51, max_q1: 320.12, min_q1: -0.52
	batch_reward: 3.01, batch_reward_max: 5.51, batch_reward_min: 0.01

2023-04-03 13:08:15 - 
[#Step 750000] eval_reward: 3304.55, eval_step: 1000, eval_time: 2, time: 12.91
	critic_loss: 9.51, actor_loss: -273.79
	q1: 272.37, max_q1: 319.85, min_q1: 17.64
	batch_reward: 2.98, batch_reward_max: 4.97, batch_reward_min: -0.21

2023-04-03 13:08:27 - 
[#Step 760000] eval_reward: 3205.87, eval_step: 1000, eval_time: 2, time: 13.11
	critic_loss: 8.88, actor_loss: -267.99
	q1: 266.75, max_q1: 322.56, min_q1: 13.35
	batch_reward: 2.89, batch_reward_max: 5.37, batch_reward_min: 0.31

2023-04-03 13:08:38 - 
[#Step 770000] eval_reward: 3283.75, eval_step: 1000, eval_time: 2, time: 13.30
	critic_loss: 84.48, actor_loss: -276.17
	q1: 273.81, max_q1: 322.87, min_q1: -2.92
	batch_reward: 2.91, batch_reward_max: 4.96, batch_reward_min: 0.01

2023-04-03 13:08:49 - 
[#Step 780000] eval_reward: 3156.03, eval_step: 1000, eval_time: 2, time: 13.48
	critic_loss: 17.00, actor_loss: -278.12
	q1: 276.17, max_q1: 325.87, min_q1: -7.22
	batch_reward: 2.92, batch_reward_max: 4.76, batch_reward_min: 0.13

2023-04-03 13:09:01 - 
[#Step 790000] eval_reward: 3213.37, eval_step: 1000, eval_time: 2, time: 13.67
	critic_loss: 44.47, actor_loss: -274.53
	q1: 271.85, max_q1: 324.41, min_q1: -49.58
	batch_reward: 2.91, batch_reward_max: 5.57, batch_reward_min: 0.58

2023-04-03 13:09:12 - 
[#Step 800000] eval_reward: 3242.11, eval_step: 1000, eval_time: 2, time: 13.86
	critic_loss: 11.22, actor_loss: -276.02
	q1: 274.75, max_q1: 323.57, min_q1: -15.07
	batch_reward: 2.91, batch_reward_max: 5.05, batch_reward_min: 0.05

2023-04-03 13:09:12 - Saving checkpoint at step: 4
2023-04-03 13:09:12 - Saved checkpoint at saved_models/td3/Hopper-v3/s2_20230403_125520/actor_4
2023-04-03 13:09:12 - Saving checkpoint at step: 4
2023-04-03 13:09:12 - Saved checkpoint at saved_models/td3/Hopper-v3/s2_20230403_125520/critic_4
2023-04-03 13:09:23 - 
[#Step 810000] eval_reward: 3041.64, eval_step: 936, eval_time: 2, time: 14.04
	critic_loss: 16.76, actor_loss: -277.98
	q1: 276.53, max_q1: 325.14, min_q1: 11.61
	batch_reward: 2.86, batch_reward_max: 4.92, batch_reward_min: 0.07

2023-04-03 13:09:34 - 
[#Step 820000] eval_reward: 3271.58, eval_step: 1000, eval_time: 2, time: 14.23
	critic_loss: 62.02, actor_loss: -278.52
	q1: 276.62, max_q1: 324.14, min_q1: 3.43
	batch_reward: 3.02, batch_reward_max: 5.14, batch_reward_min: 0.27

2023-04-03 13:09:44 - 
[#Step 830000] eval_reward: 2308.72, eval_step: 725, eval_time: 2, time: 14.40
	critic_loss: 8.43, actor_loss: -279.98
	q1: 277.74, max_q1: 323.12, min_q1: -4.58
	batch_reward: 2.91, batch_reward_max: 4.90, batch_reward_min: 0.41

2023-04-03 13:09:56 - 
[#Step 840000] eval_reward: 3308.73, eval_step: 1000, eval_time: 2, time: 14.59
	critic_loss: 15.60, actor_loss: -271.68
	q1: 269.75, max_q1: 325.54, min_q1: -31.24
	batch_reward: 2.95, batch_reward_max: 5.45, batch_reward_min: -0.40

2023-04-03 13:10:07 - 
[#Step 850000] eval_reward: 3329.06, eval_step: 1000, eval_time: 2, time: 14.78
	critic_loss: 15.39, actor_loss: -271.18
	q1: 268.98, max_q1: 323.62, min_q1: -7.59
	batch_reward: 2.95, batch_reward_max: 4.61, batch_reward_min: -0.12

2023-04-03 13:10:18 - 
[#Step 860000] eval_reward: 3319.80, eval_step: 1000, eval_time: 2, time: 14.97
	critic_loss: 38.13, actor_loss: -272.83
	q1: 271.25, max_q1: 326.06, min_q1: -78.19
	batch_reward: 2.97, batch_reward_max: 4.83, batch_reward_min: 0.02

2023-04-03 13:10:30 - 
[#Step 870000] eval_reward: 3332.23, eval_step: 1000, eval_time: 2, time: 15.16
	critic_loss: 5.00, actor_loss: -281.16
	q1: 280.17, max_q1: 327.96, min_q1: 13.08
	batch_reward: 2.91, batch_reward_max: 5.06, batch_reward_min: 0.28

2023-04-03 13:10:41 - 
[#Step 880000] eval_reward: 3285.88, eval_step: 1000, eval_time: 2, time: 15.35
	critic_loss: 7.99, actor_loss: -283.27
	q1: 282.32, max_q1: 328.41, min_q1: 4.67
	batch_reward: 3.09, batch_reward_max: 5.08, batch_reward_min: 0.80

2023-04-03 13:10:52 - 
[#Step 890000] eval_reward: 3289.71, eval_step: 1000, eval_time: 2, time: 15.54
	critic_loss: 27.39, actor_loss: -275.17
	q1: 273.64, max_q1: 325.50, min_q1: -9.81
	batch_reward: 2.96, batch_reward_max: 5.44, batch_reward_min: 0.35

2023-04-03 13:11:04 - 
[#Step 900000] eval_reward: 3267.25, eval_step: 1000, eval_time: 2, time: 15.72
	critic_loss: 7.14, actor_loss: -285.63
	q1: 284.71, max_q1: 327.37, min_q1: -7.50
	batch_reward: 3.03, batch_reward_max: 4.79, batch_reward_min: -0.15

2023-04-03 13:11:15 - 
[#Step 910000] eval_reward: 3239.61, eval_step: 1000, eval_time: 2, time: 15.91
	critic_loss: 6.24, actor_loss: -278.76
	q1: 277.72, max_q1: 328.12, min_q1: -4.17
	batch_reward: 3.05, batch_reward_max: 5.23, batch_reward_min: 0.55

2023-04-03 13:11:26 - 
[#Step 920000] eval_reward: 3282.70, eval_step: 1000, eval_time: 2, time: 16.10
	critic_loss: 6.89, actor_loss: -286.77
	q1: 285.73, max_q1: 327.08, min_q1: 1.01
	batch_reward: 3.07, batch_reward_max: 5.11, batch_reward_min: 0.76

2023-04-03 13:11:37 - 
[#Step 930000] eval_reward: 3295.33, eval_step: 1000, eval_time: 2, time: 16.28
	critic_loss: 6.40, actor_loss: -285.48
	q1: 284.33, max_q1: 324.10, min_q1: 2.64
	batch_reward: 3.00, batch_reward_max: 5.20, batch_reward_min: 0.00

2023-04-03 13:11:48 - 
[#Step 940000] eval_reward: 3228.77, eval_step: 1000, eval_time: 2, time: 16.47
	critic_loss: 9.52, actor_loss: -280.73
	q1: 278.19, max_q1: 327.28, min_q1: -18.85
	batch_reward: 2.99, batch_reward_max: 5.09, batch_reward_min: 0.04

2023-04-03 13:11:59 - 
[#Step 950000] eval_reward: 3255.77, eval_step: 1000, eval_time: 2, time: 16.65
	critic_loss: 4.58, actor_loss: -288.84
	q1: 288.00, max_q1: 326.80, min_q1: 12.36
	batch_reward: 3.04, batch_reward_max: 4.66, batch_reward_min: 0.11

2023-04-03 13:12:06 - 
[#Step 955000] eval_reward: 3265.40, eval_step: 1000, eval_time: 2, time: 16.77
	critic_loss: 7.60, actor_loss: -283.26
	q1: 281.76, max_q1: 326.55, min_q1: -4.58
	batch_reward: 2.97, batch_reward_max: 5.09, batch_reward_min: -0.23

2023-04-03 13:12:13 - 
[#Step 960000] eval_reward: 3265.83, eval_step: 1000, eval_time: 2, time: 16.88
	critic_loss: 15.67, actor_loss: -286.27
	q1: 285.13, max_q1: 326.43, min_q1: 20.62
	batch_reward: 3.05, batch_reward_max: 5.26, batch_reward_min: 0.77

2023-04-03 13:12:20 - 
[#Step 965000] eval_reward: 3239.69, eval_step: 1000, eval_time: 2, time: 17.00
	critic_loss: 13.56, actor_loss: -285.24
	q1: 284.28, max_q1: 329.03, min_q1: 15.06
	batch_reward: 2.97, batch_reward_max: 5.15, batch_reward_min: 0.30

2023-04-03 13:12:27 - 
[#Step 970000] eval_reward: 3309.91, eval_step: 1000, eval_time: 2, time: 17.11
	critic_loss: 5.41, actor_loss: -284.62
	q1: 283.39, max_q1: 325.97, min_q1: 30.41
	batch_reward: 2.98, batch_reward_max: 5.05, batch_reward_min: 0.74

2023-04-03 13:12:33 - 
[#Step 975000] eval_reward: 3237.89, eval_step: 1000, eval_time: 2, time: 17.22
	critic_loss: 12.11, actor_loss: -288.02
	q1: 286.93, max_q1: 328.45, min_q1: 11.12
	batch_reward: 3.01, batch_reward_max: 5.48, batch_reward_min: 0.87

2023-04-03 13:12:40 - 
[#Step 980000] eval_reward: 3298.92, eval_step: 1000, eval_time: 2, time: 17.34
	critic_loss: 7.15, actor_loss: -289.51
	q1: 288.35, max_q1: 327.19, min_q1: 17.47
	batch_reward: 3.01, batch_reward_max: 4.84, batch_reward_min: -0.18

2023-04-03 13:12:47 - 
[#Step 985000] eval_reward: 3317.81, eval_step: 1000, eval_time: 2, time: 17.45
	critic_loss: 5.08, actor_loss: -287.51
	q1: 286.74, max_q1: 329.73, min_q1: 5.20
	batch_reward: 3.05, batch_reward_max: 5.28, batch_reward_min: -0.30

2023-04-03 13:12:54 - 
[#Step 990000] eval_reward: 3264.32, eval_step: 1000, eval_time: 2, time: 17.57
	critic_loss: 5.75, actor_loss: -284.28
	q1: 283.35, max_q1: 330.53, min_q1: 10.14
	batch_reward: 3.07, batch_reward_max: 5.71, batch_reward_min: 0.08

2023-04-03 13:13:01 - 
[#Step 995000] eval_reward: 3287.86, eval_step: 1000, eval_time: 2, time: 17.68
	critic_loss: 5.92, actor_loss: -286.65
	q1: 285.76, max_q1: 331.20, min_q1: 30.05
	batch_reward: 2.95, batch_reward_max: 5.27, batch_reward_min: 0.21

2023-04-03 13:13:08 - 
[#Step 1000000] eval_reward: 3232.65, eval_step: 1000, eval_time: 2, time: 17.80
	critic_loss: 13.94, actor_loss: -284.87
	q1: 283.75, max_q1: 326.42, min_q1: 9.24
	batch_reward: 3.01, batch_reward_max: 5.49, batch_reward_min: 0.35

2023-04-03 13:13:08 - Saving checkpoint at step: 5
2023-04-03 13:13:08 - Saved checkpoint at saved_models/td3/Hopper-v3/s2_20230403_125520/actor_5
2023-04-03 13:13:08 - Saving checkpoint at step: 5
2023-04-03 13:13:08 - Saved checkpoint at saved_models/td3/Hopper-v3/s2_20230403_125520/critic_5
