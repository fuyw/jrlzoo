2023-04-03 12:09:20 - Exp configurations:
batch_size: 256
ckpt_freq: 200000
env_name: Walker2d-v3
eval_episodes: 10
eval_freq: 5000
expl_noise: 0.1
gamma: 0.99
hidden_dims: !!python/tuple
- 256
- 256
initializer: glorot_uniform
log_dir: logs
lr: 0.0003
max_timesteps: 1000000
model_dir: saved_models
noise_clip: 0.5
policy_freq: 2
policy_noise: 0.2
seed: 1
start_timesteps: 25000
tau: 0.005

2023-04-03 12:09:24 - 
[#Step 10000] eval_reward: -7.79, eval_step: 10, eval_time: 0

2023-04-03 12:09:26 - 
[#Step 20000] eval_reward: -7.87, eval_step: 10, eval_time: 0

2023-04-03 12:09:35 - 
[#Step 30000] eval_reward: -33.65, eval_step: 79, eval_time: 0, time: 0.25
	critic_loss: 4.92, actor_loss: -20.40
	q1: 17.37, max_q1: 24.91, min_q1: -3.82
	batch_reward: 0.05, batch_reward_max: 1.69, batch_reward_min: -1.87

2023-04-03 12:09:44 - 
[#Step 40000] eval_reward: 193.88, eval_step: 130, eval_time: 0, time: 0.41
	critic_loss: 9.50, actor_loss: -47.48
	q1: 43.99, max_q1: 63.41, min_q1: -5.11
	batch_reward: 0.48, batch_reward_max: 4.76, batch_reward_min: -1.49

2023-04-03 12:09:54 - 
[#Step 50000] eval_reward: 174.33, eval_step: 160, eval_time: 0, time: 0.56
	critic_loss: 23.37, actor_loss: -70.05
	q1: 66.81, max_q1: 87.10, min_q1: -56.28
	batch_reward: 0.59, batch_reward_max: 3.47, batch_reward_min: -2.77

2023-04-03 12:10:04 - 
[#Step 60000] eval_reward: 662.50, eval_step: 551, eval_time: 1, time: 0.74
	critic_loss: 26.23, actor_loss: -78.48
	q1: 74.09, max_q1: 103.18, min_q1: -10.31
	batch_reward: 0.75, batch_reward_max: 4.46, batch_reward_min: -1.34

2023-04-03 12:10:14 - 
[#Step 70000] eval_reward: 274.74, eval_step: 165, eval_time: 0, time: 0.90
	critic_loss: 26.34, actor_loss: -87.66
	q1: 83.86, max_q1: 120.51, min_q1: 0.08
	batch_reward: 0.90, batch_reward_max: 3.71, batch_reward_min: -1.23

2023-04-03 12:10:24 - 
[#Step 80000] eval_reward: 315.07, eval_step: 210, eval_time: 1, time: 1.07
	critic_loss: 22.21, actor_loss: -94.25
	q1: 91.48, max_q1: 123.03, min_q1: -12.09
	batch_reward: 0.93, batch_reward_max: 4.36, batch_reward_min: -1.65

2023-04-03 12:10:33 - 
[#Step 90000] eval_reward: 259.58, eval_step: 133, eval_time: 0, time: 1.23
	critic_loss: 32.99, actor_loss: -99.46
	q1: 95.05, max_q1: 135.10, min_q1: -10.77
	batch_reward: 0.92, batch_reward_max: 4.34, batch_reward_min: -1.98

2023-04-03 12:10:43 - 
[#Step 100000] eval_reward: 322.64, eval_step: 173, eval_time: 0, time: 1.39
	critic_loss: 19.21, actor_loss: -101.08
	q1: 97.89, max_q1: 135.74, min_q1: -9.11
	batch_reward: 1.03, batch_reward_max: 4.95, batch_reward_min: -1.50

2023-04-03 12:10:53 - 
[#Step 110000] eval_reward: 348.82, eval_step: 196, eval_time: 0, time: 1.56
	critic_loss: 29.30, actor_loss: -102.46
	q1: 99.73, max_q1: 133.90, min_q1: -5.90
	batch_reward: 1.19, batch_reward_max: 5.31, batch_reward_min: -1.76

2023-04-03 12:11:03 - 
[#Step 120000] eval_reward: 326.23, eval_step: 174, eval_time: 0, time: 1.71
	critic_loss: 17.76, actor_loss: -102.03
	q1: 98.97, max_q1: 136.45, min_q1: -12.27
	batch_reward: 1.24, batch_reward_max: 4.63, batch_reward_min: -1.83

2023-04-03 12:11:12 - 
[#Step 130000] eval_reward: 200.41, eval_step: 109, eval_time: 0, time: 1.87
	critic_loss: 19.96, actor_loss: -102.44
	q1: 100.16, max_q1: 136.21, min_q1: -5.80
	batch_reward: 1.39, batch_reward_max: 4.74, batch_reward_min: -1.45

2023-04-03 12:11:22 - 
[#Step 140000] eval_reward: 630.97, eval_step: 338, eval_time: 1, time: 2.03
	critic_loss: 29.35, actor_loss: -101.01
	q1: 97.83, max_q1: 138.61, min_q1: -18.06
	batch_reward: 1.32, batch_reward_max: 5.23, batch_reward_min: -1.89

2023-04-03 12:11:31 - 
[#Step 150000] eval_reward: 437.25, eval_step: 227, eval_time: 1, time: 2.19
	critic_loss: 29.16, actor_loss: -103.90
	q1: 101.51, max_q1: 165.20, min_q1: 0.13
	batch_reward: 1.40, batch_reward_max: 4.28, batch_reward_min: -0.89

2023-04-03 12:11:41 - 
[#Step 160000] eval_reward: 499.50, eval_step: 241, eval_time: 1, time: 2.36
	critic_loss: 30.98, actor_loss: -105.62
	q1: 102.74, max_q1: 163.19, min_q1: -6.70
	batch_reward: 1.45, batch_reward_max: 6.49, batch_reward_min: -1.52

2023-04-03 12:11:51 - 
[#Step 170000] eval_reward: 405.37, eval_step: 215, eval_time: 1, time: 2.52
	critic_loss: 27.27, actor_loss: -107.30
	q1: 104.66, max_q1: 161.50, min_q1: -23.35
	batch_reward: 1.46, batch_reward_max: 4.43, batch_reward_min: -1.68

2023-04-03 12:12:00 - 
[#Step 180000] eval_reward: 321.62, eval_step: 164, eval_time: 0, time: 2.68
	critic_loss: 27.48, actor_loss: -106.27
	q1: 102.32, max_q1: 161.57, min_q1: -9.83
	batch_reward: 1.32, batch_reward_max: 4.90, batch_reward_min: -1.32

2023-04-03 12:12:10 - 
[#Step 190000] eval_reward: 579.92, eval_step: 329, eval_time: 1, time: 2.84
	critic_loss: 26.60, actor_loss: -109.87
	q1: 108.24, max_q1: 164.37, min_q1: 0.62
	batch_reward: 1.44, batch_reward_max: 4.57, batch_reward_min: -1.67

2023-04-03 12:12:20 - 
[#Step 200000] eval_reward: 604.70, eval_step: 471, eval_time: 1, time: 3.01
	critic_loss: 30.63, actor_loss: -109.57
	q1: 107.29, max_q1: 162.38, min_q1: -18.47
	batch_reward: 1.37, batch_reward_max: 4.67, batch_reward_min: -2.77

2023-04-03 12:12:20 - Saving checkpoint at step: 1
2023-04-03 12:12:20 - Saved checkpoint at saved_models/td3/Walker2d-v3/s1_20230403_120920/actor_1
2023-04-03 12:12:20 - Saving checkpoint at step: 1
2023-04-03 12:12:20 - Saved checkpoint at saved_models/td3/Walker2d-v3/s1_20230403_120920/critic_1
2023-04-03 12:12:31 - 
[#Step 210000] eval_reward: 1085.55, eval_step: 630, eval_time: 2, time: 3.19
	critic_loss: 40.29, actor_loss: -106.59
	q1: 104.35, max_q1: 173.89, min_q1: -10.76
	batch_reward: 1.54, batch_reward_max: 4.89, batch_reward_min: -1.70

2023-04-03 12:12:41 - 
[#Step 220000] eval_reward: 816.24, eval_step: 411, eval_time: 1, time: 3.36
	critic_loss: 29.87, actor_loss: -115.54
	q1: 113.81, max_q1: 177.85, min_q1: -11.78
	batch_reward: 1.49, batch_reward_max: 4.75, batch_reward_min: -0.89

2023-04-03 12:12:51 - 
[#Step 230000] eval_reward: 629.39, eval_step: 356, eval_time: 1, time: 3.53
	critic_loss: 27.78, actor_loss: -117.99
	q1: 116.37, max_q1: 188.11, min_q1: -14.07
	batch_reward: 1.64, batch_reward_max: 5.26, batch_reward_min: -1.51

2023-04-03 12:13:02 - 
[#Step 240000] eval_reward: 1232.36, eval_step: 623, eval_time: 1, time: 3.71
	critic_loss: 39.63, actor_loss: -119.13
	q1: 116.60, max_q1: 194.77, min_q1: -13.45
	batch_reward: 1.64, batch_reward_max: 4.71, batch_reward_min: -1.86

2023-04-03 12:13:12 - 
[#Step 250000] eval_reward: 737.36, eval_step: 285, eval_time: 1, time: 3.87
	critic_loss: 29.58, actor_loss: -119.81
	q1: 117.08, max_q1: 197.50, min_q1: -8.64
	batch_reward: 1.61, batch_reward_max: 4.51, batch_reward_min: -2.42

2023-04-03 12:13:22 - 
[#Step 260000] eval_reward: 573.73, eval_step: 273, eval_time: 1, time: 4.03
	critic_loss: 26.11, actor_loss: -125.90
	q1: 123.30, max_q1: 215.94, min_q1: -15.66
	batch_reward: 1.77, batch_reward_max: 7.11, batch_reward_min: -1.10

2023-04-03 12:13:31 - 
[#Step 270000] eval_reward: 394.76, eval_step: 198, eval_time: 0, time: 4.19
	critic_loss: 26.15, actor_loss: -127.18
	q1: 124.96, max_q1: 211.93, min_q1: -17.64
	batch_reward: 1.65, batch_reward_max: 5.10, batch_reward_min: -0.83

2023-04-03 12:13:42 - 
[#Step 280000] eval_reward: 1388.97, eval_step: 542, eval_time: 1, time: 4.37
	critic_loss: 35.86, actor_loss: -125.47
	q1: 123.20, max_q1: 241.77, min_q1: -29.21
	batch_reward: 1.63, batch_reward_max: 5.38, batch_reward_min: -2.45

2023-04-03 12:13:52 - 
[#Step 290000] eval_reward: 919.46, eval_step: 329, eval_time: 1, time: 4.53
	critic_loss: 43.21, actor_loss: -132.64
	q1: 129.14, max_q1: 227.23, min_q1: -21.69
	batch_reward: 1.64, batch_reward_max: 6.34, batch_reward_min: -1.59

2023-04-03 12:14:01 - 
[#Step 300000] eval_reward: 846.51, eval_step: 274, eval_time: 1, time: 4.69
	critic_loss: 39.30, actor_loss: -133.39
	q1: 130.90, max_q1: 236.55, min_q1: -3.97
	batch_reward: 1.77, batch_reward_max: 6.64, batch_reward_min: -1.42

2023-04-03 12:14:12 - 
[#Step 310000] eval_reward: 1792.18, eval_step: 544, eval_time: 1, time: 4.87
	critic_loss: 41.39, actor_loss: -142.66
	q1: 140.16, max_q1: 229.47, min_q1: -9.58
	batch_reward: 1.75, batch_reward_max: 6.90, batch_reward_min: -2.62

2023-04-03 12:14:22 - 
[#Step 320000] eval_reward: 1032.65, eval_step: 320, eval_time: 1, time: 5.04
	critic_loss: 52.40, actor_loss: -141.19
	q1: 138.22, max_q1: 244.73, min_q1: -14.85
	batch_reward: 1.80, batch_reward_max: 4.91, batch_reward_min: -1.41

2023-04-03 12:14:33 - 
[#Step 330000] eval_reward: 1788.44, eval_step: 556, eval_time: 1, time: 5.22
	critic_loss: 51.67, actor_loss: -153.43
	q1: 150.41, max_q1: 242.44, min_q1: -0.18
	batch_reward: 1.95, batch_reward_max: 7.19, batch_reward_min: -0.67

2023-04-03 12:14:43 - 
[#Step 340000] eval_reward: 1588.73, eval_step: 575, eval_time: 1, time: 5.39
	critic_loss: 42.05, actor_loss: -152.32
	q1: 149.77, max_q1: 246.64, min_q1: -3.85
	batch_reward: 1.90, batch_reward_max: 5.44, batch_reward_min: -0.97

2023-04-03 12:14:53 - 
[#Step 350000] eval_reward: 1011.44, eval_step: 341, eval_time: 1, time: 5.56
	critic_loss: 51.37, actor_loss: -157.05
	q1: 154.36, max_q1: 248.61, min_q1: -23.02
	batch_reward: 1.93, batch_reward_max: 5.77, batch_reward_min: -1.78

2023-04-03 12:15:03 - 
[#Step 360000] eval_reward: 1123.07, eval_step: 374, eval_time: 1, time: 5.73
	critic_loss: 52.95, actor_loss: -154.67
	q1: 151.98, max_q1: 247.23, min_q1: -5.41
	batch_reward: 2.06, batch_reward_max: 6.06, batch_reward_min: -1.40

2023-04-03 12:15:13 - 
[#Step 370000] eval_reward: 963.30, eval_step: 322, eval_time: 1, time: 5.89
	critic_loss: 45.69, actor_loss: -158.99
	q1: 155.89, max_q1: 252.88, min_q1: -9.67
	batch_reward: 1.96, batch_reward_max: 4.95, batch_reward_min: -2.07

2023-04-03 12:15:23 - 
[#Step 380000] eval_reward: 1147.77, eval_step: 359, eval_time: 1, time: 6.06
	critic_loss: 50.55, actor_loss: -156.94
	q1: 153.06, max_q1: 261.04, min_q1: -21.67
	batch_reward: 1.85, batch_reward_max: 5.11, batch_reward_min: -0.92

2023-04-03 12:15:33 - 
[#Step 390000] eval_reward: 917.49, eval_step: 313, eval_time: 1, time: 6.23
	critic_loss: 39.34, actor_loss: -167.28
	q1: 164.73, max_q1: 259.16, min_q1: -7.78
	batch_reward: 2.04, batch_reward_max: 5.63, batch_reward_min: -0.97

2023-04-03 12:15:44 - 
[#Step 400000] eval_reward: 1401.49, eval_step: 414, eval_time: 1, time: 6.40
	critic_loss: 47.35, actor_loss: -162.81
	q1: 160.42, max_q1: 260.17, min_q1: -19.42
	batch_reward: 2.09, batch_reward_max: 5.77, batch_reward_min: -1.43

2023-04-03 12:15:44 - Saving checkpoint at step: 2
2023-04-03 12:15:44 - Saved checkpoint at saved_models/td3/Walker2d-v3/s1_20230403_120920/actor_2
2023-04-03 12:15:44 - Saving checkpoint at step: 2
2023-04-03 12:15:44 - Saved checkpoint at saved_models/td3/Walker2d-v3/s1_20230403_120920/critic_2
2023-04-03 12:15:54 - 
[#Step 410000] eval_reward: 1815.17, eval_step: 532, eval_time: 1, time: 6.58
	critic_loss: 44.26, actor_loss: -166.01
	q1: 163.03, max_q1: 273.10, min_q1: 1.00
	batch_reward: 2.06, batch_reward_max: 6.45, batch_reward_min: -1.23

2023-04-03 12:16:05 - 
[#Step 420000] eval_reward: 1678.48, eval_step: 478, eval_time: 1, time: 6.75
	critic_loss: 64.67, actor_loss: -168.83
	q1: 165.79, max_q1: 261.02, min_q1: -4.14
	batch_reward: 2.14, batch_reward_max: 5.70, batch_reward_min: -0.85

2023-04-03 12:16:15 - 
[#Step 430000] eval_reward: 1305.36, eval_step: 395, eval_time: 1, time: 6.92
	critic_loss: 56.57, actor_loss: -168.93
	q1: 166.39, max_q1: 264.50, min_q1: -16.93
	batch_reward: 2.23, batch_reward_max: 5.41, batch_reward_min: -1.09

2023-04-03 12:16:26 - 
[#Step 440000] eval_reward: 2562.22, eval_step: 723, eval_time: 2, time: 7.10
	critic_loss: 35.82, actor_loss: -166.35
	q1: 163.44, max_q1: 279.00, min_q1: -61.34
	batch_reward: 2.13, batch_reward_max: 5.72, batch_reward_min: -1.15

2023-04-03 12:16:37 - 
[#Step 450000] eval_reward: 2196.22, eval_step: 626, eval_time: 2, time: 7.28
	critic_loss: 40.30, actor_loss: -175.04
	q1: 172.67, max_q1: 262.48, min_q1: -1.80
	batch_reward: 2.26, batch_reward_max: 6.12, batch_reward_min: -1.59

2023-04-03 12:16:48 - 
[#Step 460000] eval_reward: 2565.77, eval_step: 730, eval_time: 2, time: 7.47
	critic_loss: 56.15, actor_loss: -172.50
	q1: 169.61, max_q1: 268.30, min_q1: -21.15
	batch_reward: 2.25, batch_reward_max: 5.58, batch_reward_min: -1.90

2023-04-03 12:16:58 - 
[#Step 470000] eval_reward: 2337.31, eval_step: 662, eval_time: 2, time: 7.64
	critic_loss: 41.12, actor_loss: -180.40
	q1: 177.25, max_q1: 279.97, min_q1: -105.49
	batch_reward: 2.28, batch_reward_max: 6.50, batch_reward_min: -1.31

2023-04-03 12:17:09 - 
[#Step 480000] eval_reward: 2704.90, eval_step: 744, eval_time: 2, time: 7.82
	critic_loss: 44.38, actor_loss: -180.92
	q1: 177.97, max_q1: 282.32, min_q1: -14.89
	batch_reward: 2.37, batch_reward_max: 5.81, batch_reward_min: -1.35

2023-04-03 12:17:20 - 
[#Step 490000] eval_reward: 2714.01, eval_step: 736, eval_time: 2, time: 8.01
	critic_loss: 31.06, actor_loss: -182.78
	q1: 179.94, max_q1: 288.81, min_q1: -25.66
	batch_reward: 2.41, batch_reward_max: 6.53, batch_reward_min: -0.69

2023-04-03 12:17:31 - 
[#Step 500000] eval_reward: 3216.63, eval_step: 917, eval_time: 2, time: 8.20
	critic_loss: 73.00, actor_loss: -181.04
	q1: 178.35, max_q1: 302.13, min_q1: -55.65
	batch_reward: 2.10, batch_reward_max: 4.86, batch_reward_min: -1.43

2023-04-03 12:17:43 - 
[#Step 510000] eval_reward: 3020.47, eval_step: 810, eval_time: 2, time: 8.38
	critic_loss: 45.11, actor_loss: -189.56
	q1: 186.91, max_q1: 299.76, min_q1: -49.51
	batch_reward: 2.29, batch_reward_max: 5.68, batch_reward_min: -2.19

2023-04-03 12:17:53 - 
[#Step 520000] eval_reward: 2408.94, eval_step: 678, eval_time: 2, time: 8.56
	critic_loss: 53.54, actor_loss: -185.16
	q1: 180.88, max_q1: 299.49, min_q1: -8.76
	batch_reward: 2.27, batch_reward_max: 6.95, batch_reward_min: -1.81

2023-04-03 12:18:04 - 
[#Step 530000] eval_reward: 2807.98, eval_step: 773, eval_time: 2, time: 8.75
	critic_loss: 50.46, actor_loss: -194.72
	q1: 191.34, max_q1: 295.17, min_q1: -34.54
	batch_reward: 2.49, batch_reward_max: 7.65, batch_reward_min: -1.04

2023-04-03 12:18:16 - 
[#Step 540000] eval_reward: 3604.06, eval_step: 986, eval_time: 2, time: 8.94
	critic_loss: 37.98, actor_loss: -198.15
	q1: 194.73, max_q1: 293.18, min_q1: -11.21
	batch_reward: 2.27, batch_reward_max: 5.51, batch_reward_min: -1.08

2023-04-03 12:18:27 - 
[#Step 550000] eval_reward: 2999.67, eval_step: 815, eval_time: 2, time: 9.13
	critic_loss: 45.77, actor_loss: -188.55
	q1: 185.43, max_q1: 309.70, min_q1: -34.69
	batch_reward: 2.27, batch_reward_max: 6.03, batch_reward_min: -2.55

2023-04-03 12:18:39 - 
[#Step 560000] eval_reward: 3004.44, eval_step: 853, eval_time: 2, time: 9.32
	critic_loss: 57.44, actor_loss: -196.67
	q1: 192.74, max_q1: 312.19, min_q1: -29.63
	batch_reward: 2.37, batch_reward_max: 5.42, batch_reward_min: -1.15

2023-04-03 12:18:50 - 
[#Step 570000] eval_reward: 2853.66, eval_step: 803, eval_time: 2, time: 9.51
	critic_loss: 41.03, actor_loss: -208.53
	q1: 205.55, max_q1: 320.79, min_q1: -11.11
	batch_reward: 2.51, batch_reward_max: 6.71, batch_reward_min: -1.07

2023-04-03 12:19:02 - 
[#Step 580000] eval_reward: 3585.12, eval_step: 983, eval_time: 2, time: 9.70
	critic_loss: 45.09, actor_loss: -210.86
	q1: 207.41, max_q1: 309.37, min_q1: -68.94
	batch_reward: 2.52, batch_reward_max: 5.19, batch_reward_min: -1.20

2023-04-03 12:19:13 - 
[#Step 590000] eval_reward: 2840.29, eval_step: 789, eval_time: 2, time: 9.89
	critic_loss: 55.48, actor_loss: -199.42
	q1: 195.59, max_q1: 307.98, min_q1: -16.61
	batch_reward: 2.45, batch_reward_max: 5.19, batch_reward_min: -1.06

2023-04-03 12:19:24 - 
[#Step 600000] eval_reward: 3265.16, eval_step: 896, eval_time: 2, time: 10.08
	critic_loss: 42.46, actor_loss: -212.56
	q1: 209.95, max_q1: 326.53, min_q1: 4.04
	batch_reward: 2.66, batch_reward_max: 6.32, batch_reward_min: -1.00

2023-04-03 12:19:24 - Saving checkpoint at step: 3
2023-04-03 12:19:24 - Saved checkpoint at saved_models/td3/Walker2d-v3/s1_20230403_120920/actor_3
2023-04-03 12:19:24 - Saving checkpoint at step: 3
2023-04-03 12:19:24 - Saved checkpoint at saved_models/td3/Walker2d-v3/s1_20230403_120920/critic_3
2023-04-03 12:19:36 - 
[#Step 610000] eval_reward: 3731.28, eval_step: 1000, eval_time: 2, time: 10.27
	critic_loss: 35.90, actor_loss: -209.99
	q1: 206.89, max_q1: 321.55, min_q1: -22.40
	batch_reward: 2.44, batch_reward_max: 6.27, batch_reward_min: -1.08

2023-04-03 12:19:47 - 
[#Step 620000] eval_reward: 3661.88, eval_step: 1000, eval_time: 2, time: 10.46
	critic_loss: 85.86, actor_loss: -208.77
	q1: 205.69, max_q1: 316.62, min_q1: -27.63
	batch_reward: 2.48, batch_reward_max: 7.69, batch_reward_min: -1.04

2023-04-03 12:19:59 - 
[#Step 630000] eval_reward: 3864.00, eval_step: 1000, eval_time: 3, time: 10.66
	critic_loss: 37.90, actor_loss: -215.33
	q1: 212.48, max_q1: 317.70, min_q1: 3.42
	batch_reward: 2.55, batch_reward_max: 7.27, batch_reward_min: -1.17

2023-04-03 12:20:11 - 
[#Step 640000] eval_reward: 3707.32, eval_step: 1000, eval_time: 2, time: 10.85
	critic_loss: 56.11, actor_loss: -216.18
	q1: 212.18, max_q1: 316.99, min_q1: -19.77
	batch_reward: 2.65, batch_reward_max: 6.22, batch_reward_min: -0.73

2023-04-03 12:20:23 - 
[#Step 650000] eval_reward: 3746.17, eval_step: 1000, eval_time: 2, time: 11.05
	critic_loss: 61.19, actor_loss: -210.20
	q1: 207.34, max_q1: 331.58, min_q1: -30.66
	batch_reward: 2.59, batch_reward_max: 6.02, batch_reward_min: -1.56

2023-04-03 12:20:34 - 
[#Step 660000] eval_reward: 3852.79, eval_step: 1000, eval_time: 2, time: 11.24
	critic_loss: 35.01, actor_loss: -228.14
	q1: 226.08, max_q1: 338.12, min_q1: -53.50
	batch_reward: 2.68, batch_reward_max: 5.30, batch_reward_min: -0.82

2023-04-03 12:20:46 - 
[#Step 670000] eval_reward: 3827.54, eval_step: 1000, eval_time: 2, time: 11.43
	critic_loss: 62.02, actor_loss: -228.65
	q1: 226.07, max_q1: 337.73, min_q1: -24.12
	batch_reward: 2.75, batch_reward_max: 5.54, batch_reward_min: -1.42

2023-04-03 12:20:57 - 
[#Step 680000] eval_reward: 3802.89, eval_step: 1000, eval_time: 2, time: 11.63
	critic_loss: 49.38, actor_loss: -223.43
	q1: 220.11, max_q1: 333.65, min_q1: -118.17
	batch_reward: 2.61, batch_reward_max: 5.12, batch_reward_min: -0.93

2023-04-03 12:21:09 - 
[#Step 690000] eval_reward: 3887.49, eval_step: 1000, eval_time: 2, time: 11.82
	critic_loss: 43.90, actor_loss: -226.20
	q1: 222.83, max_q1: 345.90, min_q1: -82.59
	batch_reward: 2.57, batch_reward_max: 5.74, batch_reward_min: -3.21

2023-04-03 12:21:20 - 
[#Step 700000] eval_reward: 3838.98, eval_step: 1000, eval_time: 2, time: 12.01
	critic_loss: 52.19, actor_loss: -226.99
	q1: 223.48, max_q1: 342.34, min_q1: -21.78
	batch_reward: 2.50, batch_reward_max: 5.24, batch_reward_min: -1.54

2023-04-03 12:21:32 - 
[#Step 710000] eval_reward: 3890.96, eval_step: 1000, eval_time: 2, time: 12.20
	critic_loss: 43.53, actor_loss: -230.94
	q1: 227.88, max_q1: 339.60, min_q1: -71.69
	batch_reward: 2.63, batch_reward_max: 5.16, batch_reward_min: -1.21

2023-04-03 12:21:43 - 
[#Step 720000] eval_reward: 3870.77, eval_step: 1000, eval_time: 2, time: 12.39
	critic_loss: 43.05, actor_loss: -233.26
	q1: 229.72, max_q1: 347.00, min_q1: -72.74
	batch_reward: 2.74, batch_reward_max: 7.68, batch_reward_min: -0.82

2023-04-03 12:21:55 - 
[#Step 730000] eval_reward: 3787.82, eval_step: 1000, eval_time: 2, time: 12.59
	critic_loss: 41.52, actor_loss: -239.84
	q1: 236.71, max_q1: 346.24, min_q1: -53.74
	batch_reward: 2.75, batch_reward_max: 5.98, batch_reward_min: -1.27

2023-04-03 12:22:06 - 
[#Step 740000] eval_reward: 3168.42, eval_step: 834, eval_time: 2, time: 12.77
	critic_loss: 50.91, actor_loss: -239.71
	q1: 236.31, max_q1: 345.67, min_q1: -14.85
	batch_reward: 2.64, batch_reward_max: 6.25, batch_reward_min: -0.69

2023-04-03 12:22:17 - 
[#Step 750000] eval_reward: 3378.28, eval_step: 914, eval_time: 2, time: 12.96
	critic_loss: 53.77, actor_loss: -235.39
	q1: 231.26, max_q1: 342.42, min_q1: -87.88
	batch_reward: 2.57, batch_reward_max: 6.14, batch_reward_min: -0.79

2023-04-03 12:22:29 - 
[#Step 760000] eval_reward: 3783.71, eval_step: 1000, eval_time: 2, time: 13.16
	critic_loss: 50.20, actor_loss: -249.77
	q1: 247.09, max_q1: 345.42, min_q1: -31.86
	batch_reward: 2.85, batch_reward_max: 5.59, batch_reward_min: -3.66

2023-04-03 12:22:41 - 
[#Step 770000] eval_reward: 3896.84, eval_step: 1000, eval_time: 2, time: 13.36
	critic_loss: 55.42, actor_loss: -240.48
	q1: 237.74, max_q1: 345.59, min_q1: -52.23
	batch_reward: 2.81, batch_reward_max: 5.44, batch_reward_min: -0.91

2023-04-03 12:22:53 - 
[#Step 780000] eval_reward: 3937.25, eval_step: 1000, eval_time: 2, time: 13.55
	critic_loss: 54.54, actor_loss: -252.14
	q1: 248.40, max_q1: 354.97, min_q1: -63.87
	batch_reward: 2.81, batch_reward_max: 6.28, batch_reward_min: -1.33

2023-04-03 12:23:04 - 
[#Step 790000] eval_reward: 3612.26, eval_step: 920, eval_time: 2, time: 13.74
	critic_loss: 27.10, actor_loss: -252.67
	q1: 250.25, max_q1: 345.56, min_q1: 2.91
	batch_reward: 2.87, batch_reward_max: 5.70, batch_reward_min: -1.76

2023-04-03 12:23:16 - 
[#Step 800000] eval_reward: 3976.91, eval_step: 1000, eval_time: 2, time: 13.93
	critic_loss: 66.32, actor_loss: -255.54
	q1: 252.51, max_q1: 346.45, min_q1: -0.22
	batch_reward: 2.93, batch_reward_max: 7.06, batch_reward_min: -0.98

2023-04-03 12:23:16 - Saving checkpoint at step: 4
2023-04-03 12:23:16 - Saved checkpoint at saved_models/td3/Walker2d-v3/s1_20230403_120920/actor_4
2023-04-03 12:23:16 - Saving checkpoint at step: 4
2023-04-03 12:23:16 - Saved checkpoint at saved_models/td3/Walker2d-v3/s1_20230403_120920/critic_4
2023-04-03 12:23:27 - 
[#Step 810000] eval_reward: 3947.84, eval_step: 1000, eval_time: 2, time: 14.12
	critic_loss: 42.93, actor_loss: -251.64
	q1: 249.06, max_q1: 343.72, min_q1: -19.77
	batch_reward: 2.89, batch_reward_max: 5.65, batch_reward_min: -0.83

2023-04-03 12:23:39 - 
[#Step 820000] eval_reward: 4005.13, eval_step: 1000, eval_time: 2, time: 14.32
	critic_loss: 34.79, actor_loss: -243.74
	q1: 240.30, max_q1: 347.89, min_q1: -84.71
	batch_reward: 2.85, batch_reward_max: 5.33, batch_reward_min: -1.70

2023-04-03 12:23:50 - 
[#Step 830000] eval_reward: 3511.13, eval_step: 912, eval_time: 2, time: 14.50
	critic_loss: 50.19, actor_loss: -251.93
	q1: 248.94, max_q1: 364.14, min_q1: -1.15
	batch_reward: 2.95, batch_reward_max: 6.41, batch_reward_min: -0.65

2023-04-03 12:24:02 - 
[#Step 840000] eval_reward: 3951.79, eval_step: 1000, eval_time: 3, time: 14.70
	critic_loss: 45.94, actor_loss: -250.54
	q1: 247.13, max_q1: 355.35, min_q1: -54.32
	batch_reward: 2.73, batch_reward_max: 6.46, batch_reward_min: -1.36

2023-04-03 12:24:14 - 
[#Step 850000] eval_reward: 3931.66, eval_step: 1000, eval_time: 2, time: 14.90
	critic_loss: 64.41, actor_loss: -254.44
	q1: 250.92, max_q1: 352.40, min_q1: -9.70
	batch_reward: 2.81, batch_reward_max: 6.39, batch_reward_min: -1.31

2023-04-03 12:24:26 - 
[#Step 860000] eval_reward: 3917.93, eval_step: 1000, eval_time: 3, time: 15.10
	critic_loss: 52.63, actor_loss: -263.38
	q1: 260.61, max_q1: 355.93, min_q1: 2.34
	batch_reward: 2.92, batch_reward_max: 5.80, batch_reward_min: -1.19

2023-04-03 12:24:38 - 
[#Step 870000] eval_reward: 3918.09, eval_step: 1000, eval_time: 3, time: 15.30
	critic_loss: 52.84, actor_loss: -253.30
	q1: 250.07, max_q1: 360.68, min_q1: -13.83
	batch_reward: 2.82, batch_reward_max: 5.50, batch_reward_min: -1.06

2023-04-03 12:24:50 - 
[#Step 880000] eval_reward: 3908.15, eval_step: 1000, eval_time: 3, time: 15.50
	critic_loss: 40.84, actor_loss: -261.89
	q1: 259.45, max_q1: 366.25, min_q1: 4.57
	batch_reward: 2.86, batch_reward_max: 5.10, batch_reward_min: -0.61

2023-04-03 12:25:02 - 
[#Step 890000] eval_reward: 3974.96, eval_step: 1000, eval_time: 2, time: 15.70
	critic_loss: 63.59, actor_loss: -260.58
	q1: 257.55, max_q1: 359.83, min_q1: -39.78
	batch_reward: 3.00, batch_reward_max: 5.90, batch_reward_min: -0.91

2023-04-03 12:25:13 - 
[#Step 900000] eval_reward: 3983.22, eval_step: 1000, eval_time: 2, time: 15.89
	critic_loss: 45.71, actor_loss: -257.28
	q1: 254.62, max_q1: 361.10, min_q1: 0.36
	batch_reward: 2.79, batch_reward_max: 5.15, batch_reward_min: -0.84

2023-04-03 12:25:25 - 
[#Step 910000] eval_reward: 3985.59, eval_step: 1000, eval_time: 2, time: 16.09
	critic_loss: 47.54, actor_loss: -272.37
	q1: 269.93, max_q1: 362.59, min_q1: -24.88
	batch_reward: 2.95, batch_reward_max: 6.07, batch_reward_min: -1.89

2023-04-03 12:25:36 - 
[#Step 920000] eval_reward: 3967.29, eval_step: 1000, eval_time: 2, time: 16.28
	critic_loss: 46.74, actor_loss: -271.21
	q1: 267.75, max_q1: 362.93, min_q1: -32.68
	batch_reward: 2.96, batch_reward_max: 5.86, batch_reward_min: -1.31

2023-04-03 12:25:48 - 
[#Step 930000] eval_reward: 3583.51, eval_step: 908, eval_time: 2, time: 16.47
	critic_loss: 50.63, actor_loss: -266.89
	q1: 264.43, max_q1: 360.59, min_q1: -9.69
	batch_reward: 3.06, batch_reward_max: 5.54, batch_reward_min: -0.51

2023-04-03 12:25:59 - 
[#Step 940000] eval_reward: 3610.90, eval_step: 906, eval_time: 2, time: 16.66
	critic_loss: 43.99, actor_loss: -265.91
	q1: 263.07, max_q1: 368.34, min_q1: -58.63
	batch_reward: 2.92, batch_reward_max: 5.43, batch_reward_min: -1.94

2023-04-03 12:26:11 - 
[#Step 950000] eval_reward: 4005.54, eval_step: 1000, eval_time: 2, time: 16.86
	critic_loss: 34.01, actor_loss: -266.08
	q1: 263.79, max_q1: 366.20, min_q1: 6.47
	batch_reward: 2.85, batch_reward_max: 5.26, batch_reward_min: -1.04

2023-04-03 12:26:18 - 
[#Step 955000] eval_reward: 3938.12, eval_step: 1000, eval_time: 2, time: 16.97
	critic_loss: 45.63, actor_loss: -275.01
	q1: 271.30, max_q1: 360.06, min_q1: 0.55
	batch_reward: 2.90, batch_reward_max: 6.05, batch_reward_min: -0.98

2023-04-03 12:26:25 - 
[#Step 960000] eval_reward: 4048.89, eval_step: 1000, eval_time: 2, time: 17.09
	critic_loss: 49.70, actor_loss: -263.30
	q1: 259.48, max_q1: 364.33, min_q1: -38.45
	batch_reward: 2.96, batch_reward_max: 6.04, batch_reward_min: -0.48

2023-04-03 12:26:32 - 
[#Step 965000] eval_reward: 3942.12, eval_step: 1000, eval_time: 2, time: 17.20
	critic_loss: 33.29, actor_loss: -278.27
	q1: 276.17, max_q1: 372.17, min_q1: -26.41
	batch_reward: 3.01, batch_reward_max: 5.31, batch_reward_min: -0.90

2023-04-03 12:26:39 - 
[#Step 970000] eval_reward: 3802.13, eval_step: 962, eval_time: 2, time: 17.32
	critic_loss: 30.13, actor_loss: -271.96
	q1: 269.48, max_q1: 361.07, min_q1: -14.54
	batch_reward: 3.14, batch_reward_max: 6.67, batch_reward_min: -0.83

2023-04-03 12:26:46 - 
[#Step 975000] eval_reward: 4001.72, eval_step: 1000, eval_time: 2, time: 17.44
	critic_loss: 47.88, actor_loss: -274.83
	q1: 271.34, max_q1: 367.07, min_q1: 3.24
	batch_reward: 3.09, batch_reward_max: 5.33, batch_reward_min: -1.32

2023-04-03 12:26:53 - 
[#Step 980000] eval_reward: 4055.05, eval_step: 1000, eval_time: 2, time: 17.55
	critic_loss: 58.09, actor_loss: -272.97
	q1: 270.50, max_q1: 369.33, min_q1: -31.59
	batch_reward: 2.99, batch_reward_max: 5.48, batch_reward_min: -1.76

2023-04-03 12:27:00 - 
[#Step 985000] eval_reward: 3991.08, eval_step: 1000, eval_time: 2, time: 17.67
	critic_loss: 25.88, actor_loss: -280.17
	q1: 278.14, max_q1: 364.05, min_q1: -8.41
	batch_reward: 3.17, batch_reward_max: 5.68, batch_reward_min: -0.44

2023-04-03 12:27:07 - 
[#Step 990000] eval_reward: 3978.67, eval_step: 1000, eval_time: 2, time: 17.79
	critic_loss: 46.16, actor_loss: -280.60
	q1: 277.90, max_q1: 365.83, min_q1: -26.80
	batch_reward: 3.09, batch_reward_max: 5.31, batch_reward_min: -1.13

2023-04-03 12:27:14 - 
[#Step 995000] eval_reward: 3970.29, eval_step: 1000, eval_time: 2, time: 17.91
	critic_loss: 43.32, actor_loss: -278.63
	q1: 276.24, max_q1: 371.22, min_q1: -21.69
	batch_reward: 3.12, batch_reward_max: 5.78, batch_reward_min: -0.84

2023-04-03 12:27:21 - 
[#Step 1000000] eval_reward: 3548.02, eval_step: 907, eval_time: 2, time: 18.02
	critic_loss: 50.94, actor_loss: -272.43
	q1: 269.69, max_q1: 368.78, min_q1: -15.39
	batch_reward: 3.09, batch_reward_max: 7.18, batch_reward_min: -0.65

2023-04-03 12:27:21 - Saving checkpoint at step: 5
2023-04-03 12:27:21 - Saved checkpoint at saved_models/td3/Walker2d-v3/s1_20230403_120920/actor_5
2023-04-03 12:27:21 - Saving checkpoint at step: 5
2023-04-03 12:27:21 - Saved checkpoint at saved_models/td3/Walker2d-v3/s1_20230403_120920/critic_5
